{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec1b8edf-14ee-43b3-937a-2cb398680030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc61caf-8474-4793-8546-6436906c7f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5484536c-ea79-4797-988a-c6352d860cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "def calculate_f1_score(actual_keyphrases, predicted_keyphrases):\n",
    "    actual_set = set([s.lower() for s in actual_keyphrases])\n",
    "    predicted_set = set(s.lower() for s in predicted_keyphrases)\n",
    "\n",
    "    true_positives = len(actual_set.intersection(predicted_set))\n",
    "    precision = true_positives / len(predicted_set) if predicted_set else 0\n",
    "    recall = true_positives / len(actual_set) if actual_set else 0\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        f1_score = 0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    # print(f\"Precision: {precision} \\t Reacll: {recall} \\t F1 Score: {f1_score}\")\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "\n",
    "actual_keyphrases = ['keyphrase one', 'keyphrase two', 'keyphrase three']\n",
    "predicted_keyphrases = ['keyphrase one', 'keyphrase four', 'keyphrase two']\n",
    "p,r,f1_score = calculate_f1_score(actual_keyphrases, predicted_keyphrases)\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "736cb321-63f7-45dd-b6c4-6816deeca491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6666666666666666 \t Reacll: 0.8 \t F1 Score for partial match: 0.7272727272727272\n"
     ]
    }
   ],
   "source": [
    "def convert_to_unigrams(keyphrases):\n",
    "    \"\"\"Convert a list of keyphrases to a set of unigrams.\"\"\"\n",
    "    return set(unigram for keyphrase in keyphrases for unigram in keyphrase.split())\n",
    "\n",
    "def partial_f1_score(gold_keyphrases, extracted_keyphrases):\n",
    "    \"\"\"Calculate the F1 score for partial matches between two lists of keyphrases.\"\"\"\n",
    "    gold_unigrams = convert_to_unigrams(gold_keyphrases)\n",
    "    extracted_unigrams = convert_to_unigrams(extracted_keyphrases)\n",
    "\n",
    "    true_positives = len(gold_unigrams.intersection(extracted_unigrams))\n",
    "    false_positives = len(extracted_unigrams - gold_unigrams)\n",
    "    false_negatives = len(gold_unigrams - extracted_unigrams)\n",
    "\n",
    "    if true_positives == 0:\n",
    "        return 0,0,0  # Return 0 to avoid division by zero if there are no true positives\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Example usage\n",
    "gold_keyphrases = ['machine learning', 'deep learning', 'neural networks']\n",
    "extracted_keyphrases = ['learning in machines', 'networks', 'deep neural learning']\n",
    "\n",
    "precision,recall,f1_score = partial_f1_score(gold_keyphrases, extracted_keyphrases)\n",
    "# print(f\"F1 Score for partial match: {f1_score}\")\n",
    "print(f\"Precision: {precision} \\t Reacll: {recall} \\t F1 Score for partial match: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cbae31-b925-46ba-b113-6f64deb73d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e4377dc-c6d2-4a59-8f19-6f8f99c58e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishanthkrishna/miniforge3/envs/nlp/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for taln-ls2n/inspec contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/taln-ls2n/inspec\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"taln-ls2n/inspec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56de4b50-8f03-4df4-8cfa-cf98539ce293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37606915-3fb0-4bcf-942c-a5ae6206fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(dataset['test'])\n",
    "validation_df = pd.DataFrame(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "726a6fbe-9377-47aa-bf2d-2312c3192c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(my_list):\n",
    "    return [i.lower() for i in my_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa5a3b84-dd8f-4a68-91b1-e5476ab446c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abstract'] = df['abstract'].apply(lambda x: x.lower())\n",
    "df['keyphrases'] = df['keyphrases'].apply(lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eb1765e-4c82-46a3-b81a-a291dd79d7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keyphrases</th>\n",
       "      <th>prmu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>761</td>\n",
       "      <td>Towards a NMR implementation of a quantum latt...</td>\n",
       "      <td>recent theoretical results suggest that an arr...</td>\n",
       "      <td>[nmr implementation, quantum lattice gas algor...</td>\n",
       "      <td>[P, P, P, P, P, P, P, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>724</td>\n",
       "      <td>Banking on SMA funds [separately managed accou...</td>\n",
       "      <td>from investment management to technology to ba...</td>\n",
       "      <td>[separately managed accounts, investment manag...</td>\n",
       "      <td>[P, P, P, P, P, P]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1371</td>\n",
       "      <td>Design methodology for diagnostic strategies f...</td>\n",
       "      <td>this paper presents a method for the construct...</td>\n",
       "      <td>[design methodology, diagnostic strategies, in...</td>\n",
       "      <td>[P, P, P, P, P]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1334</td>\n",
       "      <td>A shy invariant of graphs</td>\n",
       "      <td>moving from a well known result of p.l. hammer...</td>\n",
       "      <td>[graph invariant, induced odd cycles, minimum ...</td>\n",
       "      <td>[P, P, P, P, P, P]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1419</td>\n",
       "      <td>PacketVideo. One step ahead of the streaming w...</td>\n",
       "      <td>go beyond the hype, however, and it's clear th...</td>\n",
       "      <td>[packetvideo, wireless devices, mpeg-4, wirele...</td>\n",
       "      <td>[P, P, P, P, P, P, P, R]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1124</td>\n",
       "      <td>Data extraction from the Web based on pre-defi...</td>\n",
       "      <td>with the development of the internet, the worl...</td>\n",
       "      <td>[data extraction, schema, internet, informatio...</td>\n",
       "      <td>[P, P, P, P, P, R, M, U, U]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>118</td>\n",
       "      <td>Sensorless control of induction motor drives</td>\n",
       "      <td>controlled induction motor drives without mech...</td>\n",
       "      <td>[sensorless control, induction motor drives, r...</td>\n",
       "      <td>[P, P, P, P, P, P, P, P, P, P, P, P, P, P, P, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>635</td>\n",
       "      <td>Detection and estimation of abrupt changes in ...</td>\n",
       "      <td>detection of change-points in normal means is ...</td>\n",
       "      <td>[generalized likelihood ratio test statistic, ...</td>\n",
       "      <td>[P, P, P, P, P, P, P, P, P, P, P, P, P, P, P, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1260</td>\n",
       "      <td>A dataflow computer which accelerates executio...</td>\n",
       "      <td>in the dataflow machine, it is important to av...</td>\n",
       "      <td>[dataflow computer, sequential programs, prece...</td>\n",
       "      <td>[P, P, P, P, P, P, P, P, P, R, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1225</td>\n",
       "      <td>BT voices its support for IP</td>\n",
       "      <td>btexact's chief technology officer, mick reeve...</td>\n",
       "      <td>[btexact, voice over dsl, virtual private netw...</td>\n",
       "      <td>[P, P, P, P]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0     761  Towards a NMR implementation of a quantum latt...   \n",
       "1     724  Banking on SMA funds [separately managed accou...   \n",
       "2    1371  Design methodology for diagnostic strategies f...   \n",
       "3    1334                          A shy invariant of graphs   \n",
       "4    1419  PacketVideo. One step ahead of the streaming w...   \n",
       "..    ...                                                ...   \n",
       "995  1124  Data extraction from the Web based on pre-defi...   \n",
       "996   118       Sensorless control of induction motor drives   \n",
       "997   635  Detection and estimation of abrupt changes in ...   \n",
       "998  1260  A dataflow computer which accelerates executio...   \n",
       "999  1225                       BT voices its support for IP   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    recent theoretical results suggest that an arr...   \n",
       "1    from investment management to technology to ba...   \n",
       "2    this paper presents a method for the construct...   \n",
       "3    moving from a well known result of p.l. hammer...   \n",
       "4    go beyond the hype, however, and it's clear th...   \n",
       "..                                                 ...   \n",
       "995  with the development of the internet, the worl...   \n",
       "996  controlled induction motor drives without mech...   \n",
       "997  detection of change-points in normal means is ...   \n",
       "998  in the dataflow machine, it is important to av...   \n",
       "999  btexact's chief technology officer, mick reeve...   \n",
       "\n",
       "                                            keyphrases  \\\n",
       "0    [nmr implementation, quantum lattice gas algor...   \n",
       "1    [separately managed accounts, investment manag...   \n",
       "2    [design methodology, diagnostic strategies, in...   \n",
       "3    [graph invariant, induced odd cycles, minimum ...   \n",
       "4    [packetvideo, wireless devices, mpeg-4, wirele...   \n",
       "..                                                 ...   \n",
       "995  [data extraction, schema, internet, informatio...   \n",
       "996  [sensorless control, induction motor drives, r...   \n",
       "997  [generalized likelihood ratio test statistic, ...   \n",
       "998  [dataflow computer, sequential programs, prece...   \n",
       "999  [btexact, voice over dsl, virtual private netw...   \n",
       "\n",
       "                                                  prmu  \n",
       "0                             [P, P, P, P, P, P, P, M]  \n",
       "1                                   [P, P, P, P, P, P]  \n",
       "2                                      [P, P, P, P, P]  \n",
       "3                                   [P, P, P, P, P, P]  \n",
       "4                             [P, P, P, P, P, P, P, R]  \n",
       "..                                                 ...  \n",
       "995                        [P, P, P, P, P, R, M, U, U]  \n",
       "996  [P, P, P, P, P, P, P, P, P, P, P, P, P, P, P, ...  \n",
       "997  [P, P, P, P, P, P, P, P, P, P, P, P, P, P, P, ...  \n",
       "998               [P, P, P, P, P, P, P, P, P, R, M, M]  \n",
       "999                                       [P, P, P, P]  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67ed3d81-9b6e-4d47-bac2-2816700dc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "from transformers import (\n",
    "    Text2TextGenerationPipeline,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "class KeyphraseGenerationPipeline(Text2TextGenerationPipeline):\n",
    "    def __init__(self, model, keyphrase_sep_token=\";\", *args, **kwargs):\n",
    "        super().__init__(\n",
    "            model=AutoModelForSeq2SeqLM.from_pretrained(model),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model),\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.keyphrase_sep_token = keyphrase_sep_token\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        results = super().postprocess(\n",
    "            model_outputs=model_outputs\n",
    "        )\n",
    "        return [[keyphrase.strip() for keyphrase in result.get(\"generated_text\").split(self.keyphrase_sep_token) if keyphrase != \"\"] for result in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "417e7435-8ae4-4a56-86f8-4528c191d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline\n",
    "model_name = \"ml6team/keyphrase-generation-t5-small-inspec\"\n",
    "generator = KeyphraseGenerationPipeline(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63cc10fe-3bd6-4ff6-b339-7e159daa7381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['quantum information processors', 'fluid dynamics problems', 'quantum lattice-gas algorithms']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishanthkrishna/miniforge3/envs/nlp/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text = df['abstract'][0]\n",
    "\n",
    "keyphrases = generator(text)\n",
    "\n",
    "print(keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "531aad2f-e485-45a5-9772-5dc721acb154",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qubit: 0.3605\n",
      "quantum: 0.3381\n",
      "nmr: 0.3305\n",
      "lattice: 0.2493\n",
      "diffusion: 0.2144\n",
      "processors: 0.2031\n",
      "dynamics: 0.2009\n",
      "simulation: 0.187\n",
      "density: 0.1866\n",
      "ensemble: 0.1732\n",
      "gas: 0.1584\n",
      "algorithms: 0.153\n",
      "implementation: 0.1522\n",
      "pulse: 0.1501\n",
      "magnetic: 0.1438\n",
      "architectures: 0.142\n",
      "qlga: 0.1381\n",
      "resonance: 0.1371\n",
      "algorithm: 0.1349\n",
      "steps: 0.1305\n",
      "encode: 0.1301\n",
      "nonlinear: 0.1273\n",
      "through: 0.1246\n",
      "fluid: 0.1196\n",
      "channels: 0.1072\n",
      "via: 0.0968\n",
      "nuclear: 0.0946\n",
      "initial: 0.0865\n",
      "communicating: 0.0802\n",
      "burgers: 0.0801\n",
      "classical: 0.0785\n",
      "information: 0.0746\n",
      "array: 0.0745\n",
      "follow: 0.0654\n",
      "techniques: 0.0615\n",
      "first: 0.061\n",
      "theoretical: 0.058\n",
      "progress: 0.0565\n",
      "qualitatively: 0.0538\n",
      "running: 0.0533\n",
      "been: 0.0529\n",
      "recent: 0.05\n",
      "have: 0.0479\n",
      "observed: 0.0463\n",
      "in: 0.046\n",
      "equations: 0.0453\n",
      "solves: 0.0452\n",
      "an: 0.0447\n",
      "mass: 0.0321\n",
      "then: 0.0262\n",
      "the: 0.0233\n",
      "describe: 0.0229\n",
      "evolved: 0.0168\n",
      "improved: 0.0163\n",
      "two: 0.0163\n",
      "methods: 0.0126\n",
      "suggest: 0.0104\n",
      "shown: 0.0099\n",
      "manipulated: 0.0071\n",
      "experimental: 0.0067\n",
      "on: 0.0052\n",
      "control: 0.0046\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from keybert import KeyBERT\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text\n",
    "# text = \"The quick brown fox jumps over the lazy dog. It barked and played in the garden.\"\n",
    "\n",
    "# Process the text with spaCy for POS tagging\n",
    "doc = nlp(text)\n",
    "\n",
    "# Filter words based on POS tags\n",
    "# categories = ['NOUN', 'PROPN', 'VERB', 'ADJ']\n",
    "# filtered_text = \" \".join([token.text for token in doc if token.pos_ in categories])\n",
    "\n",
    "# Now, use KeyBERT to extract keywords from the filtered text\n",
    "kw_model = KeyBERT()\n",
    "keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 1), stop_words=None, top_n=100)\n",
    "\n",
    "# Print all extracted keywords and their scores\n",
    "all_words = [word for word,_ in keywords if _>0]\n",
    "keywords_score_dict = {}\n",
    "for word, score in keywords:\n",
    "    if score>0:\n",
    "        print(f\"{word}: {score}\")\n",
    "        keywords_score_dict[word]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e2b6833-48ec-4393-88fb-41fa51bfbfc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algorithm',\n",
       " 'algorithms',\n",
       " 'an',\n",
       " 'architectures',\n",
       " 'array',\n",
       " 'been',\n",
       " 'burgers',\n",
       " 'channels',\n",
       " 'classical',\n",
       " 'communicating',\n",
       " 'control',\n",
       " 'density',\n",
       " 'describe',\n",
       " 'diffusion',\n",
       " 'dynamics',\n",
       " 'encode',\n",
       " 'ensemble',\n",
       " 'equations',\n",
       " 'evolved',\n",
       " 'experimental',\n",
       " 'first',\n",
       " 'fluid',\n",
       " 'follow',\n",
       " 'gas',\n",
       " 'have',\n",
       " 'implementation',\n",
       " 'improved',\n",
       " 'in',\n",
       " 'information',\n",
       " 'initial',\n",
       " 'lattice',\n",
       " 'magnetic',\n",
       " 'manipulated',\n",
       " 'mass',\n",
       " 'methods',\n",
       " 'nmr',\n",
       " 'nonlinear',\n",
       " 'nuclear',\n",
       " 'observed',\n",
       " 'on',\n",
       " 'processors',\n",
       " 'progress',\n",
       " 'pulse',\n",
       " 'qlga',\n",
       " 'qualitatively',\n",
       " 'quantum',\n",
       " 'qubit',\n",
       " 'recent',\n",
       " 'resonance',\n",
       " 'running',\n",
       " 'shown',\n",
       " 'simulation',\n",
       " 'solves',\n",
       " 'steps',\n",
       " 'suggest',\n",
       " 'techniques',\n",
       " 'the',\n",
       " 'then',\n",
       " 'theoretical',\n",
       " 'through',\n",
       " 'two',\n",
       " 'via']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "531dcb69-25ee-41ca-8a0e-b1153a316f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nuclear',\n",
       " 'nonlinear',\n",
       " 'quantum',\n",
       " 'resonance',\n",
       " 'diffusion',\n",
       " 'information',\n",
       " 'nmr',\n",
       " 'dynamics',\n",
       " 'algorithm',\n",
       " 'two-qubit',\n",
       " 'processors',\n",
       " 'fluid',\n",
       " 'lattice',\n",
       " 'information.processors',\n",
       " 'magnetic',\n",
       " 'problems',\n",
       " 'burgers',\n",
       " 'equations',\n",
       " 'implementation',\n",
       " 'gas',\n",
       " 'equation']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_values = []\n",
    "for i in df['keyphrases'][0]:\n",
    "    true_values += i.split(\" \")\n",
    "true_values = list(set(true_values))\n",
    "true_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8ffe0ac-2b9f-4020-abb0-5004d26c55b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27419354838709675, 0.8095238095238095, 0.4096385542168674)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_f1_score(true_values, all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bb94994-b804-4c26-8b99-95028164032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequential_tokens(doc, interested_pos, lower):\n",
    "    # to get sequential tokens from the text\n",
    "    sentences = []\n",
    "    for sent in doc.sents:\n",
    "        selected_words = []\n",
    "        for token in sent:\n",
    "            if token.pos_ in interested_pos:\n",
    "                if lower:\n",
    "                    selected_words.append(token.text.lower())\n",
    "                else:\n",
    "                    selected_words.append(token.text)\n",
    "            else:\n",
    "                selected_words.append(\"*\")\n",
    "        sentences.append(selected_words)\n",
    "    return sentences\n",
    "\n",
    "def get_n_grams(sentences):\n",
    "    # to get n_grams outta sequential tokens\n",
    "    n_grams = []\n",
    "    for sent in sentences:\n",
    "        temp_list = []\n",
    "        for word in sent:\n",
    "            if word == '*':\n",
    "                if len(temp_list)!=0:\n",
    "                    n_grams.append(temp_list)\n",
    "                    temp_list = []\n",
    "            else:\n",
    "                temp_list.append(word)\n",
    "    return n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18fcce87-cae1-48da-9bf5-c67c45e3e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_sequence_and_scores(n_grams, unigrams, keywords_score_dict):\n",
    "    longest_sequences = []\n",
    "    \n",
    "    for n_gram in n_grams:\n",
    "        current_sequence = []\n",
    "        longest_sequence = []\n",
    "        \n",
    "        for word in n_gram:\n",
    "            if word in unigrams:\n",
    "                current_sequence.append(word)\n",
    "                if len(current_sequence) > len(longest_sequence):\n",
    "                    longest_sequence = current_sequence.copy()\n",
    "            else:\n",
    "                current_sequence = []\n",
    "        \n",
    "        if len(longest_sequence)>0:\n",
    "            longest_sequences.append(longest_sequence)\n",
    "    \n",
    "    longest_sequences = [' '.join(i) for i in sorted(longest_sequences, key=len, reverse=True)]\n",
    "\n",
    "    final_scores = {}\n",
    "    for seq in longest_sequences:\n",
    "        score = 0\n",
    "        for word in seq.split(\" \"):\n",
    "            score += keywords_score_dict[word]\n",
    "        final_scores[seq] = score\n",
    "    \n",
    "    return longest_sequences, final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32582e6f-ebce-4c7f-9c23-7beefa0d6214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmed(my_list):\n",
    "    lemmed_list = []\n",
    "    for seq in my_list:\n",
    "        lemmed_list.append(' '.join([token.lemma_ for token in nlp(seq)]))\n",
    "    return lemmed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d70fce44-0561-4a6a-893c-065767e52089",
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_pos = ['NOUN', 'PROPN', 'VERB', 'ADJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9f8d409-b885-41b4-af59-a8ede594cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(df['abstract'][0].replace('-',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3ba5037-743c-4e97-aeb3-ea2861581bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recent theoretical results suggest that an array of quantum information processors communicating via classical channels can be used to solve fluid dynamics problems. quantum lattice gas algorithms (qlga) running on such architectures have been shown to solve the diffusion equation and the nonlinear burgers equations. in this report, we describe progress towards an ensemble nuclear magnetic resonance (nmr) implementation of a qlga that solves the diffusion equation. the methods rely on nmr techniques to encode an initial mass density into an ensemble of two qubit quantum information processors. using standard pulse techniques, the mass density can then manipulated and evolved through the steps of the algorithm. we provide the experimental results of our first attempt to realize the nmr implementation. the results qualitatively follow the ideal simulation, but the observed implementation errors highlight the need for improved control"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "164462ff-005b-4712-8d4b-2af5c60f33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = get_sequential_tokens(doc, interested_pos, lower=False)\n",
    "n_grams = get_n_grams(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b13aaed-3388-4f57-879d-d1550edd3d8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['recent', 'theoretical', 'results', 'suggest'],\n",
       " ['array'],\n",
       " ['quantum', 'information', 'processors', 'communicating'],\n",
       " ['classical', 'channels'],\n",
       " ['used'],\n",
       " ['solve', 'fluid', 'dynamics', 'problems'],\n",
       " ['quantum', 'lattice', 'gas', 'algorithms'],\n",
       " ['qlga'],\n",
       " ['running'],\n",
       " ['such', 'architectures'],\n",
       " ['shown'],\n",
       " ['solve'],\n",
       " ['diffusion', 'equation'],\n",
       " ['nonlinear', 'burgers', 'equations'],\n",
       " ['report'],\n",
       " ['describe', 'progress'],\n",
       " ['ensemble', 'nuclear', 'magnetic', 'resonance'],\n",
       " ['nmr'],\n",
       " ['implementation'],\n",
       " ['qlga'],\n",
       " ['solves'],\n",
       " ['diffusion', 'equation'],\n",
       " ['methods', 'rely'],\n",
       " ['nmr', 'techniques'],\n",
       " ['encode'],\n",
       " ['initial', 'mass', 'density'],\n",
       " ['ensemble'],\n",
       " ['qubit', 'quantum', 'information', 'processors'],\n",
       " ['using', 'standard', 'pulse', 'techniques'],\n",
       " ['mass', 'density'],\n",
       " ['manipulated'],\n",
       " ['evolved'],\n",
       " ['steps'],\n",
       " ['algorithm'],\n",
       " ['provide'],\n",
       " ['experimental', 'results'],\n",
       " ['first', 'attempt'],\n",
       " ['realize'],\n",
       " ['nmr', 'implementation'],\n",
       " ['results'],\n",
       " ['follow'],\n",
       " ['ideal', 'simulation'],\n",
       " ['observed', 'implementation', 'errors', 'highlight'],\n",
       " ['need']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4779054-8fd3-4b49-9cf5-d8cceaeac2fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algorithm',\n",
       " 'algorithms',\n",
       " 'an',\n",
       " 'architectures',\n",
       " 'array',\n",
       " 'been',\n",
       " 'burgers',\n",
       " 'channels',\n",
       " 'classical',\n",
       " 'communicating',\n",
       " 'control',\n",
       " 'density',\n",
       " 'describe',\n",
       " 'diffusion',\n",
       " 'dynamics',\n",
       " 'encode',\n",
       " 'ensemble',\n",
       " 'equations',\n",
       " 'evolved',\n",
       " 'experimental',\n",
       " 'first',\n",
       " 'fluid',\n",
       " 'follow',\n",
       " 'gas',\n",
       " 'have',\n",
       " 'implementation',\n",
       " 'improved',\n",
       " 'in',\n",
       " 'information',\n",
       " 'initial',\n",
       " 'lattice',\n",
       " 'magnetic',\n",
       " 'manipulated',\n",
       " 'mass',\n",
       " 'methods',\n",
       " 'nmr',\n",
       " 'nonlinear',\n",
       " 'nuclear',\n",
       " 'observed',\n",
       " 'on',\n",
       " 'processors',\n",
       " 'progress',\n",
       " 'pulse',\n",
       " 'qlga',\n",
       " 'qualitatively',\n",
       " 'quantum',\n",
       " 'qubit',\n",
       " 'recent',\n",
       " 'resonance',\n",
       " 'running',\n",
       " 'shown',\n",
       " 'simulation',\n",
       " 'solves',\n",
       " 'steps',\n",
       " 'suggest',\n",
       " 'techniques',\n",
       " 'the',\n",
       " 'then',\n",
       " 'theoretical',\n",
       " 'through',\n",
       " 'two',\n",
       " 'via']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42687953-3ee5-4030-966f-a3dea0748889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quantum information processors communicating',\n",
       " 'quantum lattice gas algorithms',\n",
       " 'ensemble nuclear magnetic resonance',\n",
       " 'qubit quantum information processors',\n",
       " 'nonlinear burgers equations',\n",
       " 'initial mass density',\n",
       " 'recent theoretical',\n",
       " 'classical channels',\n",
       " 'fluid dynamics',\n",
       " 'describe progress',\n",
       " 'nmr techniques',\n",
       " 'pulse techniques',\n",
       " 'mass density',\n",
       " 'nmr implementation',\n",
       " 'observed implementation',\n",
       " 'array',\n",
       " 'qlga',\n",
       " 'running',\n",
       " 'architectures',\n",
       " 'shown',\n",
       " 'diffusion',\n",
       " 'nmr',\n",
       " 'implementation',\n",
       " 'qlga',\n",
       " 'solves',\n",
       " 'diffusion',\n",
       " 'methods',\n",
       " 'encode',\n",
       " 'ensemble',\n",
       " 'manipulated',\n",
       " 'evolved',\n",
       " 'steps',\n",
       " 'algorithm',\n",
       " 'experimental',\n",
       " 'first',\n",
       " 'follow',\n",
       " 'simulation']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, scores = find_longest_sequence_and_scores(n_grams, all_words, keywords_score_dict)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ffe2a45-de55-4078-8ee3-245bcd9a67d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qubit quantum information processors': 0.9763,\n",
       " 'quantum lattice gas algorithms': 0.8988,\n",
       " 'quantum information processors communicating': 0.696,\n",
       " 'ensemble nuclear magnetic resonance': 0.5487,\n",
       " 'nmr implementation': 0.4827,\n",
       " 'nmr techniques': 0.392,\n",
       " 'nmr': 0.3305,\n",
       " 'fluid dynamics': 0.3205,\n",
       " 'initial mass density': 0.30519999999999997,\n",
       " 'nonlinear burgers equations': 0.2527,\n",
       " 'mass density': 0.21869999999999998,\n",
       " 'diffusion': 0.2144,\n",
       " 'pulse techniques': 0.2116,\n",
       " 'observed implementation': 0.1985,\n",
       " 'simulation': 0.187,\n",
       " 'classical channels': 0.1857,\n",
       " 'ensemble': 0.1732,\n",
       " 'implementation': 0.1522,\n",
       " 'architectures': 0.142,\n",
       " 'qlga': 0.1381,\n",
       " 'algorithm': 0.1349,\n",
       " 'steps': 0.1305,\n",
       " 'encode': 0.1301,\n",
       " 'recent theoretical': 0.10800000000000001,\n",
       " 'describe progress': 0.0794,\n",
       " 'array': 0.0745,\n",
       " 'follow': 0.0654,\n",
       " 'first': 0.061,\n",
       " 'running': 0.0533,\n",
       " 'solves': 0.0452,\n",
       " 'evolved': 0.0168,\n",
       " 'methods': 0.0126,\n",
       " 'shown': 0.0099,\n",
       " 'manipulated': 0.0071,\n",
       " 'experimental': 0.0067}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)}\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fb6ffaf-1ed2-4ba3-ae6e-814d5bbe29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res = list(scores.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6669eb9-8421-4ea4-a58d-df0a396defb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qubit quantum information processors',\n",
       " 'quantum lattice gas algorithms',\n",
       " 'quantum information processors communicating',\n",
       " 'ensemble nuclear magnetic resonance',\n",
       " 'nmr implementation',\n",
       " 'nmr techniques',\n",
       " 'nmr',\n",
       " 'fluid dynamics',\n",
       " 'initial mass density',\n",
       " 'nonlinear burgers equations']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a33a9475-bbd4-44e2-bdbe-5795e2de0417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nmr implementation',\n",
       " 'quantum lattice gas algorithm',\n",
       " 'quantum information processors',\n",
       " 'fluid dynamics problems',\n",
       " 'diffusion equation',\n",
       " 'nonlinear burgers equations',\n",
       " 'nuclear magnetic resonance',\n",
       " 'two-qubit quantum information.processors']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keyphrases'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78d9896a-9f06-43d7-8945-fbec48e200ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3, 0.375, 0.33333333333333326)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_f1_score(lemmed(df['keyphrases'][0]),lemmed(final_res) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2cb7a1d-5efb-4ebf-918d-4f41862c11cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7391304347826086, 0.7727272727272727, 0.7555555555555555)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_f1_score(lemmed(df['keyphrases'][0]),lemmed(final_res) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19e9647a-d0cd-4433-9ec7-0c340d279aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keyphrases</th>\n",
       "      <th>prmu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>761</td>\n",
       "      <td>Towards a NMR implementation of a quantum latt...</td>\n",
       "      <td>recent theoretical results suggest that an arr...</td>\n",
       "      <td>[nmr implementation, quantum lattice gas algor...</td>\n",
       "      <td>[P, P, P, P, P, P, P, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>724</td>\n",
       "      <td>Banking on SMA funds [separately managed accou...</td>\n",
       "      <td>from investment management to technology to ba...</td>\n",
       "      <td>[separately managed accounts, investment manag...</td>\n",
       "      <td>[P, P, P, P, P, P]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1371</td>\n",
       "      <td>Design methodology for diagnostic strategies f...</td>\n",
       "      <td>this paper presents a method for the construct...</td>\n",
       "      <td>[design methodology, diagnostic strategies, in...</td>\n",
       "      <td>[P, P, P, P, P]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1334</td>\n",
       "      <td>A shy invariant of graphs</td>\n",
       "      <td>moving from a well known result of p.l. hammer...</td>\n",
       "      <td>[graph invariant, induced odd cycles, minimum ...</td>\n",
       "      <td>[P, P, P, P, P, P]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1419</td>\n",
       "      <td>PacketVideo. One step ahead of the streaming w...</td>\n",
       "      <td>go beyond the hype, however, and it's clear th...</td>\n",
       "      <td>[packetvideo, wireless devices, mpeg-4, wirele...</td>\n",
       "      <td>[P, P, P, P, P, P, P, R]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1124</td>\n",
       "      <td>Data extraction from the Web based on pre-defi...</td>\n",
       "      <td>with the development of the internet, the worl...</td>\n",
       "      <td>[data extraction, schema, internet, informatio...</td>\n",
       "      <td>[P, P, P, P, P, R, M, U, U]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>118</td>\n",
       "      <td>Sensorless control of induction motor drives</td>\n",
       "      <td>controlled induction motor drives without mech...</td>\n",
       "      <td>[sensorless control, induction motor drives, r...</td>\n",
       "      <td>[P, P, P, P, P, P, P, P, P, P, P, P, P, P, P, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>635</td>\n",
       "      <td>Detection and estimation of abrupt changes in ...</td>\n",
       "      <td>detection of change-points in normal means is ...</td>\n",
       "      <td>[generalized likelihood ratio test statistic, ...</td>\n",
       "      <td>[P, P, P, P, P, P, P, P, P, P, P, P, P, P, P, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1260</td>\n",
       "      <td>A dataflow computer which accelerates executio...</td>\n",
       "      <td>in the dataflow machine, it is important to av...</td>\n",
       "      <td>[dataflow computer, sequential programs, prece...</td>\n",
       "      <td>[P, P, P, P, P, P, P, P, P, R, M, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1225</td>\n",
       "      <td>BT voices its support for IP</td>\n",
       "      <td>btexact's chief technology officer, mick reeve...</td>\n",
       "      <td>[btexact, voice over dsl, virtual private netw...</td>\n",
       "      <td>[P, P, P, P]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0     761  Towards a NMR implementation of a quantum latt...   \n",
       "1     724  Banking on SMA funds [separately managed accou...   \n",
       "2    1371  Design methodology for diagnostic strategies f...   \n",
       "3    1334                          A shy invariant of graphs   \n",
       "4    1419  PacketVideo. One step ahead of the streaming w...   \n",
       "..    ...                                                ...   \n",
       "995  1124  Data extraction from the Web based on pre-defi...   \n",
       "996   118       Sensorless control of induction motor drives   \n",
       "997   635  Detection and estimation of abrupt changes in ...   \n",
       "998  1260  A dataflow computer which accelerates executio...   \n",
       "999  1225                       BT voices its support for IP   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    recent theoretical results suggest that an arr...   \n",
       "1    from investment management to technology to ba...   \n",
       "2    this paper presents a method for the construct...   \n",
       "3    moving from a well known result of p.l. hammer...   \n",
       "4    go beyond the hype, however, and it's clear th...   \n",
       "..                                                 ...   \n",
       "995  with the development of the internet, the worl...   \n",
       "996  controlled induction motor drives without mech...   \n",
       "997  detection of change-points in normal means is ...   \n",
       "998  in the dataflow machine, it is important to av...   \n",
       "999  btexact's chief technology officer, mick reeve...   \n",
       "\n",
       "                                            keyphrases  \\\n",
       "0    [nmr implementation, quantum lattice gas algor...   \n",
       "1    [separately managed accounts, investment manag...   \n",
       "2    [design methodology, diagnostic strategies, in...   \n",
       "3    [graph invariant, induced odd cycles, minimum ...   \n",
       "4    [packetvideo, wireless devices, mpeg-4, wirele...   \n",
       "..                                                 ...   \n",
       "995  [data extraction, schema, internet, informatio...   \n",
       "996  [sensorless control, induction motor drives, r...   \n",
       "997  [generalized likelihood ratio test statistic, ...   \n",
       "998  [dataflow computer, sequential programs, prece...   \n",
       "999  [btexact, voice over dsl, virtual private netw...   \n",
       "\n",
       "                                                  prmu  \n",
       "0                             [P, P, P, P, P, P, P, M]  \n",
       "1                                   [P, P, P, P, P, P]  \n",
       "2                                      [P, P, P, P, P]  \n",
       "3                                   [P, P, P, P, P, P]  \n",
       "4                             [P, P, P, P, P, P, P, R]  \n",
       "..                                                 ...  \n",
       "995                        [P, P, P, P, P, R, M, U, U]  \n",
       "996  [P, P, P, P, P, P, P, P, P, P, P, P, P, P, P, ...  \n",
       "997  [P, P, P, P, P, P, P, P, P, P, P, P, P, P, P, ...  \n",
       "998               [P, P, P, P, P, P, P, P, P, R, M, M]  \n",
       "999                                       [P, P, P, P]  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a20b8d98-0d4b-4ee5-a845-bd37d33a8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(text, number=20):\n",
    "    def get_sequential_tokens(doc, interested_pos, lower):\n",
    "        # to get sequential tokens from the text\n",
    "        sentences = []\n",
    "        for sent in doc.sents:\n",
    "            selected_words = []\n",
    "            for token in sent:\n",
    "                if token.pos_ in interested_pos:\n",
    "                    if lower:\n",
    "                        selected_words.append(token.text.lower())\n",
    "                    else:\n",
    "                        selected_words.append(token.text)\n",
    "                else:\n",
    "                    selected_words.append(\"*\")\n",
    "            sentences.append(selected_words)\n",
    "        return sentences\n",
    "    \n",
    "    def get_n_grams(sentences):\n",
    "        # to get n_grams outta sequential tokens\n",
    "        n_grams = []\n",
    "        for sent in sentences:\n",
    "            temp_list = []\n",
    "            for word in sent:\n",
    "                if word == '*':\n",
    "                    if len(temp_list)!=0:\n",
    "                        n_grams.append(temp_list)\n",
    "                        temp_list = []\n",
    "                else:\n",
    "                    temp_list.append(word)\n",
    "        return n_grams\n",
    "        \n",
    "    def find_longest_sequence_and_scores(n_grams, unigrams, keywords_score_dict):\n",
    "        longest_sequences = []\n",
    "        \n",
    "        for n_gram in n_grams:\n",
    "            current_sequence = []\n",
    "            longest_sequence = []\n",
    "            \n",
    "            for word in n_gram:\n",
    "                if word in unigrams:\n",
    "                    current_sequence.append(word)\n",
    "                    if len(current_sequence) > len(longest_sequence):\n",
    "                        longest_sequence = current_sequence.copy()\n",
    "                else:\n",
    "                    current_sequence = []\n",
    "            \n",
    "            if len(longest_sequence)>0:\n",
    "                longest_sequences.append(longest_sequence)\n",
    "        \n",
    "        longest_sequences = [' '.join(i) for i in sorted(longest_sequences, key=len, reverse=True)]\n",
    "    \n",
    "        final_scores = {}\n",
    "        for seq in longest_sequences:\n",
    "            score = 0\n",
    "            for word in seq.split(\" \"):\n",
    "                score += keywords_score_dict[word]\n",
    "            final_scores[seq] = score\n",
    "        \n",
    "        return longest_sequences, final_scores\n",
    "    \n",
    "    def lemmed(my_list):\n",
    "        lemmed_list = []\n",
    "        for seq in my_list:\n",
    "            lemmed_list.append(' '.join([token.lemma_ for token in nlp(seq)]))\n",
    "        return lemmed_list\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    spacy_text = nlp(text)\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in spacy_text])\n",
    "    doc = nlp(spacy_text)\n",
    "    \n",
    "    kw_model = KeyBERT()\n",
    "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 1), stop_words=None, top_n=100)\n",
    "    \n",
    "    all_words = [word for word,_ in keywords if _>0]\n",
    "    keywords_score_dict = {}\n",
    "    for word, score in keywords:\n",
    "        if score>0:\n",
    "            # print(f\"{word}: {score}\")\n",
    "            keywords_score_dict[word]=score\n",
    "    \n",
    "    interested_pos = ['NOUN', 'PROPN', 'VERB', 'ADJ']\n",
    "    sents = get_sequential_tokens(doc, interested_pos, lower=False)\n",
    "    n_grams = get_n_grams(sents)\n",
    "\n",
    "    res, scores = find_longest_sequence_and_scores(n_grams, all_words, keywords_score_dict)\n",
    "    scores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    final_res = list(scores.keys())[:number]\n",
    "\n",
    "    return lemmed(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c012a4a2-bf17-4029-8123-30c0f1005a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from tqdm.auto import tqdm\n",
    "# tqdm.pandas()\n",
    "\n",
    "# # Assuming 'lemmed' and 'extract' are your functions for lemmatization and keyphrase extraction.\n",
    "# # And assuming 'df' is your DataFrame with columns 'keyphrases' and 'abstract'.\n",
    "\n",
    "# # Apply the 'lemmed' function to the 'keyphrases' column with a progress bar\n",
    "# df['true'] = df['keyphrases'].progress_apply(lemmed)\n",
    "\n",
    "# # Apply the 'extract' function to the 'abstract' column with a progress bar\n",
    "# df['preds'] = df['abstract'].progress_apply(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de75ba63-3268-4ff3-a5e9-c9b7e1d77ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"t5_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c8d7425-e612-47f3-958d-5765d27c2f75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m partial_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y,y_hat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(true_values, pred):\n\u001b[0;32m----> 9\u001b[0m     total_f1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m calculate_f1_score(y,y_hat)\n\u001b[1;32m     10\u001b[0m     partial_f1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m partial_f1_score(y,y_hat)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExact F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_f1\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'int' and 'tuple'"
     ]
    }
   ],
   "source": [
    "pred = list(df['preds'])\n",
    "true_values = list(df['true'])\n",
    "\n",
    "p = 0\n",
    "r = 0\n",
    "total_f1 = 0\n",
    "partial_f1 = 0\n",
    "for y,y_hat in zip(true_values, pred):\n",
    "    total_f1 += calculate_f1_score(y,y_hat)\n",
    "    partial_f1 += partial_f1_score(y,y_hat)\n",
    "print(f\"Exact F1: {total_f1/len(pred)}\")\n",
    "print(f\"Partial F1:{partial_f1/len(pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76800bb-cfa1-4375-bc98-38bdc4b35afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d38edd76-9122-4182-b6af-0387686c08db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"t5_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "73be6e6c-0c05-4188-a605-8e63c1ca3a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(df,true,preds,n=10):\n",
    "    pred = list(df[f\"{preds}\"])\n",
    "    true_values = list(df[f\"{true}\"])\n",
    "    \n",
    "    exact_precision = 0\n",
    "    exact_recall = 0\n",
    "    exact_f1 = 0\n",
    "    partial_precision = 0\n",
    "    partial_recall = 0\n",
    "    partial_f1 = 0\n",
    "    i=0\n",
    "    for y,y_hat in zip(true_values, pred):\n",
    "        e_p,e_r,e_f1 = calculate_f1_score(y,y_hat[:n])\n",
    "        exact_f1 += e_f1\n",
    "        exact_precision += e_p\n",
    "        exact_recall += e_r\n",
    "        p_p,p_r,p_f1 = partial_f1_score(y,y_hat[:n])\n",
    "        partial_f1 += p_f1\n",
    "        partial_precision += p_p\n",
    "        partial_recall += p_r\n",
    "    print(\"---\"*40)\n",
    "    print(f\"Precision: {exact_precision/len(pred)} \\t Reacll: {exact_recall/len(pred)} \\t Exact F1: {exact_f1/len(pred)}\")\n",
    "    print(\"---\"*40)\n",
    "    print(f\"Precision: {partial_precision/len(pred)} \\t Reacll: {partial_recall/len(pred)} \\t Partial F1: {partial_f1/len(pred)}\")\n",
    "    print(\"---\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2650e6c-7294-4ad3-82e3-4b0db1f46295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7db17c50-4a17-4c3f-b669-9b398e326170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Exact F1: 0.21165691647273954 \t Precision: 0.3045999999999983 \t Reacll: 0.17768604624800505\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Partial F1: 0.46394135121348384 \t Precision: 0.660525524475525 \t Reacll: 0.3944366412550005\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_scores(df,'true','preds',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e26da08a-6d52-47b0-b29c-6a58d4010d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Exact F1: 0.2614753087425845 \t Precision: 0.26528571428571424 \t Reacll: 0.2865150920654644\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Partial F1: 0.5376599091851008 \t Precision: 0.5924233433273641 \t Reacll: 0.5481750861655554\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_scores(df,'true','preds',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4984f5c0-0256-4f07-aa44-ca8372caad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Exact F1: 0.2430312919754198 \t Precision: 0.19280114803067638 \t Reacll: 0.36796760938086626\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Partial F1: 0.5406408323023981 \t Precision: 0.49088944213127433 \t Reacll: 0.6712053586286151\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_scores(df,'true','preds',20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8e814408-f3f3-4bb2-b899-7fa56df1bcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nmr implementation',\n",
       " 'quantum lattice gas algorithm',\n",
       " 'quantum information processor',\n",
       " 'fluid dynamic problem',\n",
       " 'diffusion equation',\n",
       " 'nonlinear burger equation',\n",
       " 'nuclear magnetic resonance',\n",
       " 'two - qubit quantum information.processor']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['true'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3431c828-9db9-4877-a9b8-24e4fd6ef3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qubit quantum information processor',\n",
       " 'quantum information processor communicate',\n",
       " 'quantum lattice',\n",
       " 'ensemble nuclear magnetic resonance',\n",
       " 'nmr implementation',\n",
       " 'nmr technique',\n",
       " 'nmr',\n",
       " 'fluid dynamic',\n",
       " 'gas algorithm',\n",
       " 'initial mass density']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preds'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "48d69b52-c1f7-429a-a8d8-d8ede954b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.1 \t Reacll: 0.125 \t F1 Score: 0.11111111111111112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11111111111111112"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_f1_score(df['true'][0], df['preds'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "63540d4b-884b-406a-b65f-1f0446d32213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keyphrases</th>\n",
       "      <th>prmu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007</td>\n",
       "      <td>The creation of a high-fidelity finite element...</td>\n",
       "      <td>A detailed finite element model of the human k...</td>\n",
       "      <td>[high-fidelity finite element model, kidney, t...</td>\n",
       "      <td>[P, P, P, P, P, P, P, P, P, P, P, P, P, P, P, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2042</td>\n",
       "      <td>Hybrid simulation of space plasmas: models wit...</td>\n",
       "      <td>For pt.III. see Prikl. Mat. Informatika, MAKS ...</td>\n",
       "      <td>[hybrid simulation, space plasmas, massless fl...</td>\n",
       "      <td>[P, P, P, P, P, P, P, P, P, P, P, P, P]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>308</td>\n",
       "      <td>On-line Homework/Quiz/Exam applet: freely avai...</td>\n",
       "      <td>The Homework/Quiz/Exam applet is a freely avai...</td>\n",
       "      <td>[freely available Java software, database conn...</td>\n",
       "      <td>[P, P, P, P, P, P, P, P, P, M, M, R, R, R, R, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215</td>\n",
       "      <td>A conceptual framework for evaluation of infor...</td>\n",
       "      <td>The decision to acquire a new information tech...</td>\n",
       "      <td>[information technology investments, technolog...</td>\n",
       "      <td>[P, P, P, P, P, P, P, P, P, P, P, P, P, P, P, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>Aim for the enterprise: Microsoft Project 2002</td>\n",
       "      <td>A long-time favorite of project managers, Micr...</td>\n",
       "      <td>[Microsoft Project 2002, Web-based collaborati...</td>\n",
       "      <td>[P, P, P, P, P, P, R]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>341</td>\n",
       "      <td>How should team captains order golfers on the ...</td>\n",
       "      <td>I used game theory to examine how team captain...</td>\n",
       "      <td>[game theory, slate, golf, golfer ordering, Ry...</td>\n",
       "      <td>[P, P, U, R, R]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>219</td>\n",
       "      <td>Firewall card shields data</td>\n",
       "      <td>The SlotShield 3000 firewall on a PCI card sav...</td>\n",
       "      <td>[SlotShield 3000 firewall, PCI card, security,...</td>\n",
       "      <td>[P, P, P, P]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1967</td>\n",
       "      <td>Modeling daily realized futures volatility wit...</td>\n",
       "      <td>Using singular spectrum analysis (SSA), we mod...</td>\n",
       "      <td>[daily realized futures volatility, singular s...</td>\n",
       "      <td>[P, P, P, P, P, P, P, P, P, P, M, U, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2116</td>\n",
       "      <td>Optimization of the characteristics of computa...</td>\n",
       "      <td>The scalableness of resources is taken to mean...</td>\n",
       "      <td>[computational processes, scalable resources, ...</td>\n",
       "      <td>[P, P, P, P, P, P, P, P, P, P, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2153</td>\n",
       "      <td>Post-haste. 100th robotic containerization sys...</td>\n",
       "      <td>Spot welding, machine tending, material handli...</td>\n",
       "      <td>[robotic containerization system, mail sorting...</td>\n",
       "      <td>[P, P, P, P, P, U, R]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0    2007  The creation of a high-fidelity finite element...   \n",
       "1    2042  Hybrid simulation of space plasmas: models wit...   \n",
       "2     308  On-line Homework/Quiz/Exam applet: freely avai...   \n",
       "3     215  A conceptual framework for evaluation of infor...   \n",
       "4     250     Aim for the enterprise: Microsoft Project 2002   \n",
       "..    ...                                                ...   \n",
       "495   341  How should team captains order golfers on the ...   \n",
       "496   219                         Firewall card shields data   \n",
       "497  1967  Modeling daily realized futures volatility wit...   \n",
       "498  2116  Optimization of the characteristics of computa...   \n",
       "499  2153  Post-haste. 100th robotic containerization sys...   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    A detailed finite element model of the human k...   \n",
       "1    For pt.III. see Prikl. Mat. Informatika, MAKS ...   \n",
       "2    The Homework/Quiz/Exam applet is a freely avai...   \n",
       "3    The decision to acquire a new information tech...   \n",
       "4    A long-time favorite of project managers, Micr...   \n",
       "..                                                 ...   \n",
       "495  I used game theory to examine how team captain...   \n",
       "496  The SlotShield 3000 firewall on a PCI card sav...   \n",
       "497  Using singular spectrum analysis (SSA), we mod...   \n",
       "498  The scalableness of resources is taken to mean...   \n",
       "499  Spot welding, machine tending, material handli...   \n",
       "\n",
       "                                            keyphrases  \\\n",
       "0    [high-fidelity finite element model, kidney, t...   \n",
       "1    [hybrid simulation, space plasmas, massless fl...   \n",
       "2    [freely available Java software, database conn...   \n",
       "3    [information technology investments, technolog...   \n",
       "4    [Microsoft Project 2002, Web-based collaborati...   \n",
       "..                                                 ...   \n",
       "495  [game theory, slate, golf, golfer ordering, Ry...   \n",
       "496  [SlotShield 3000 firewall, PCI card, security,...   \n",
       "497  [daily realized futures volatility, singular s...   \n",
       "498  [computational processes, scalable resources, ...   \n",
       "499  [robotic containerization system, mail sorting...   \n",
       "\n",
       "                                                  prmu  \n",
       "0    [P, P, P, P, P, P, P, P, P, P, P, P, P, P, P, ...  \n",
       "1              [P, P, P, P, P, P, P, P, P, P, P, P, P]  \n",
       "2    [P, P, P, P, P, P, P, P, P, M, M, R, R, R, R, ...  \n",
       "3    [P, P, P, P, P, P, P, P, P, P, P, P, P, P, P, ...  \n",
       "4                                [P, P, P, P, P, P, R]  \n",
       "..                                                 ...  \n",
       "495                                    [P, P, U, R, R]  \n",
       "496                                       [P, P, P, P]  \n",
       "497            [P, P, P, P, P, P, P, P, P, P, M, U, M]  \n",
       "498                  [P, P, P, P, P, P, P, P, P, P, M]  \n",
       "499                              [P, P, P, P, P, U, R]  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6380975f-0e60-40a4-b93f-b89531a6bce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354ab60639da49bdaf8d745e293bf5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02046def6f14fa1a8cd1a9c3e4a5821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Assuming 'lemmed' and 'extract' are your functions for lemmatization and keyphrase extraction.\n",
    "# And assuming 'df' is your DataFrame with columns 'keyphrases' and 'abstract'.\n",
    "\n",
    "# Apply the 'lemmed' function to the 'keyphrases' column with a progress bar\n",
    "test_df['true'] = test_df['keyphrases'].progress_apply(lemmed)\n",
    "\n",
    "# Apply the 'extract' function to the 'abstract' column with a progress bar\n",
    "test_df['preds'] = test_df['abstract'].progress_apply(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a2b8f3e1-7784-4a07-bf4f-9966dd5912f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Precision: 0.2915000000000005 \t Reacll: 0.171508232936406 \t Exact F1: 0.2038569082167069\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Precision: 0.6616756127933773 \t Reacll: 0.3735623698033408 \t Partial F1: 0.45356797063765153\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_scores(test_df,'true','preds',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ca19685a-9316-4a1a-ba50-07e84cb435e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Precision: 0.2357793650793651 \t Reacll: 0.2552031711454316 \t Exact F1: 0.23165449803317084\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Precision: 0.5804797613185791 \t Reacll: 0.509689632671014 \t Partial F1: 0.5165817661337387\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_scores(test_df,'true','preds',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8293480e-b836-44d1-9b25-1cdd48823474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Precision: 0.17458552668521732 \t Reacll: 0.3205708465705938 \t Exact F1: 0.2153073611086031\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Precision: 0.485167324044939 \t Reacll: 0.6177772903984373 \t Partial F1: 0.5181069757254992\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_scores(test_df,'true','preds',20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8b330-e096-408d-bf2f-bf56f8b56635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
