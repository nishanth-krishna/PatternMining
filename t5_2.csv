,id,title,abstract,keyphrases,prmu,true,preds
0,761,Towards a NMR implementation of a quantum lattice gas algorithm,"recent theoretical results suggest that an array of quantum information processors communicating via classical channels can be used to solve fluid dynamics problems. quantum lattice-gas algorithms (qlga) running on such architectures have been shown to solve the diffusion equation and the nonlinear burgers equations. in this report, we describe progress towards an ensemble nuclear magnetic resonance (nmr) implementation of a qlga that solves the diffusion equation. the methods rely on nmr techniques to encode an initial mass density into an ensemble of two-qubit quantum information processors. using standard pulse techniques, the mass density can then manipulated and evolved through the steps of the algorithm. we provide the experimental results of our first attempt to realize the nmr implementation. the results qualitatively follow the ideal simulation, but the observed implementation errors highlight the need for improved control","['nmr implementation', 'quantum lattice gas algorithm', 'quantum information processors', 'fluid dynamics problems', 'diffusion equation', 'nonlinear burgers equations', 'nuclear magnetic resonance', 'two-qubit quantum information.processors']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['nmr implementation', 'quantum lattice gas algorithm', 'quantum information processor', 'fluid dynamic problem', 'diffusion equation', 'nonlinear burger equation', 'nuclear magnetic resonance', 'two - qubit quantum information.processor']","['qubit quantum information processor', 'quantum information processor communicate', 'quantum lattice', 'ensemble nuclear magnetic resonance', 'nmr implementation', 'nmr technique', 'nmr', 'fluid dynamic', 'gas algorithm', 'initial mass density']"
1,724,Banking on SMA funds [separately managed accounts],"from investment management to technology to back-office services, outsourcers are elbowing their way into the sma business. small banks are paying attention-and hoping to reap the rewards","['separately managed accounts', 'investment management', 'technology', 'back-office services', 'outsourcers', 'small banks']","['P', 'P', 'P', 'P', 'P', 'P']","['separately manage account', 'investment management', 'technology', 'back - office service', 'outsourcer', 'small bank']","['sma business', 'small bank', 'outsourcer', 'office service', 'investment management', 'pay attention', 'technology', 'reap', 'elbow', 'way']"
2,1371,Design methodology for diagnostic strategies for industrial systems,"this paper presents a method for the construction of diagnostic systems for complex industrial applications. the approach has been explicitely developed to shorten the design cycle and meet some specific requirements, such as modularity, flexibility, and the possibility of merging many different sources of information. the method allows one to consider multiple simultaneous failures and is specifically designed to make easier the coordination and simplification of local diagnostic algorithms developed by different teams","['design methodology', 'diagnostic strategies', 'industrial systems', 'modularity', 'local diagnostic algorithms']","['P', 'P', 'P', 'P', 'P']","['design methodology', 'diagnostic strategy', 'industrial system', 'modularity', 'local diagnostic algorithm']","['local diagnostic algorithm develop', 'diagnostic system', 'consider multiple simultaneous failure', 'complex industrial application', 'design cycle', 'merge many', 'modularity', 'coordination', 'construction', 'specific requirement']"
3,1334,A shy invariant of graphs,"moving from a well known result of p.l. hammer et al. (1982), we introduce a new graph invariant, say lambda (g) referring to any graph g. it is a non-negative integer which is non-zero whenever g contains particular induced odd cycles or, equivalently, admits a particular minimum clique-partition. we show that).(g) can be efficiently evaluated and that its determination allows one to reduce the hard problem of computing a minimum clique-cover of a graph to an identical problem of smaller size and special structure. furthermore, one has alpha (g) <or= theta (g) - lambda (g), where alpha (g) and theta (g) respectively denote the cardinality of a maximum stable set of g and of a minimum clique-partition of g","['graph invariant', 'induced odd cycles', 'minimum clique-partition', 'minimum clique-cover', 'cardinality', 'maximum stable set']","['P', 'P', 'P', 'P', 'P', 'P']","['graph invariant', 'induce odd cycle', 'minimum clique - partition', 'minimum clique - cover', 'cardinality', 'maximum stable set']","['particular minimum clique', 'minimum clique', 'new graph invariant', 'contain particular induce odd cycle', 'maximum stable set', 'graph', 'special structure', 'small size', 'cardinality', 'negative integer']"
4,1419,PacketVideo. One step ahead of the streaming wireless market,"go beyond the hype, however, and it's clear that packetvideo is making strides in delivering streaming multimedia content to wireless devices. for one thing, its technology, based on the industry-standard motion pictures expert group 4 (mpeg-4) video encoder/decoder, actually works as promised. secondly, the company has forged a broad-based band of alliances that not only will eventually help it reach potential customers down the road, but provides it financial support until the company can ramp up sales. the list of packetvideo's technology partners who are also investors-and who have pumped more than $121 million into the company-includes not just wireless device manufacturers, but content providers and semiconductor vendors, all of whom stand to benefit by increased sales of handheld wireless terminals","['packetvideo', 'wireless devices', 'mpeg-4', 'wireless device manufacturers', 'content providers', 'semiconductor vendors', 'handheld wireless terminals', 'multimedia content streaming']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['packetvideo', 'wireless device', 'mpeg-4', 'wireless device manufacturer', 'content provider', 'semiconductor vendor', 'handheld wireless terminal', 'multimedia content stream']","['deliver stream multimedia content', 'wireless device manufacturer', 'technology partner', 'standard motion picture expert group', 'packetvideo', 'wireless device', 'content provider', 'video encoder', 'semiconductor vendor', 'financial support']"
5,1070,Universal simulation of Hamiltonian dynamics for quantum systems with finite-dimensional state spaces,"what interactions are sufficient to simulate arbitrary quantum dynamics in a composite quantum system? dodd et al. [phys. rev. a 65, 040301(r) (2002)] provided a partial solution to this problem in the form of an efficient algorithm to simulate any desired two-body hamiltonian evolution using any fixed two-body entangling n-qubit hamiltonian, and local unitaries. we extend this result to the case where the component systems are qudits, that is, have d dimensions. as a consequence we explain how universal quantum computation can be performed with any fixed two-body entangling n-qudit hamiltonian, and local unitaries","['universal simulation', 'hamiltonian dynamics', 'quantum systems', 'quantum dynamics', 'composite quantum system', 'two-body hamiltonian evolution', 'fixed two-body entangling n-qubit hamiltonian', 'local unitaries', 'universal quantum computation', 'fixed two-body entangling n-qudit hamiltonian', 'finite- dimensional state spaces', 'd-dimensional component systems']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M']","['universal simulation', 'hamiltonian dynamic', 'quantum system', 'quantum dynamic', 'composite quantum system', 'two - body hamiltonian evolution', 'fix two - body entangle n - qubit hamiltonian', 'local unitarie', 'universal quantum computation', 'fix two - body entangle n - qudit hamiltonian', 'finite- dimensional state space', 'd - dimensional component system']","['simulate arbitrary quantum dynamic', 'universal quantum computation', 'qubit hamiltonian', 'composite quantum system', 'qudit hamiltonian', 'body hamiltonian evolution', 'body entangle', 'component system', 'qudit', 'simulate']"
6,1035,H/sub 2/ optimization of the three-element type dynamic vibration absorbers,"the dynamic vibration absorber (dva) is a passive vibration control device which is attached to a vibrating body (called a primary system) subjected to exciting force or motion. in this paper, we will discuss an optimization problem of the three-element type dva on the basis of the h/sub 2/ optimization criterion. the objective of the h/sub 2/ optimization is to reduce the total vibration energy of the system for overall frequencies; the total area under the power spectrum response curve is minimized in this criterion. if the system is subjected to random excitation instead of sinusoidal excitation, then the h/sub 2/ optimization is probably more desirable than the popular h/sub infinity / optimization. in the past decade there has been increasing interest in the three-element type dva. however, most previous studies on this type of dva were based on the h/sub infinity / optimization design, and no one has been able to find the algebraic solution as of yet. we found a closed-form exact solution for a special case where the primary system has no damping. furthermore, the general case solution including the damped primary system is presented in the form of a numerical solution. the optimum parameters obtained here are compared to those of the conventional voigt type dva. they are also compared to other optimum parameters based on the h/sub infinity / criterion","['h/sub 2/ optimization', 'three-element type dynamic vibration absorbers', 'passive vibration control', 'power spectrum response', 'voigt type dynamic vibration absorber']","['P', 'P', 'P', 'P', 'R']","['h / sub 2/ optimization', 'three - element type dynamic vibration absorber', 'passive vibration control', 'power spectrum response', 'voigt type dynamic vibration absorber']","['dynamic vibration absorber', 'total vibration energy', 'passive vibration control', 'optimization design', 'optimum parameter obtain', 'optimization criterion', 'vibrate body', 'optimum parameter', 'damp', 'optimization problem']"
7,1128,The semi-algebraic theory of stochastic games,"the asymptotic behavior of the min-max value of a finite-state zero-sum discounted stochastic game, as the discount rate approaches 0, has been studied in the past using the theory of real-closed fields. we use the theory of semi-algebraic sets and mappings to prove some asymptotic properties of the min-max value, which hold uniformly for all stochastic games in which the number of states and players' actions are predetermined to some fixed values. as a corollary, we prove a uniform polynomial convergence rate of the value of the n-stage game to the value of the nondiscount game, over a bounded set of payoffs","['asymptotic behavior', 'min-max value', 'finite-state zero-sum discounted stochastic game', 'discount rate', 'uniform polynomial convergence rate', 'n-stage game', 'semi-algebraic set theory', 'two-player zero-sum finite-state stochastic games']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['asymptotic behavior', 'min - max value', 'finite - state zero - sum discount stochastic game', 'discount rate', 'uniform polynomial convergence rate', 'n - stage game', 'semi - algebraic set theory', 'two - player zero - sum finite - state stochastic game']","['sum discount stochastic game', 'discount rate approach', 'stochastic game', 'uniform polynomial convergence rate', 'nondiscount game', 'algebraic set', 'asymptotic property', 'max value', 'asymptotic behavior', 'close field']"
8,538,Polarization of the RF field in a human head at high field: a study with a quadrature surface coil at 7.0 T,"the rf field intensity distribution in the human brain becomes inhomogeneous due to wave behavior at high field. this is further complicated by the spatial distribution of rf field polarization that must be considered to predict image intensity distribution. an additional layer of complexity is involved when a quadrature coil is used for transmission and reception. to study such complicated rf field behavior, a computer modeling method was employed to investigate the rf field of a quadrature surface coil at 300 mhz. theoretical and experimental results for a phantom and the human head at 7.0 t are presented. the results are theoretically important and practically useful for high-field quadrature coil design and application","['quadrature surface coil', '7.0 t', 'rf field intensity distribution', 'human brain', 'spatial distribution', 'rf field polarization', 'image intensity distribution', 'computer modeling', '300 mhz', 'high field mri', 'high-field coil design', 'whole-body mri', 'phantom samples', 'segmented images', '3d multitissue head model', 'gradient echo images', 'finite difference time domain method', 'maxwell wave equations', 'reception fields', 'transmission fields']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'U', 'M', 'M', 'M', 'M', 'M', 'M', 'R', 'R']","['quadrature surface coil', '7.0 t', 'rf field intensity distribution', 'human brain', 'spatial distribution', 'rf field polarization', 'image intensity distribution', 'computer modeling', '300 mhz', 'high field mri', 'high - field coil design', 'whole - body mri', 'phantom sample', 'segment image', '3d multitissue head model', 'gradient echo image', 'finite difference time domain method', 'maxwell wave equation', 'reception field', 'transmission field']","['rf field intensity distribution', 'field quadrature coil design', 'rf field polarization', 'quadrature surface coil', 'complicate rf field', 'quadrature coil', 'rf field', 'image intensity distribution', 'mhz', 'high field']"
9,681,Construction of information retrieval thesaurus for family planning terms using CDS/ISIS,"the thesaurus as a tool for information retrieval and as an alternative to the existing scheme of classifications in information retrieval is discussed. the paper considers the emergence of the information retrieval thesaurus and its definition. family planning is a multidisciplinary subject covering socio economic, cultural, psychological and medical fields. this necessitated the construction of a thesaurus for the family planning discipline. the construction is based on unisist, iso 2788 and bs 5723 guidelines by using cds/isis software","['information retrieval', 'thesaurus', 'family planning terms', 'family planning', 'classification', 'culture', 'psychology', 'unisist', 'iso 2788', 'bs 5723', 'cds/isis software', 'bibliographic databases', 'socio economic field', 'medicine']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'R', 'U']","['information retrieval', 'thesaurus', 'family planning term', 'family planning', 'classification', 'culture', 'psychology', 'unisist', 'iso 2788', 'bs 5723', 'cd / isis software', 'bibliographic database', 'socio economic field', 'medicine']","['information retrieval thesaurus', 'multidisciplinary subject cover socio economic', 'family planning discipline', 'thesaurus', 'information retrieval', 'family planning', 'use cd', 'classification', 'medical field', 'paper consider']"
10,1291,Taking back control [SCADA system],"most common way to implement a scada system is to go outside. however, in the author's opinion, to truly take control of a scada project, in-house personnel should handle as much of the job as possible. this includes design, equipment specification, installation, and programming. the more of these tasks one does in-house, the more control and ownership one has. to accomplish this, we first evaluated the existing scada system and investigated new technologies to establish a list of features the new system needed to incorporate","['scada', 'supervisory control', 'data acquisition', 'in-house integration', 'compatibility', 'programmable logic controllers']","['P', 'M', 'U', 'M', 'U', 'M']","['scada', 'supervisory control', 'datum acquisition', 'in - house integration', 'compatibility', 'programmable logic controller']","['exist scada system', 'scada system', 'scada project', 'equipment specification', 'house personnel', 'new system need', 'take control', 'investigate new technology', 'control', 'include design']"
11,1229,Dot-Net makes slow progress,"microsoft's windows .net enterprise server release candidate i, which was released at the end of last month, provides an early glimpse of the system that will eventually replace windows 200 advanced server. the software has been improved so that active directory is more flexible and easier to deploy; and security, scalability and management have also been enhanced","['windows .net enterprise server', 'active directory', 'security', 'scalability']","['P', 'P', 'P', 'P']","['window .net enterprise server', 'active directory', 'security', 'scalability']","['enterprise server release candidate', 'advanced server', 'microsoft', 'replace window', 'software', 'active directory', 'last month', 'release', 'deploy', 'improve']"
12,639,Distributed servers approach for large-scale secure multicast,"in order to offer backward and forward secrecy for multicast applications (i.e., a new member cannot decrypt the multicast data sent before its joining and a former member cannot decrypt the data sent after its leaving), the data encryption key has to be changed whenever a user joins or leaves the system. such a change has to be made known to all the current users. the bandwidth used for such re-key messaging can be high when the user pool is large. we propose a distributed servers approach to minimize the overall system bandwidth (and complexity) by splitting the user pool into multiple groups each served by a (logical) server. after presenting an analytic model for the system based on a hierarchical key tree, we show that there is an optimal number of servers to achieve minimum system bandwidth. as the underlying user traffic fluctuates, we propose a simple dynamic scheme with low overhead where a physical server adaptively splits and merges its traffic into multiple groups each served by a logical server so as to minimize its total bandwidth. our results show that a distributed servers approach is able to substantially reduce the total bandwidth required as compared with the traditional single-server approach, especially for those applications with a large user pool, short holding time, and relatively low bandwidth of a data stream, as in the internet stock quote applications","['distributed servers', 'large-scale secure multicast', 'forward secrecy', 'multicast applications', 'data encryption key', 're-key messaging', 'system bandwidth', 'hierarchical key tree', 'user traffic', 'short holding time', 'internet stock quote applications', 'backward secrecy', 'system complexity', 'traffic merging', 'dynamic split-and-merge scheme', 'key management']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'M']","['distribute server', 'large - scale secure multicast', 'forward secrecy', 'multicast application', 'datum encryption key', 're - key messaging', 'system bandwidth', 'hierarchical key tree', 'user traffic', 'short holding time', 'internet stock quote application', 'backward secrecy', 'system complexity', 'traffic merging', 'dynamic split - and - merge scheme', 'key management']","['distribute server approach', 'datum encryption key have', 'achieve minimum system bandwidth', 'multicast application', 'multicast datum', 'overall system bandwidth', 'forward secrecy', 'total bandwidth require', 'server approach', 'low bandwidth']"
13,114,Cooperative three- and four-player quantum games,a cooperative multi-player quantum game played by 3 and 4 players has been studied. a quantum superposed operator is introduced in this work which solves the non-zero sum difficulty in previous treatments. the role of quantum entanglement of the initial state is discussed in detail,"['quantum superposed operator', 'quantum entanglement', 'initial state', 'cooperative three-player quantum games', 'cooperative four-player quantum games', 'nonzero sum difficulty']","['P', 'P', 'P', 'M', 'R', 'M']","['quantum superpose operator', 'quantum entanglement', 'initial state', 'cooperative three - player quantum game', 'cooperative four - player quantum game', 'nonzero sum difficulty']","['player quantum game play', 'quantum entanglement', 'quantum superpose operator', 'sum difficulty', 'initial state', 'player', 'solve', 'non', 'role', 'previous treatment']"
14,957,A Blog in every law firm?,"you don't know today what you'll want to know next year. rather than trying to solve that problem, focus on providing simple tools to users that create valuable content across the firm. individual contributions will be more visible, and you will have a searchable archive of your institutional memory and a simplified process for ensuring everyone is up to speed. whether you embrace weblogs for their individual or institutional benefits, one thing is certain: they will become powerful tools for those who seek ways to more efficiently and intelligently manage information","['law firm', 'institutional memory', 'weblogs', 'web site']","['P', 'P', 'P', 'U']","['law firm', 'institutional memory', 'weblog', 'web site']","['embrace weblog', 'institutional memory', 'institutional benefit', 'create valuable content', 'searchable archive', 'provide simple tool', 'individual contribution', 'become powerful tool', 'know next year', 'ensure']"
15,912,Grey-box model identification via evolutionary computing,"this paper presents an evolutionary grey-box model identification methodology that makes the best use of a priori knowledge on a clear-box model with a global structural representation of the physical system under study, whilst incorporating accurate blackbox models for immeasurable and local nonlinearities of a practical system. the evolutionary technique is applied to building dominant structural identification with local parametric tuning without the need of a differentiable performance index in the presence of noisy data. it is shown that the evolutionary technique provides an excellent fitting performance and is capable of accommodating multiple objectives such as to examine the relationships between model complexity and fitting accuracy during the model building process. validation results show that the proposed method offers robust, uncluttered and accurate models for two practical systems. it is expected that this type of grey-box models will accommodate many practical engineering systems for a better modelling accuracy","['grey-box models', 'system identification', 'evolutionary algorithms', 'genetic evolution', 'multiobjective optimisation', 'hydraulic system', 'nonlinear system']","['P', 'R', 'M', 'U', 'U', 'M', 'R']","['grey - box model', 'system identification', 'evolutionary algorithm', 'genetic evolution', 'multiobjective optimisation', 'hydraulic system', 'nonlinear system']","['box model identification methodology', 'incorporate accurate blackbox model', 'accommodate many practical engineering system', 'model building process', 'model complexity', 'structural identification', 'evolutionary grey', 'box model', 'box model', 'accurate model']"
16,580,A genetic approach to the optimization of automatic generation control parameters for power systems,"this paper presents a method based on genetic algorithm for the automatic generation control of power systems. the technique is applied to control a system, which includes two areas tied together through a power line. as a consequence of continuous load variation, the frequency of the power system changes with time. in conventional studies, frequency transients are minimized by using integral controllers and thus zero steady-state error is obtained. in this paper, integral controller gains and frequency bias factors are determined by using the genetic algorithm. the results of simulation reveal the application of the genetic algorithm having easy implementation to find the global optimum values of the control parameters","['genetic algorithm', 'power line', 'continuous load variation', 'frequency transients', 'integral controller gains', 'frequency bias factors', 'power systems automatic generation control parameters optimization', 'control design', 'interconnected power networks', 'control simulation']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M', 'R']","['genetic algorithm', 'power line', 'continuous load variation', 'frequency transient', 'integral controller gain', 'frequency bias factor', 'power system automatic generation control parameter optimization', 'control design', 'interconnect power network', 'control simulation']","['automatic generation control', 'genetic algorithm', 'frequency transient', 'integral controller gain', 'integral controller', 'frequency', 'global optimum', 'power line', 'control', 'power system']"
17,1190,Buying into the relationship [business software],"choosing the right software to improve business processes can have a huge impact on a company's efficiency and profitability. while it is sometimes hard to get beyond vendor hype about software features and functionality and know what to realistically expect, it is even more difficult to determine if the vendor is the right vendor to partner with. thus picking the right software is important, but companies have to realize that what they are really buying into is a relationship with the vendor","['business software', 'functionality', 'vendor relationship', 'management', 'software evaluation']","['P', 'P', 'R', 'U', 'M']","['business software', 'functionality', 'vendor relationship', 'management', 'software evaluation']","['software feature', 'improve business process', 'right software', 'right vendor', 'vendor hype', 'vendor', 'company have', 'partner', 'company', 'choose']"
18,1214,Multi-agent collaboration for B2B workflow monitoring,"business-to-business (b2b) application environments are exceedingly dynamic and competitive. this dynamism is manifested in the form of changing process requirements and time constraints. however, current workflow management technologies have difficulties trying to solve problems, such as: how to deal with the dynamic nature of b2b commerce processes, how to manage the distributed knowledge and recourses, and how to reduce the transaction risk. in this paper, a collaborative multi-agent system is proposed. multiple intelligent agents in our system can work together not only to identify the workflow problems, but also to solve such problems, by applying business rules, such as re-organizing the procurement and the transaction processes, and making necessary workflow process changes","['multi-agent collaboration', 'b2b workflow monitoring', 'changing process requirements', 'time constraints', 'workflow management', 'transaction risk', 'business rules', 'internet', 'business-to-business applications', 'electronic commerce']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'R', 'M']","['multi - agent collaboration', 'b2b workflow monitor', 'change process requirement', 'time constraint', 'workflow management', 'transaction risk', 'business rule', 'internet', 'business - to - business application', 'electronic commerce']","['workflow management technology', 'b2b commerce process', 'multiple intelligent agent', 'workflow problem', 'transaction process', 'collaborative multi', 'business rule', 'change process requirement', 'distribute knowledge', 'application environment']"
19,1251,A synergic analysis for Web-based enterprise resources planning systems,"as the central nervous system for managing an organization's mission and critical business data, enterprise resource planning (erp) system has evolved to become the backbone of e-business implementation. since an erp system is multimodule application software that helps a company manage its important business functions, it should be versatile enough to automate every aspect of business processes, including e-business","['synergic analysis', 'web-based enterprise resources planning', 'enterprise resource planning', 'erp', 'e-business', 'customer relationship management']","['P', 'P', 'P', 'P', 'P', 'M']","['synergic analysis', 'web - base enterprise resource plan', 'enterprise resource planning', 'erp', 'e - business', 'customer relationship management']","['enterprise resource planning', 'erp system', 'multimodule application software', 'business process', 'business implementation', 'business datum', 'important business function', 'company manage', 'automate', 'manage']"
20,604,SRP rolls out reliability and asset management initiative,"reliability planning analysis at the salt river project (srp, tempe, arizona, us) prioritizes geographic areas for preventive inspections based on a cost benefit model. however, srp wanted a new application system to prioritize inspections and to predict when direct buried cable would fail using the same cost benefit model. in the business cases, the represented type of kilowatt load-residential, commercial or critical circuit-determines the cost benefit per circuit. the preferred solution was to develop a geographical information system (gis) application allowing for a circuit query for the specific geographic areas it crosses and the density of load points of a given type within those areas. the query returns results based on the type of equipment analysis execution: wood pole, preventive maintenance for a line or cable replacement. this differentiation insures that all the facilities relevant to a specific analysis type influence prioritization of the geographic areas","['reliability planning analysis', 'salt river project', 'tempe', 'arizona', 'geographic areas', 'preventive inspections', 'cost benefit model', 'direct buried cable', 'geographical information system', 'gis', 'equipment analysis execution', 'wood pole', 'cable replacement', 'usa', 'condition monitoring']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'U']","['reliability planning analysis', 'salt river project', 'tempe', 'arizona', 'geographic area', 'preventive inspection', 'cost benefit model', 'direct bury cable', 'geographical information system', 'gi', 'equipment analysis execution', 'wood pole', 'cable replacement', 'usa', 'condition monitoring']","['prioritize geographic area', 'reliability planning analysis', 'specific geographic area', 'prioritize inspection', 'geographical information system', 'preventive inspection base', 'equipment analysis execution', 'same cost benefit model', 'preventive maintenance', 'cost benefit model']"
21,641,Multiecho segmented EPI with z-shimmed background gradient compensation (MESBAC) pulse sequence for fMRI,"a multiecho segmented epi with z-shimmed background gradient compensation (mesbac) pulse sequence is proposed and validated for functional mri (fmri) study in regions suffering from severe susceptibility artifacts. this sequence provides an effective tradeoff between spatial and temporal resolution and reduces image distortion and signal dropout. the blood oxygenation level-dependent (bold)-weighted fmri signal can be reliably obtained in the region of the orbitofrontal cortex (ofc). to overcome physiological motion artifacts during prolonged multisegment epi acquisition, two sets of navigator echoes were acquired in both the readout and phase-encoding directions. ghost artifacts generally produced by single-shot epi acquisition were eliminated by separately placing the even and odd echoes in different k-space trajectories. unlike most z-shim methods that focus on increasing temporal resolution for event-related functional brain mapping, the mesbac sequence simultaneously addresses problems of image distortion and signal dropout while maintaining sufficient temporal resolution. the mesbac sequence will be particularly useful for pharmacological and affective fmri studies in brain regions such as the ofc, nucleus accumbens, amygdala, para-hippocampus, etc","['multiecho segmented epi', 'z-shimmed background gradient compensation', 'fmri', 'severe susceptibility artifacts', 'temporal resolution', 'image distortion', 'signal dropout', 'orbitofrontal cortex', 'navigator echoes', 'ghost artifacts', 'event-related functional brain mapping', 'gradient compensation pulse sequence', 'bold-weighted signal', 'spatial resolution']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'R']","['multiecho segment epi', 'z - shim background gradient compensation', 'fmri', 'severe susceptibility artifact', 'temporal resolution', 'image distortion', 'signal dropout', 'orbitofrontal cortex', 'navigator echo', 'ghost artifact', 'event - relate functional brain mapping', 'gradient compensation pulse sequence', 'bold - weight signal', 'spatial resolution']","['fmri signal', 'functional brain mapping', 'prolong multisegment epi acquisition', 'functional mri', 'fmri study', 'fmri', 'navigator echo', 'brain region', 'orbitofrontal cortex', 'multiecho segment epi']"
22,129,Phase conditions for Schur polynomials,"the rate of change of phase of a real or complex schur polynomial, evaluated along the unit circle traversed counterclockwise, is strictly positive. for polynomials with real coefficients, this bound can be tightened. these and some other fundamental bounds on the rate of change of phase are derived here, using the tchebyshev representation of the image of a real polynomial evaluated on the unit circle","['phase conditions', 'schur polynomial', 'rate of change of phase', 'real coefficients', 'tchebyshev representation', 'phase monotonicity', 'robust stability', 'discrete-time control systems', 'stabilization']","['P', 'P', 'P', 'P', 'P', 'M', 'U', 'U', 'U']","['phase condition', 'schur polynomial', 'rate of change of phase', 'real coefficient', 'tchebyshev representation', 'phase monotonicity', 'robust stability', 'discrete - time control system', 'stabilization']","['complex schur polynomial', 'real polynomial evaluate', 'unit circle traverse counterclockwise', 'polynomial', 'tchebyshev representation', 'phase', 'real coefficient', 'other fundamental bound', 'bind', 'positive']"
23,1115,Four-point wavelets and their applications,"multiresolution analysis (mra) and wavelets provide useful and efficient tools for representing functions at multiple levels of details. wavelet representations have been used in a broad range of applications, including image compression, physical simulation and numerical analysis. in this paper, the authors construct a new class of wavelets, called four-point wavelets, based on an interpolatory four-point subdivision scheme. they are of local support, symmetric and stable. the analysis and synthesis algorithms have linear time complexity. depending on different weight parameters w, the scaling functions and wavelets generated by the four-point subdivision scheme are of different degrees of smoothness. therefore the user can select better wavelets relevant to the practice among the classes of wavelets. the authors apply the four-point wavelets in signal compression. the results show that the four-point wavelets behave much better than b-spline wavelets in many situations","['four-point wavelets', 'multiresolution analysis', 'wavelet representations', 'image compression', 'physical simulation', 'numerical analysis', 'interpolatory four-point subdivision scheme', 'linear time complexity', 'weight parameters', 'scaling functions', 'b-spline wavelets']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['four - point wavelet', 'multiresolution analysis', 'wavelet representation', 'image compression', 'physical simulation', 'numerical analysis', 'interpolatory four - point subdivision scheme', 'linear time complexity', 'weight parameter', 'scale function', 'b - spline wavelet']","['spline wavelet', 'point wavelet', 'wavelet provide useful', 'wavelet relevant', 'wavelet generate', 'wavelet representation', 'multiresolution analysis', 'wavelet', 'synthesis algorithm have linear time complexity', 'signal compression']"
24,1150,Effect of multileaf collimator leaf width on physical dose distributions in the treatment of CNS and head and neck neoplasms with intensity modulated radiation therapy,"the purpose of this work is to examine physical radiation dose differences between two multileaf collimator (mlc) leaf widths (5 and 10 mm) in the treatment of cns and head and neck neoplasms with intensity modulated radiation therapy (imrt). three clinical patients with cns tumors were planned with two different mlc leaf sizes, 5 and 10 mm, representing varian-120 and varian-80 millennium multileaf collimators, respectively. two sets of imrt treatment plans were developed. the goal of the first set was radiation dose conformality in three dimensions. the goal for the second set was organ avoidance of a nearby critical structure while maintaining adequate coverage of the target volume. treatment planning utilized the cadplan/helios system (varian medical systems, milpitas ca) for dynamic mlc treatment delivery. all beam parameters and optimization (cost function) parameters were identical for the 5 and 10 mm plans. for all cases the number of beams, gantry positions, and table positions were taken from clinically treated three-dimensional conformal radiotherapy plans. conformality was measured by the ratio of the planning isodose volume to the target volume. organ avoidance was measured by the volume of the critical structure receiving greater than 90% of the prescription dose (v/sub 90/). for three patients with squamous cell carcinoma of the head and neck (t2-t4 n0-n2c m0) 5 and 10 mm leaf widths were compared for parotid preservation utilizing nine coplanar equally spaced beams delivering a simultaneous integrated boost. because modest differences in physical dose to the parotid were detected, a ntcp model based upon the clinical parameters of eisbruch et al. was then used for comparisons. the conformality improved in all three cns cases for the 5 mm plans compared to the 10 mm plans. for the organ avoidance plans, v/sub 90/ also improved in two of the three cases when the 5 mm leaf width was utilized for imrt treatment delivery. in the third case, both the 5 and 10 mm plans were able to spare the critical structure with none of the structure receiving more than 90% of the prescription dose, but in the moderate dose range, less dose was delivered to the critical structure with the 5 mm plan. for the head and neck cases both the 5 and 10*2.5 mm beamlets dmlc sliding window techniques spared the contralateral parotid gland while maintaining target volume coverage. the mean parotid dose was modestly lower with the smaller beamlet size (21.04 gy vs 22.36 gy). the resulting average ntcp values were 13.72% for 10 mm dmlc and 8.24% for 5 mm dmlc. in conclusion, five mm leaf width results in an improvement in physical dose distribution over 10 mm leaf width that may be clinically relevant in some cases. these differences may be most pronounced for single fraction radiosurgery or in cases where the tolerance of the sensitive organ is less than or close to the target volume prescription","['multileaf collimator leaf width', 'physical dose distributions', 'head and neck neoplasms', 'intensity modulated radiation therapy', '10 mm', 'cns tumors', 'treatment planning', 'conformal radiotherapy', 'parotid preservation', '5 mm', 'beamlet size', '21.04 gy', '22.36 gy', 'single fraction radiosurgery', 'cns neoplasms', 'optimization parameters', 'acceptable tumor coverage', 'minimal toxicity', 'collimator rotation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'U', 'M']","['multileaf collimator leaf width', 'physical dose distribution', 'head and neck neoplasm', 'intensity modulate radiation therapy', '10 mm', 'cns tumor', 'treatment planning', 'conformal radiotherapy', 'parotid preservation', '5 mm', 'beamlet size', '21.04 gy', '22.36 gy', 'single fraction radiosurgery', 'cns neoplasm', 'optimization parameter', 'acceptable tumor coverage', 'minimal toxicity', 'collimator rotation']","['radiation dose difference', 'radiotherapy plan', 'radiation dose conformality', 'radiation therapy', 'different mlc leaf size', 'cns tumor', 'radiosurgery', 'multileaf collimator', 'multileaf collimator', 'mlc treatment delivery']"
25,997,Production capacity of flexible manufacturing systems with fixed production ratios,"determining the production capacity of flexible manufacturing systems is a very important issue in the design of such systems. we propose an approach for determining the production capacity (i.e. the maximum production rate) of a flexible manufacturing system with several part types, dedicated pallets, and fixed production ratios among the different part types. we show that the problem reduces to the determination of a single parameter for which we propose an iterative procedure. simulation or approximate analytical techniques can be used as the building block performance evaluation technique in the iterative procedure","['production capacity', 'flexible manufacturing systems', 'fixed production ratios', 'maximum production rate', 'dedicated pallets', 'iterative procedure', 'simulation', 'approximate analytical techniques', 'building block performance evaluation technique', 'multiple part type', 'single parameter determination', 'stability condition', 'numerical experiments']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'U', 'U']","['production capacity', 'flexible manufacturing system', 'fix production ratio', 'maximum production rate', 'dedicate pallet', 'iterative procedure', 'simulation', 'approximate analytical technique', 'building block performance evaluation technique', 'multiple part type', 'single parameter determination', 'stability condition', 'numerical experiment']","['flexible manufacturing system', 'flexible manufacturing system', 'production capacity', 'maximum production rate', 'fix production ratio', 'iterative procedure', 'dedicate pallet', 'performance evaluation', 'approximate analytical technique', 'several part type']"
26,540,Ventilation-perfusion ratio of signal intensity in human lung using oxygen-enhanced and arterial spin labeling techniques,"this study investigates the distribution of ventilation-perfusion (v/q) signal intensity (si) ratios using oxygen-enhanced and arterial spin labeling (asl) techniques in the lungs of 10 healthy volunteers. ventilation and perfusion images were simultaneously acquired using the flow-sensitive alternating inversion recovery (fair) method as volunteers alternately inhaled room air and 100% oxygen. images of the t/sub 1/ distribution were calculated for five volunteers for both selective (t/sub 1f/) and nonselective (t/sub 1/) inversion. the average t/sub 1/ was 1360 ms+or-116 ms, and the average t/sub 1f/ was 1012 ms+or-112 ms, yielding a difference that is statistically significant (p<0.002). excluding large pulmonary vessels, the average v/q si ratios were 0.355+or-0.073 for the left lung and 0.371+or-0.093 for the right lung, which are in agreement with the theoretical v/q si ratio. plots of the wo si ratio are similar to the logarithmic normal distribution obtained by multiple inert gas elimination techniques, with a range of ratios matching ventilation and perfusion. this mri v/q technique is completely noninvasive and does not involve ionized radiation. a limitation of this method is the nonsimultaneous acquisition of perfusion and ventilation data, with oxygen administered only for the ventilation data","['ventilation-perfusion ratio', 'signal intensity', 'human lung', 'arterial spin labeling techniques', 'perfusion images', 'flow-sensitive alternating inversion recovery', 'logarithmic normal distribution', 'multiple inert gas elimination', 'mri', 'nonsimultaneous acquisition', 'oxygen-enhanced techniques', 'ventilation images', 'gas exchange efficiency', 'pathomechanisms', 'time delay', 'pixel-by-pixel maps', 'pulmonary embolism', 'chronic obstructive pulmonary disease']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'U', 'U', 'U', 'M', 'M']","['ventilation - perfusion ratio', 'signal intensity', 'human lung', 'arterial spin labeling technique', 'perfusion image', 'flow - sensitive alternate inversion recovery', 'logarithmic normal distribution', 'multiple inert gas elimination', 'mri', 'nonsimultaneous acquisition', 'oxygen - enhance technique', 'ventilation image', 'gas exchange efficiency', 'pathomechanism', 'time delay', 'pixel - by - pixel map', 'pulmonary embolism', 'chronic obstructive pulmonary disease']","['inhale room air', 'ratio match ventilation', 'alternate inversion recovery', 'ventilation datum', 'ventilation', 'pulmonary vessel', 'arterial spin', 'oxygen administer', 'lung', 'perfusion image']"
27,86,Laser-based internal profile measurement system,"an automatic laser-based system to measure the internal profiles of various structures has been developed. the system uses a point laser source through a rotating optical device fixed on to a laser measurement meter. a notebook computer with custom software is used to control the laser meter and rotating device to estimate the scanned profile shape and to determine the resulting cross-section area. the information provided by this system is essential to construction industry, including window and door builders; the glass, panel, board, and floor tile manufacturers; carpet venders; and building contractors for cost estimation and production control. as a result, the lead time for delivering the customized windowpanes, woodwork, floor tiles, and ceilings can be reduced. applications of this system for measuring the shapes of window frames and floor plans are described and demonstrated. the measurement accuracy is evaluated and analyzed. results have indicated that the measurement accuracy can be achieved within 4% of the measurement distance, for typical window designs and floor patterns required by major window manufacturers. recommendations to improve the system are also included","['laser-based internal profile measurement system', 'internal profiles', 'point laser source', 'rotating optical device', 'laser meter', 'rotating device', 'floor tile manufacturers', 'carpet venders', 'building contractors', 'cost estimation', 'production control', 'customized windowpanes', 'window frames']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['laser - base internal profile measurement system', 'internal profile', 'point laser source', 'rotate optical device', 'laser meter', 'rotate device', 'floor tile manufacturer', 'carpet vender', 'build contractor', 'cost estimation', 'production control', 'customize windowpane', 'window frame']","['laser measurement meter', 'laser meter', 'measurement accuracy', 'floor tile manufacturer', 'measurement distance', 'rotate optical device', 'point laser', 'automatic laser', 'floor tile', 'window frame']"
28,1008,Quadratic programming algorithms for large-scale model predictive control,"quadratic programming (qp) methods are an important element in the application of model predictive control (mpc). as larger and more challenging mpc applications are considered, more attention needs to be focused on the construction and tailoring of efficient qp algorithms. in this study, we tailor and apply a new qp method, called qpschur, to large mpc applications, such as cross directional control problems in paper machines. written in c++, qpschur is an object oriented implementation of a novel dual space, schur complement algorithm. we compare this approach to three widely applied qp algorithms and show that qpschur is significantly more efficient (up to two orders of magnitude) than the other algorithms. in addition, detailed simulations are considered that demonstrate the importance of the flexible, object oriented construction of qpschur, along with additional features for constraint handling, warm starts and partial solution","['quadratic programming algorithms', 'large-scale model predictive control', 'qpschur', 'cross directional control problems', 'paper machines', 'object oriented implementation', 'simulations', 'constraint handling', 'warm starts', 'partial solution', 'dual space schur complement algorithm', 'flexible object oriented construction']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['quadratic programming algorithm', 'large - scale model predictive control', 'qpschur', 'cross directional control problem', 'paper machine', 'object orient implementation', 'simulation', 'constraint handle', 'warm start', 'partial solution', 'dual space schur complement algorithm', 'flexible object orient construction']","['efficient qp algorithm', 'model predictive control', 'schur complement algorithm', 'quadratic programming', 'challenge mpc application', 'large mpc application', 'cross directional control problem', 'paper machine', 'new qp method', 'constraint handle']"
29,719,War games: The truth [network security],"with al qaeda on the tip of tongues around the world, find out how terror groups could target your network. what are the dangers and how do you fight them?","['networks', 'security', 'malicious attacks', 'employees']","['P', 'P', 'U', 'U']","['network', 'security', 'malicious attack', 'employee']","['al qaeda', 'terror group', 'danger', 'network', 'tongue', 'target', 'fight', 'tip', 'find', 'world']"
30,1309,Transcripts: bane or boon? [law reporting],"because judge-made law, by its very nature, is less immediately accessible than the law of codified, statutory systems, it calls for an efficient system of law reporting. of necessity, any such system will be selective, the majority of decisions going unreported. considerable power thereby comes to repose in the hands of the law reporters. the author shares his invaluable perception and extensive research on the difficulties which arise from the excess of access to judgments","['transcripts', 'law reporting', 'judge-made law', 'judgments']","['P', 'P', 'P', 'P']","['transcript', 'law report', 'judge - make law', 'judgment']","['law report', 'law reporter', 'judge', 'make law', 'statutory system', 'law', 'invaluable perception', 'extensive research', 'considerable power', 'efficient system']"
31,1424,FinancialContent. Credibility is king,"if you went to a site named financialcontent.com, you'd probably expect to find, well, financial content. maybe stock prices or company earnings or market charts or economic statistics or corporate news reports. well, you'd be partially correct. financialcontent.com does deal in financial information, but its main objective is not to distribute its financial content to individual investors, but to distribute it through other web sites. in other words, financialcontent is a wholesaler, not a retailer. as an aggregator, financialcontent provides partner sites with financial information that is tailored to that individual web site","['financialcontent.com', 'financial information', 'web sites', 'aggregator', 'partner sites']","['P', 'P', 'P', 'P', 'P']","['financialcontent.com', 'financial information', 'web site', 'aggregator', 'partner site']","['financialcontent provide partner site', 'financial content', 'financialcontent', 'financial information', 'corporate news report', 'other web site', 'stock price', 'company earning', 'market chart', 'economic statistic']"
32,832,Senate to Powell: regulate more [FCC],"fcc chairman michael powell pitched a six-step market-based recovery plan to the senate last week, but two members of the commerce committee told him telecom's revival requires more reliance on regulation","['fcc', 'recovery plan', 'us senate commerce committee', 'telecom industry']","['P', 'P', 'M', 'M']","['fcc', 'recovery plan', 'us senate commerce committee', 'telecom industry']","['fcc chairman michael powell pitch', 'base recovery plan', 'commerce committee tell', 'senate last week', 'revival require more reliance', 'step market', 'telecom', 'member']"
33,877,What do you say? Open letters to women considering a computer science major,"in the last decade we have both monitored with great interest the ratio of female to male computer science majors at our respective institutions. with each entering class, we think: ""surely, now is the time when the numbers will become more balanced."" logic tells us that this must eventually happen, because the opportunities in computing are simply too attractive for an entire segment of our population to routinely pass up. but each year we are again disappointed in the number of women students, as they continue to be woefully under-represented among computer science majors. so, what do you say to a young woman who is considering a college choice and a choice of major in order to make computer science a more attractive option? we have organized some thoughts on that subject into open letters","['women', 'computer science majors', 'female', 'male', 'computer science education', 'gender issues']","['P', 'P', 'P', 'P', 'M', 'U']","['woman', 'computer science major', 'female', 'male', 'computer science education', 'gender issue']","['male computer science major', 'computer science major', 'college choice', 'woman student', 'make computer science', 'attractive option', 'young woman', 'major', 'female', 'opportunity']"
34,698,Robust stability analysis for current-programmed regulators,"uncertainty models for the three basic switch-mode converters: buck, boost, and buck-boost are given in this paper. the resulting models are represented by linear fractional transformations with structured dynamic uncertainties. uncertainties are assumed for the load resistance r=r/sub o/(1+ delta /sub r/), inductance l=l/sub o/(1+ delta /sub l/), and capacitance c=c/sub o/(1+ delta /sub c/). the interest in these models is clearly motivated by the need to have models for switch-mode dc-dc converters that are compatible with robust control analysis, which require a model structure consisting of a nominal model and a norm-bounded modeling uncertainty. therefore, robust stability analysis can be realized using standard mu -tools. at the end of the paper, an illustrative example is given which shows the simplicity of the procedure","['robust stability analysis', 'current-programmed regulators', 'uncertainty models', 'linear fractional transformations', 'structured dynamic uncertainties', 'load resistance', 'inductance', 'capacitance', 'switch-mode dc-dc converters', 'control analysis', 'nominal model', 'norm-bounded modeling uncertainty', 'buck converters', 'boost converters', 'buck-boost converters']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['robust stability analysis', 'current - program regulator', 'uncertainty model', 'linear fractional transformation', 'structure dynamic uncertainty', 'load resistance', 'inductance', 'capacitance', 'switch - mode dc - dc converter', 'control analysis', 'nominal model', 'norm - bound modeling uncertainty', 'buck converter', 'boost converter', 'buck - boost converter']","['robust stability', 'linear fractional transformation', 'uncertainty model', 'robust control', 'model uncertainty', 'dc converter', 'structure dynamic uncertainty', 'mode converter', 'uncertainty', 'mode dc']"
35,1288,A modal logic for indiscernibility and complementarity in information systems,"in this paper, we study indiscernibility relations and complementarity relations in information systems, the first-order characterization of indiscernibility and complementarity is obtained through a duality result between information systems and certain structures of relational type characterized by first-order conditions. the modal analysis of indiscernibility and complementarity is performed through a modal logic which modalities correspond to indiscernibility relations and complementarity relations in information systems","['modal logic', 'indiscernibility', 'complementarity', 'information systems', 'first-order characterization', 'duality result', 'relational type', 'first-order conditions']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['modal logic', 'indiscernibility', 'complementarity', 'information system', 'first - order characterization', 'duality result', 'relational type', 'first - order condition']","['relational type characterize', 'indiscernibility relation', 'complementarity relation', 'information system', 'modal logic', 'modality correspond', 'indiscernibility', 'order characterization', 'complementarity', 'modal analysis']"
36,1131,A min-max theorem on feedback vertex sets,"we establish a necessary and sufficient condition for the linear system {x : hx >or= e, x >or= 0} associated with a bipartite tournament to be totally dual integral, where h is the cycle-vertex incidence matrix and e is the all-one vector. the consequence is a min-max relation on packing and covering cycles, together with strongly polynomial time algorithms for the feedback vertex set problem and the cycle packing problem on the corresponding bipartite tournaments. in addition, we show that the feedback vertex set problem on general bipartite tournaments is np-complete and approximable within 3.5 based on the min-max theorem","['min-max theorem', 'feedback vertex sets', 'linear system', 'bipartite tournament', 'cycle-vertex incidence matrix', 'all-one vector', 'covering cycles', 'strongly polynomial time algorithms', 'feedback vertex set problem', 'cycle packing problem', 'necessary sufficient condition', 'totally dual integral system', 'np-complete problem', 'graphs', 'combinatorial optimization problems', 'linear programming duality theory']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'U', 'M', 'M']","['min - max theorem', 'feedback vertex set', 'linear system', 'bipartite tournament', 'cycle - vertex incidence matrix', 'all - one vector', 'cover cycle', 'strongly polynomial time algorithm', 'feedback vertex set problem', 'cycle packing problem', 'necessary sufficient condition', 'totally dual integral system', 'np - complete problem', 'graph', 'combinatorial optimization problem', 'linear programming duality theory']","['correspond bipartite tournament', 'general bipartite tournament', 'bipartite tournament', 'feedback vertex set problem', 'vertex incidence matrix', 'cycle packing problem', 'cover cycle', 'polynomial time algorithm', 'dual integral', 'linear system']"
37,1174,Optimization of cutting conditions for single pass turning operations using a deterministic approach,"an optimization analysis, strategy and cam software for the selection of economic cutting conditions in single pass turning operations are presented using a deterministic approach. the optimization is based on criteria typified by the maximum production rate and includes a host of practical constraints. it is shown that the deterministic optimization approach involving mathematical analyses of constrained economic trends and graphical representation on the feed-speed domain provides a clearly defined strategy that not only provides a unique global optimum solution, but also the software that is suitable for on-line cam applications. a numerical study has verified the developed optimization strategies and software and has shown the economic benefits of using optimization","['single pass turning operations', 'deterministic approach', 'cam software', 'economic cutting conditions', 'maximum production rate', 'mathematical analyses', 'constrained economic trends', 'cutting conditions optimization', 'process planning']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U']","['single pass turn operation', 'deterministic approach', 'cam software', 'economic cutting condition', 'maximum production rate', 'mathematical analysis', 'constrain economic trend', 'cut condition optimization', 'process plan']","['pass turn operation', 'economic cutting condition', 'deterministic optimization approach', 'constrain economic trend', 'develop optimization strategy', 'optimization analysis', 'maximum production rate', 'optimization', 'global optimum', 'practical constraint']"
38,564,Development of a computer-aided manufacturing system for profiled edge lamination tooling,"profiled edge lamination (pel) tooling is a promising rapid tooling (rt) method involving the assembly of an array of laminations whose top edges are simultaneously profiled and beveled based on a cad model of the intended tool surface. to facilitate adoption of this rt method by industry, a comprehensive pel tooling development system is proposed. the two main parts of this system are: (1) iterative tool design based on thermal and structural models; and (2) fabrication of the tool using a computer-aided manufacturing (cam) software and abrasive water jet cutting. cam software has been developed to take lamination slice data (profiles) from any proprietary rp software in the form of polylines and create smooth, kinematically desirable cutting trajectories for each tool lamination. two cutting trajectory algorithms, called identical equidistant profile segmentation and adaptively vector profiles projection (avpp), were created for this purpose. by comparing the performance of both algorithms with a benchmark part shape, the avpp algorithm provided better cutting trajectories for complicated tool geometries. a 15-layer aluminum pel tool was successfully fabricated using a 5-axis cnc awj cutter and nc code generated by the cam software","['profiled edge lamination tooling', 'rapid tooling', 'abrasive water jet cutting', 'cam software', 'cutting trajectory algorithms', 'identical equidistant profile segmentation', 'adaptively vector profiles projection', 'computer aided manufacturing']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['profile edge lamination tooling', 'rapid tooling', 'abrasive water jet cutting', 'cam software', 'cut trajectory algorithm', 'identical equidistant profile segmentation', 'adaptively vector profile projection', 'computer aid manufacturing']","['profile edge lamination', 'tool lamination', 'lamination slice', 'pel tooling development', 'cut trajectory algorithm', 'iterative tool design', 'layer aluminum pel tool', 'axis cnc awj cutter', 'rapid tooling', 'tool geometry']"
39,599,Keen but confused [workflow & content management],"it users find workflow, content and business process management software appealing but by no means straightforward to implement. pat sweet reports on our latest research","['workflow', 'content management', 'business process management software', 'research', 'survey', 'market overview']","['P', 'P', 'P', 'P', 'U', 'U']","['workflow', 'content management', 'business process management software', 'research', 'survey', 'market overview']","['business process management software appeal', 'user find workflow', 'pat sweet report', 'implement', 'content', 'mean straightforward']"
40,1189,CRM: approaching zenith,"looks at how manufacturers are starting to warm up to the concept of customer relationship management. crm has matured into what is expected to be big business. as crm software evolves to its second, some say third, generation, it's likely to be more valuable to holdouts in manufacturing and other sectors","['crm', 'manufacturers', 'manufacturers', 'customer relationship management', 'manufacturing']","['P', 'P', 'P', 'P', 'P']","['crm', 'manufacturer', 'manufacturer', 'customer relationship management', 'manufacture']","['customer relationship management', 'crm software evolve', 'crm', 'big business', 'manufacturer', 'manufacture', 'concept', 'holdout', 'generation', 'mature']"
41,1230,Server safeguards tax service,peterborough-based tax consultancy ie taxguard wanted real-time failover protection for important windows-based applications. its solution was to implement a powerful failover server from uk supplier neverfail in order to provide real-time backup for three core production servers,"['tax consultancy', 'ie taxguard', 'failover server', 'neverfail', 'backup']","['P', 'P', 'P', 'P', 'P']","['tax consultancy', 'ie taxguard', 'failover server', 'neverfail', 'backup']","['failover server', 'time failover protection', 'taxguard', 'base tax consultancy', 'uk supplier neverfail', 'time backup', 'base application', 'important window', 'peterborough', 'provide real']"
42,1275,Modeling dynamic objects in distributed systems with nested Petri nets,"nested petri nets (np-nets) is a petri net extension, allowing tokens in a net marking to be represented by marked nets themselves. the paper discusses applicability of np-nets for modeling task planning systems, multi-agent systems and recursive-parallel systems. a comparison of np-nets with some other formalisms, such as opns of r. valk (2000), recursive parallel programs of o. kushnarenko and ph. schnoebelen (1997) and process algebras is given. some aspects of decidability for object-oriented petri net extensions are also discussed","['distributed systems', 'nested petri nets', 'multi-agent systems', 'recursive-parallel systems', 'process algebras', 'decidability', 'object-oriented petri net', 'dynamic objects modelling']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['distribute system', 'nest petri net', 'multi - agent system', 'recursive - parallel system', 'process algebra', 'decidability', 'object - orient petri net', 'dynamic object model']","['orient petri net extension', 'petri net extension', 'model task planning system', 'nest petri net', 'recursive parallel program', 'net marking', 'parallel system', 'agent system', 'process algebra', 'paper discuss applicability']"
43,620,Adaptive image enhancement for retinal blood vessel segmentation,"retinal blood vessel images are enhanced by removing the nonstationary background, which is adaptively estimated based on local neighbourhood information. the result is a much better segmentation of the blood vessels with a simple algorithm and without the need to obtain a priori illumination knowledge of the imaging system","['adaptive image enhancement', 'retinal blood vessel images', 'local neighbourhood information', 'nonstationary background removal', 'image segmentation', 'personal identification', 'security applications']","['P', 'P', 'P', 'R', 'R', 'U', 'U']","['adaptive image enhancement', 'retinal blood vessel image', 'local neighbourhood information', 'nonstationary background removal', 'image segmentation', 'personal identification', 'security application']","['retinal blood vessel image', 'blood vessel', 'well segmentation', 'priori illumination knowledge', 'local neighbourhood information', 'nonstationary background', 'simple algorithm', 'remove', 'enhance', 'base']"
44,1094,Efficient allocation of knowledge in distributed business structures,"accelerated business processes demand new concepts and realizations of information systems and knowledge databases. this paper presents the concept of the collaborative information space (cis), which supplies the necessary tools to transform individual knowledge into collective useful information. the creation of 'information objects' in the cis allows an efficient allocation of information in all business process steps at any time. furthermore, the specific availability of heterogeneous, distributed data is realized by a web-based user interface, which enables effective search by a multidimensionally hierarchical composition","['distributed business structures', 'accelerated business processes', 'information systems', 'knowledge databases', 'collaborative information space', 'information objects', 'business process steps', 'web-based user interface', 'multidimensionally hierarchical composition', 'efficient knowledge allocation', 'heterogeneous distributed data', 'interactive system']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M']","['distribute business structure', 'accelerate business process', 'information system', 'knowledge database', 'collaborative information space', 'information object', 'business process step', 'web - base user interface', 'multidimensionally hierarchical composition', 'efficient knowledge allocation', 'heterogeneous distribute datum', 'interactive system']","['accelerate business process demand new concept', 'collaborative information space', 'collective useful information', 'business process step', 'knowledge database', 'distribute datum', 'information system', 'transform individual knowledge', 'information object', 'enable effective search']"
45,1445,Applying BGL to computational geometry,"the author applies boost graph library to the domain of computational geometry. first, he formulates a concrete problem in graph terms. second, he develops a way to transform the output of an existing algorithm into an appropriate boost graph library data structure. finally, he implements two new algorithms for my boost graph library graph. the first algorithm gets the job done, but could have been written in any programming language. the second algorithm, however, shows the power of boost graph library's generic programming approach.graphs, graphics, and generic programming combine in this novel use of the boost graph library","['computational geometry', 'boost graph library', 'generic programming approach', 'boost libraries', 'c++', 'threads', 'smart pointers', 'graph-theoretic concepts', 'directed graph', 'file dependencies', 'bgl graph']","['P', 'P', 'P', 'R', 'U', 'U', 'U', 'U', 'M', 'U', 'R']","['computational geometry', 'boost graph library', 'generic programming approach', 'boost library', 'c++', 'thread', 'smart pointer', 'graph - theoretic concept', 'direct graph', 'file dependency', 'bgl graph']","['boost graph library graph', 'appropriate boost graph library datum structure', 'boost graph library', 'computational geometry', 'graph term', 'second algorithm', 'new algorithm', 'exist algorithm', 'first algorithm', 'programming language']"
46,816,Accelerating filtering techniques for numeric CSPs,"search algorithms for solving numeric csps (constraint satisfaction problems) make an extensive use of filtering techniques. in this paper we show how those filtering techniques can be accelerated by discovering and exploiting some regularities during the filtering process. two kinds of regularities are discussed, cyclic phenomena in the propagation queue and numeric regularities of the domains of the variables. we also present in this paper an attempt to unify numeric csps solving methods from two distinct communities, that of csp in artificial intelligence, and that of interval analysis","['filtering techniques', 'numeric csps', 'search algorithms', 'constraint satisfaction problems', 'propagation', 'artificial intelligence', 'interval analysis', 'csps-solving', 'extrapolation methods', 'pruning']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'M', 'U']","['filter technique', 'numeric csp', 'search algorithm', 'constraint satisfaction problem', 'propagation', 'artificial intelligence', 'interval analysis', 'csp - solving', 'extrapolation method', 'prune']","['numeric csp solve method', 'solve numeric csp', 'constraint satisfaction problem', 'search algorithm', 'filter process', 'filter technique', 'numeric regularity', 'propagation queue', 'csp', 'regularity']"
47,853,Virtual Development Center,"the virtual development center of the institute for women and technology seeks to significantly enhance the impact of women on technology. it addresses this goal by increasing the number of women who have input on created technology, enhancing the ways people teach and develop technology, and developing need-based technology that serves the community. through activities of the virtual development center, a pattern is emerging regarding how computing technologies do or do not satisfy the needs of community groups, particularly those communities serving women. this paper describes the virtual development center program and offers observations on the impact of computing technology on non-technical communities","['virtual development center', 'women', 'teaching', 'community groups', 'information technology', 'gender issues', 'computer science education']","['P', 'P', 'P', 'P', 'M', 'U', 'M']","['virtual development center', 'woman', 'teach', 'community group', 'information technology', 'gender issue', 'computer science education']","['virtual development center program', 'virtual development center', 'community serve woman', 'develop technology', 'compute technology', 'compute technology', 'community group', 'create technology', 'technology seek', 'develop need']"
48,778,Access matters,"discusses accessibility needs of people with disabilities, both from the perspective of getting the information from i&r programs (including accessible web sites, tty access, braille, and other mechanisms) and from the perspective of being aware of accessibility needs when referring clients to resources. includes information on ada legislation requiring accessibility to public places and recommends several organizations and web sites for additional information","['accessibility needs', 'accessible web sites', 'tty access', 'braille', 'ada legislation', 'public places', 'disabled people', 'information and referral programs']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['accessibility need', 'accessible web site', 'tty access', 'braille', 'ada legislation', 'public place', 'disabled people', 'information and referral program']","['ada legislation require accessibility', 'discuss accessibility need', 'include accessible web site', 'accessibility need', 'tty access', 'disability', 'web site', 'braille', 'include information', 'public place']"
49,1368,Exploratory study of the adoption of manufacturing technology innovations in the USA and the UK,"manufacturing technologies, appropriately implemented, provide competitive advantage to manufacturers. the use of manufacturing technologies across countries is difficult to compare. one such comparison has been provided in the literature with a study of us and japanese practices in advanced manufacturing technology use using a common questionnaire. the present study compares the use of 17 different technologies in similar industries in the usa (n=1025) and uk (n=166) using a common questionnaire. largely, there are remarkable similarities between the two countries. this may partly correlate with the heavy traffic in foreign direct investment between the two nations. notable differences are (1) across-the-board, us manufacturers are ahead of the uk firms in computerized integration with units inside and outside manufacturing organizations; (2) us manufacturers show higher labour productivity, which is consistent with macro-economic data, and (3) more uk manufacturers report the use of soft technologies such as just-in-time, total quality manufacturing and manufacturing cells. hypotheses for future investigation are proposed","['manufacturing technology innovations', 'usa', 'uk', 'competitive advantage', 'foreign direct investment', 'labour productivity', 'macro-economic data', 'soft technologies', 'just-in-time', 'total quality manufacturing', 'manufacturing cells']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['manufacture technology innovation', 'usa', 'uk', 'competitive advantage', 'foreign direct investment', 'labour productivity', 'macro - economic datum', 'soft technology', 'just - in - time', 'total quality manufacturing', 'manufacture cell']","['advanced manufacturing technology use use', 'manufacture technology', 'high labour productivity', 'more uk manufacturer report', 'total quality manufacturing', 'manufacturing organization', 'foreign direct investment', 'uk firm', 'soft technology', 'manufacture']"
50,1395,Work in progress: Developing policies for access to government information in the New South Africa,"following south africa's transition to democracy in 1994, the sa government has adopted policies supporting freedom of expression and freedom of access to information. the bill of rights in the new constitution includes a constitutional right of access to information held by the state. since 1994 various initiatives have been taken by government and other bodies to promote such access. these include moves to reorganize government printing and publishing, restructure the government's public information services, make government information available on the internet, and extend telephony and internet access to poor communities. sa's new legal deposit act, (1997) makes provision for the creation of official publications depositories. the promotion of access to information act, (2000) was enacted to ensure access to information held by the state and public bodies. however, despite much activity, it has proved difficult to translate principles into practical and well-coordinated measures to improve access to government information. a specific concern is the failure of policy-makers to visualize a role for libraries","['government information', 'south africa', 'freedom of expression', 'freedom of access to information', 'bill of rights', 'constitutional right of access', 'government printing', 'public information services', 'internet', 'official publications depositories', 'public bodies', 'libraries', 'government publishing']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['government information', 'south africa', 'freedom of expression', 'freedom of access to information', 'bill of right', 'constitutional right of access', 'government printing', 'public information service', 'internet', 'official publication depository', 'public body', 'librarie', 'government publishing']","['public information service', 'new legal deposit act', 'adopt policy support freedom', 'make government information available', 'sa government', 'government information', 'promote such access', 'information act', 'official publication depository', 'internet access']"
51,785,Networking without wires,"several types of devices use radio transmitters to send data over thin air. are wlans, wireless local area networks, the end to all cables? will dalrymple weighs up the costs and benefits","['wireless local area networks', 'costs', 'benefits']","['P', 'P', 'P']","['wireless local area network', 'cost', 'benefit']","['device use radio transmitter', 'wireless local area network', 'wlan', 'cable', 'thin air', 'send datum', 'cost', 'dalrymple weigh', 'several type', 'end']"
52,1069,Entangling atoms in bad cavities,"we propose a method to produce entangled spin squeezed states of a large number of atoms inside an optical cavity. by illuminating the atoms with bichromatic light, the coupling to the cavity induces pairwise exchange of excitations which entangles the atoms. unlike most proposals for entangling atoms by cavity qed, our proposal does not require the strong coupling regime g/sup 2// kappa gamma >>1, where g is the atom cavity coupling strength, kappa is the cavity decay rate, and gamma is the decay rate of the atoms. in this work the important parameter is ng/sup 2// kappa gamma , where n is the number of atoms, and our proposal permits the production of entanglement in bad cavities as long as they contain a large number of atoms","['bad cavities', 'entangled spin squeezed states', 'optical cavity', 'coupling', 'pairwise exchange', 'excitations', 'cavity qed', 'strong coupling regime', 'atom cavity coupling strength', 'cavity decay rate', 'atom entanglement', 'bichromatic light illumination']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['bad cavity', 'entangle spin squeeze state', 'optical cavity', 'couple', 'pairwise exchange', 'excitation', 'cavity qed', 'strong coupling regime', 'atom cavity coupling strength', 'cavity decay rate', 'atom entanglement', 'bichromatic light illumination']","['entangle spin squeeze state', 'atom cavity coupling', 'entangle atom', 'cavity induce pairwise exchange', 'optical cavity', 'cavity decay rate', 'entanglement', 'entangle', 'cavity qed', 'bichromatic light']"
53,893,"Use of natural language processing to translate clinical information from a database of 889,921 chest radiographic reports","the aim was to evaluate translation of chest radiographic reports using natural language processing and to compare the findings with those in the literature. a natural language processor coded 10 years of narrative chest radiographic reports from an urban academic medical center. coding for 150 reports was compared with manual coding. frequencies and cooccurrences of 24 clinical conditions (diseases, abnormalities, and clinical states) were estimated. the ratio of right to left lung mass, association of pleural effusion with other conditions, and frequency of bullet and stab wounds were compared with independent observations. the sensitivity and specificity of the system's pneumothorax coding were compared with those of manual financial coding. internal and external validation in this study confirmed the accuracy of natural language processing for translating chest radiographic narrative reports into a large database of information","['natural language processing', 'urban academic medical center', 'pleural effusion', 'stab wounds', 'pneumothorax coding', 'chest radiographic report database', 'clinical information translation', 'clinical condition frequency', 'clinical condition cooccurrence', 'right to left lung mass ratio', 'bullet wounds']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'R', 'R']","['natural language processing', 'urban academic medical center', 'pleural effusion', 'stab wound', 'pneumothorax coding', 'chest radiographic report database', 'clinical information translation', 'clinical condition frequency', 'clinical condition cooccurrence', 'right to leave lung mass ratio', 'bullet wound']","['chest radiographic report use natural language processing', 'translate chest radiographic narrative report', 'narrative chest radiographic report', 'pneumothorax coding', 'natural language processor code', 'natural language processing', 'manual financial coding', 'pleural effusion', 'manual coding', 'academic medical']"
54,1054,Choice preferences without inferences: subconscious priming of risk attitudes,"we present a procedure for subconscious priming of risk attitudes. in experiment 1, we were reliably able to induce risk-seeking or risk-averse preferences across a range of decision scenarios using this priming procedure. in experiment 2, we showed that these priming effects can be reversed by drawing participants' attention to the priming event. our results support claims that the formation of risk preferences can be based on preconscious processing, as for example postulated by the affective primacy hypothesis, rather than rely on deliberative mental operations, as posited by several current models of judgment and decision making","['choice preferences', 'subconscious priming', 'risk attitudes', 'risk-averse preferences', 'decision scenarios', 'preconscious processing', 'affective primacy hypothesis', 'deliberative mental operations', 'risk-seeking preferences']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['choice preference', 'subconscious priming', 'risk attitude', 'risk - averse preference', 'decision scenario', 'preconscious processing', 'affective primacy hypothesis', 'deliberative mental operation', 'risk - seek preference']","['subconscious priming', 'risk attitude', 'affective primacy hypothesis', 'risk preference', 'induce risk', 'prime effect', 'deliberative mental operation', 'prime event', 'decision scenario use', 'prime procedure']"
55,1011,A self-organizing context-based approach to the tracking of multiple robot trajectories,"we have combined competitive and hebbian learning in a neural network designed to learn and recall complex spatiotemporal sequences. in such sequences, a particular item may occur more than once or the sequence may share states with another sequence. processing of repeated/shared states is a hard problem that occurs very often in the domain of robotics. the proposed model consists of two groups of synaptic weights: competitive interlayer and hebbian intralayer connections, which are responsible for encoding respectively the spatial and temporal features of the input sequence. three additional mechanisms allow the network to deal with shared states: context units, neurons disabled from learning, and redundancy used to encode sequence states. the network operates by determining the current and the next state of the learned sequences. the model is simulated over various sets of robot trajectories in order to evaluate its storage and retrieval abilities; its sequence sampling effects; its robustness to noise and its tolerance to fault","['self-organizing context-based approach', 'robot trajectories', 'hebbian learning', 'complex spatiotemporal sequences', 'shared states', 'synaptic weights', 'hebbian intralayer connections', 'context units', 'sequence states', 'retrieval abilities', 'sequence sampling effects', 'trajectories tracking', 'competitive learning', 'competitive interlayer connections', 'unsupervised learning', 'storage abilities', 'fault tolerance']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'R', 'R']","['self - organize context - base approach', 'robot trajectory', 'hebbian learning', 'complex spatiotemporal sequence', 'share state', 'synaptic weight', 'hebbian intralayer connection', 'context unit', 'sequence state', 'retrieval ability', 'sequence sample effect', 'trajectory track', 'competitive learning', 'competitive interlayer connection', 'unsupervise learning', 'storage ability', 'fault tolerance']","['recall complex spatiotemporal sequence', 'robot trajectory', 'encode sequence state', 'learn sequence', 'neural network design', 'hebbian learning', 'hebbian intralayer connection', 'synaptic weight', 'sequence sample', 'temporal feature']"
56,745,Intensity based affine registration including feature similarity for spatial normalization,"this paper presents a new spatial normalization with affine transformation. the quantitative comparison of brain architecture across different subjects requires a common coordinate system. for the analysis of a specific brain area, it is necessary to normalize and compare a region of interest and the global brain. the intensity based registration method matches the global brain well, but a region of interest may not be locally normalized compared to the feature based method. the method in this paper uses feature similarities of local regions as well as intensity similarities. the lateral ventricle and central gray nuclei of the brain, including the corpus callosum, which is used for features in schizophrenia detection, is appropriately normalized. our method reduces the difference of feature areas such as the corpus callosum (7.7%, 2.4%) and lateral ventricle (8.2%, 13.5%) compared with mutual information and talairach methods","['intensity based affine registration', 'feature similarity', 'feature similarity', 'spatial normalization', 'affine transformation', 'brain architecture', 'common coordinate system', 'region of interest', 'global brain', 'lateral ventricle', 'central gray nuclei', 'corpus callosum', 'schizophrenia detection', 'talairach method', 'feature similarities', 'mutual information method']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['intensity base affine registration', 'feature similarity', 'feature similarity', 'spatial normalization', 'affine transformation', 'brain architecture', 'common coordinate system', 'region of interest', 'global brain', 'lateral ventricle', 'central gray nucleus', 'corpus callosum', 'schizophrenia detection', 'talairach method', 'feature similarity', 'mutual information method']","['spatial normalization', 'specific brain area', 'schizophrenia detection', 'feature area such', 'global brain', 'brain architecture', 'normalize compare', 'intensity base registration method', 'normalize', 'normalize']"
57,700,Digital stochastic realization of complex analog controllers,"stochastic logic is based on digital processing of a random pulse stream, where the information is codified as the probability of a high level in a finite sequence. this binary pulse sequence can be digitally processed exploiting the similarity between boolean algebra and statistical algebra. given a random pulse sequence, any boolean operation among individual pulses will correspond to an algebraic expression among the variables represented by their respective average pulse rates. subsequently, this pulse stream can be digitally processed to perform analog operations. in this paper, we propose a stochastic approach to the digital implementation of complex controllers using programmable devices as an alternative to traditional digital signal processors. as an example, a practical realization of nonlinear dissipative controllers for a series resonant converter is presented","['digital stochastic realization', 'complex analog controllers', 'stochastic logic', 'random pulse stream', 'pulse stream', 'finite sequence', 'binary pulse sequence', 'boolean algebra', 'statistical algebra', 'random pulse sequence', 'boolean operation', 'average pulse rates', 'stochastic approach', 'programmable devices', 'nonlinear dissipative controllers', 'series resonant converter', 'parallel resonant dc-to-dc converters', 'series resonant dc-to-dc converters']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M']","['digital stochastic realization', 'complex analog controller', 'stochastic logic', 'random pulse stream', 'pulse stream', 'finite sequence', 'binary pulse sequence', 'boolean algebra', 'statistical algebra', 'random pulse sequence', 'boolean operation', 'average pulse rate', 'stochastic approach', 'programmable device', 'nonlinear dissipative controller', 'series resonant converter', 'parallel resonant dc - to - dc converter', 'series resonant dc - to - dc converter']","['traditional digital signal processor', 'nonlinear dissipative controller', 'series resonant converter', 'digital implementation', 'stochastic logic', 'perform analog operation', 'digital processing', 'random pulse stream', 'binary pulse sequence', 'random pulse sequence']"
58,1355,Comparison of push and pull systems with transporters: a metamodelling approach,"analyses push and pull systems with transportation consideration. a multiproduct, multiline, multistage production system was used to compare the two systems. the effects of four factors (processing time variation, demand variation, transporters, batch size) on throughput rate, average waiting time in the system and machine utilization were studied. the study uses metamodels to compare the two systems. they serve a dual purpose of expressing system performance measures in the form of a simple equation and reducing computational time when comparing the two systems. research shows that the number of transporters used and the batch size have a significant effect on the performance measures of both systems","['pull systems', 'transporters', 'metamodelling approach', 'processing time variation', 'demand variation', 'batch size', 'throughput rate', 'average waiting time', 'machine utilization', 'performance measures', 'push systems', 'multiproduct multiline multistage production system']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['pull system', 'transporter', 'metamodelle approach', 'processing time variation', 'demand variation', 'batch size', 'throughput rate', 'average waiting time', 'machine utilization', 'performance measure', 'push system', 'multiproduct multiline multistage production system']","['multistage production system', 'machine utilization', 'system performance measure', 'pull system', 'throughput rate', 'analysis push', 'performance measure', 'batch size', 'transporter use', 'transporter']"
59,1310,Cat and class: what use are these skills to the new legal information professional?,this article looks at the cataloguing and classification skills taught on information studies courses and the use these skills are to new legal information professionals. the article is based on the opinions of nine new legal information professionals from both academic and law firm libraries,"['legal information professional', 'cataloguing', 'classification', 'information studies courses', 'law firm libraries', 'academic libraries']","['P', 'P', 'P', 'P', 'P', 'R']","['legal information professional', 'catalogue', 'classification', 'information study course', 'law firm librarie', 'academic library']","['new legal information professional', 'information study course', 'classification skill teach', 'catalogue', 'academic', 'skill', 'base', 'article look', 'article', 'use']"
60,130,Resolution of a current-mode algorithmic analog-to-digital converter,"errors limiting the resolution of current-mode algorithmic analog-to-digital converters are mainly related to current mirror operation. while systematic errors can be minimized by proper circuit techniques, random sources are unavoidable. in this paper a statistical analysis of the resolution of a typical converter is carried out taking into account process tolerances. to support the analysis, a 4-bit adc, realized in a 0.35- mu m cmos technology, was exhaustively simulated. results were found to be in excellent agreement with theoretical derivations","['resolution', 'analog-to-digital converters', 'circuit techniques', 'statistical analysis', 'cmos technology', 'current-mode adc', 'algorithmic adc', 'a/d converters', 'error analysis', 'tolerance analysis', 'circuit analysis', '0.35 micron', '4 bit']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'R', 'R', 'R', 'U', 'U']","['resolution', 'analog - to - digital converter', 'circuit technique', 'statistical analysis', 'cmos technology', 'current - mode adc', 'algorithmic adc', 'a / d converter', 'error analysis', 'tolerance analysis', 'circuit analysis', '0.35 micron', '4 bit']","['digital converter', 'typical converter', 'bit adc', 'resolution', 'current mirror operation', 'current', 'tolerance', 'proper circuit', 'systematic error', 'error']"
61,973,Time-integration of multiphase chemistry in size-resolved cloud models,"the existence of cloud drops leads to a transfer of chemical species between the gas and aqueous phases. species concentrations in both phases are modified by chemical reactions and by this phase transfer. the model equations resulting from such multiphase chemical systems are nonlinear, highly coupled and extremely stiff. in the paper we investigate several numerical approaches for treating such processes. the droplets are subdivided into several classes. this decomposition of the droplet spectrum into classes is based on their droplet size and the amount of scavenged material inside the drops, respectively. the very fast dissociations in the aqueous phase chemistry are treated as forward and backward reactions. the aqueous phase and gas phase chemistry, the mass transfer between the different droplet classes among themselves and with the gas phase are integrated in an implicit and coupled manner by the second order bdf method. for this part we apply a modification of the code lsode with special linear system solvers. these direct sparse techniques exploit the special block structure of the corresponding jacobian. furthermore we investigate an approximate matrix factorization which is related to operator splitting at the linear algebra level. the sparse jacobians are generated explicitly and stored in a sparse form. the efficiency and accuracy of our time-integration schemes is discussed for four multiphase chemistry systems of different complexity and for a different number of droplet classes","['multiphase chemistry', 'size-resolved cloud models', 'cloud drops', 'chemical species', 'chemical reactions', 'multiphase chemical systems', 'aqueous phase chemistry', 'gas phase chemistry', 'approximate matrix factorization', 'operator splitting', 'linear algebra', 'sparse jacobians', 'time-integration schemes', 'air pollution modelling']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['multiphase chemistry', 'size - resolve cloud model', 'cloud drop', 'chemical specie', 'chemical reaction', 'multiphase chemical system', 'aqueous phase chemistry', 'gas phase chemistry', 'approximate matrix factorization', 'operator splitting', 'linear algebra', 'sparse jacobian', 'time - integration scheme', 'air pollution modelling']","['gas phase chemistry', 'multiphase chemistry system', 'aqueous phase chemistry', 'droplet spectrum', 'multiphase chemical system', 'linear system solver', 'cloud drop', 'droplet class', 'approximate matrix factorization', 'direct sparse technique exploit']"
62,936,Resonant controllers for smart structures,in this paper we propose a special type of colocated feedback controller for smart structures. the controller is a parallel combination of high-q resonant circuits. each of the resonant circuits is tuned to a pole (or the resonant frequency) of the smart structure. it is proven that the parallel combination of resonant controllers is stable with an infinite gain margin. only one set of actuator-sensor can damp multiple resonant modes with the resonant controllers. experimental results are presented to show the robustness of the proposed controller in damping multimode resonances,"['smart structures', 'smart structures', 'feedback controller', 'high-q resonant circuits', 'resonant frequency', 'actuator-sensor', 'damping', 'multiple resonant modes', 'multimode resonances', 'smart structure', 'laminate beam']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U']","['smart structure', 'smart structure', 'feedback controller', 'high - q resonant circuit', 'resonant frequency', 'actuator - sensor', 'damp', 'multiple resonant mode', 'multimode resonance', 'smart structure', 'laminate beam']","['damp multiple resonant mode', 'resonant controller', 'colocate feedback controller', 'resonant frequency', 'resonant circuit', 'smart structure', 'propose controller', 'smart structure', 'controller', 'actuator']"
63,1248,Public business libraries: the next chapter,"traces the history of the provision of business information by leeds public libraries, uk, from the opening of the public commercial and technical library in 1918 to the revolutionary impact of the internet in the 1990s. describes how the library came to terms with the need to integrate the internet into its mainstream business information services, with particular reference to its limitations and to the provision of company information, market research, british standards information, press cuttings and articles from specialized trade and scientific journals, and patents information. focuses on some of the reasons why the public business library is still needed as a service to businesses, even after the introduction of the internet and considers the library's changing role and the need to impress on all concerned, especially government, the continuing value of these services. looks to the partnerships formed by the library over the years and the ways in which these are expected to assist in realizing future opportunities, in particular, the fact that all public libraries in england gained free internet access at the end of 2001. offers some useful ideas about how the library could develop, noting that sinto, a sheffield based information network formed in 1938 and originally a partnership between the public library, the two sheffield universities and various leading steel companies of the time, is being examined as a model for future services in leeds. concludes that the way forward can be defined in terms of five actions: redefinition of priorities; marketing; budgets; resources; and the use of information technology (it)","['public business libraries', 'history', 'leeds public libraries', 'public commercial and technical library', 'internet', 'business information services', 'company information', 'market research', 'marketing', 'british standards information', 'press cuttings', 'patents information', 'government', 'sinto', 'information network', 'sheffield universities', 'steel companies', 'budgets', 'resources', 'trade journal articles', 'scientific journal articles', 'priority redefinition', 'it use']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R']","['public business librarie', 'history', 'leed public library', 'public commercial and technical library', 'internet', 'business information service', 'company information', 'market research', 'marketing', 'british standard information', 'press cutting', 'patent information', 'government', 'sinto', 'information network', 'sheffield university', 'steel company', 'budget', 'resource', 'trade journal article', 'scientific journal article', 'priority redefinition', 'it use']","['leed public library', 'public business library', 'mainstream business information service', 'sheffield base information network form', 'public library', 'public library', 'free internet access', 'business information', 'technical library', 'company information']"
64,658,Process pioneers [agile business],"by managing it infrastructures along so-called 'top down' lines, organisations can streamline their business processes, eliminate redundant tasks and increase automation","['agile business', 'managing it infrastructures', 'business processes', 'increase automation']","['P', 'P', 'P', 'P']","['agile business', 'manage it infrastructure', 'business process', 'increase automation']","['eliminate redundant task', 'business process', 'infrastructure', 'organisation', 'manage', 'streamline', 'top', 'line', 'call']"
65,62,Text-independent speaker verification using utterance level scoring and covariance modeling,"this paper describes a computationally simple method to perform text independent speaker verification using second order statistics. the suggested method, called utterance level scoring (uls), allows one to obtain a normalized score using a single pass through the frames of the tested utterance. the utterance sample covariance is first calculated and then compared to the speaker covariance using a distortion measure. subsequently, a distortion measure between the utterance covariance and the sample covariance of data taken from different speakers is used to normalize the score. experimental results from the 2000 nist speaker recognition evaluation are presented for uls, used with different distortion measures, and for a gaussian mixture model (gmm) system. the results indicate that uls as a viable alternative to gmm whenever the computational complexity and verification accuracy needs to be traded","['text-independent speaker verification', 'utterance level scoring', 'covariance modeling', 'computationally simple method', 'second order statistics', 'normalized score', 'sample covariance', 'speaker covariance', 'distortion measure', 'distortion measure', 'nist speaker recognition evaluation', 'gaussian mixture model', 'gmm', 'computational complexity', 'verification accuracy', 'distortion measures']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['text - independent speaker verification', 'utterance level scoring', 'covariance modeling', 'computationally simple method', 'second order statistic', 'normalize score', 'sample covariance', 'speaker covariance', 'distortion measure', 'distortion measure', 'nist speaker recognition evaluation', 'gaussian mixture model', 'gmm', 'computational complexity', 'verification accuracy', 'distortion measure']","['perform text independent speaker verification use second order statistic', 'nist speaker recognition evaluation', 'call utterance level scoring', 'utterance sample covariance', 'speaker covariance use', 'normalize score use', 'verification accuracy need', 'utterance covariance', 'gaussian mixture model', 'test utterance']"
66,1149,Deterministic calculations of photon spectra for clinical accelerator targets,"a method is proposed to compute photon energy spectra produced in clinical electron accelerator targets, based on the deterministic solution of the boltzmann equation for coupled electron-photon transport in one-dimensional (1-d) slab geometry. it is shown that the deterministic method gives similar results as monte carlo calculations over the angular range of interest for therapy applications. relative energy spectra computed by deterministic and 3-d monte carlo methods, respectively, are compared for several realistic target materials and different electron beams, and are found to give similar photon energy distributions and mean energies. the deterministic calculations typically require 1-2 mins of execution time on a sun workstation, compared to 2-36 h for the monte carlo runs","['deterministic calculations', 'photon energy spectra', 'clinical electron accelerator targets', 'boltzmann equation', 'coupled electron-photon transport', 'angular range of interest', 'therapy applications', 'relative energy spectra', '3-d monte carlo methods', 'one-dimensional slab geometry', 'linear accelerator', 'therapy planning', 'integrodifferential equation', 'pencil beam source representations']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M', 'M', 'M']","['deterministic calculation', 'photon energy spectra', 'clinical electron accelerator target', 'boltzmann equation', 'couple electron - photon transport', 'angular range of interest', 'therapy application', 'relative energy spectra', '3 - d monte carlo method', 'one - dimensional slab geometry', 'linear accelerator', 'therapy planning', 'integrodifferential equation', 'pencil beam source representation']","['compute photon energy spectra', 'clinical electron accelerator target', 'photon energy distribution', 'monte carlo calculation', 'energy spectra compute', 'electron beam', 'photon transport', 'monte carlo', 'electron', 'boltzmann']"
67,559,Is open source more or less secure?,"networks dominate today's computing landscape and commercial technical protection is lagging behind attack technology. as a result, protection programme success depends more on prudent management decisions than on the selection of technical safeguards. the paper takes a management view of protection and seeks to reconcile the need for security with the limitations of technology","['commercial technical protection', 'attack technology', 'management', 'open source software security', 'computer networks', 'data security']","['P', 'P', 'P', 'M', 'R', 'M']","['commercial technical protection', 'attack technology', 'management', 'open source software security', 'computer network', 'datum security']","['commercial technical protection', 'technical safeguard', 'protection programme success depend', 'attack technology', 'security', 'protection', 'prudent management decision', 'network dominate today', 'management view', 'compute landscape']"
68,747,Simulation of cardiovascular physiology: the diastolic function(s) of the heart,the cardiovascular system was simulated by using an equivalent electronic circuit. four sets of simulations were performed. the basic variables investigated were cardiac output and stroke volume. they were studied as functions (i) of right ventricular capacitance and negative intrathoracic pressure; (ii) of left ventricular relaxation and of heart rate; and (iii) of left ventricle failure. it seems that a satisfactory simulation of systolic and diastolic functions of the heart is possible. presented simulations improve our understanding of the role of the capacitance of both ventricles and of the diastolic relaxation in cardiovascular physiology,"['simulation', 'cardiovascular physiology', 'diastolic function', 'heart', 'equivalent electronic circuit', 'cardiac output', 'stroke volume', 'right ventricular capacitance', 'negative intrathoracic pressure', 'left ventricular relaxation', 'heart rate', 'left ventricle failure', 'diastolic relaxation', 'systolic functions']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['simulation', 'cardiovascular physiology', 'diastolic function', 'heart', 'equivalent electronic circuit', 'cardiac output', 'stroke volume', 'right ventricular capacitance', 'negative intrathoracic pressure', 'leave ventricular relaxation', 'heart rate', 'leave ventricle failure', 'diastolic relaxation', 'systolic function']","['right ventricular capacitance', 'leave ventricular relaxation', 'diastolic relaxation', 'leave ventricle', 'cardiovascular system', 'cardiac output', 'diastolic function', 'ventricle', 'electronic circuit', 'systolic']"
69,702,A comparison of high-power converter topologies for the implementation of FACTS controllers,"this paper compares four power converter topologies for the implementation of flexible ac transmission system (facts) controllers: three multilevel topologies (multipoint clamped (mpc), chain, and nested cell) and the well-established multipulse topology. in keeping with the need to implement very-high-power inverters, switching frequency is restricted to line frequency. the study addresses device count, dc filter ratings, restrictions on voltage control, active power transfer through the dc link, and balancing of dc-link voltages. emphasis is placed on capacitor sizing because of its impact on the cost and size of the facts controller. a method for the dimensioning the dc capacitor filter is presented. it is found that the chain converter is attractive for the implementation of a static compensator or a static synchronous series compensator. the mpc converter is attractive for the implementation of a unified power flow controller or an interline power flow controller, but a special arrangement is required to overcome the limitations on voltage control","['facts controllers', 'multilevel topologies', 'multipulse topology', 'inverters', 'switching frequency', 'device count', 'dc filter ratings', 'static compensator', 'static synchronous series compensator', 'unified power flow controller', 'high-power converter topologies comparison', 'multipoint clamped topology', 'statcom', 'upfc']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U', 'U']","['fact controller', 'multilevel topology', 'multipulse topology', 'inverter', 'switch frequency', 'device count', 'dc filter rating', 'static compensator', 'static synchronous series compensator', 'unify power flow controller', 'high - power converter topology comparison', 'multipoint clamp topology', 'statcom', 'upfc']","['dc capacitor filter', 'power converter topology', 'mpc converter', 'fact controller', 'flexible ac transmission system', 'chain converter', 'power inverter', 'multilevel topology', 'dc filter', 'switch frequency']"
70,1357,Work sequencing in a manufacturing cell with limited labour constraints,"this study focuses on the analysis of group scheduling heuristics in a dual-constrained, automated manufacturing cell, where labour utilization is limited to setups, tear-downs and loads/unloads. this scenario is realistic in today's automated manufacturing cells. the results indicate that policies for allocating labour to tasks have very little impact in such an environment. furthermore, the performance of efficiency oriented, exhaustive, group scheduling heuristics deteriorated while the performance of the more complex, non-exhaustive heuristics improved. thus, it is recommended that production managers use the simplest labour scheduling policy, and instead focus their efforts to activities such as job scheduling and production planning in such environments","['work sequencing', 'manufacturing cell', 'limited labour constraints', 'group scheduling heuristics', 'automated manufacturing cells', 'job scheduling', 'production planning', 'dual-constrained automated manufacturing cell', 'labour allocation policies', 'efficiency oriented exhaustive group scheduling heuristics', 'nonexhaustive heuristics']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M']","['work sequence', 'manufacture cell', 'limit labour constraint', 'group scheduling heuristic', 'automate manufacturing cell', 'job scheduling', 'production planning', 'dual - constrain automate manufacturing cell', 'labour allocation policy', 'efficiency orient exhaustive group scheduling heuristic', 'nonexhaustive heuristic']","['group scheduling heuristic deteriorate', 'group scheduling heuristic', 'simple labour scheduling policy', 'job scheduling', 'automate manufacturing cell', 'automate manufacturing cell', 'production manager', 'allocate labour', 'labour utilization', 'production planning']"
71,1312,Stability in the numerical solution of the heat equation with nonlocal boundary conditions,"this paper deals with numerical methods for the solution of the heat equation with integral boundary conditions. finite differences are used for the discretization in space. the matrices specifying the resulting semidiscrete problem are proved to satisfy a sectorial resolvent condition, uniformly with respect to the discretization parameter. using this resolvent condition, unconditional stability is proved for the fully discrete numerical process generated by applying a( theta )-stable one-step methods to the semidiscrete problem. this stability result is established in the maximum norm; it improves some previous results in the literature in that it is not subject to various unnatural restrictions which were imposed on the boundary conditions and on the one-step methods","['stability', 'numerical solution', 'heat equation', 'nonlocal boundary conditions', 'integral boundary conditions', 'finite differences', 'matrices', 'semidiscrete problem', 'sectorial resolvent condition', 'fully discrete numerical process', 'one-step methods', 'maximum norm', 'space discretization']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['stability', 'numerical solution', 'heat equation', 'nonlocal boundary condition', 'integral boundary condition', 'finite difference', 'matrix', 'semidiscrete problem', 'sectorial resolvent condition', 'fully discrete numerical process', 'one - step method', 'maximum norm', 'space discretization']","['discretization parameter', 'integral boundary condition', 'numerical method', 'sectorial resolvent condition', 'discrete numerical process', 'discretization', 'boundary condition', 'resolvent condition', 'semidiscrete problem', 'heat equation']"
72,829,Santera targets independents in major strategy overhaul [telecom],"with big carriers slashing capital expense budgets, santera systems is broadening the reach of its next-generation switching platform to include independent telcos. this week, the vendor will announce that it has signed a deal with kerman, calif-based kerman telephone co. furthermore, the company is angling for inclusion in the rural utilities service's approved equipment list, hoping to sell its class 5 replacement boxes to the smallest carriers. the move is almost a complete reversal for the plano, texas-based vendor, which previously focused solely on large carriers, including the rbocs","['santera systems', 'switching', 'kerman telephone', 'rural utilities service']","['P', 'P', 'P', 'P']","['santera system', 'switch', 'kerman telephone', 'rural utility service']","['big carrier slash capital expense budget', 'santera system', 'base kerman telephone', 'include independent telco', 'large carrier', 'rural utility service', 'small carrier', 'generation switch platform', 'replacement box', 'base vendor']"
73,891,Establishing the discipline of physics-based CMP modeling,"for the past decade, a physically based comprehensive process model for chemical mechanical polishing has eluded the semiconductor industry. however, a long-term collaborative effort has now resulted in a workable version of that approach. the highly fundamental model is based on advanced finite element analysis and is beginning to show promise in cmp process development","['cmp', 'chemical mechanical polishing', 'finite element analysis', 'cmp process development', 'physically based process model']","['P', 'P', 'P', 'P', 'R']","['cmp', 'chemical mechanical polishing', 'finite element analysis', 'cmp process development', 'physically base process model']","['chemical mechanical polishing', 'comprehensive process model', 'semiconductor industry', 'fundamental model', 'advance finite element analysis', 'collaborative effort', 'workable', 'approach', 'show']"
74,1056,Eliminating recency with self-review: the case of auditors' 'going concern' judgments,"this paper examines the use of self-review to debias recency. recency is found in the 'going concern' judgments of staff auditors, but is successfully eliminated by the auditor's use of a simple self-review technique that would be extremely easy to implement in audit practice. auditors who self-review are also less inclined to make audit report choices that are inconsistent with their going concern judgments. these results are important because the judgments of staff auditors often determine the type and extent of documentation in audit workpapers and serve as preliminary inputs for senior auditors' judgments and choices. if staff auditors' judgments are affected by recency, the impact of this bias may be impounded in the ultimate judgments and choices of senior auditors. since biased judgments can expose auditors to significant costs involving extended audit procedures, legal liability and diminished reputation, simple debiasing techniques that reduce this exposure are valuable. the paper also explores some future research needs and other important issues concerning judgment debiasing in applied professional settings","['self-review', 'staff auditors', 'audit report choices', 'documentation', 'audit workpapers', 'senior auditors', 'extended audit procedures', 'legal liability', 'diminished reputation', 'judgment debiasing', 'applied professional settings', 'auditor going concern judgments', 'recency debiasing', 'accountability', 'probability judgments']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U', 'M']","['self - review', 'staff auditor', 'audit report choice', 'documentation', 'audit workpaper', 'senior auditor', 'extend audit procedure', 'legal liability', 'diminish reputation', 'judgment debiase', 'apply professional setting', 'auditor go concern judgment', 'recency debiase', 'accountability', 'probability judgment']","['other important issue concern judgment debiase', 'significant cost involve extended audit procedure', 'make audit report choice', 'staff auditor', 'bias judgment', 'concern judgment', 'audit workpaper', 'audit practice', 'expose auditor', 'simple debiasing technique']"
75,1013,A scalable intelligent takeoff controller for a simulated running jointed leg,"running with jointed legs poses a difficult control problem in robotics. neural controllers are attractive because they allow the robot to adapt to changing environmental conditions. however, scalability is an issue with many neural controllers. the paper describes the development of a scalable neurofuzzy controller for the takeoff phase of the running stride. scalability is achieved by selecting a controller whose size does not grow with the dimensionality of the problem. empirical results show that with proper design the takeoff controller scales from a leg with a single movable link to one with three movable links without a corresponding growth in size and without a loss of accuracy","['scalable intelligent takeoff controller', 'scalability', 'simulated running jointed leg', 'neural controllers', 'changing environmental conditions', 'scalable neurofuzzy controller', 'takeoff phase', 'running stride', 'intelligent robotic control']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['scalable intelligent takeoff controller', 'scalability', 'simulate run jointed leg', 'neural controller', 'change environmental condition', 'scalable neurofuzzy controller', 'takeoff phase', 'run stride', 'intelligent robotic control']","['scalable neurofuzzy controller', 'takeoff controller scale', 'run stride', 'joint leg pose', 'many neural controller', 'neural controller', 'robotic', 'takeoff', 'controller', 'robot']"
76,60,Perceptual audio coding using adaptive pre- and post-filters and lossless compression,"this paper proposes a versatile perceptual audio coding method that achieves high compression ratios and is capable of low encoding/decoding delay. it accommodates a variety of source signals (including both music and speech) with different sampling rates. it is based on separating irrelevance and redundancy reductions into independent functional units. this contrasts traditional audio coding where both are integrated within the same subband decomposition. the separation allows for the independent optimization of the irrelevance and redundancy reduction units. for both reductions, we rely on adaptive filtering and predictive coding as much as possible to minimize the delay. a psycho-acoustically controlled adaptive linear filter is used for the irrelevance reduction, and the redundancy reduction is carried out by a predictive lossless coding scheme, which is termed weighted cascaded least mean squared (wclms) method. experiments are carried out on a database of moderate size which contains mono-signals of different sampling rates and varying nature (music, speech, or mixed). they show that the proposed wclms lossless coder outperforms other competing lossless coders in terms of compression ratios and delay, as applied to the pre-filtered signal. moreover, a subjective listening test of the combined pre-filter/lossless coder and a state-of-the-art perceptual audio coder (pac) shows that the new method achieves a comparable compression ratio and audio quality with a lower delay","['perceptual audio coding', 'lossless compression', 'high compression ratio', 'low encoding/decoding delay', 'source signals', 'music', 'sampling rates', 'redundancy reduction', 'adaptive filtering', 'predictive coding', 'psycho-acoustically controlled adaptive linear filter', 'irrelevance reduction', 'predictive lossless coding', 'weighted cascaded least mean squared', 'wclms lossless coder', 'subjective listening test', 'pre-filter/lossless coder', 'audio quality', 'adaptive pre-filters', 'adaptive post-filters']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['perceptual audio code', 'lossless compression', 'high compression ratio', 'low encoding / decode delay', 'source signal', 'music', 'sample rate', 'redundancy reduction', 'adaptive filtering', 'predictive coding', 'psycho - acoustically control adaptive linear filter', 'irrelevance reduction', 'predictive lossless coding', 'weight cascade least mean square', 'wclm lossless coder', 'subjective listening test', 'pre - filter / lossless coder', 'audio quality', 'adaptive pre - filter', 'adaptive post - filter']","['versatile perceptual audio code method', 'art perceptual audio coder', 'wclm lossless coder outperform', 'predictive lossless coding', 'audio code', 'term weight cascade least mean square', 'lossless coder', 'adaptive linear filter', 'audio quality', 'comparable compression ratio']"
77,132,A unified view for vector rotational CORDIC algorithms and architectures based on angle quantization approach,"vector rotation is the key operation employed extensively in many digital signal processing applications. in this paper, we introduce a new design concept called angle quantization (aq). it can be used as a design index for vector rotational operation, where the rotational angle is known in advance. based on the aq process, we establish a unified design framework for cost-effective low-latency rotational algorithms and architectures. several existing works, such as conventional coordinate rotational digital computer (cordic), ar-cordic, mvr-cordic, and eeas-based cordic, can be fitted into the design framework, forming a vector rotational cordic family. moreover, we address four searching algorithms to solve the optimization problem encountered in the proposed vector rotational cordic family. the corresponding scaling operations of the cordic family are also discussed. based on the new design framework, we can realize high-speed/low-complexity rotational vlsi circuits, whereas without degrading the precision performance in fixed-point implementations","['vector rotational cordic algorithms', 'angle quantization', 'digital signal processing applications', 'design index', 'vector rotational operation', 'unified design framework', 'low-latency rotational algorithms', 'searching algorithms', 'optimization problem', 'scaling operations', 'low-complexity rotational vlsi circuits', 'fixed-point implementations', 'dsp applications', 'greedy searching algorithm', 'low-latency rotational architectures', 'high-speed rotational vlsi circuits', 'trellis-based searching algorithm']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'R', 'R', 'M']","['vector rotational cordic algorithm', 'angle quantization', 'digital signal processing application', 'design index', 'vector rotational operation', 'unify design framework', 'low - latency rotational algorithm', 'search algorithm', 'optimization problem', 'scale operation', 'low - complexity rotational vlsi circuit', 'fix - point implementation', 'dsp application', 'greedy search algorithm', 'low - latency rotational architecture', 'high - speed rotational vlsi circuit', 'trellis - base searching algorithm']","['vector rotational cordic family', 'complexity rotational vlsi circuit', 'coordinate rotational digital computer', 'vector rotational operation', 'latency rotational algorithm', 'vector rotation', 'rotational angle', 'cordic family', 'cordic', 'search algorithm']"
78,971,Homogenization in L/sup infinity /,"homogenization of deterministic control problems with l/sup infinity / running cost is studied by viscosity solutions techniques. it is proved that the value function of an l/sup infinity / problem in a medium with a periodic micro-structure converges uniformly on the compact sets to the value function of the homogenized problem as the period shrinks to 0. our main convergence result extends that of ishii (stochastic analysis, control, optimization and applications, pp. 305-324, birkhauser boston, boston, ma, 1999.) to the case of a discontinuous hamiltonian. the cell problem is solved, but, as nonuniqueness occurs, the effective hamiltonian must be selected in a careful way. the paper also provides a representation formula for the effective hamiltonian and gives illustrations to calculus of variations, averaging and one-dimensional problems","['homogenization', 'deterministic control', 'l/sup infinity / running cost', 'value function', 'convergence', 'cell problem', 'calculus of variations', 'averaging', 'optimal control']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['homogenization', 'deterministic control', 'l / sup infinity / running cost', 'value function', 'convergence', 'cell problem', 'calculus of variation', 'average', 'optimal control']","['discontinuous hamiltonian', 'deterministic control problem', 'stochastic analysis', 'effective hamiltonian', 'viscosity solution', 'homogenize problem', 'periodic micro', 'compact set', 'sup infinity', 'optimization']"
79,934,Induced-shear piezoelectric actuators for rotor blade trailing edge flaps,"much of the current rotorcraft research is focused on improving performance by reducing unwanted helicopter noise and vibration. one of the most promising active rotorcraft vibration control systems is an active trailing edge flap. in this paper, an induced-shear piezoelectric tube actuator is used in conjunction with a simple lever-cusp hinge amplification device to generate a useful combination of trailing edge flap deflections and hinge moments. a finite-element model of the actuator tube and trailing edge flap (including aerodynamic and inertial loading) was used to guide the design of the actuator-flap system. a full-scale induced shear tube actuator flap system was fabricated and bench top testing was conducted to validate the analysis. hinge moments corresponding to various rotor speeds were applied to the actuator using mechanical springs. the testing demonstrated that for an applied electric field of 3 kv cm/sup -1/ the tube actuator deflected a representative full-scale 12 inch flap +or-2.8 degrees at 0 rpm and +or-1.4 degrees for a hinge moment simulating a 400 rpm condition. the per cent error between the predicted and experimental full-scale flap deflections ranged from 4% (low rpm) to 12.5% (large rpm). increasing the electric field to 4 kv cm/sup -1/ results in +or-2.5 degrees flap deflection at a rotation speed of 400 rpm, according to the design analysis. a trade study was conducted to compare the performance of the piezoelectric tube actuator to the state of the art in trailing edge flap actuators and indicated that the induced-shear tube actuator shows promise as a trailing edge flap actuator","['rotorcraft', 'helicopter noise', 'vibration control', 'active trailing edge flap', 'piezoelectric tube actuator', 'lever-cusp hinge amplification device', 'finite-element model', 'inertial loading', 'design', 'shear tube actuator flap', 'bench top testing', '12 inch flap', '12 inch', 'induced-shear tube actuator', 'helicopter vibration', 'aerodynamic loading']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['rotorcraft', 'helicopter noise', 'vibration control', 'active trail edge flap', 'piezoelectric tube actuator', 'lever - cusp hinge amplification device', 'finite - element model', 'inertial loading', 'design', 'shear tube actuator flap', 'bench top testing', '12 inch flap', '12 inch', 'induce - shear tube actuator', 'helicopter vibration', 'aerodynamic loading']","['shear tube actuator flap system', 'shear piezoelectric tube actuator', 'piezoelectric tube actuator', 'actuator use mechanical spring', 'trail edge flap actuator', 'active rotorcraft vibration control', 'tube actuator deflect', 'shear tube actuator', 'actuator tube', 'trail edge flap deflection']"
80,1232,Techniques for compiling and implementing all NAS parallel benchmarks in HPF,"the nas parallel benchmarks (npb) are a well-known benchmark set for high-performance machines. much effort has been made to implement them in high-performance fortran (hpf). in previous attempts, however, the hpf versions did not include the complete set of benchmarks, and the performance was not always good. in this study, we implement all eight benchmarks of the npb in hpf, and parallelize them using an hpf compiler that we have developed. this report describes the implementation techniques and compiler features necessary to achieve good performance. we evaluate the hpf version on the hitachi sr2201, a distributed-memory parallel machine. with 16 processors, the execution time of the hpf version is within a factor of 1.5 of the hand-parallelized version of the npb 2.3 beta","['compiler', 'nas parallel benchmarks', 'high-performance machines', 'hpf compiler', 'distributed-memory parallel supercomputers']","['P', 'P', 'P', 'P', 'M']","['compiler', 'nas parallel benchmark', 'high - performance machine', 'hpf compiler', 'distribute - memory parallel supercomputer']","['nas parallel benchmark', 'performance fortran', 'memory parallel machine', 'hpf compiler', 'performance machine', 'parallelize version', 'compiler feature', 'benchmark', 'parallelize', 'know benchmark']"
81,1277,Dynamic modification of object Petri nets. An application to modelling protocols with fork-join structures,in this paper we discuss possibilities of modelling protocols by objects in object-based high-level petri nets. some advantages of dynamically modifying the structure of token objects are discussed and the need for further investigations into mathematically rigorous foundations of object net formalisms incorporating facilities for such operations on its token nets is emphasised,"['dynamic modification', 'object petri nets', 'protocols', 'fork-join structures', 'token objects', 'mathematically rigorous foundations', 'object net formalisms']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['dynamic modification', 'object petri net', 'protocol', 'fork - join structure', 'token object', 'mathematically rigorous foundation', 'object net formalism']","['object net formalism incorporate facility', 'level petri net', 'model protocol', 'token object', 'token net', 'object', 'such operation', 'object', 'rigorous foundation', 'structure']"
82,622,Source/channel coding of still images using lapped transforms and block classification,"a novel scheme for joint source/channel coding of still images is proposed. by using efficient lapped transforms, channel-optimised robust quantisers and classification methods it is shown that significant improvements over traditional source/channel coding of images can be obtained while keeping the complexity low","['still images', 'lapped transforms', 'block classification', 'channel-optimised robust quantisers', 'joint source-channel coding', 'image coding', 'low complexity']","['P', 'P', 'P', 'P', 'M', 'R', 'R']","['still image', 'lapped transform', 'block classification', 'channel - optimise robust quantiser', 'joint source - channel coding', 'image code', 'low complexity']","['channel code', 'optimise robust quantiser', 'use efficient lapped transform', 'image', 'classification method', 'channel', 'joint source', 'keep', 'source', 'scheme']"
83,909,Influence of the process design on the control strategy: application in electropneumatic field,"this article proposes an example of electropneumatic system where the architecture of the process is modified with respect to both the specifications for position and velocity tracking and a criterion concerning the energy consumption. experimental results are compared and analyzed using an industrial bench test. for this, a complete model of the system is presented, and two kinds of nonlinear control laws are developed, a monovariable and multivariable type based on the flatness theory","['electropneumatic systems', 'tracking', 'energy consumption', 'nonlinear control', 'flatness theory', 'positioning systems', 'position control', 'monovariable control', 'multivariable control', 'velocity control']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'R']","['electropneumatic system', 'track', 'energy consumption', 'nonlinear control', 'flatness theory', 'position system', 'position control', 'monovariable control', 'multivariable control', 'velocity control']","['electropneumatic system', 'nonlinear control law', 'velocity tracking', 'multivariable type base', 'industrial bench', 'monovariable', 'specification', 'system', 'position', 'energy']"
84,1133,An analytic center cutting plane method for semidefinite feasibility problems,"semidefinite feasibility problems arise in many areas of operations research. the abstract form of these problems can be described as finding a point in a nonempty bounded convex body gamma in the cone of symmetric positive semidefinite matrices. assume that gamma is defined by an oracle, which for any given m * m symmetric positive semidefinite matrix gamma either confirms that y epsilon gamma or returns a cut, i.e., a symmetric matrix a such that gamma is in the half-space {y : a . y <or= a . y}. we study an analytic center cutting plane algorithm for this problem. at each iteration, the algorithm computes an approximate analytic center of a working set defined by the cutting plane system generated in the previous iterations. if this approximate analytic center is a solution, then the algorithm terminates; otherwise the new cutting plane returned by the oracle is added into the system. as the number of iterations increases, the working set shrinks and the algorithm eventually finds a solution to the problem. all iterates generated by the algorithm are positive definite matrices. the algorithm has a worst-case complexity of o*(m/sup 3// epsilon /sup 2/) on the total number of cuts to be used, where epsilon is the maximum radius of a ball contained by gamma","['analytic center cutting plane method', 'semidefinite feasibility problems', 'operations research', 'nonempty bounded convex body', 'symmetric positive semidefinite matrices', 'oracle', 'iteration', 'approximate analytic center', 'working set', 'worst-case complexity', 'maximum ball radius']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['analytic center cut plane method', 'semidefinite feasibility problem', 'operation research', 'nonempty bound convex body', 'symmetric positive semidefinite matrix', 'oracle', 'iteration', 'approximate analytic center', 'work set', 'bad - case complexity', 'maximum ball radius']","['analytic center cut plane algorithm', 'symmetric positive semidefinite matrix gamma', 'semidefinite feasibility problem arise', 'symmetric positive semidefinite matrix', 'cut plane system generate', 'algorithm compute', 'algorithm terminate', 'cut plane return', 'approximate analytic center', 'bound convex']"
85,1176,A summary of methods applied to tool condition monitoring in drilling,"presents a summary of the monitoring methods, signal analysis and diagnostic techniques for tool wear and failure monitoring in drilling that have been tested and reported in the literature. the paper covers only indirect monitoring methods such as force, vibration and current measurements. signal analysis techniques cover all the methods that have been used with indirect measurements including e.g. statistical parameters and fast fourier and wavelet transform. only a limited number of automatic diagnostic tools have been developed for diagnosis of the condition of the tool in drilling. all of these rather diverse approaches that have been available are covered in this study. only in a few of the papers have attempts been made to compare the chosen approach with other methods. many of the papers only present one approach and unfortunately quite often the test material of the study is limited especially in what comes to the cutting process parameter variation and also workpiece material","['tool condition monitoring', 'drilling', 'monitoring methods', 'signal analysis', 'diagnostic techniques', 'tool wear', 'failure monitoring', 'indirect monitoring methods', 'current measurements', 'statistical parameters', 'wavelet transform', 'automatic diagnostic tools', 'force measurements', 'vibration measurements', 'fast fourier transform']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['tool condition monitoring', 'drill', 'monitor method', 'signal analysis', 'diagnostic technique', 'tool wear', 'failure monitoring', 'indirect monitoring method', 'current measurement', 'statistical parameter', 'wavelet transform', 'automatic diagnostic tool', 'force measurement', 'vibration measurement', 'fast fouri transform']","['automatic diagnostic tool', 'drill', 'signal analysis technique', 'tool wear', 'failure monitoring', 'monitor method', 'signal analysis', 'tool', 'cut process parameter', 'diagnostic technique']"
86,566,Sensing and control of double-sided arc welding process,"the welding industry is driven to improve productivity without sacrificing quality. for thick material welding, the current practice is to use backing or multiple passes. the laser welding process, capable of achieving deep narrow penetration, can significantly improve welding productivity for such applications by reducing the number of passes. however, its competitiveness in comparison with traditional arc welding is weakened by its high cost, strict fit-up requirement, and difficulty in welding large structures. in this work, a different method, referred to as double-sided arc welding (dsaw) is developed to improve the arc concentration for arc welding. a sensing and control system is developed to achieve deep narrow penetration under variations in welding conditions. experiments verified that the pulsed keyhole dsaw system developed is capable of achieving deep narrow penetration on a 1/2 inch thick square butt joint in a single pass","['double-sided arc welding', 'thick material welding', 'laser welding process', 'control system', 'process control', 'energy density', 'controlled pulse keyhole']","['P', 'P', 'P', 'P', 'R', 'U', 'R']","['double - sided arc welding', 'thick material welding', 'laser welding process', 'control system', 'process control', 'energy density', 'control pulse keyhole']","['side arc welding', 'arc welding', 'laser welding process', 'pulse keyhole dsaw', 'improve welding productivity', 'weld industry', 'achieve deep narrow penetration', 'inch thick square butt joint', 'weld', 'deep narrow penetration']"
87,6,SBC gets more serious on regulatory compliance,"with one eye on the past and the other on its future, sbc communications last week created a unit it hopes will bring a cohesiveness and efficiency to its regulatory compliance efforts that previously had been lacking. the carrier also hopes the new regulatory compliance unit will help it accomplish its short-term goal of landing fcc approval. to provide long-distance service throughout its region, and its longer-term, goal of reducing the regulatory burdens under which it and currently operate","['regulatory compliance', 'sbc communications', 'telecom carrier']","['P', 'P', 'M']","['regulatory compliance', 'sbc communication', 'telecom carrier']","['sbc communication last week create', 'new regulatory compliance unit', 'land fcc approval', 'regulatory compliance effort', 'distance service', 'regulatory burden', 'carrier', 'provide long', 'term goal', 'unit']"
88,1397,Computer program for calculating the p-value in testing process capability index C/sub pmk/,"many process capability indices, including c/sub p/, c/sub pk/, and c/sub pm/, have been proposed to provide numerical measures on the process potential and performance. combining the advantages of these indices, pearn et al. (1992) introduced a new capability index called c/sub pmk/, which has been shown to be a useful capability index for processes with two-sided specification limits. in this paper, the authors implement the theory of a testing hypothesis using the natural estimator of c/sub pmk/, and provide an efficient maple computer program to calculate the p-values. they also provide tables of the critical values for some commonly used capability requirements. based on the test, they develop a simple step-by-step procedure for in-plant applications. the practitioners can use the proposed procedure to determine whether their process meets the preset capability requirement, and make reliable decisions","['computer program', 'testing process capability index', 'process potential', 'testing hypothesis', 'natural estimator', 'maple', 'in-plant applications', 'preset capability requirement', 'reliable decisions', 'process performance', 'p-value calculation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['computer program', 'testing process capability index', 'process potential', 'test hypothesis', 'natural estimator', 'maple', 'in - plant application', 'preset capability requirement', 'reliable decision', 'process performance', 'p - value calculation']","['many process capability index', 'capability requirement', 'preset capability requirement', 'useful capability index', 'new capability index', 'specification limit', 'efficient maple computer program', 'process potential', 'provide numerical measure', 'plant application']"
89,787,New kit on the block [IT upgrades],"as time passes, new hardware and software replace the old. the hows are straightforward: it resellers and consultants can help with upgrade practicalities. will dalrymple examines the business issues and costs involved in it upgrades","['it upgrades', 'it resellers', 'consultants', 'business issues', 'costs', 'microsoft']","['P', 'P', 'P', 'P', 'P', 'U']","['it upgrade', 'it reseller', 'consultant', 'business issue', 'cost', 'microsoft']","['upgrade practicality', 'new hardware', 'software replace', 'dalrymple examine', 'business issue', 'reseller', 'cost involve', 'consultant', 'old', 'help']"
90,1096,Evaluating alternative manufacturing control strategies using a benchmark system,"this paper describes an investigation of the effects of dynamic job routing and job sequencing decisions on the performance of a distributed control system and its adaptability against disturbances. this experimental work was carried out to compare the performance of alternative control strategies in various manufacturing environments and to investigate the relationship between the 'control' and 'controlled' systems. the experimental test-bed presented in this paper consists of an agent-based control system (implemented in c++) and a discrete-event simulation model. using this test-bed, various control strategies were tested on a benchmark manufacturing system by varying production volumes (to model the production system with looser/tighter schedules) and disturbance frequencies. it was found that hybrid strategies that combine reactive agent mechanisms (and allocation strategies such as the contract net) with appropriate job sequencing heuristics provide the best performance, particularly when job congestion increases on a shop-floor","['alternative manufacturing control strategies', 'benchmark system', 'dynamic job routing', 'job sequencing decisions', 'distributed control system', 'experimental test-bed', 'agent-based control system', 'discrete-event simulation model', 'benchmark manufacturing system', 'production volumes', 'disturbance frequencies', 'hybrid strategies', 'reactive agent mechanisms', 'allocation strategies', 'contract net', 'job congestion', 'disturbance adaptability']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['alternative manufacturing control strategy', 'benchmark system', 'dynamic job route', 'job sequence decision', 'distribute control system', 'experimental test - bed', 'agent - base control system', 'discrete - event simulation model', 'benchmark manufacturing system', 'production volume', 'disturbance frequency', 'hybrid strategy', 'reactive agent mechanism', 'allocation strategy', 'contract net', 'job congestion', 'disturbance adaptability']","['combine reactive agent mechanism', 'appropriate job sequence heuristic', 'distribute control system', 'dynamic job route', 'job sequence decision', 'various control strategy', 'alternative control strategy', 'base control system', 'benchmark manufacturing system', 'event simulation model']"
91,1447,International swinging: making Swing components locale-sensitive,"although java and its gui library swing provide software developers with a highly customizable framework for creating truly ""international"" applications, the swing library is not sensitive to locale switches: it cannot automatically change an application's appearance to conform to the conventions of a specific locale at run time. several types of applications benefit from the ability to easily switch the language at run time. training applications and other programs that run on computers in public spaces (such as libraries, airports, or government offices) may need to support multiple languages. other applications (like travel dictionaries or translation programs) are inherently multilingual and are specifically designed to support users of dissimilar tongues. such applications would greatly benefit if the user-interface language could be customized at run time. the article shows you how to customize swing to support locale switching at run time. the author has created a new look-and-feel called the mlmetallookandfeel (where ml stands for multilingual). this new look-and-feel extends the standard metal look-and-feel but is locale-sensitive at run time","['java', 'gui library', 'swing library', 'locale switching', 'travel dictionaries', 'translation programs', 'user-interface language', 'mlmetallookandfeel']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['java', 'gui library', 'swing library', 'locale switch', 'travel dictionary', 'translation program', 'user - interface language', 'mlmetallookandfeel']","['gui library swing', 'locale switch', 'locale switch', 'interface language', 'customize swing', 'customizable framework', 'multiple language', 'specific locale', 'swing library', 'multilingual']"
92,1402,Web talk is cheap,web technology provides a wealth of opportunities for reaching potential customers. so how do you make it work for your business?,"['website', 'web chat', 'collaborative browsing', 'customer service representative', 'call centre']","['U', 'M', 'U', 'M', 'U']","['website', 'web chat', 'collaborative browsing', 'customer service representative', 'call centre']","['web technology provide', 'reach potential customer', 'business', 'wealth', 'work', 'opportunity', 'make']"
93,814,A framework for image deblurring using wavelet packet bases,"we show that the average over translations of an operator diagonal in a wavelet packet basis is a convolution. we also show that an operator diagonal in a wavelet packet basis can be decomposed into several operators of the same kind, each of them being better conditioned. we investigate the possibility of using such a convolution to approximate a given convolution (in practice an image blur). then we use these approximations to deblur images. first, we show that this framework permits us to redefine existing deblurring methods. then, we show that it permits us to define a new variational method which combines the wavelet packet and the total variation approaches. we argue and show by experiments that this permits us to avoid the drawbacks of both approaches which are, respectively, ringing and staircasing","['image deblurring', 'wavelet packet bases', 'operator diagonal', 'convolution', 'total variation approach', 'ringing', 'staircasing', 'deconvolution']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'U']","['image deblurre', 'wavelet packet basis', 'operator diagonal', 'convolution', 'total variation approach', 'ring', 'staircase', 'deconvolution']","['wavelet packet basis', 'wavelet packet', 'redefine exist deblurre method', 'image blur', 'new variational method', 'deblur image', 'total variation approach', 'give convolution', 'convolution', 'operator diagonal']"
94,851,Unlocking the clubhouse: the Carnegie Mellon experience,"in the fall of 1995, just seven of 95 students entering the undergraduate program in computer science at carnegie mellon university were women. in 2000, 54 of 130, or 42%, were women. what happened? this article presents a brief history of the transformation at carnegie mellon's school of computer science, and the research project that lay behind it","['students', 'undergraduate program', 'carnegie mellon university', 'women', 'history', 'research project', 'computer science education', 'gender issues']","['P', 'P', 'P', 'P', 'P', 'P', 'M', 'U']","['student', 'undergraduate program', 'carnegie mellon university', 'woman', 'history', 'research project', 'computer science education', 'gender issue']","['carnegie mellon university', 'carnegie mellon', 'undergraduate program', 'student enter', 'computer science', 'woman', 'research project', 'school', 'brief history', 'happen']"
95,84,Efficient cellular automata based versatile multiplier for GF(2/sup m/),"in this paper, a low-complexity programmable cellular automata (pca) based versatile modular multiplier in gf(2/sup m/) is presented. the proposed versatile multiplier increases flexibility by using the same multiplier in different security environments, and it reduces the user's cost. moreover, the multiplier can be easily extended to high order of m for more security, and low-cost serial implementation is feasible in restricted computing environments, such as smart cards and wireless devices","['cellular automata based versatile multiplier', 'low-complexity programmable cellular automata', 'security environments', 'restricted computing environments', 'smart cards', 'wireless devices']","['P', 'P', 'P', 'P', 'P', 'P']","['cellular automata base versatile multipli', 'low - complexity programmable cellular automata', 'security environment', 'restrict compute environment', 'smart card', 'wireless device']","['complexity programmable cellular automata', 'versatile modular multipli', 'propose versatile multipli increase flexibility', 'cost serial implementation', 'restrict compute environment', 'multiplier', 'different security environment', 'smart card', 'security', 'pca']"
96,1117,An attack-finding algorithm for security protocols,"this paper proposes an automatic attack construction algorithm in order to find potential attacks on security protocols. it is based on a dynamic strand space model, which enhances the original strand space model by introducing active nodes on strands so as to characterize the dynamic procedure of protocol execution. with exact causal dependency relations between messages considered in the model, this algorithm can avoid state space explosion caused by asynchronous composition. in order to get a finite state space, a new method called strand-added on demand is exploited, which extends a bundle in an incremental manner without requiring explicit configuration of protocol execution parameters. a finer granularity model of term structure is also introduced, in which subterms are divided into check subterms and data subterms. moreover, data subterms can be further classified based on the compatible data subterm relation to obtain automatically the finite set of valid acceptable terms for an honest principal. in this algorithm, terms core is designed to represent the intruder's knowledge compactly, and forward search technology is used to simulate attack patterns easily. using this algorithm, a new attack on the dolve-yao protocol can be found, which is even more harmful because the secret is revealed before the session terminates","['attack-finding algorithm', 'security protocols', 'dynamic strand space model', 'strand space model', 'state space explosion', 'asynchronous composition', 'strand-added on demand', 'check subterms', 'data subterms', 'dolve-yao protocol']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['attack - finding algorithm', 'security protocol', 'dynamic strand space model', 'strand space model', 'state space explosion', 'asynchronous composition', 'strand - add on demand', 'check subterm', 'datum subterm', 'dolve - yao protocol']","['security protocol', 'protocol execution parameter', 'simulate attack pattern', 'yao protocol', 'automatic attack construction algorithm', 'protocol execution', 'new attack', 'compatible datum subterm relation', 'dynamic strand', 'term structure']"
97,1152,Incorporating multi-leaf collimator leaf sequencing into iterative IMRT optimization,"intensity modulated radiation therapy (imrt) treatment planning typically considers beam optimization and beam delivery as separate tasks. following optimization, a multi-leaf collimator (mlc) or other beam delivery device is used to generate fluence patterns for patient treatment delivery. due to limitations and characteristics of the mlc, the deliverable intensity distributions often differ from those produced by the optimizer, leading to differences between the delivered and the optimized doses. objective function parameters are then adjusted empirically, and the plan is reoptimized to achieve a desired deliverable dose distribution. the resulting plan, though usually acceptable, may not be the best achievable. a method has been developed to incorporate the mlc restrictions into the optimization process. our in-house imrt system has been modified to include the calculation of the deliverable intensity into the optimizer. in this process, prior to dose calculation, the mlc leaf sequencer is used to convert intensities to dynamic mlc sequences, from which the deliverable intensities are then determined. all other optimization steps remain the same. to evaluate the effectiveness of deliverable-based optimization, 17 patient cases have been studied. compared with standard optimization plus conversion to deliverable beams, deliverable-based optimization results show improved isodose coverage and a reduced dose to critical structures. deliverable-based optimization results are close to the original nondeliverable optimization results, suggesting that imrt can overcome the mlc limitations by adjusting individual beamlets. the use of deliverable-based optimization may reduce the need for empirical adjustment of objective function parameters and reoptimization of a plan to achieve desired results","['intensity modulated radiation therapy', 'treatment planning', 'beam optimization', 'beam delivery', 'fluence patterns', 'objective function parameters', 'deliverable dose distribution', 'empirical adjustment', 'iterative optimization', 'multileaf collimator leaf sequencing', 'tumor dose', 'optimized intensity', 'gradient-based search algorithm', 'beamlet ray intensities', 'newton method', 'dose-volume objective values']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M', 'R', 'U', 'M', 'M', 'M']","['intensity modulate radiation therapy', 'treatment planning', 'beam optimization', 'beam delivery', 'fluence pattern', 'objective function parameter', 'deliverable dose distribution', 'empirical adjustment', 'iterative optimization', 'multileaf collimator leaf sequence', 'tumor dose', 'optimize intensity', 'gradient - base search algorithm', 'beamlet ray intensity', 'newton method', 'dose - volume objective value']","['intensity modulate radiation therapy', 'desire deliverable dose distribution', 'beam optimization', 'deliverable intensity distribution', 'optimize dose', 'other beam delivery device', 'beam delivery', 'deliverable intensity', 'patient treatment delivery', 'original nondeliverable optimization result']"
98,995,Vehicle travel time models for AGV systems under various dispatching rules,the design and evaluation of agv-based material handling systems are highly complex because of the randomness and the large number of variables involved. vehicle travel time is a fundamental parameter for solving various flexible manufacturing system (fms) design problems. this article presents stochastic vehicle travel time models for agv-based material handling systems with emphasis on the empty travel times of vehicles. various vehicle dispatching rules examined here include the nearest vehicle selection rule and longest idle vehicle selection rule. a simulation experiment is used to evaluate and demonstrate the presented models,"['vehicle travel time', 'agv', 'material handling systems', 'flexible manufacturing system', 'fms', 'vehicle dispatching rules', 'nearest vehicle selection rule', 'longest idle vehicle selection rule', 'automatic guided vehicle']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['vehicle travel time', 'agv', 'material handling system', 'flexible manufacturing system', 'fms', 'vehicle dispatch rule', 'near vehicle selection rule', 'long idle vehicle selection rule', 'automatic guide vehicle']","['article present stochastic vehicle travel time model', 'long idle vehicle selection rule', 'various vehicle dispatch rule', 'vehicle travel time', 'near vehicle selection rule', 'solve various flexible manufacturing system', 'material handling system', 'vehicle', 'travel time', 'simulation']"
99,542,The treatment of fear of flying: a controlled study of imaginal and virtual reality graded exposure therapy,"the goal of this study was to determine if virtual reality graded exposure therapy (vrget) was equally efficacious, more efficacious, or less efficacious, than imaginal exposure therapy in the treatment of fear of flying. thirty participants (age=39.8+or-9.7) with confirmed dsm-iv diagnosis of specific phobia fear of flying were randomly assigned to one of three groups: vrget with no physiological feedback (vrgetno), vrget with physiological feedback (vrgetpm), or systematic desensitization with imaginal exposure therapy (iet). eight sessions were conducted once a week. during each session, physiology was measured to give an objective measurement of improvement over the course of exposure therapy. in addition, self-report questionnaires, subjective ratings of anxiety (suds), and behavioral observations (included here as flying behavior before beginning treatment and at a three-month posttreatment followup) were included. in the analysis of results, the chi-square test of behavioral observations based on a three-month posttreatment followup revealed a statistically significant difference in flying behavior between the groups [ chi /sup 2/(4)=19.41, p<0.001]. only one participant (10%) who received iet, eight of the ten participants (80%) who received vrgetno, and ten out of the ten participants (100%) who received vrgetpm reported an ability to fly without medication or alcohol at three-month followup. although this study included small sample sizes for the three groups, the results showed vrget was more effective than iet in the treatment of flying. it also suggests that physiological feedback may add to the efficacy of vr treatment","['virtual reality graded exposure therapy', 'imaginal exposure therapy', 'phobia', 'physiological feedback', 'physiology', 'questionnaires', 'subjective ratings of anxiety', 'behavioral observations', 'chi-square test', 'flying fear', 'patient treatment']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['virtual reality grade exposure therapy', 'imaginal exposure therapy', 'phobia', 'physiological feedback', 'physiology', 'questionnaire', 'subjective rating of anxiety', 'behavioral observation', 'chi - square test', 'fly fear', 'patient treatment']","['phobia fear', 'imaginal exposure therapy', 'exposure therapy', 'fly behavior', 'anxiety', 'behavioral observation', 'fly', 'result show vrget', 'fear', 'physiological feedback']"
100,968,Stabilization of global invariant sets for chaotic systems: an energy based control approach,"this paper presents a new control approach for steering trajectories of three-dimensional nonlinear chaotic systems towards stable stationary states or time-periodic orbits. the proposed method mainly consists in a sliding mode-based control design that is extended by an explicit consideration of system energy as basis for both controller design and system stabilization. the control objective is then to regulate the energy with respect to a shaped nominal representation implicitly related to system trajectories. in this paper, we establish some theoretical results to introduce the control design approach referred to as energy based sliding mode control. then, some capabilities of the proposed approach are illustrated through examples related to the chaotic circuit of chua","['global invariant sets', 'three-dimensional nonlinear chaotic systems', 'stable stationary states', 'time-periodic orbits', 'sliding mode-based control', 'energy based sliding mode control', ""chua's circuit""]","['P', 'P', 'P', 'P', 'P', 'P', 'M']","['global invariant set', 'three - dimensional nonlinear chaotic system', 'stable stationary state', 'time - periodic orbit', 'slide mode - base control', 'energy base slide mode control', ""chua 's circuit""]","['dimensional nonlinear chaotic system', 'energy base slide mode control', 'steer trajectory', 'system trajectory', 'chaotic circuit', 'periodic orbit', 'system stabilization', 'slide mode', 'base control design', 'stable stationary state']"
101,1216,Knowledge flow management for distributed team software development,cognitive cooperation is often neglected in current team software development processes. this issue becomes more important than ever when team members are globally distributed. this paper presents a notion of knowledge flow and the related management mechanism for realizing an ordered knowledge sharing and cognitive cooperation in a geographically distributed team software development process. the knowledge flow can carry and accumulate knowledge when it goes through from one team member to another. the coordination between the knowledge flow process and the workflow process of a development team provides a new way to improve traditional team software development processes. a knowledge grid platform has been implemented to support the knowledge flow management across the internet,"['knowledge flow management', 'distributed team software development', 'cognitive cooperation', 'ordered knowledge sharing', 'workflow process', 'knowledge grid platform', 'internet', 'knowledge flow representation', 'software development management', 'cooperative work']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'M']","['knowledge flow management', 'distribute team software development', 'cognitive cooperation', 'order knowledge sharing', 'workflow process', 'knowledge grid platform', 'internet', 'knowledge flow representation', 'software development management', 'cooperative work']","['distribute team software development process', 'team software development process', 'knowledge flow management', 'knowledge flow process', 'knowledge grid platform', 'cognitive cooperation', 'development team provide', 'order knowledge sharing', 'workflow process', 'knowledge flow']"
102,1253,Application of XML for neural network exchange,"this article introduces a framework for the interchange of trained neural network models. an xml-based language (neural network markup language) for the neural network model description is offered. it allows to write down all the components of neural network model which are necessary for its reproduction. we propose to use xml notation for the full description of neural models, including data dictionary, properties of training sample, preprocessing methods, details of network structure and parameters and methods for network output interpretation","['xml', 'neural network exchange', 'neural network markup language', 'data dictionary', 'preprocessing methods', 'network structure', 'network output interpretation']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['xml', 'neural network exchange', 'neural network markup language', 'datum dictionary', 'preprocesse method', 'network structure', 'network output interpretation']","['train neural network model', 'neural network markup language', 'neural network model description', 'neural network model', 'use xml notation', 'neural model', 'xml', 'network structure', 'training sample', 'datum dictionary']"
103,606,Taiwan power company phases into AM/FM,"to face the challenges and impact of the inevitable trend toward privatization and deregulation, the taiwan power co. (tpc) devised short- and long-term strategic computerization development plans. these development efforts created a master plan that included building an automated mapping and facilities management (am/ fm) system for taipei city district office (tcdo). this project included a pilot project followed by evaluation before the roll out to the complete service territory of tcdo. the pilot project took three years to install, commission and-via the evaluation process-reach the conclusion that am/fm was technologically feasible","['taiwan power company', 'am/fm', 'privatization', 'deregulation', 'automated mapping and facilities management', 'taipei city district office', 'pilot project', 'complete service territory']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['taiwan power company', 'be / fm', 'privatization', 'deregulation', 'automate mapping and facility management', 'taipei city district office', 'pilot project', 'complete service territory']","['term strategic computerization development plan', 'taipei city district office', 'facility management', 'automate mapping', 'taiwan power', 'tpc', 'evaluation process', 'development effort create', 'complete service territory', 'privatization']"
104,79,An efficient and stable ray tracing algorithm for parametric surfaces,"in this paper, we propose an efficient and stable algorithm for finding ray-surface intersections. newton's method and bezier clipping are adapted to form the core of our algorithm. ray coherence is used to find starting points for newton iteration. we introduce an obstruction detection technique to verify whether an intersection point found using newton's method is the closest. when newton's method fails to achieve convergence, we use bezier clipping substitution to find the intersection points. this combination achieves a significant improvement in tracing primary rays. a similar approach successfully improves the performance of tracing secondary rays","['parametric surfaces', 'ray-surface intersections', 'bezier clipping', 'ray coherence', 'newton iteration', 'obstruction detection technique', 'convergence', 'efficient stable ray tracing algorithm', 'newton method', 'primary ray tracing', 'secondary ray tracing']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R']","['parametric surface', 'ray - surface intersection', 'bezier clip', 'ray coherence', 'newton iteration', 'obstruction detection technique', 'convergence', 'efficient stable ray trace algorithm', 'newton method', 'primary ray tracing', 'secondary ray trace']","['trace primary ray', 'surface intersection', 'ray coherence', 'find ray', 'use bezi clip substitution', 'obstruction detection technique', 'intersection point', 'intersection point', 'bezier clip', 'newton iteration']"
105,643,Time-resolved contrast-enhanced imaging with isotropic resolution and broad coverage using an undersampled 3D projection trajectory,"time-resolved contrast-enhanced 3d mr angiography (mra) methods have gained in popularity but are still limited by the tradeoff between spatial and temporal resolution. a method is presented that greatly reduces this tradeoff by employing undersampled 3d projection reconstruction trajectories. the variable density k-space sampling intrinsic to this sequence is combined with temporal k-space interpolation to provide time frames as short as 4 s. this time resolution reduces the need for exact contrast timing while also providing dynamic information. spatial resolution is determined primarily by the projection readout resolution and is thus isotropic across the fov, which is also isotropic. although undersampling the outer regions of k-space introduces aliased energy into the image, which may compromise resolution, this is not a limiting factor in high-contrast applications such as mra. results from phantom and volunteer studies are presented demonstrating isotropic resolution, broad coverage with an isotropic field of view (fov), minimal projection reconstruction artifacts, and temporal information. in one application, a single breath-hold exam covering the entire pulmonary vasculature generates high-resolution, isotropic imaging volumes depicting the bolus passage","['time-resolved contrast-enhanced imaging', 'isotropic resolution', 'broad coverage', 'undersampled 3d projection trajectory', 'variable density k-space sampling', 'temporal k-space interpolation', 'isotropic field of view', 'pulmonary vasculature', 'bolus passage', '3d mri angiography', 'abdomen', 'thorax', 'image artifacts', 'breath-hold imaging']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U', 'U', 'R', 'R']","['time - resolve contrast - enhance imaging', 'isotropic resolution', 'broad coverage', 'undersample 3d projection trajectory', 'variable density k - space sampling', 'temporal k - space interpolation', 'isotropic field of view', 'pulmonary vasculature', 'bolus passage', '3d mri angiography', 'abdomen', 'thorax', 'image artifact', 'breath - hold imaging']","['enhance 3d mr angiography', 'employ undersampled 3d projection reconstruction trajectory', 'image volume depict', 'present demonstrating isotropic resolution', 'projection readout resolution', 'minimal projection reconstruction artifact', 'spatial resolution', 'pulmonary vasculature', 'temporal resolution', 'time resolution']"
106,1426,Groove Networks. Matching technology with human needs,"if what has been occurring in information technology during the past decade or so can be classified as the ""information age,"" then going forward, i believe it's going to be viewed more as the ""connection age"","" says ray ozzie, ceo and chairman of groove networks, the beverly, massachusetts company that produces collaboration software. ""we're all going to be thinking more about the connections between people and the connections between companies,"" ozzie says. ""our mission has two parts: to help businesses achieve a greater ""return on connection"" from their relationships with customers, vendors, and partners; and to help individuals strengthen online connections with the people with whom they interact.""","['groove networks', 'businesses', 'online connections', 'server products', 'organizational perspective', 'personal perspective', 'online collaboration', 'knowledge work', 'collaborative technologies', 'inking technology']","['P', 'P', 'P', 'U', 'U', 'U', 'R', 'U', 'R', 'M']","['groove network', 'business', 'online connection', 'server product', 'organizational perspective', 'personal perspective', 'online collaboration', 'knowledge work', 'collaborative technology', 'ink technology']","['help individual strengthen online connection', 'produce collaboration software', 'connection age', 'information technology', 'groove network', 'information age', 'help business achieve', 'connection', 'connection', 'past decade']"
107,830,The real story behind Calpoint [telecom],"a former qwest executive sheds light on the carrier's controversial deal with calpoint. discusses why calpoint gets a monthly check from quest, regardless of whether it provides services","['calpoint', 'qwest', 'telecom carrier']","['P', 'P', 'R']","['calpoint', 'qwest', 'telecom carrier']","['calpoint get', 'former qw executive', 'calpoint', 'monthly check', 'carrier', 'quest', 'discuss', 'deal']"
108,875,Women of color in computing,"it is well known that there is a need to increase the number of women in the area of computing, that is in computer science and computer engineering. if we consider women of color, that is women of under-represented ethnicities, we find the numbers are very dismal. the goal of this article is to bring to light the unique issues of women of color based upon the personal experience of one african-american woman who has been in the field of computing for over 20 years (including the years of higher education)","['women of color', 'computer science', 'computer engineering', 'higher education', 'ethnic minority', 'society', 'gender issues']","['P', 'P', 'P', 'P', 'M', 'U', 'M']","['woman of color', 'computer science', 'computer engineering', 'high education', 'ethnic minority', 'society', 'gender issue']","['american woman', 'represent ethnicity', 'computer engineering', 'computer science', 'color base', 'consider woman', 'woman', 'compute', 'unique issue', 'high education']"
109,888,Storage functionals and Lyapunov functions for passive dynamical systems,"for nonlinear time-invariant input-output dynamical systems the passivity conditions are obtained under some restrictions. the conditions imply storage functions satisfying a dissipation inequality. a class of storage functions allowing unique reconstruction of a passive dynamical system is defined. these results are illustrated by an example of a linear system with fading memory. an important, for practical application, class of the linear relaxation systems without direct input-output interaction is considered. a necessary condition for dynamical systems to be of the relaxation type is obtained for this class. the condition is connected with the existence of a unique quadratic lyapunov function satisfying the complete monotonicity condition. this unique lyapunov function corresponds to a ""standard"" thermodynamic potential in a compact family of potentials in the nonequilibrium thermodynamics. the results obtained can be useful in automatic control, mechanics of viscoelastic materials, and various applications in physics and the system theory","['storage functionals', 'passive dynamical systems', 'nonlinear time-invariant input-output dynamical systems', 'passivity conditions', 'dissipation inequality', 'linear system', 'fading memory', 'necessary condition', 'unique quadratic lyapunov function', 'complete monotonicity condition', 'thermodynamic potential', 'nonequilibrium thermodynamics', 'automatic control', 'mechanics', 'viscoelastic materials']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['storage functional', 'passive dynamical system', 'nonlinear time - invariant input - output dynamical system', 'passivity condition', 'dissipation inequality', 'linear system', 'fade memory', 'necessary condition', 'unique quadratic lyapunov function', 'complete monotonicity condition', 'thermodynamic potential', 'nonequilibrium thermodynamic', 'automatic control', 'mechanic', 'viscoelastic material']","['unique quadratic lyapunov function', 'unique lyapunov function', 'linear relaxation system', 'passive dynamical system', 'nonequilibrium thermodynamic', 'output dynamical system', 'dynamical system', 'thermodynamic potential', 'storage function allow unique reconstruction', 'dissipation inequality']"
110,1072,Quantum-state information retrieval in a Rydberg-atom data register,"we analyze a quantum search protocol to retrieve phase information from a rydberg-atom data register using a subpicosecond half-cycle electric field pulse. calculations show that the half-cycle pulse can perform the phase retrieval only within a range of peak field values. by varying the phases of the constituent orbitals of the rydberg wave packet register, we demonstrate coherent control of the phase retrieval process. by specially programming the phases of the orbitals comprising the initial wave packet, we show that it is possible to use the search method as a way to synthesize single energy eigenstates","['quantum-state information retrieval', 'rydberg-atom data register', 'quantum search protocol', 'phase information', 'subpicosecond half-cycle electric field pulse', 'half-cycle pulse', 'phase retrieval', 'peak field values', 'constituent orbitals', 'rydberg wave packet register', 'coherent control', 'initial wave packet', 'search method', 'single energy eigenstates']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['quantum - state information retrieval', 'rydberg - atom datum register', 'quantum search protocol', 'phase information', 'subpicosecond half - cycle electric field pulse', 'half - cycle pulse', 'phase retrieval', 'peak field value', 'constituent orbital', 'rydberg wave packet register', 'coherent control', 'initial wave packet', 'search method', 'single energy eigenstate']","['rydberg wave packet register', 'quantum search protocol', 'atom data register', 'phase retrieval process', 'phase retrieval', 'retrieve phase information', 'rydberg', 'cycle electric field pulse', 'initial wave packet', 'phase']"
111,1037,A stochastic averaging approach for feedback control design of nonlinear systems under random excitations,this paper presents a method for designing and quantifying the performance of feedback stochastic controls for nonlinear systems. the design makes use of the method of stochastic averaging to reduce the dimension of the state space and to derive the ito stochastic differential equation for the response amplitude process. the moment equation of the amplitude process closed by the rayleigh approximation is used as a means to characterize the transient performance of the feedback control. the steady state and transient response of the amplitude process are used as the design criteria for choosing the feedback control gains. numerical examples are studied to demonstrate the performance of the control,"['stochastic averaging', 'feedback control', 'nonlinear systems', 'random excitations', 'feedback stochastic controls', 'ito stochastic differential equation', 'rayleigh approximation', 'steady state', 'transient response']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['stochastic average', 'feedback control', 'nonlinear system', 'random excitation', 'feedback stochastic control', 'ito stochastic differential equation', 'rayleigh approximation', 'steady state', 'transient response']","['feedback stochastic control', 'ito stochastic', 'stochastic average', 'feedback control gain', 'feedback control', 'amplitude process close', 'amplitude process', 'nonlinear system', 'transient performance', 'rayleigh approximation']"
112,848,Women in computing around the world,"this paper describes the participation of women in computing in more than 30 countries, by focussing on participation at undergraduate level. a brief discussion covers how societal and cultural factors may affect women's participation. statistics from many different sources are presented for comparison. generally, participation is low - most countries fall in the 10-40% range with a few below 10% and a few above 40%","['women', 'cultural factors', 'statistics', 'undergraduate computing', 'societal factors']","['P', 'P', 'P', 'R', 'R']","['woman', 'cultural factor', 'statistic', 'undergraduate computing', 'societal factor']","['most country fall', 'affect woman', 'cultural factor', 'participation', 'woman', 'undergraduate level', 'compute', 'societal', 'country', 'brief discussion cover']"
113,763,A quantum full adder for a scalable nuclear spin quantum computer,"we demonstrate a strategy for implementation a quantum full adder in a spin chain quantum computer. as an example, we simulate a quantum full adder in a chain containing 201 spins. our simulations also demonstrate how one can minimize errors generated by non-resonant effects","['quantum full adder', 'scalable nuclear spin quantum computer', 'nonresonant effects', 'error minimization']","['P', 'P', 'M', 'R']","['quantum full adder', 'scalable nuclear spin quantum computer', 'nonresonant effect', 'error minimization']","['spin chain quantum computer', 'quantum full adder', 'spin', 'chain', 'simulate', 'simulation', 'implementation', 'example', 'demonstrate', 'generate']"
114,726,New wrinkle on the Web? Hmm. [banking],"the financial sector produced its share of technology hype during the new economy years. you. can't blame folks if the next next thing, a wave of internet-related innovation called web services, is being met with healthy skepticism. many gurus are placing their bets on web services to drive the next chapter of finance technology, dramatically upgrading disappointing automated customer management strategies by electronically breaking down barriers between products, firms and customers, and perhaps creating a whole new line of business in the process. but it's not a magic wand. it doesn't change the need for a bank to reorganize and streamline its operations","['bank', 'web services']","['P', 'P']","['bank', 'web service']","['upgrade disappointing automate customer management strategy', 'financial sector produce', 'finance technology', 'new economy year', 'web service', 'technology hype', 'bank', 'relate innovation', 'next next thing', 'business']"
115,1373,Agent-based product-support logistics system using XML and RDF,"the capability of the timely provision of maintenance services and service parts is critical to the competitiveness of industrial systems. to enhance the timely operations in a product-support logistics chain, business partners (equipment manufacturers, parts distributors, customers) may have to collaborate for the efficient exchange of relevant information. we propose the architecture of an agent-based product-support logistics system. emphasis is placed on the problems of sharing and exchanging information through agent communication. we adopt the resource description framework (rdf) schema for information modelling in product-support logistics domain. the extensible markup language (xml) serialization generates messages for agent communication. the use of xml and rdf enables software agents to understand the contents of messages correctly and consistently. we demonstrate the feasibility of our agent architecture using a scenario in logistical support processes. we believe that the approach can provide a promising way to the automation of business processes in product-support logistics through seamless communication among the partners","['agent-based product-support logistics system', 'xml', 'rdf', 'maintenance services', 'service parts', 'industrial systems', 'information modelling', 'extensible markup language', 'software agents', 'resource description framework schema']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['agent - base product - support logistic system', 'xml', 'rdf', 'maintenance service', 'service part', 'industrial system', 'information model', 'extensible markup language', 'software agent', 'resource description framework schema']","['rdf enable software agent', 'support logistic system', 'support logistic chain', 'logistical support process', 'support logistic domain', 'support logistic', 'maintenance service', 'agent architecture use', 'resource description framework', 'service part']"
116,1336,On abelian branched coverings of the sphere,"we obtain an enumeration formula for the number of weak equivalence classes of the branched (a * b)-covering of the sphere with m-branch points, when a and b are finite abelian groups with (|a|, |b|) = 1. from this, we can deduce an explicit formula for enumerating the weak equivalence classes of pseudofree spherical (zp * zq)-actions on a given surface, when p and q are distinct primes","['abelian branched coverings', 'enumeration formula', 'weak equivalence classes', 'finite abelian groups', 'explicit formula', 'pseudofree spherical']","['P', 'P', 'P', 'P', 'P', 'P']","['abelian branch covering', 'enumeration formula', 'weak equivalence class', 'finite abelian group', 'explicit formula', 'pseudofree spherical']","['finite abelian group', 'pseudofree spherical', 'branch point', 'weak equivalence class', 'give surface', 'branch', 'enumeration formula', 'sphere', 'explicit formula', 'enumerate']"
117,116,Frontier between separability and quantum entanglement in a many spin system,"we discuss the critical point x/sub c/ separating the quantum entangled and separable states in two series of n spins s in the simple mixed state characterized by the matrix operator rho = x| phi >< phi |+1-x/d/sup n/i/sub d/n, where x in [0, 1], d = 2s + 1, i/sub d/n is the d/sup n/ * d/sup n/ unity matrix and | phi > is a special entangled state. the cases x = 0 and x = 1 correspond respectively to fully random spins and to a fully entangled state. in the first of these series we consider special states | phi > invariant under charge conjugation, that generalizes the n = 2 spin s = 1/2 einstein-podolsky-rosen state, and in the second one we consider generalizations of the werner (1989) density matrices. the evaluation of the critical point x/sub c/ was done through bounds coming from the partial transposition method of peres (1996) and the conditional nonextensive entropy criterion. our results suggest the conjecture that whenever the bounds coming from both methods coincide the result of x/sub c/ is the exact one. the results we present are relevant for the discussion of quantum computing, teleportation and cryptography","['separability', 'quantum entanglement', 'many spin system', 'critical point', 'separable states', 'matrix operator', 'unity matrix', 'entangled state', 'random spin', 'charge conjugation', 'einstein-podolsky-rosen state', 'partial transposition method', 'nonextensive entropy criterion', 'quantum computing', 'teleportation', 'cryptography', 'werner density matrices']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['separability', 'quantum entanglement', 'many spin system', 'critical point', 'separable state', 'matrix operator', 'unity matrix', 'entangle state', 'random spin', 'charge conjugation', 'einstein - podolsky - rosen state', 'partial transposition method', 'nonextensive entropy criterion', 'quantum computing', 'teleportation', 'cryptography', 'werner density matrix']","['quantum entangle', 'special entangled state', 'entangle state', 'quantum computing', 'mix state characterize', 'matrix operator rho', 'random spin', 'nonextensive entropy criterion', 'consider special state', 'werner']"
118,955,From the DOS dog days to e-filing [law firms],"the poster child for a successful e-filing venture is the case management and electronic case file system now rolling through the district and bankruptcy courts. a project of the administrative office of the united states courts, cm/ecf is a loud proponent of the benefits of the pdf approach and it has a full head of steam. present plans are for all federal courts to implement cm/ecf by 2005. that means a radical shift in methodology and tools for a lot of lawyers. it also means that you should get cozy with acrobat real soon","['e-filing', 'case management and electronic case file system', 'united states courts', 'pdf', 'adobe acrobat']","['P', 'P', 'P', 'P', 'M']","['e - filing', 'case management and electronic case file system', 'united states court', 'pdf', 'adobe acrobat']","['electronic case file system', 'bankruptcy court', 'federal court', 'file venture', 'united states court', 'ecf', 'administrative office', 'pdf approach', 'implement cm', 'case management']"
119,910,Control of a heavy-duty robotic excavator using time delay control with integral sliding surface,"the control of a robotic excavator is difficult from the standpoint of the following problems: parameter variations in mechanical structures, various nonlinearities in hydraulic actuators and disturbance due to the contact with the ground. in addition, the more the size of robotic excavators increases, the more the length and mass of the excavator links; the more the parameters of a heavy-duty excavator vary. a time-delay control with switching action (tdcsa) using an integral sliding surface is proposed in this paper for the control of a 21-ton robotic excavator. through analysis and experiments, we show that using an integral sliding surface for the switching action of tdcsa is better than using a pd-type sliding surface. the proposed controller is applied to straight-line motions of a 21-ton robotic excavator with a speed level at which skillful operators work. experiments, which were designed for surfaces with various inclinations and over broad ranges of joint motions, show that the proposed controller exhibits good performance","['robotic excavator', 'integral sliding surface', 'time-delay control', 'robust control', 'motion control', 'trajectory control', 'dynamics', 'tracking', 'pressure control']","['P', 'P', 'P', 'M', 'R', 'M', 'U', 'U', 'M']","['robotic excavator', 'integral slide surface', 'time - delay control', 'robust control', 'motion control', 'trajectory control', 'dynamic', 'track', 'pressure control']","['ton robotic excavator', 'robotic excavator', 'robotic excavator', 'duty excavator vary', 'integral slide surface', 'hydraulic actuator', 'type slide surface', 'excavator link', 'delay control', 'joint motion']"
120,582,Optimal estimation of a finite sample of a discrete chaotic process,the synthesis of optimal algorithms for estimating discrete chaotic processes specified by a finite sample is considered; various possible approaches are discussed. expressions determining the potential accuracy in estimating a single value of the chaotic process are derived. an example of the application of the general equations obtained is given,"['optimal estimation', 'finite sample', 'discrete chaotic process', 'optimal algorithm synthesis', 'space-time filtering']","['P', 'P', 'P', 'R', 'U']","['optimal estimation', 'finite sample', 'discrete chaotic process', 'optimal algorithm synthesis', 'space - time filtering']","['estimate discrete chaotic process specify', 'optimal algorithm', 'chaotic process', 'estimate', 'finite sample', 'expression determine', 'synthesis', 'general equation obtain', 'accuracy', 'single value']"
121,1192,Construction of two-sided bounds for initial-boundary value problems,"this paper extends the bounding operator approach developed for boundary value problems to the case of initial-boundary value problems (ibvps). following the general principle of bounding operators enclosing methods for the case of partial differential equations are discussed. in particular, continuous discretization methods with an appropriate error bound controlled shift and monotone extensions of rothe's method for parabolic problems are investigated","['two-sided bounds', 'initial-boundary value problems', 'bounding operator approach', 'bounding operators', 'partial differential equations', 'parabolic problems']","['P', 'P', 'P', 'P', 'P', 'P']","['two - sided bound', 'initial - boundary value problem', 'bound operator approach', 'bound operator', 'partial differential equation', 'parabolic problem']","['bound operator enclose method', 'continuous discretization method', 'bound operator approach develop', 'boundary value problem', 'error bind control shift', 'parabolic problem', 'partial differential equation', 'method', 'ibvps', 'rothe']"
122,683,Knowledge management,"the article defines knowledge management, discusses its role, and describes its functions. it also explains the principles of knowledge management, enumerates the strategies involved in knowledge management, and traces its history in brief. the focus is on its interdisciplinary nature. the steps involved in knowledge management i.e. identifying, collecting and capturing, selecting, organizing and storing, sharing, applying, and creating, are explained. the pattern of knowledge management initiatives is also considered",['knowledge management'],['P'],['knowledge management'],"['article define knowledge management', 'knowledge management initiative', 'knowledge management', 'organize', 'strategy involve', 'interdisciplinary nature', 'create', 'discuss', 'share', 'step involve']"
123,1293,Truss topology optimization by a modified genetic algorithm,"this paper describes the use of a stochastic search procedure based on genetic algorithms for developing near-optimal topologies of load-bearing truss structures. most existing cases these publications express the truss topology as a combination of members. these methods, however, have the disadvantage that the resulting topology may include needless members or those which overlap other members. in addition to these problems, the generated structures are not necessarily structurally stable. a new method, which resolves these problems by expressing the truss topology as a combination of triangles, is proposed in this paper. details of the proposed methodology are presented as well as the results of numerical examples that clearly show the effectiveness and efficiency of the method","['truss topology optimization', 'modified genetic algorithm', 'stochastic search procedure', 'near-optimal topologies', 'load-bearing truss structures', 'triangles']","['P', 'P', 'P', 'P', 'P', 'P']","['truss topology optimization', 'modify genetic algorithm', 'stochastic search procedure', 'near - optimal topology', 'load - bear truss structure', 'triangle']","['bear truss structure', 'truss topology', 'genetic algorithm', 'optimal topology', 'stochastic search procedure', 'generate structure', 'propose methodology', 'topology', 'triangle', 'numerical']"
124,1422,Taxonomy's role in content management,"a taxonomy is simply a way of classifying things. still, there is a rapidly growing list of vendors offering taxonomy software and related applications. they promise many benefits, especially to enterprise customers: content management will be more efficient. corporate portals will be enhanced by easily created yahoo!-like directories of internal information. and the end-user experience will be dramatically improved by more successful content retrieval and more effective knowledge discovery. but today's taxonomy products represent emerging technologies. they are not out-of-the-box solutions. and even the most automated systems require some manual assistance from people who know how to classify content","['content management', 'taxonomy software', 'enterprise customers', 'corporate portals', 'internal information', 'effective knowledge discovery', 'taxonomy applications']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['content management', 'taxonomy software', 'enterprise customer', 'corporate portal', 'internal information', 'effective knowledge discovery', 'taxonomy application']","['vendor offer taxonomy software', 'taxonomy product', 'taxonomy', 'classify thing', 'relate application', 'successful content retrieval', 'corporate portal', 'automate system', 'effective knowledge discovery', 'content management']"
125,834,Commerce Department plan eases 3G spectrum crunch,"the federal government made its first move last week toward cleaning up a spectrum allocation system that was in shambles just a year ago and had some, spectrum-starved wireless carriers fearing they wouldn't be able to compete in third-generation services. the move, however, is far from complete and leaves numerous details unsettled","['3g spectrum', 'federal government', 'spectrum allocation system', 'wireless carriers']","['P', 'P', 'P', 'P']","['3 g spectrum', 'federal government', 'spectrum allocation system', 'wireless carrier']","['spectrum allocation system', 'starve wireless carrier fear', 'federal government', 'first move last week', 'spectrum', 'generation service', 'move', 'shamble', 'year', 'third']"
126,871,Priming the pipeline [women in computer science careers],"in 1997 the backyard project, a pilot program of the garnett foundation, was instituted to encourage high school girls to explore careers in the computer industry. at that time, the garnett foundation commissioned the global strategy group to execute a survey of 652 college-bound high school students (grades 9 through 12), to help discover directions that the backyard project might take to try to move toward the mission of the pilot program. it conducted the study by telephone between march 25 and april 8, 1997 in the silicon valley, boston, and austin metropolitan areas. it conducted all interviews using a random digit dialing methodology, derived from a file of american households with high incidences of adolescent children. the top six answers from girls to the survey question ""why are girls less likely to pursue computer science careers?"" in order of perceived importance by the girls were: not enough role models; women have other interests; didn't know about the industry; limited opportunity; negative media; and too nerdy. these responses are discussed","['the backyard project', 'high school girls', 'college-bound high school students', 'computer industry careers']","['P', 'P', 'P', 'R']","['the backyard project', 'high school girl', 'college - bind high school student', 'computer industry career']","['pursue computer science career', 'encourage high school girl', 'bind high school student', 'random digit dialing methodology', 'explore career', 'garnett foundation commission', 'adolescent child', 'global strategy group', 'computer industry', 'garnett foundation']"
127,929,Closed loop finite-element modeling of active constrained layer damping in the time domain analysis,"a three-dimensional finite-element closed-loop model has been developed to predict the effects of active-passive damping on a vibrating structure. the golla-hughes-mctavish method is employed to capture the viscoelastic material behavior in a time domain analysis. the parametric study includes the different control gains as well as geometric parameters related to the active constrained layer damping (acld) treatment. comparisons are made among several acld models, the passive constrained model and the active damping model. the results obtained here reiterate that acld is somewhat better for vibration suppression than either the purely passive or the active system and provides higher structural damping with less control gain when compared to the purely active system. since the acld performance can be reduced by the viscoelastic layer, the design of the acld model must be given a careful consideration in order to optimize the effect of passive damping","['active constrained layer damping', 'time domain analysis', 'three-dimensional finite-element closed-loop model', 'golla-hughes-mctavish method', 'viscoelastic material', 'acld models', 'passive constrained model', 'active damping model', 'vibration suppression', 'structural damping', 'viscoelastic layer', 'passive damping']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['active constrained layer damp', 'time domain analysis', 'three - dimensional finite - element closed - loop model', 'golla - hughes - mctavish method', 'viscoelastic material', 'acld model', 'passive constrained model', 'active damp model', 'vibration suppression', 'structural damp', 'viscoelastic layer', 'passive damp']","['active constrained layer damp', 'active damp model', 'structural damp', 'passive damp', 'viscoelastic layer', 'viscoelastic material', 'vibration suppression', 'vibrate structure', 'passive constrained model', 'acld model']"
128,1212,TCRM: diagnosing tuple inconsistency for granulized datasets,"many approaches to granularization have been presented for knowledge discovery. however, the inconsistent tuples that exist in granulized datasets are hardly ever revealed. we developed a model, tuple consistency recognition model (tcrm) to help efficiently detect inconsistent tuples for datasets that are granulized. the main outputs of the developed model include explored inconsistent tuples and consumed processing time. we further conducted an empirical test where eighteen continuous real-life datasets granulized by the equal width interval technique that embedded s-plus histogram binning algorithm (shba) and largest binning size algorithm (lbsa) binning algorithms were diagnosed. remarkable results: almost 40% of the granulized datasets contain inconsistent tuples and 22% have the amount of inconsistent tuples more than 20%","['tcrm', 'tuple inconsistency', 'granulized datasets', 'granularization', 'knowledge discovery', 'tuple consistency recognition model', 'processing time', 'equal width interval technique', 's-plus histogram binning algorithm', 'largest binning size algorithm', 'relational database', 'large database', 'sql']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'U', 'U']","['tcrm', 'tuple inconsistency', 'granulize dataset', 'granularization', 'knowledge discovery', 'tuple consistency recognition model', 'processing time', 'equal width interval technique', 's - plus histogram binning algorithm', 'large binning size algorithm', 'relational database', 'large database', 'sql']","['granulize dataset contain inconsistent tuple', 'histogram binning algorithm', 'tuple consistency recognition model', 'detect inconsistent tuple', 'develop model include explore inconsistent tuple', 'life dataset granulize', 'granulize dataset', 'large binning size algorithm', 'inconsistent tuple more', 'bin algorithm']"
129,1257,Definition of a similarity measure between cases based on auto/cross-fuzzy thesauri,"a similarity measure between cases is needed in order to evaluate the degree of similarity when using past similar cases in order to resolve current problems. in similar case retrieval, multiple indices are set up in order to characterize the queries and individual cases, then terms are given as values to each. the similarity measure between cases commonly used is defined using the rate at which the values provided from the corresponding indices match. in practice, however, values cannot be expected to be mutually exclusive. as a result, a natural expansion of this approach is to have relationships in which mutually similar meanings are reflected in the similarity measure between cases. in this paper the authors consider an auto-fuzzy thesaurus which gives the relationship for values between corresponding indices and a cross-fuzzy thesaurus which gives the relationship for values between mutually distinct indices, then defines a similarity measure between cases which considers the relationship of index values based on these thesauri. this definition satisfies the characteristics required for the operation of case-based retrieval even when one value is not necessarily given in the index. finally, using a test similar case retrieval system, the authors perform a comparative analysis of the proposed similarity measure between cases and a conventional approach","['similar case retrieval', 'corresponding indices', 'auto-fuzzy thesaurus', 'cross-fuzzy thesaurus', 'mutually distinct indices', 'case-based retrieval', 'case similarity measure', 'relationship indices', 'decision making support system', 'problem solving']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'M']","['similar case retrieval', 'correspond index', 'auto - fuzzy thesaurus', 'cross - fuzzy thesaurus', 'mutually distinct index', 'case - base retrieval', 'case similarity measure', 'relationship index', 'decision make support system', 'problem solve']","['test similar case retrieval system', 'similar case retrieval', 'fuzzy thesaurus', 'propose similarity measure', 'similarity measure', 'correspond index match', 'similar case', 'similarity', 'similar meaning', 'comparative analysis']"
130,602,Image fusion between /sup 18/FDG-PET and MRI/CT for radiotherapy planning of oropharyngeal and nasopharyngeal carcinomas,"accurate diagnosis of tumor extent is important in three-dimensional conformal radiotherapy. this study reports the use of image fusion between (18)f-fluoro-2-deoxy-d-glucose positron emission tomography (/sup 18/fdg-pet) and magnetic resonance imaging/computed tomography (mri/ct) for better targets delineation in radiotherapy planning of head-and-neck cancers. the subjects consisted of 12 patients with oropharyngeal carcinoma and 9 patients with nasopharyngeal carcinoma (npc) who were treated with radical radiotherapy between july 1999 and february 2001. image fusion between /sup 18/fdg-pet and mri/ct was performed using an automatic multimodality image registration algorithm, which used the brain as an internal reference for registration. gross tumor volume (gtv) was determined based on clinical examination and /sup 18/fdg uptake on the fusion images. clinical target volume (ctv) was determined following the usual pattern of lymph node spread for each disease entity along with the clinical presentation of each patient. except for 3 cases with superficial tumors, all the other primary tumors were detected by /sup 18/fdg-pet. the gtv volumes for primary tumors were not changed by image fusion in 19 cases (89%), increased by 49% in one npc, and decreased by 45% in another npc. normal tissue sparing was more easily performed based on clearer gtv and ctv determination on the fusion images. in particular, parotid sparing became possible in 15 patients (71%) whose upper neck areas near the parotid glands were tumor-free by /sup 18/fdg-pet. within a mean follow-up period of 18 months, no recurrence occurred in the areas defined as ctv, which was treated prophylactically, except for 1 patient who experienced nodal recurrence in the ctv and simultaneous primary site recurrence. in conclusion, this preliminary study showed that image fusion between /sup 18/fdg-pet and mri/ct was useful in gtv and ctv determination in conformal rt, thus sparing normal tissues","['image fusion', '/sup 18/fdg-pet', 'mri/ct', 'radiotherapy planning', 'nasopharyngeal carcinomas', 'oropharyngeal carcinomas', 'superficial tumors', 'primary tumors', 'normal tissues sparing', 'parotid glands', 'simultaneous primary site recurrence', 'f']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U']","['image fusion', '/sup 18 / fdg - pet', 'mri / ct', 'radiotherapy planning', 'nasopharyngeal carcinoma', 'oropharyngeal carcinoma', 'superficial tumor', 'primary tumor', 'normal tissue spare', 'parotid gland', 'simultaneous primary site recurrence', 'f']","['oropharyngeal carcinoma', 'dimensional conformal radiotherapy', 'nasopharyngeal carcinoma', 'multimodality image registration algorithm', 'neck cancer', 'radiotherapy planning', 'radical radiotherapy', 'other primary tumor', 'gross tumor volume', 'compute tomography']"
131,647,Experimental design methodology and data analysis technique applied to optimise an organic synthesis,"the study was aimed at maximising the yield of a michaelis-becker dibromoalkane monophosphorylation reaction. in order to save time and money, we first applied a full factorial experimental design to search for the optimum conditions while performing a small number of experiments. we then used the principal component analysis (pca) technique to evidence two uncontrolled factors. lastly, a special experimental design that took into account all the influential factors allowed us to determine the maximum-yield experimental conditions. this study also evidenced the complementary nature of experimental design methodology and data analysis techniques","['data analysis technique', 'organic synthesis', 'michaelis-becker dibromoalkane monophosphorylation reaction', 'full factorial experimental design', 'optimum conditions', 'principal component analysis', 'uncontrolled factors', 'maximum-yield experimental conditions']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['datum analysis technique', 'organic synthesis', 'michaelis - becker dibromoalkane monophosphorylation reaction', 'full factorial experimental design', 'optimum condition', 'principal component analysis', 'uncontrolled factor', 'maximum - yield experimental condition']","['becker dibromoalkane monophosphorylation reaction', 'experimental design methodology', 'full factorial experimental design', 'yield experimental condition', 'special experimental design', 'influential factor allow', 'uncontrolled factor', 'experiment', 'yield', 'optimum condition']"
132,80,Evaluating the performance of a distributed database of repetitive elements in complete genomes,"the original version of the repeat sequence database (rsdb) was created based on centralized database systems (cdbss). rsdb presently includes an enormous amount of data, with the amount of biological data increasing rapidly. distributed rsdb (drsdb) is developed to yield better performance. this study proposed many approaches to data distribution and experimentally determines the best approach to obtain good performance of our database. experimental results indicate that drsdb performs well for particular types of query","['repetitive elements', 'complete genomes', 'biological data', 'data distribution', 'queries', 'distributed repeat sequence database', 'performance evaluation']","['P', 'P', 'P', 'P', 'P', 'R', 'R']","['repetitive element', 'complete genome', 'biological datum', 'datum distribution', 'query', 'distribute repeat sequence database', 'performance evaluation']","['repeat sequence database', 'distribute rsdb', 'centralize database system', 'database', 'datum distribution', 'rsdb', 'biological datum', 'drsdb perform', 'drsdb', 'datum']"
133,1113,Word spotting based on a posterior measure of keyword confidence,"in this paper, an approach of keyword confidence estimation is developed that well combines acoustic layer scores and syllable-based statistical language model (lm) scores. an a posteriori (ap) confidence measure and its forward-backward calculating algorithm are deduced. a zero false alarm (zfa) assumption is proposed for evaluating relative confidence measures by word spotting task. in a word spotting experiment with a vocabulary of 240 keywords, the keyword accuracy under the ap measure is above 94%, which well approaches its theoretical upper limit. in addition, a syllable lattice hidden markov model (slhmm) is formulated and a unified view of confidence estimation, word spotting, optimal path search, and n-best syllable re-scoring is presented. the proposed ap measure can be easily applied to various speech recognition systems as well","['word spotting', 'a posterior measure', 'keyword confidence', 'confidence estimation', 'acoustic layer scores', 'forward-backward calculating algorithm', 'relative confidence measures', 'word spotting task', 'syllable lattice hidden markov model', 'optimal path search', 'n-best syllable re-scoring', 'speech recognition systems', 'syllable-based statistical language model scores', 'a posteriori confidence measure', 'zero false alarm assumption']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['word spot', 'a posterior measure', 'keyword confidence', 'confidence estimation', 'acoustic layer score', 'forward - backward calculate algorithm', 'relative confidence measure', 'word spot task', 'syllable lattice hide markov model', 'optimal path search', 'n - good syllable re - score', 'speech recognition system', 'syllable - base statistical language model score', 'a posteriori confidence measure', 'zero false alarm assumption']","['syllable lattice hide markov model', 'keyword confidence estimation', 'speech recognition system', 'statistical language model', 'keyword accuracy', 'confidence estimation', 'evaluate relative confidence measure', 'acoustic layer score', 'syllable', 'word spot task']"
134,1156,Favorable noise uniformity properties of Fourier-based interpolation and reconstruction approaches in single-slice helical computed tomography,"volumes reconstructed by standard methods from single-slice helical computed tomography (ct) data have been shown to have noise levels that are highly nonuniform relative to those in conventional ct. these noise nonuniformities can affect low-contrast object detectability and have also been identified as the cause of the zebra artifacts that plague maximum intensity projection (mip) images of such volumes. while these spatially variant noise levels have their root in the peculiarities of the helical scan geometry, there is also a strong dependence on the interpolation and reconstruction algorithms employed. in this paper, we seek to develop image reconstruction strategies that eliminate or reduce, at its source, the nonuniformity of noise levels in helical ct relative to that in conventional ct. we pursue two approaches, independently and in concert. we argue, and verify, that fourier-based longitudinal interpolation approaches lead to more uniform noise ratios than do the standard 360li and 180li approaches. we also demonstrate that a fourier-based fan-to-parallel rebinning algorithm, used as an alternative to fanbeam filtered backprojection for slice reconstruction, also leads to more uniform noise ratios, even when making use of the 180li and 360li interpolation approaches","['noise uniformity properties', 'fourier-based interpolation', 'reconstruction approaches', 'single-slice helical computed tomography', 'conventional ct', 'low-contrast object detectability', 'zebra artifacts', 'more uniform noise ratios', 'fourier-based fan-to-parallel rebinning algorithm', 'medical diagnostic imaging', 'maximum intensity projection images', 'helical span geometry']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'M']","['noise uniformity property', 'fourier - base interpolation', 'reconstruction approach', 'single - slice helical compute tomography', 'conventional ct', 'low - contrast object detectability', 'zebra artifact', 'more uniform noise ratio', 'fourier - base fan - to - parallel rebinning algorithm', 'medical diagnostic imaging', 'maximum intensity projection image', 'helical span geometry']","['slice helical compute tomography', 'volume reconstruct', 'helical scan geometry', 'helical ct', 'maximum intensity projection', 'image reconstruction', 'slice reconstruction', 'reconstruction algorithm', 'longitudinal interpolation approach lead', 'fanbeam filter backprojection']"
135,991,Estimation of blocking probabilities in cellular networks with dynamic channel assignment,"blocking probabilities in cellular mobile communication networks using dynamic channel assignment are hard to compute for realistic sized systems. this computational difficulty is due to the structure of the state space, which imposes strong coupling constraints amongst components of the occupancy vector. approximate tractable models have been proposed, which have product form stationary state distributions. however, for real channel assignment schemes, the product form is a poor approximation and it is necessary to simulate the actual occupancy process in order to estimate the blocking probabilities. meaningful estimates of the blocking probability typically require an enormous amount of cpu time for simulation, since blocking events are usually rare. advanced simulation approaches use importance sampling (is) to overcome this problem. we study two regimes under which blocking is a rare event: low-load and high cell capacity. our simulations use the standard clock (sc) method. for low load, we propose a change of measure that we call static issc, which has bounded relative error. for high capacity, we use a change of measure that depends on the current state of the network occupancy. this is the dynamic issc method. we prove that this method yields zero variance estimators for single clique models, and we empirically show the advantages of this method over naive simulation for networks of moderate size and traffic loads","['dynamic channel assignment', 'cellular mobile communication networks', 'strong coupling constraints', 'occupancy vector', 'approximate tractable models', 'product form stationary state distributions', 'simulation', 'cpu time', 'importance sampling', 'low-load', 'high cell capacity', 'bounded relative error', 'dynamic issc method', 'zero variance estimators', 'single clique models', 'blocking probability estimation', 'standard clock method', 'static issc method', 'quality of service', 'network traffic load']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'R']","['dynamic channel assignment', 'cellular mobile communication network', 'strong coupling constraint', 'occupancy vector', 'approximate tractable model', 'product form stationary state distribution', 'simulation', 'cpu time', 'importance sample', 'low - load', 'high cell capacity', 'bound relative error', 'dynamic issc method', 'zero variance estimator', 'single clique model', 'block probability estimation', 'standard clock method', 'static issc method', 'quality of service', 'network traffic load']","['cellular mobile communication network', 'real channel assignment scheme', 'block event', 'block probability', 'network occupancy', 'block probability', 'clique model', 'approximate tractable model', 'importance sample', 'cell capacity']"
136,546,Real-time quasi-2-D inversion of array resistivity logging data using neural network,"we present a quasi-2-d real-time inversion algorithm for a modern galvanic array tool via dimensional reduction and neural network simulation. using reciprocity and superposition, we apply a numerical focusing technique to the unfocused data. the numerically focused data are much less subject to 2-d and layering effects and can be approximated as from a cylindrical 1-d earth. we then perform 1-d inversion on the focused data to provide approximate information about the 2-d resistivity structure. a neural network is used to perform forward modeling in the 1-d inversion, which is several hundred times faster than conventional numerical forward solutions. testing our inversion algorithm on both synthetic and field data shows that this fast inversion algorithm is useful for providing formation resistivity information at a well site","['real-time quasi-2-d inversion', 'array resistivity logging data', 'neural network', 'real-time inversion algorithm', 'galvanic array tool', 'dimensional reduction', 'reciprocity', 'superposition', 'numerical focusing technique', 'unfocused data', 'focused data', '1-d inversion', 'forward modeling', 'formation resistivity', 'well site']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['real - time quasi-2 - d inversion', 'array resistivity log data', 'neural network', 'real - time inversion algorithm', 'galvanic array tool', 'dimensional reduction', 'reciprocity', 'superposition', 'numerical focus technique', 'unfocused datum', 'focus datum', '1 - d inversion', 'forward model', 'formation resistivity', 'well site']","['fast inversion algorithm', 'inversion algorithm', 'neural network simulation', 'numerical focus technique', 'galvanic array', 'inversion', 'formation resistivity', 'conventional numerical forward solution', 'resistivity structure', 'neural network']"
137,687,Image reconstruction of simulated specimens using convolution back projection,"this paper reports the reconstruction of cross-sections of composite structures. the convolution back projection (cbp) algorithm has been used to capture the attenuation field over the specimen. five different test cases have been taken up for evaluation. these cases represent varying degrees of complexity. in addition, the role of filters on the nature of the reconstruction errors has also been discussed. numerical results obtained in the study reveal that cbp algorithm is a useful tool for qualitative as well as quantitative assessment of composite regions encountered in engineering applications","['image reconstruction', 'simulated specimens', 'convolution back projection', 'composite structures', 'attenuation field', 'filters', 'reconstruction errors', 'cbp algorithm', 'composite regions', 'engineering applications', 'computerised tomography']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U']","['image reconstruction', 'simulate specimen', 'convolution back projection', 'composite structure', 'attenuation field', 'filter', 'reconstruction error', 'cbp algorithm', 'composite region', 'engineering application', 'computerised tomography']","['composite structure', 'composite region', 'attenuation field', 'reconstruction error', 'reconstruction', 'cbp algorithm', 'convolution', 'projection', 'speciman', 'numerical result']"
138,1297,Stochastic optimization of acoustic response - a numerical and experimental comparison,"the objective of the work presented is to compare results from numerical optimization with experimental data and to highlight and discuss the differences between two fundamentally different optimization methods. the problem domain is minimization of acoustic emission and the structure used in the work is a closed cylinder with forced vibration of one end. the optimization method used in this paper is simulated annealing (sa), a stochastic method. the results are compared with those from a gradient-based method used on the same structure in an earlier paper (tinnsten, 2000)","['stochastic optimization', 'acoustic response', 'numerical optimization', 'structure', 'closed cylinder', 'forced vibration', 'simulated annealing', 'gradient-based method', 'acoustic emission minimization']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['stochastic optimization', 'acoustic response', 'numerical optimization', 'structure', 'close cylinder', 'force vibration', 'simulate annealing', 'gradient - base method', 'acoustic emission minimization']","['numerical optimization', 'optimization method', 'optimization method', 'acoustic emission', 'simulate annealing', 'minimization', 'stochastic method', 'close cylinder', 'vibration', 'gradient']"
139,112,"Revisiting Hardy's paradox: Counterfactual statements, real measurements, entanglement and weak values","hardy's (1992) paradox is revisited. usually the paradox is dismissed on grounds of counterfactuality, i.e., because the paradoxical effects appear only when one considers results of experiments which do not actually take place. we suggest a new set of measurements in connection with hardy's scheme, and show that when they are actually performed, they yield strange and surprising outcomes. more generally, we claim that counterfactual paradoxes point to a deeper structure inherent to quantum mechanics","['counterfactual statements', 'real measurements', 'entanglement', 'weak values', 'paradoxical effects', 'quantum mechanics', 'hardy paradox', 'gedanken-experiments']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'U']","['counterfactual statement', 'real measurement', 'entanglement', 'weak value', 'paradoxical effect', 'quantum mechanic', 'hardy paradox', 'gedanken - experiment']","['counterfactual paradox', 'paradoxical effect appear', 'paradox', 'counterfactuality', 'surprising outcome', 'experiment', 'hardy', 'deep structure inherent', 'revisit', 'consider result']"
140,951,How to drive strategic innovation [law firms],innovation. it has everything to do with organization and attitude. marginal improvement isn't enough anymore. convert your problem-solving skills into a new value for the entire firm. 10 initiatives,"['strategic innovation', 'law firms', 'management', 'change', 'clients', 'experiments']","['P', 'P', 'U', 'U', 'U', 'U']","['strategic innovation', 'law firm', 'management', 'change', 'client', 'experiment']","['marginal improvement', 'solve skill', 'innovation', 'organization', 'entire firm', 'new value', 'problem', 'attitude', 'have', 'do']"
141,914,A knowledge management framework for the support of decision making in humanitarian assistance/disaster relief,"the major challenge in current humanitarian assistance/disaster relief (ha/dr) efforts is that diverse information and knowledge are widely distributed and owned by different organizations. these resources are not efficiently organized and utilized during ha/dr operations. we present a knowledge management framework that integrates multiple information technologies to collect, analyze, and manage information and knowledge for supporting decision making in ha/dr. the framework will help identify the information needs, be aware of a disaster situation, and provide decision-makers with useful relief recommendations based on past experience. a comprehensive, consistent and authoritative knowledge base within the framework will facilitate knowledge sharing and reuse. this framework can also be applied to other similar real-time decision-making environments, such as crisis management and emergency medical assistance","['knowledge management framework', 'humanitarian assistance', 'disaster relief', 'organizations', 'information technology', 'information needs', 'knowledge sharing', 'real-time decision-making environments', 'crisis management', 'emergency medical assistance', 'decision support system', 'knowledge reuse', 'case-based reasoning']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'U']","['knowledge management framework', 'humanitarian assistance', 'disaster relief', 'organization', 'information technology', 'information need', 'knowledge sharing', 'real - time decision - make environment', 'crisis management', 'emergency medical assistance', 'decision support system', 'knowledge reuse', 'case - base reasoning']","['knowledge management framework', 'integrate multiple information technology', 'facilitate knowledge sharing', 'authoritative knowledge base', 'manage information', 'useful relief recommendation base', 'humanitarian assistance', 'disaster relief', 'crisis management', 'information need']"
142,586,A strategy for a payoff-switching differential game based on fuzzy reasoning,"in this paper, a new concept of a payoff-switching differential game is introduced. in this new game, any one player at any time may have several choices of payoffs for the future. moreover, the payoff-switching process, including the time of payoff switching and the outcome payoff, of any one player is unknown to the other. indeed, the overall payoff, which is a sequence of several payoffs, is unknown until the game ends. an algorithm for determining a reasoning strategy based on fuzzy reasoning is proposed. in this algorithm, the fuzzy theory is used to estimate the behavior of one player during a past time interval. by deriving two fuzzy matrices gsm, game similarity matrix, and vgsm, variation of gsm, the behavior of the player can be quantified. two weighting vectors are selected to weight the relative importance of the player's behavior at each past time instant. finally a simple fuzzy inference rule is adopted to generate a linear reasoning strategy. the advantage of this algorithm is that it provides a flexible way for differential game specialists to convert their knowledge into a ""reasonable"" strategy. a practical example of guarding three territories is given to illustrate our main ideas","['payoff-switching differential game', 'differential game', 'fuzzy reasoning', 'payoff switching', 'outcome payoff', 'reasoning strategy', 'fuzzy matrices', 'game similarity matrix', 'weighting vectors', 'fuzzy inference']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['payoff - switch differential game', 'differential game', 'fuzzy reasoning', 'payoff switch', 'outcome payoff', 'reasoning strategy', 'fuzzy matrix', 'game similarity matrix', 'weighting vector', 'fuzzy inference']","['reasoning strategy base', 'switch differential game', 'simple fuzzy inference rule', 'linear reasoning strategy', 'game similarity matrix', 'fuzzy matrix gsm', 'fuzzy reasoning', 'payoff switch', 'differential game specialist', 'fuzzy theory']"
143,1196,Multiple shooting using a dichotomically stable integrator for solving differential-algebraic equations,"in previous work by the first author, it has been established that a dichotomically stable discretization is needed when solving a stiff boundary-value problem in ordinary differential equations (odes), when sharp boundary layers may occur at each end of the interval. a dichotomically stable implicit runge-kutta method, using the 3-stage, fourth-order, lobatto iiia formulae, has been implemented in a variable step-size initial-value integrator, which could be used in a multiple-shooting approach. in the case of index-one differential-algebraic equations (daes) the use of the lobatto iiia formulae has an advantage, over a comparable gaussian method, that the order is the same for both differential and algebraic variables, and there is no need to treat them separately. the ode integrator has been adapted for the solution of index-one daes, and the resulting integrator (symdae) has been inserted into the multiple-shooting code (mshdae) previously developed by r. lamour for differential-algebraic boundary-value problems. the standard version of mshdae uses a bdf integrator, which is not dichotomically stable, and for some stiff test problems this fails to integrate across the interval of interest, while the dichotomically stable integrator symdae encounters no difficulty. indeed, for such problems, the modified version of mshdae produces an accurate solution, and within limits imposed by computer word length, the efficiency of the solution process improves with increasing stiffness. for some nonstiff problems, the solution is also entirely satisfactory","['multiple shooting', 'dichotomically stable integrator', 'differential-algebraic equations', 'stiff boundary-value problem', 'ordinary differential equations', 'implicit runge-kutta method', 'lobatto iiia formulae', 'initial-value integrator']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['multiple shooting', 'dichotomically stable integrator', 'differential - algebraic equation', 'stiff boundary - value problem', 'ordinary differential equation', 'implicit runge - kutta method', 'lobatto iiia formulae', 'initial - value integrator']","['ode integrator', 'stable integrator symdae', 'lobatto iiia formulae have', 'lobatto iiia formulae', 'bdf integrator', 'kutta method', 'stable discretization', 'ordinary differential equation', 'value integrator', 'integrator']"
144,809,"Edison's direct current influenced ""Broadway"" show lighting","during the early decades of the 20 th century, midtown manhattan in new york city developed an extensive underground direct current (dc) power distribution system. this was a result of the original introduction of direct current by thomas edison's pioneering pearl street station in 1882. the availability of dc power in the theater district, led to the perpetuation of an archaic form of stage lighting control through nearly three-quarters of the 20 th century. this control device was known as a ""resistance dimmer."" it was essentially a series-connected rheostat, but it was wound with a special resistance ""taper"" so as to provide a uniform change in the apparent light output of typical incandescent lamps throughout the travel of its manually operated arm. the development and use of dc powered stage lighting is discussed in this article","['manhattan', 'new york city', 'theater district', 'stage lighting control', 'resistance dimmer', 'series-connected rheostat', 'apparent light output', 'incandescent lamps', 'dc powered stage lighting', 'broadway show lighting', 'underground direct current power distribution system', ""thomas edison's pearl street station"", 'resistance taper']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R']","['manhattan', 'new york city', 'theater district', 'stage lighting control', 'resistance dimmer', 'series - connect rheostat', 'apparent light output', 'incandescent lamp', 'dc powered stage lighting', 'broadway show light', 'underground direct current power distribution system', ""thomas edison 's pearl street station"", 'resistance taper']","['dc powered stage lighting', 'underground direct current', 'stage lighting control', 'typical incandescent lamp', 'midtown manhattan', 'new york city develop', 'resistance dimmer', 'direct current', 'thomas edison', 'pioneer pearl street station']"
145,767,Quantum computation for physical modeling,"one of the most famous american physicists of the twentieth century, richard feynman, in 1982 was the first to propose using a quantum mechanical computing device to efficiently simulate quantum mechanical many-body dynamics, a task that is exponentially complex in the number of particles treated and is completely intractable by any classical computing means for large systems of many particles. in the two decades following his work, remarkable progress has been made both theoretically and experimentally in the new field of quantum computation","['quantum computation', 'physical modeling', 'quantum mechanical computing', 'quantum mechanical many-body dynamics']","['P', 'P', 'P', 'P']","['quantum computation', 'physical modeling', 'quantum mechanical computing', 'quantum mechanical many - body dynamic']","['simulate quantum mechanical many', 'quantum mechanical compute device', 'richard feynman', 'famous american physicist', 'many particle', 'classical computing', 'particle', 'body dynamic', 'remarkable progress', 'large system']"
146,722,Updating systems for monitoring and controlling power equipment on the basis of the firmware system SARGON,the economic difficulties experienced by the power industry of russia has considerably retarded the speed of commissioning new capacities and reconstructing equipment in service. the increasing deterioration of the equipment at power stations makes the problem of its updating very acute. the main efforts of organizations working in the power industry are now focused on updating all kinds of equipment installed at power installations. the necessary condition for the efficient operation of power equipment is to carry out serious modernization of systems for monitoring and control (smc) of technological processes. the specialists at zao nvt-avtomatika have developed efficient technology for updating the smc on the basis of the firmware system sargon which ensures the fast introduction of high-quality systems of automation with a minimal payback time of the capital outlay. this paper discusses the updating of equipment using sargon,"['power industry', 'russia', 'zao nvt-avtomatika', 'sargon firmware system', 'monitoring systems', 'control systems', 'power equipment monitoring', 'power equipment control']","['P', 'P', 'P', 'R', 'R', 'R', 'R', 'R']","['power industry', 'russia', 'zao nvt - avtomatika', 'sargon firmware system', 'monitor system', 'control system', 'power equipment monitoring', 'power equipment control']","['firmware system sargon', 'commission new capacity', 'power equipment', 'reconstruct equipment', 'equipment instal', 'power station make', 'power installation', 'technological process', 'automation', 'monitor']"
147,1377,Open hypermedia for product support,"as industrial systems become increasingly more complex, the maintenance and operating information increases both in volume and complexity. with the current pressures on manufacturing, the management of information resources has become a critical issue. in particular, ensuring that personnel can access current information quickly and effectively when undertaking a specific task. this paper discusses some of the issues involved in, and the benefits of using, open hypermedia to manage and deliver a diverse range of information. while the paper concentrates on the problems specifically associated with manufacturing organizations, the problems are generic across other business sectors such as healthcare, defence and finance. the open hypermedia approach to information management and delivery allows a multimedia resource base to be used for a range of applications and it permits a user to have controlled access to the required information in an easily accessible and structured manner. recent advancement in hypermedia also permits just-in-time support in the most appropriate format for all users. our approach is illustrated by the discussion of a case study in which an open hypermedia system delivers maintenance and process information to factory-floor users to support the maintenance and operation of a very large manufacturing cell","['open hypermedia', 'product support', 'maintenance', 'operating information', 'information resources', 'just-in-time support']","['P', 'P', 'P', 'P', 'P', 'P']","['open hypermedia', 'product support', 'maintenance', 'operate information', 'information resource', 'just - in - time support']","['open hypermedia system deliver maintenance', 'open hypermedia approach', 'multimedia resource base', 'operate information', 'information management', 'open hypermedia', 'other business sector such', 'process information', 'information resource', 'industrial system become']"
148,1332,Personal cards for on-line purchases,"buying presents over the web has advantages for a busy person: lots of choices, 24-hour accessibility, quick delivery, and you don't even have to wrap the gift. but many people like to select a card or write a personal note to go with their presents, and the options for doing that have been limited. two companies have seen this limitation as an opportunity: 4yoursoul.com and cardinthebox.com","['personal cards', '4yoursoul.com', 'cardinthebox.com', 'personalized printing', 'online purchases']","['P', 'P', 'P', 'M', 'M']","['personal card', '4yoursoul.com', 'cardinthebox.com', 'personalize printing', 'online purchase']","['buy present', 'present', 'gift', 'quick delivery', 'card', 'personal note', 'busy person', 'web', 'wrap', 'limit']"
149,1076,Delayed-choice entanglement swapping with vacuum-one-photon quantum states,"we report the experimental realization of a recently discovered quantum-information protocol by peres implying an apparent nonlocal quantum mechanical retrodiction effect. the demonstration is carried out by a quantum optical method by which each singlet entangled state is physically implemented by a two-dimensional subspace of fock states of a mode of the electromagnetic field, specifically the space spanned by the vacuum and the one-photon state, along lines suggested recently by e. knill et al. [nature (london) 409, 46 (2001)] and by m. duan et al. [ibid. 414, 413 (2001)]","['delayed-choice entanglement', 'vacuum-one-photon quantum states', 'quantum-information', 'nonlocal quantum mechanical retrodiction effect', 'quantum optical method', 'singlet entangled state', 'two-dimensional subspace', 'fock states', 'one-photon state', 'state entanglement', 'electromagnetic field mode', 'vacuum state']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['delay - choice entanglement', 'vacuum - one - photon quantum state', 'quantum - information', 'nonlocal quantum mechanical retrodiction effect', 'quantum optical method', 'singlet entangle state', 'two - dimensional subspace', 'fock state', 'one - photon state', 'state entanglement', 'electromagnetic field mode', 'vacuum state']","['apparent nonlocal quantum mechanical retrodiction effect', 'quantum optical', 'singlet entangle state', 'discover quantum', 'information protocol', 'photon state', 'fock state', 'experimental realization', 'electromagnetic field', 'space span']"
150,1033,Optical two-step modified signed-digit addition based on binary logic gates,"a new modified signed-digit (msd) addition algorithm based on binary logic gates is proposed for parallel computing. it is shown that by encoding each of the input msd digits and flag digits into a pair of binary bits, the number of addition steps can be reduced to two. the flag digit is introduced to characterize the next low order pair (nlop) of the input digits in order to suppress carry propagation. the rules for two-step addition of binary coded msd (bcmsd) numbers are formulated that can be implemented using optical shadow-casting logic system","['optical two-step modified signed-digit addition', 'binary logic gates', 'parallel computing', 'input msd digits', 'flag digits', 'binary bits', 'addition steps', 'low order pair', 'two-step addition', 'binary coded msd', 'optical shadow-casting logic system', 'modified signed-digit addition algorithm', 'carry propagation suppression']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['optical two - step modify sign - digit addition', 'binary logic gate', 'parallel computing', 'input msd digit', 'flag digit', 'binary bit', 'addition step', 'low order pair', 'two - step addition', 'binary code msd', 'optical shadow - cast logic system', 'modify sign - digit addition algorithm', 'carry propagation suppression']","['binary code msd', 'binary logic gate', 'binary bit', 'addition algorithm', 'parallel computing', 'flag digit', 'input msd digit', 'flag digit', 'addition step', 'optical shadow']"
151,64,Speech enhancement using a mixture-maximum model,"we present a spectral domain, speech enhancement algorithm. the new algorithm is based on a mixture model for the short time spectrum of the clean speech signal, and on a maximum assumption in the production of the noisy speech spectrum. in the past this model was used in the context of noise robust speech recognition. in this paper we show that this model is also effective for improving the quality of speech signals corrupted by additive noise. the computational requirements of the algorithm can be significantly reduced, essentially without paying performance penalties, by incorporating a dual codebook scheme with tied variances. experiments, using recorded speech signals and actual noise sources, show that in spite of its low computational requirements, the algorithm shows improved performance compared to alternative speech enhancement algorithms","['mixture-maximum model', 'spectral domain', 'speech enhancement algorithm', 'mixture model', 'short time spectrum', 'clean speech signal', 'noisy speech spectrum', 'noise robust speech recognition', 'additive noise', 'performance penalties', 'dual codebook', 'tied variances', 'recorded speech signals', 'noise sources', 'low computational requirements', 'speech signal quality', 'gaussian mixture model', 'mixmax model', 'speech intelligibility']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M', 'M']","['mixture - maximum model', 'spectral domain', 'speech enhancement algorithm', 'mixture model', 'short time spectrum', 'clean speech signal', 'noisy speech spectrum', 'noise robust speech recognition', 'additive noise', 'performance penalty', 'dual codebook', 'tie variance', 'record speech signal', 'noise source', 'low computational requirement', 'speech signal quality', 'gaussian mixture model', 'mixmax model', 'speech intelligibility']","['noise robust speech recognition', 'noisy speech spectrum', 'speech enhancement algorithm', 'use record speech signal', 'speech signal corrupt', 'algorithm show improved performance', 'additive noise', 'clean speech signal', 'noise source', 'spectral domain']"
152,136,Design of 1-D and 2-D variable fractional delay allpass filters using weighted least-squares method,"in this paper, a weighted least-squares method is presented to design one-dimensional and two-dimensional variable fractional delay allpass filters. first, each coefficient of the variable allpass filter is expressed as the polynomial of the fractional delay parameter. then, the nonlinear phase error is approximated by a weighted equation error such that the cost function can be converted into a quadratic form. next, by minimizing the weighted equation error, the optimal polynomial coefficients can be obtained iteratively by solving a set of linear simultaneous equations at each iteration. finally, the design examples are demonstrated to illustrate the effectiveness of the proposed approach","['variable fractional delay allpass filters', 'weighted least-squares method', 'fractional delay parameter', 'weighted equation error', 'cost function', 'optimal polynomial coefficients', 'linear simultaneous equations', '1d allpass filters', '2d allpass filters', 'nonlinear phase error approximation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'R']","['variable fractional delay allpass filter', 'weight least - square method', 'fractional delay parameter', 'weight equation error', 'cost function', 'optimal polynomial coefficient', 'linear simultaneous equation', '1d allpass filter', '2d allpass filter', 'nonlinear phase error approximation']","['variable fractional delay allpass filter', 'variable allpass filter', 'fractional delay parameter', 'optimal polynomial coefficient', 'nonlinear phase error', 'weight equation error', 'coefficient', 'linear', 'polynomial', 'quadratic']"
153,975,Algebraic conditions for high-order convergent deferred correction schemes based on Runge-Kutta-Nystrom methods for second order boundary value problems,"in [t. van hecke, m. van daele, j. comp. appl. math., vol. 132, p. 107-125, (2001)] the investigation of high-order convergence of deferred correction schemes for the numerical solution of second order nonlinear two-point boundary value problems not containing the first derivative, is made. the derivation of the algebraic conditions to raise the increase of order by the deferred correction scheme was based on taylor series expansions. in this paper we describe a more elegant way by means of p-series to obtain this necessary conditions and generalize this idea to equations of the form y"" = f (t, y, y')","['algebraic conditions', 'high-order convergent deferred correction schemes', 'deferred correction schemes', 'runge-kutta-nystrom methods', 'second order boundary value problems', 'second order nonlinear two-point boundary value problems', 'taylor series expansions']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['algebraic condition', 'high - order convergent defer correction scheme', 'defer correction scheme', 'runge - kutta - nystrom method', 'second order boundary value problem', 'second order nonlinear two - point boundary value problem', 'taylor series expansion']","['second order nonlinear', 'taylor series expansion', 'defer correction scheme', 'defer correction scheme', 'numerical solution', 'point boundary value problem', 'order convergence', 'first derivative', 'series', 'equation']"
154,930,NARX-based technique for the modelling of magneto-rheological damping devices,"this paper presents a methodology for identifying variable-structure nonlinear models of magneto-rheological dampers (mrd) and similar devices. its peculiarity with respect to the mainstream literature is to be especially conceived for obtaining models that are structurally simple, easy to estimate and well suited for model-based control. this goal is pursued by adopting linear-in-the-parameters narx models, for which an identification method is developed based on the minimization of the simulation error. this method is capable of selecting the model structure together with the parameters, thus it does not require a priori structural information. a set of validation tests is reported, with the aim of demonstrating the technique's efficiency by comparing it to a widely accepted mrd modelling approach","['modelling', 'identification', 'model-based control', 'narx models', 'minimization', 'simulation error', 'validation', 'mrd modelling', 'magnetorheological damping']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['model', 'identification', 'model - base control', 'narx model', 'minimization', 'simulation error', 'validation', 'mrd modelling', 'magnetorheological damp']","['rheological damper', 'parameter narx model', 'structure nonlinear model', 'model structure', 'parameter', 'magneto', 'model', 'model', 'simulation error', 'mrd']"
155,988,A new merging algorithm for constructing suffix trees for integer alphabets,"a new approach for constructing a suffix tree t/sub s/ for a given string s is to construct recursively a suffix tree t/sub o/ for odd positions, construct a suffix, tree t/sub e/ for even positions from t/sub o/ and then merge t/sub o/ and t/sub e/ into t/sub s/. to construct suffix trees for integer alphabets in linear time had been a major open problem on index data structures. farach used this approach and gave the first linear-time algorithm for integer alphabets. the hardest part of farach's algorithm is the merging step. in this paper we present a new and simpler merging algorithm based on a coupled bfs (breadth-first search). our merging algorithm is more intuitive than farach's coupled dfs (depth-first search) merging, and thus it can be easily extended to other applications","['merging algorithm', 'suffix trees', 'integer alphabets', 'linear time', 'index data structures', 'coupled bfs', 'breadth-first search', 'recursive construction']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['merge algorithm', 'suffix tree', 'integer alphabet', 'linear time', 'index datum structure', 'couple bfs', 'breadth - first search', 'recursive construction']","['simple merging algorithm base', 'construct suffix tree', 'suffix tree', 'merge algorithm', 'index datum structure', 'integer alphabet', 'suffix', 'time algorithm', 'algorithm', 'give string']"
156,99,Radianz and Savvis look to expand service in wake of telecom scandals [finance],"with confidence in network providers waning, radianz and savvis try to prove their stability. savvis and radianz, which both specialize in providing the data-extranet components of telecommunication infrastructures, may see more networking doors open at investment banks, brokerage houses, exchanges and alternative-trading systems","['radianz', 'savvis', 'network providers', 'data-extranet', 'telecommunication infrastructures', 'investment banks', 'brokerage houses', 'exchanges', 'alternative-trading systems']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['radianz', 'savvis', 'network provider', 'data - extranet', 'telecommunication infrastructure', 'investment bank', 'brokerage house', 'exchange', 'alternative - trading system']","['network provider wane', 'see more networking door open', 'telecommunication infrastructure', 'investment bank', 'extranet component', 'radianz', 'savvis', 'brokerage house', 'stability', 'exchange']"
157,895,Algorithms for improving the quality of R-trees,"a novel approach to operation with a structure for spatial indexing of extended objects shaped as r-trees is considered. it consists of the initial global construction of an efficient r-tree structure and the subsequent operation with it using conventional dynamic algorithms. a global strategy for constructing an r-tree reduced to a problem of dividing a set of rectangular objects into k parts with minimum mutual overlay is suggested. base, box, and ""divide and conquer"" algorithms are suggested. the results of experimental modeling of the execution of various algorithms are discussed","['r-trees', 'spatial indexing', 'extended objects', 'dynamic algorithms', 'rectangular objects', 'minimum mutual overlay', 'graphical search', 'computational geometry']","['P', 'P', 'P', 'P', 'P', 'P', 'U', 'U']","['r - tree', 'spatial indexing', 'extend object', 'dynamic algorithm', 'rectangular object', 'minimum mutual overlay', 'graphical search', 'computational geometry']","['spatial indexing', 'dynamic algorithm', 'extend object shape', 'rectangular object', 'tree structure', 'various algorithm', 'algorithm', 'tree reduce', 'tree', 'minimum mutual overlay']"
158,1052,Developing a high-performance web server in Concurrent Haskell,"server applications, and in particular network-based server applications, place a unique combination of demands on a programming language: lightweight concurrency, high i/o throughput, and fault tolerance are all important. this paper describes a prototype web server written in concurrent haskell (with extensions), and presents two useful results: firstly, a conforming server could be written with minimal effort, leading to an implementation in less than 1500 lines of code, and secondly the naive implementation produced reasonable performance. furthermore, making minor modifications to a few time-critical components improved performance to a level acceptable for anything but the most heavily loaded web servers","['high-performance web server', 'concurrent haskell', 'network-based server applications', 'lightweight concurrency', 'high i/o throughput', 'fault tolerance', 'conforming server', 'time-critical components']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['high - performance web server', 'concurrent haskell', 'network - base server application', 'lightweight concurrency', 'high i / o throughput', 'fault tolerance', 'conform server', 'time - critical component']","['prototype web server write', 'concurrent haskell', 'lightweight concurrency', 'naive implementation produce reasonable performance', 'base server application', 'server application', 'conform server', 'critical component improve performance', 'programming language', 'throughput']"
159,1017,Searching a scalable approach to cerebellar based control,"decades of research into the structure and function of the cerebellum have led to a clear understanding of many of its cells, as well as how learning might take place. furthermore, there are many theories on what signals the cerebellum operates on, and how it works in concert with other parts of the nervous system. nevertheless, the application of computational cerebellar models to the control of robot dynamics remains in its infant state. to date, few applications have been realized. the currently emerging family of light-weight robots poses a new challenge to robot control: due to their complex dynamics traditional methods, depending on a full analysis of the dynamics of the system, are no longer applicable since the joints influence each other dynamics during movement. can artificial cerebellar models compete here?","['scalable approach', 'cerebellar based control', 'nervous system', 'computational cerebellar models', 'light-weight robots', 'robot control']","['P', 'P', 'P', 'P', 'P', 'P']","['scalable approach', 'cerebellar base control', 'nervous system', 'computational cerebellar model', 'light - weight robot', 'robot control']","['artificial cerebellar model compete', 'computational cerebellar model', 'robot dynamic', 'robot control', 'cerebellum operate', 'weight robot pose', 'cerebellum', 'complex dynamic', 'dynamic', 'movement']"
160,743,Local satellite,consumer based mobile satellite phone services went from boom to burn up in twelve months despite original forecasts predicting 10 million to 40 million users by 2005. julian bright wonders what prospects the technology has now and if going regional might be one answer,['mobile satellite phone services'],['P'],['mobile satellite phone service'],"['consumer base mobile satellite phone service', 'forecast predict', 'technology have', 'go regional', 'prospect', 'julian bright wonder', 'boom', 'burn', 'month', 'user']"
161,706,Enhancing the reliability of modular medium-voltage drives,"a method to increase the reliability of modular medium-voltage induction motor drives is discussed, by providing means to bypass a failed module. the impact on reliability is shown. a control, which maximizes the output voltage available after bypass, is described, and experimental results are given","['modular medium-voltage induction motor drives', 'reliability enhancement', 'failed module bypass', 'available output voltage control']","['P', 'R', 'R', 'R']","['modular medium - voltage induction motor drive', 'reliability enhancement', 'fail module bypass', 'available output voltage control']","['voltage induction motor drive', 'fail module', 'reliability', 'modular medium', 'voltage', 'bypass', 'control']"
162,1353,Generalized spatio-chromatic diffusion,"a framework for diffusion of color images is presented. the method is based on the theory of thermodynamics of irreversible transformations which provides a suitable basis for designing correlations between the different color channels. more precisely, we derive an equation for color evolution which comprises a purely spatial diffusive term and a nonlinear term that depends on the interactions among color channels over space. we apply the proposed equation to images represented in several color spaces, such as rgb, cielab, opponent colors, and ihs","['generalized spatio-chromatic diffusion', 'diffusion', 'color images', 'thermodynamics', 'irreversible transformations', 'color channels', 'color evolution', 'spatial diffusive term', 'nonlinear term', 'rgb', 'cielab', 'opponent colors', 'ihs', 'vector-valued diffusion', 'scale-space']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U']","['generalize spatio - chromatic diffusion', 'diffusion', 'color image', 'thermodynamic', 'irreversible transformation', 'color channel', 'color evolution', 'spatial diffusive term', 'nonlinear term', 'rgb', 'cielab', 'opponent color', 'ihs', 'vector - value diffusion', 'scale - space']","['color image', 'different color channel', 'color evolution', 'color channel', 'spatial diffusive term', 'diffusion', 'opponent color', 'irreversible transformation', 'rgb', 'color space']"
163,1316,Understanding Internet traffic streams: dragonflies and tortoises,"we present the concept of network traffic streams and the ways they aggregate into flows through internet links. we describe a method of measuring the size and lifetime of internet streams, and use this method to characterize traffic distributions at two different sites. we find that although most streams (about 45 percent of them) are dragonflies, lasting less than 2 seconds, a significant number of streams have lifetimes of hours to days, and can carry a high proportion (50-60 percent) of the total bytes on a given link. we define tortoises as streams that last longer than 15 minutes. we point out that streams can be classified not only by lifetime (dragonflies and tortoises) but also by size (mice and elephants), and note that stream size and lifetime are independent dimensions. we submit that isps need to be aware of the distribution of internet stream sizes, and the impact of the difference in behavior between short and long streams. in particular, any forwarding cache mechanisms in internet routers must be able to cope with a high volume of short streams. in addition isps should realize that long-running streams can contribute a significant fraction of their packet and byte volumes-something they may not have allowed for when using traditional ""flat rate user bandwidth consumption"" approaches to provisioning and engineering","['internet traffic streams', 'dragonflies', 'tortoises', 'network traffic streams', 'traffic distributions', 'mice', 'elephants', 'isp', 'forwarding cache mechanisms', 'internet routers', 'long-running streams', 'internet stream size measurement', 'internet stream lifetime measurement', 'packet volume', 'byte volume', 'traffic provisioning', 'traffic engineering']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'R', 'R']","['internet traffic stream', 'dragonfly', 'tortoise', 'network traffic stream', 'traffic distribution', 'mouse', 'elephant', 'isp', 'forward cache mechanism', 'internet router', 'long - run stream', 'internet stream size measurement', 'internet stream lifetime measurement', 'packet volume', 'byte volume', 'traffic provisioning', 'traffic engineering']","['network traffic stream', 'rate user bandwidth consumption', 'internet stream size', 'internet stream', 'internet router', 'long stream', 'short stream', 'run stream', 'forward cache', 'internet link']"
164,868,Two quantum analogues of Fisher information from a large deviation viewpoint of quantum estimation,"we discuss two quantum analogues of the fisher information, the symmetric logarithmic derivative fisher information and kubo-mori-bogoljubov fisher information from a large deviation viewpoint of quantum estimation and prove that the former gives the true bound and the latter gives the bound of consistent superefficient estimators. as another comparison, it is shown that the difference between them is characterized by the change of the order of limits","['quantum analogues', 'large deviation viewpoint', 'quantum estimation', 'symmetric logarithmic derivative fisher information', 'kubo-mori-bogoljubov fisher information', 'consistent superefficient estimators', 'statistical inference']","['P', 'P', 'P', 'P', 'P', 'P', 'U']","['quantum analogue', 'large deviation viewpoint', 'quantum estimation', 'symmetric logarithmic derivative fisher information', 'kubo - mori - bogoljubov fisher information', 'consistent superefficient estimator', 'statistical inference']","['symmetric logarithmic derivative fisher information', 'bogoljubov fisher information', 'quantum estimation', 'fisher information', 'consistent superefficient estimator', 'quantum analogue', 'large deviation', 'true bound', 'bind', 'kubo']"
165,1092,Ride quality evaluation of an actively-controlled stretcher for an ambulance,"this study considers the subjective evaluation of ride quality during ambulance transportation using an actively-controlled stretcher (acs). the ride quality of a conventional stretcher and an assistant driver's seat is also compared. braking during ambulance transportation generates negative foot-to-head acceleration in patients and causes blood pressure to rise in the patient's head. the acs absorbs the foot-to-head acceleration by changing the angle of the stretcher, thus reducing the blood pressure variation. however, the ride quality of the acs should be investigated further because the movement of the acs may cause motion sickness and nausea. experiments of ambulance transportation, including rapid acceleration and deceleration, are performed to evaluate the effect of differences in posture of the transported subject on the ride quality; the semantic differential method and factor analysis are used in the investigations. subjects are transported using a conventional stretcher with head forward, a conventional stretcher with head backward, the acs, and an assistant driver's seat for comparison with transportation using a stretcher. experimental results show that the acs gives the most comfortable transportation when using a stretcher. moreover, the reduction of the negative foot-to-head acceleration at frequencies below 0.2 hz and the small variation of the foot-to-head acceleration result in more comfortable transportation. conventional transportation with the head forward causes the worst transportation, although the characteristics of the vibration of the conventional stretcher seem to be superior to that of the acs","['ride quality evaluation', 'actively-controlled stretcher', 'ambulance', 'subjective evaluation', 'ambulance transportation', 'conventional stretcher', 'braking', 'negative foot-to-head acceleration', 'blood pressure variation', 'motion sickness', 'nausea', 'rapid acceleration', 'transported subject', 'semantic differential method', 'factor analysis', 'head forward', 'head backward', 'comfortable transportation', 'vibration', 'assistant driver seat', 'patient head', 'stretcher angle', 'rapid deceleration', 'posture differences']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'R']","['ride quality evaluation', 'actively - control stretcher', 'ambulance', 'subjective evaluation', 'ambulance transportation', 'conventional stretcher', 'brake', 'negative foot - to - head acceleration', 'blood pressure variation', 'motion sickness', 'nausea', 'rapid acceleration', 'transport subject', 'semantic differential method', 'factor analysis', 'head forward', 'head backward', 'comfortable transportation', 'vibration', 'assistant driver seat', 'patient head', 'stretcher angle', 'rapid deceleration', 'posture difference']","['ambulance transportation use', 'ambulance transportation', 'comfortable transportation', 'conventional stretcher seem', 'posture', 'conventional stretcher', 'conventional transportation', 'semantic differential method', 'motion sickness', 'head acceleration result']"
166,1443,C and C++: a case for compatibility,"modern c and c++ are sibling languages descended from classic c. in many people's minds, they are (wrongly, but understandably) fused into the mythical c/c++ programming language. there is no c/c++ language, but there is a c/c++ community. previously the author described some of the incompatibilities that complicate the work of developers within that c/c++ community. in this article, he discusses some of the underlying myths that help perpetuate these incompatibilities. he also shows why more compatibility (ideally, full compatibility) is in the best interest of the c/c++ community. in the next paper, he presents some examples of how the incompatibilities in c and c++ might be resolved","['c++ language', 'incompatibilities', 'c language', 'object-oriented programming', 'class hierarchies', 'low-level programming', 'c++ libraries']","['P', 'P', 'R', 'M', 'U', 'M', 'M']","['c++ language', 'incompatibility', 'c language', 'object - orient programming', 'class hierarchy', 'low - level programming', 'c++ librarie']","['programming language', 'sible language descend', 'incompatibility', 'developer', 'more compatibility', 'language', 'full compatibility', 'underlie myth', 'complicate', 'modern']"
167,1406,Bluetooth bites back,"it is now more than four years since we started to hear about bluetooth, and from the user's point of view very little seems to have happened since then. paul haddlesey looks at the progress, and the role bluetooth may eventually play in your firm's communications strategy","['bluetooth', 'communications strategy', 'wireless connection', 'mobile']","['P', 'P', 'U', 'U']","['bluetooth', 'communication strategy', 'wireless connection', 'mobile']","['firm', 'year', 'progress', 'seem', 'happen', 'hear', 'start', 'paul haddlesey', 'role', 'more']"
168,810,Oracle's Suite grows up,"once a low-cost web offering, oracle's small business suite now carries a price tag to justify var interest","['oracle small business suite', 'netledger', 'accounting', 'resellers']","['R', 'U', 'U', 'U']","['oracle small business suite', 'netledger', 'account', 'reseller']","['cost web offering', 'small business suite', 'oracle', 'price tag', 'low', 'carry']"
169,855,Support communities for women in computing,"this article highlights the many activities provided by the support communities available for women in computing. thousands of women actively participate in these programs and they receive many benefits including networking and professional support. in addition, the organizations and associations help promote the accomplishments of women computer scientists and disseminate valuable information. this article surveys some of these organizations and concludes with a list of suggestions for how faculty members can incorporate the benefits of these organizations in their own institutions","['support communities', 'women', 'computing', 'networking', 'professional support', 'faculty members', 'information dissemination']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['support community', 'woman', 'compute', 'network', 'professional support', 'faculty member', 'information dissemination']","['woman computer scientist', 'receive many benefit include network', 'support community available', 'faculty member', 'professional support', 'woman', 'many activity provide', 'organization', 'compute', 'program']"
170,1393,ERP systems implementation: Best practices in Canadian government organizations,"erp (enterprise resource planning) systems implementation is a complex exercise in organizational innovation and change management. government organizations are increasing their adoption of these systems for various benefits such as integrated real-time information, better administration, and result-based management. government organizations, due to their social obligations, higher legislative and public accountability, and unique culture face many specific challenges in the transition to enterprise systems. this motivated the authors to explore the key considerations and typical activities in government organizations adopting erp systems. the article adopts the innovation process theory framework as well as the (markus & tanis, 2000) model as a basis to delineate the erp adoption process. although, each adopting organization has a distinct set of objectives for its systems, the study found many similarities in motivations, concerns, and strategies across organizations","['erp systems implementation', 'best practices', 'canadian government organizations', 'enterprise resource planning', 'integrated real-time information', 'administration', 'result-based management', 'social obligations', 'public accountability', 'innovation process theory framework', 'higher legislative accountability']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['erp system implementation', 'good practice', 'canadian government organization', 'enterprise resource planning', 'integrate real - time information', 'administration', 'result - base management', 'social obligation', 'public accountability', 'innovation process theory framework', 'high legislative accountability']","['government organization adopt erp system', 'innovation process theory framework', 'erp adoption process', 'enterprise resource planning', 'enterprise system', 'organizational innovation', 'government organization', 'adopt organization have', 'change management', 'system implementation']"
171,783,The network society as seen from Italy,"italy was behind the european average in internet development for many years, but a new trend, which has brought considerable change, emerged at the end of 1998 and showed its effects in 2000 and the following years. now italy is one of the top ten countries worldwide in internet hostcount and the fourth largest in europe. the density of internet activity in italy in proportion to the population is still below the average in the european union, but is growing faster than germany, the uk and france, and faster than the worldwide or european average. from the point of view of media control there are several problems. italy has democratic institutions and freedom of speech, but there is an alarming concentration in the control of mainstream media (especially broadcast). there are no officially declared restrictions in the use of the internet, but several legal and regulatory decisions reveal a desire to limit freedom of opinion and dialogue and/or gain centralized control of the net","['network society', 'italy', 'european average', 'europe', 'internet development', 'internet hostcount', 'internet activity', 'european union', 'germany', 'uk', 'france', 'media control', 'democratic institutions', 'freedom of speech', 'mainstream media', 'regulatory decisions', 'centralized control', 'worldwide average', 'broadcast media', 'legal decisions']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['network society', 'italy', 'european average', 'europe', 'internet development', 'internet hostcount', 'internet activity', 'european union', 'germany', 'uk', 'france', 'medium control', 'democratic institution', 'freedom of speech', 'mainstream medium', 'regulatory decision', 'centralize control', 'worldwide average', 'broadcast medium', 'legal decision']","['italy have democratic institution', 'internet development', 'internet hostcount', 'internet activity', 'european average', 'mainstream medium', 'medium control', 'internet', 'italy', 'centralize control']"
172,1137,On deciding stability of constrained homogeneous random walks and queueing systems,"we investigate stability of scheduling policies in queueing systems. to this day no algorithmic characterization exists for checking stability of a given policy in a given queueing system. in this paper we introduce a certain generalized priority policy and prove that the stability of this policy is algorithmically undecidable. we also prove that stability of a homogeneous random walk in l/sub +//sup d/ is undecidable. finally, we show that the problem of computing a fluid limit of a queueing system or of a constrained homogeneous random walk is undecidable. to the best of our knowledge these are the first undecidability results in the area of stability of queueing systems and random walks in l/sub +//sup d/. we conjecture that stability of common policies like first-in-first-out and priority policy is also an undecidable problem","['constrained homogeneous random walks', 'queueing systems', 'generalized priority policy', 'priority policy', 'undecidability results', 'undecidable problem', 'scheduling policy stability', 'homogeneous random walk stability', 'fluid limit computation', 'first-in-first-out policy']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R']","['constrain homogeneous random walk', 'queue system', 'generalize priority policy', 'priority policy', 'undecidability result', 'undecidable problem', 'scheduling policy stability', 'homogeneous random walk stability', 'fluid limit computation', 'first - in - first - out policy']","['scheduling policy', 'give queue system', 'queue system', 'certain generalized priority policy', 'queue system', 'constrain homogeneous random walk', 'priority policy', 'algorithmic characterization exist', 'first undecidability', 'homogeneous random walk']"
173,1172,Marble cutting with single point cutting tool and diamond segments,"an investigation has been undertaken into the frame sawing with diamond blades. the kinematic behaviour of the frame sawing process is discussed. under different cutting conditions, cutting and indenting-cutting tests are carried out by single point cutting tools and single diamond segments. the results indicate that the depth of cut per diamond grit increases as the blades move forward. only a few grits per segment can remove the material in the cutting process. when the direction of the stroke changes, the cutting forces do not decrease to zero because of the residual plastic deformation beneath the diamond grits. the plastic deformation and fracture chipping of material are the dominant removal processes, which can be explained by the fracture theory of brittle material indentation","['marble cutting', 'single point cutting tool', 'diamond segments', 'frame sawing', 'kinematic behaviour', 'indenting-cutting tests', 'residual plastic deformation', 'fracture chipping', 'removal processes', 'fracture theory', 'brittle material indentation', 'cutting tests']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['marble cutting', 'single point cut tool', 'diamond segment', 'frame saw', 'kinematic behaviour', 'indent - cut test', 'residual plastic deformation', 'fracture chip', 'removal process', 'fracture theory', 'brittle material indentation', 'cut test']","['frame sawing process', 'diamond blade', 'point cut tool', 'frame saw', 'diamond segment', 'fracture chip', 'diamond grit increase', 'cut force', 'cut process', 'diamond grit']"
174,562,The Advanced Encryption Standard - implementation and transition to a new cryptographic benchmark,"cryptography is the science of coding information to create unintelligible ciphers that conceal or hide messages. the process that achieves this goal is commonly referred to as encryption. although encryption processes of various forms have been employed for centuries to protect the exchange of messages, the advent of the information age has underscored the importance of strong cryptography as a process to secure data exchanged through electronic means, and has accentuated the demand for products offering these services. this article describes the process that has led to the development of the latest cryptographic benchmark; the advanced encryption standard (aes). the article briefly examines the requirements set forth for its development, defines how the new standard is implemented, and describes how government, business, and industry can transition to aes with minimum impact to operations","['advanced encryption standard', 'cryptographic benchmark', 'coding', 'unintelligible ciphers', 'data exchange', 'aes', 'government', 'business', 'industry']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['advanced encryption standard', 'cryptographic benchmark', 'code', 'unintelligible cipher', 'datum exchange', 'aes', 'government', 'business', 'industry']","['advanced encryption standard', 'late cryptographic benchmark', 'create unintelligible cipher', 'strong cryptography', 'encryption process', 'encryption', 'secure datum exchange', 'cryptography', 'aes', 'code information']"
175,1236,Compatibility comparison and performance evaluation for Japanese HPF compilers using scientific applications,"the lack of compatibility of high-performance fortran (hpf) between vender implementations has been disheartening scientific application users so as to hinder the development of portable programs. thus parallel computing is still unpopular in the computational science community, even though parallel programming is common to the computer science community. as users would like to run the same source code on parallel machines with different architectures as fast as possible, we have investigated the compatibility of source codes for japanese hpf compilers (nec, fujitsu and hitachi) with two real-world applications: a 3d fluid code and a 2d particle code. we have found that the source-level compatibility between japanese hpf compilers is almost preserved, but more effort will be needed to sustain complete compatibility. we have also evaluated parallel performance and found that hpf can achieve good performance for the 3d fluid code with almost the same source code. for the 2d particle code, good results have also been obtained with a small number of processors, but some changes in the original source code and the addition of interface blocks is required","['hpf', 'compilers', 'high-performance fortran', 'portable programs', 'parallel programming', 'parallel performance', 'source compatability']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['hpf', 'compiler', 'high - performance fortran', 'portable program', 'parallel programming', 'parallel performance', 'source compatability']","['japanese hpf compiler', '3d fluid code', 'parallel programming', 'performance fortran', 'parallel computing', '2d particle code', 'vender implementation', 'evaluate parallel performance', 'parallel machine', 'computational science community']"
176,1273,Towards an ontology of approximate reason,"this article introduces structural aspects in an ontology of approximate reason. the basic assumption in this ontology is that approximate reason is a capability of an agent. agents are designed to classify information granules derived from sensors that respond to stimuli in the environment of an agent or received from other agents. classification of information granules is carried out in the context of parameterized approximation spaces and a calculus of granules. judgment in agents is a faculty of thinking about (classifying) the particular relative to decision rules derived from data. judgment in agents is reflective, but not in the classical philosophical sense (e.g., the notion of judgment in kant). in an agent, a reflective judgment itself is an assertion that a particular decision rule derived from data is applicable to an object (input). that is, a reflective judgment by an agent is an assertion that a particular vector of attribute (sensor) values matches to some degree the conditions for a particular rule. in effect, this form of judgment is an assertion that a vector of sensor values reflects a known property of data expressed by a decision rule. since the reasoning underlying a reflective judgment is inductive and surjective (not based on a priori conditions or universals), this form of judgment is reflective, but not in the sense of kant. unlike kant, a reflective judgment is surjective in the sense that it maps experimental attribute values onto the most closely matching descriptors (conditions) in a derived rule. again, unlike kant's notion of judgment, a reflective judgment is not the result of searching for a universal that pertains to a particular set of values of descriptors. rather, a reflective judgment by an agent is a form of recognition that a particular vector of sensor values pertains to a particular rule in some degree. this recognition takes the form of an assertion that a particular descriptor vector is associated with a particular decision rule. these considerations can be repeated for other forms of classifiers besides those defined by decision rules","['ontology', 'approximate reason', 'information granules', 'granules', 'parameterized approximation spaces', 'decision rules', 'reflective judgment', 'pattern recognition', 'rough sets']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M']","['ontology', 'approximate reason', 'information granule', 'granule', 'parameterized approximation space', 'decision rule', 'reflective judgment', 'pattern recognition', 'rough set']","['classify information granule derive', 'map experimental attribute value', 'reflective judgment', 'sensor value reflect', 'classical philosophical sense', 'particular decision rule derive', 'sensor value pertain', 'reason underlie', 'information granule', 'ontology']"
177,626,Approximate confidence intervals for one proportion and difference of two proportions,"constructing a confidence interval for a binomial proportion or the difference of two proportions is a routine exercise in daily data analysis. the best-known method is the wald interval based on the asymptotic normal approximation to the distribution of the observed sample proportion, though it is known to have bad performance for small to medium sample sizes. agresti et al. (1998, 2000) proposed an adding-4 method: 4 pseudo-observations are added with 2 successes and 2 failures and then the resulting (pseudo-)sample proportion is used. the method is simple and performs extremely well. here we propose an approximate method based on a t-approximation that takes account of the uncertainty in estimating the variance of the observed (pseudo-)sample proportion. it follows the same line of using a t-test, rather than z-test, in testing the mean of a normal distribution with an unknown variance. for some circumstances our proposed method has a higher coverage probability than the adding-4 method","['approximate confidence intervals', 'difference of two proportions', 'binomial proportion', 'data analysis', 't-approximation', 'uncertainty', 't-test', 'normal distribution', 'coverage probability', 'variance estimation', 'pseudo-sample proportion']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['approximate confidence interval', 'difference of two proportion', 'binomial proportion', 'datum analysis', 't - approximation', 'uncertainty', 't - test', 'normal distribution', 'coverage probability', 'variance estimation', 'pseudo - sample proportion']","['observe sample proportion', 'asymptotic normal approximation', 'approximate method base', 'binomial proportion', 'confidence interval', 'wald interval base', 'high coverage probability', 'sample size', 'estimate', 'approximation']"
178,59,Efficient tracking of the cross-correlation coefficient,"in many (audio) processing algorithms, involving manipulation of discrete-time signals, the performance can vary strongly over the repertoire that is used. this may be the case when the signals from the various channels are allowed to be strongly positively or negatively correlated. we propose and analyze a general formula for tracking the (time-dependent) correlation between two signals. some special cases of this formula lead to classical results known from the literature, others are new. this formula is recursive in nature, and uses only the instantaneous values of the two signals, in a low-cost and low-complexity manner; in particular, there is no need to take square roots or to carry out divisions. furthermore, this formula can be modified with respect to the occurrence of the two signals so as to further decrease the complexity, and increase ease of implementation. the latter modification comes at the expense that not the actual correlation is tracked, but, rather, a somewhat deformed version of it. to overcome this problem, we propose, for a number of instances of the tracking formula, a simple warping operation on the deformed correlation. now we obtain, at least for sinusoidal signals, the correct value of the correlation coefficient. special attention is paid to the convergence behavior of the algorithm for stationary signals and the dynamic behavior if there is a transition to another stationary state; the latter is considered to be important to study the tracking abilities to nonstationary signals. we illustrate tracking algorithm by using it for stereo music fragments, obtained from a number of digital audio recordings","['efficient tracking', 'cross-correlation coefficient', 'discrete-time signals', 'warping operation', 'deformed correlation', 'sinusoidal signals', 'convergence behavior', 'stationary signals', 'dynamic behavior', 'stationary state', 'nonstationary signals', 'tracking algorithm', 'stereo music fragments', 'digital audio recording', 'audio processing algorithms', 'time-dependent correlation', 'recursive formula']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['efficient tracking', 'cross - correlation coefficient', 'discrete - time signal', 'warp operation', 'deform correlation', 'sinusoidal signal', 'convergence behavior', 'stationary signal', 'dynamic behavior', 'stationary state', 'nonstationary signal', 'track algorithm', 'stereo music fragment', 'digital audio recording', 'audio processing algorithm', 'time - dependent correlation', 'recursive formula']","['illustrate tracking algorithm', 'stereo music fragment', 'sinusoidal signal', 'processing algorithm', 'track formula', 'correlation coefficient', 'track ability', 'time signal', 'stationary signal', 'deform correlation']"
179,663,The road ahead [supply chains],"executive supply chain managers, says david metcalfe of forrester research, need the skills and precision of mongolian archers on horseback. they must be able to hit their target, in this case customer demand, while moving at great speed. but what is wrong with the supply chains companies have in place already? according to metcalfe, current manufacturing models are too inflexible. a recent survey conducted by forrester research supports this claim. it found that 42% of respondents could not transfer production from one plant to another in the event of a glitch in the supply chain. a further 32% said it would be possible, but extremely costly","['supply chains', 'forrester research', 'manufacturing', 'survey', 'business networks']","['P', 'P', 'P', 'P', 'U']","['supply chain', 'forrester research', 'manufacture', 'survey', 'business network']","['supply chain company have', 'executive supply chain manager', 'supply chain', 'case customer demand', 'transfer production', 'mongolian archer', 'manufacturing model', 'forrester research support', 'forrester research', 'great speed']"
180,948,Pairwise thermal entanglement in the n-qubit (n <or= 5) Heisenberg XX chain,we have calculated the concurrence of the pairwise thermal entanglement for the four-qubit and five-qubit heisenberg xx chain. it is found that there is a great difference between the even-qubit and the odd-qubit chain in the aspect of the critical temperature and of the existence of the entanglement for the case of the qubit number n no more than 5,"['pairwise thermal entanglement', 'five-qubit heisenberg xx chain', 'odd-qubit chain', 'critical temperature', 'four-qubit heisenberg xx chain', 'even-qubit chain']","['P', 'P', 'P', 'P', 'R', 'R']","['pairwise thermal entanglement', 'five - qubit heisenberg xx chain', 'odd - qubit chain', 'critical temperature', 'four - qubit heisenberg xx chain', 'even - qubit chain']","['qubit heisenberg xx chain', 'pairwise thermal entanglement', 'qubit chain', 'critical temperature', 'qubit number', 'entanglement', 'qubit', 'concurrence', 'even', 'case']"
181,1391,Government budget and accounting information policy and practice in Taiwan,"the principal government budget and accounting information policies in taiwan are founded on the ability to provide integrated, consistent, and timely information for government managers to make more rational decisions concerning national resource allocation and evaluation. a specific accounting organization system has been designed for this purpose. this paper analyzes information policies and practices according to the relevant laws and regulations, identifies issues regarding the policies, and presents strategies to resolve the issues","['government budget', 'accounting information policy', 'taiwan', 'government managers', 'rational decisions', 'national resource allocation', 'national resource evaluation', 'generally accepted accounting principles']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['government budget', 'accounting information policy', 'taiwan', 'government manager', 'rational decision', 'national resource allocation', 'national resource evaluation', 'generally accept accounting principle']","['accounting information policy', 'specific accounting organization system', 'paper analyze information policy', 'principal government budget', 'national resource allocation', 'government manager', 'timely information', 'taiwan', 'policy', 'regulation']"
182,781,ICANN and Internet governance: leveraging technical coordination to realize global public policy,"the internet corporation for assigned names and numbers (icann) was created in 1998 to perform technical coordination of the internet. icann also lays the foundations for governance, creating capabilities for promulgating and enforcing global regulations on internet use. icann leverages the capabilities in the internet domain name system (dns) to implement four mechanisms of governance: authority, law, sanctions, and jurisdictions. these governance-related features are embodied in seemingly technical features of icann's institutional design. recognition of icann's governance mechanisms allows us to better understand the internet's emerging regulatory regime","['icann', 'internet governance', 'technical coordination', 'global public policy', 'internet corporation for assigned names and numbers', 'global regulations', 'internet use', 'internet domain name system', 'governance-related features', 'institutional design', 'regulatory regime', 'internet dns']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['icann', 'internet governance', 'technical coordination', 'global public policy', 'internet corporation for assign name and number', 'global regulation', 'internet use', 'internet domain name system', 'governance - relate feature', 'institutional design', 'regulatory regime', 'internet dns']","['internet domain name system', 'icann leverage', 'icann', 'governance mechanism allow', 'enforce global regulation', 'internet corporation', 'dns', 'institutional design', 'internet use', 'create capability']"
183,1028,Novel approach to super-resolution pits readout,"we proposed a novel method to realize the readout of super-resolution pits by using a super-resolution reflective film to replace the reflective layer of the conventional rom. at the same time, by using sb as the super-resolution reflective layer and sin as a dielectric layer, the super-resolution pits with diameters of 380 nm were read out by a setup whose laser wavelength is 632.8 nm and numerical aperture is 0.40. in addition, the influence of the sb thin film thickness on the readout signal was investigated, the results showed that the optimum sb thin film thickness is 28 to 30 nm, and the maximum cnr is 38 to 40 db","['super-resolution pits readout', 'super-resolution reflective film', '380 nm', '632.8 nm', 'numerical aperture', 'sb thin film thickness', 'readout signal', '28 to 30 nm', 'maximum cnr', 'sb super-resolution reflective layer', 'sin dielectric layer', 'sb-sin']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U']","['super - resolution pit readout', 'super - resolution reflective film', '380 nm', '632.8 nm', 'numerical aperture', 'sb thin film thickness', 'readout signal', '28 to 30 nm', 'maximum cnr', 'sb super - resolution reflective layer', 'sin dielectric layer', 'sb - sin']","['resolution reflective layer', 'resolution reflective film', 'resolution pit', 'laser wavelength', 'optimum sb thin film thickness', 'readout signal', 'aperture', 'rom', 'readout', 'sb thin film thickness']"
184,1090,On the contractivity of implicit-explicit linear multistep methods,"this paper is concerned with the class of implicit-explicit linear multistep methods for the numerical solution of initial value problems for ordinary differential equations which are composed of stiff and nonstiff parts. we study the contractivity of such methods, with regard to linear autonomous systems of ordinary differential equations and a (scaled) euclidean norm. in addition, we derive a strong stability result based on the stability regions of these methods","['contractivity', 'implicit-explicit linear multistep methods', 'numerical solution', 'initial value problems', 'ordinary differential equations', 'linear autonomous systems', 'euclidean norm', 'stability result']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['contractivity', 'implicit - explicit linear multistep method', 'numerical solution', 'initial value problem', 'ordinary differential equation', 'linear autonomous system', 'euclidean norm', 'stability result']","['explicit linear multistep method', 'ordinary differential equation', 'linear autonomous system', 'numerical solution', 'initial value problem', 'contractivity', 'strong stability', 'stability', 'stiff', 'method']"
185,1441,"Handles and exception safety, Part 1. A simple handle class","every c++ program that uses inheritance must manage memory somehow. the most obvious way to do so is directly, but programmers who create complicated data structures often have trouble figuring out what parts of those data structures are safe to delete when. the classical method of dealing with such complexity is to hide it in a class. such classes are typically called handles; the idea is to attach a handle object to another object that contains the actual data. the simplest form of a handle, which we have discussed in this article, is one in which each handle object corresponds to a single object from the inheritance hierarchy. such handles are straightforward to use and to implement and tend to be intrinsically exception safe in almost all respects. the one exception hazard in such a class is typically the assignment operator. assignment operators often test for self-assignment to avoid aliasing problems. as herb sutter has observed (2000), programs that need such tests are almost always exception unsafe. by rewriting the assignment operator, we ensure that we do not do anything irrevocable until the possibility of throwing an exception has passed. this strategy ensures that if an exception occurs while our assignment operator is executing, we do not corrupt the rest of our system","['handles', 'exception', 'c++ program', 'inheritance hierarchy', 'assignment operator', 'self-assignment', 'aliasing problems']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['handle', 'exception', 'c++ program', 'inheritance hierarchy', 'assignment operator', 'self - assignment', 'aliasing problem']","['inheritance hierarchy', 'use inheritance', 'exception unsafe', 'assignment operator', 'avoid aliasing problem', 'manage memory', 'assignment operator', 'handle object', 'exception occur', 'exception safe']"
186,1404,Creating the right mail model,"if you know your post room is not as efficiently organised as it might be, but you are not sure how best to go about making improvements, then consider this advice from john edgar of consultant mcs","['mail', 'post room', 'consultant', 'mcs']","['P', 'P', 'P', 'P']","['mail', 'post room', 'consultant', 'mcs']","['post room', 'make improvement', 'organise', 'consultant', 'advice', 'consider', 'john edgar', 'good', 'know', 'sure']"
187,812,eLeaders make the Web work,some companies are making the most of back-office/web integration. here are some winners,"['back-office/web integration', 'e-commerce', 'visual integrator', 'accpac etransact']","['P', 'U', 'M', 'U']","['back - office / web integration', 'e - commerce', 'visual integrator', 'accpac etransact']","['web integration', 'company', 'office', 'back', 'most', 'make']"
188,857,Leveraging an alternative source of computer scientists: reentry programs,"much has been written about the leaky pipeline of women in computer science (cs), with the percentage of women decreasing as one moves from lower levels, such as college, to higher levels, culminating in full professorship. while significant attention focused on keeping women from leaving the pipeline, there is also an opportunity to bring women into the pipeline through non-traditional programs, instead of requiring that everyone enter at the undergraduate level. both mills college, a small liberal arts institution for women, and uc berkeley, a large research university, established programs in the 80's to increase the number of women in computer science by tapping non-traditional students. both programs share the core value of accommodating older students lacking technical backgrounds. the two programs have produced similar results: graduate degrees earned in computer science by students who would not have qualified without these programs, professional employment in the computer science field by women and minorities, and a recognition that this population represents a rich source of talent for our nation","['reentry programs', 'women', 'computer science', 'mills college', 'uc berkeley', 'students', 'graduate degrees', 'professional employment', 'minorities']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['reentry program', 'woman', 'computer science', 'mills college', 'uc berkeley', 'student', 'graduate degree', 'professional employment', 'minority']","['accommodate old student lack technical background', 'small liberal art institution', 'mills college', 'large research university', 'graduate degree earn', 'computer science field', 'traditional program', 'woman decrease', 'undergraduate level', 'keep woman']"
189,739,Disposable mobiles,"after many delays, the reusable, recyclable, disposable mobile phone is finally going on sale in the us. but with a business model largely dependent on niche markets, elizabeth biddlecombe asks if these simplified handsets will be good enough to survive a brutal market","['reusable', 'recyclable', 'disposable mobile phone', 'simplified handsets']","['P', 'P', 'P', 'P']","['reusable', 'recyclable', 'disposable mobile phone', 'simplify handset']","['disposable mobile phone', 'simplify handset', 'niche market', 'business model', 'elizabeth biddlecombe ask', 'reusable', 'recyclable', 'many delay', 'sale', 'dependent']"
190,1329,PageFlex + MediaRich = PageRich,"layout and graphics innovators collaborate on fully variable combination. pageflex and equilibrium have melded their respective edit and mediarich technologies to make a variable-data composition engine with a web interface. though a first-generation effort, it shows substantial promise","['pageflex', 'mediarich', 'pagerich', 'layout', 'graphics', 'composition', 'software houses']","['P', 'P', 'P', 'P', 'P', 'P', 'U']","['pageflex', 'mediarich', 'pagerich', 'layout', 'graphic', 'composition', 'software house']","['graphic innovator collaborate', 'datum composition engine', 'web interface', 'mediarich technology', 'pageflex', 'layout', 'variable combination', 'generation effort', 'respective edit', 'equilibrium']"
191,109,An entanglement measure based on the capacity of dense coding,an asymptotic entanglement measure for any bipartite states is derived in the light of the dense coding capacity optimized with respect to local quantum operations and classical communications. general properties and some examples with explicit forms of this entanglement measure are investigated,"['entanglement measure', 'asymptotic entanglement measure', 'bipartite states', 'dense coding capacity', 'optimization', 'local quantum operations', 'classical communications']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['entanglement measure', 'asymptotic entanglement measure', 'bipartite state', 'dense code capacity', 'optimization', 'local quantum operation', 'classical communication']","['asymptotic entanglement measure', 'entanglement measure', 'dense code capacity optimize', 'bipartite state', 'local quantum operation', 'classical communication', 'general property', 'explicit form', 'light', 'example']"
192,1234,Achieving performance under OpenMP on ccNUMA and software distributed shared memory systems,"openmp is emerging as a viable high-level programming model for shared memory parallel systems. it was conceived to enable easy, portable application development on this range of systems, and it has also been implemented on cache-coherent non-uniform memory access (ccnuma) architectures. unfortunately, it is hard to obtain high performance on the latter architecture, particularly when large numbers of threads are involved. in this paper, we discuss the difficulties faced when writing openmp programs for ccnuma systems, and explain how the vendors have attempted to overcome them. we focus on one such system, the sgi origin 2000, and perform a variety of experiments designed to illustrate the impact of the vendor's efforts. we compare codes written in a standard, loop-level parallel style under openmp with alternative versions written in a single program multiple data (spmd) fashion, also realized via openmp, and show that the latter consistently provides superior performance. a carefully chosen set of language extensions can help us translate programs from the former style to the latter (or to compile directly, but in a similar manner). syntax for these extensions can be borrowed from hpf, and some aspects of hpf compiler technology can help the translation process. it is our expectation that an extended language, if well compiled, would improve the attractiveness of openmp as a language for high-performance computation on an important class of modern architectures","['openmp', 'programming model', 'shared memory parallel systems', 'cache-coherent non-uniform memory access', 'single program multiple data', 'hpf', 'parallel programming']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['openmp', 'programming model', 'share memory parallel system', 'cache - coherent non - uniform memory access', 'single program multiple datum', 'hpf', 'parallel programming']","['share memory parallel system', 'write openmp program', 'hpf compiler technology', 'uniform memory access', 'single program multiple datum', 'level parallel style', 'performance computation', 'openmp', 'provide superior performance', 'level programming']"
193,1271,Verification of non-functional properties of a composable architecture with Petri nets,"in this paper, we introduce our concept of composability and present the mss architecture as an example for a composable architecture. mss claims to be composable with respect to timing properties. we discuss, how to model and prove properties in such an architecture with time-extended petrinets. as a result, the first step of a proof of composability is presented as well as a new kind of petri net, which is more suitable for modeling architectures like mss","['composable architecture', 'petri nets', 'mss architecture', 'timing properties', 'proof of composability', 'non-functional properties verification']","['P', 'P', 'P', 'P', 'P', 'R']","['composable architecture', 'petri net', 'mss architecture', 'time property', 'proof of composability', 'non - functional property verification']","['composable architecture', 'mss architecture', 'petri net', 'modeling architecture', 'composability', 'time property', 'architecture', 'extend petrinet', 'composable', 'mss claim']"
194,624,A hybrid ML-EM algorithm for calculation of maximum likelihood estimates in semiparametric shared frailty models,"this paper describes a generalised hybrid ml-em algorithm for the calculation of maximum likelihood estimates in semiparametric shared frailty models, the cox proportional hazard models with hazard functions multiplied by a (parametric) frailty random variable. this hybrid method is much faster than the standard em method and faster than the standard direct maximum likelihood method (ml, newton-raphson) for large samples. we have previously applied this method to semiparametric shared gamma frailty models, and verified by simulations the asymptotic and small sample statistical properties of the frailty variance estimates. let theta /sub 0/ be the true value of the frailty variance parameter. then the asymptotic distribution is normal for theta /sub 0/>0 while it is a 50-50 mixture between a point mass at zero and a normal random variable on the positive axis for theta /sub 0/=0. for small samples, simulations suggest that the frailty variance estimates are approximately distributed as an x-(100-x)% mixture, 0<or=x<or=50, between a point mass at zero and a normal random variable on the positive axis even for theta /sub 0/>0. we apply this method and verify by simulations these statistical results for semiparametric shared log-normal frailty models. we also apply the semiparametric shared gamma and log-normal frailty models to busselton health study coronary heart disease data","['hybrid ml-em algorithm', 'maximum likelihood estimates', 'cox proportional hazard models', 'hazard functions', 'simulations', 'frailty variance estimates', 'asymptotic distribution', 'normal random variable', 'semiparametric shared log-normal frailty models', 'busselton health study', 'coronary heart disease data', 'data analysis', 'normal distribution']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R']","['hybrid ml - em algorithm', 'maximum likelihood estimate', 'cox proportional hazard model', 'hazard function', 'simulation', 'frailty variance estimate', 'asymptotic distribution', 'normal random variable', 'semiparametric share log - normal frailty model', 'busselton health study', 'coronary heart disease datum', 'datum analysis', 'normal distribution']","['semiparametric share gamma frailty model', 'semiparametric share frailty model', 'cox proportional hazard model', 'frailty variance estimate', 'frailty variance parameter', 'normal frailty model', 'maximum likelihood estimate', 'frailty random variable', 'semiparametric share gamma', 'maximum likelihood method']"
195,661,All change [agile business],"what does it take for an organisation to become an agile business? its employees probably need to adhere to new procurement policies, work more closely with colleagues in other departments, meet more exacting sales targets, and offer higher standards of customer service and support. in short, they need to change the way they work. implementing technologies to support agile business models and underpin new practices is a complex task in itself. but getting employees to adopt new practices is far harder, and one that requires careful handling, says barry o'connell, general manager of business-to-employee (b2e) solutions at systems vendor hewlett-packard (hp)","['agile business', 'corporate transformation', 'organisational change']","['P', 'U', 'R']","['agile business', 'corporate transformation', 'organisational change']","['support agile business model', 'agile business', 'implement technology', 'adopt new practice', 'system vendor hewlett', 'new procurement policy', 'underpin new practice', 'organisation', 'get employee', 'sale target']"
196,1135,"A combinatorial, graph-based solution method for a class of continuous-time optimal control problems","the paper addresses a class of continuous-time, optimal control problems whose solutions are typically characterized by both bang-bang and ""singular"" control regimes. analytical study and numerical computation of such solutions are very difficult and far from complete when only techniques from control theory are used. this paper solves optimal control problems by reducing them to the combinatorial search for the shortest path in a specially constructed graph. since the nodes of the graph are weighted in a sequence-dependent manner, we extend the classical, shortest-path algorithm to our case. the proposed solution method is currently limited to single-state problems with multiple control functions. a production planning problem and a train operation problem are optimally solved to illustrate the method","['continuous-time optimal control problems', 'numerical computation', 'combinatorial search', 'sequence-dependent manner', 'single-state problems', 'multiple control functions', 'production planning problem', 'train operation problem', 'combinatorial graph-based solution', 'bang-bang control regimes', 'singular control regimes', 'shortest path algorithm', 'weighted graph nodes']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'R']","['continuous - time optimal control problem', 'numerical computation', 'combinatorial search', 'sequence - dependent manner', 'single - state problem', 'multiple control function', 'production planning problem', 'train operation problem', 'combinatorial graph - base solution', 'bang - bang control regime', 'singular control regime', 'short path algorithm', 'weight graph node']","['paper solve optimal control problem', 'optimal control problem', 'production planning problem', 'train operation problem', 'path algorithm', 'short path', 'multiple control function', 'combinatorial search', 'control regime', 'numerical computation']"
197,1170,Upper bound analysis of oblique cutting with nose radius tools,"a generalized upper bound model for calculating the chip flow angle in oblique cutting using flat-faced nose radius tools is described. the projection of the uncut chip area on the rake face is divided into a number of elements parallel to an assumed chip flow direction. the length of each of these elements is used to find the length of the corresponding element on the shear surface using the ratio of the shear velocity to the chip velocity. the area of each element is found as the cross product of the length and its width along the cutting edge. summing up the area of the elements along the shear surface, the total shear surface area is obtained. the friction area is calculated using the similarity between orthogonal and oblique cutting in the 'equivalent' plane that includes both the cutting velocity and chip velocity. the cutting power is obtained by summing the shear power and the friction power. the actual chip flow angle and chip velocity are obtained by minimizing the cutting power with respect to both these variables. the shape of the curved shear surface, the chip cross section and the cutting force obtained from this model are presented","['upper bound analysis', 'oblique cutting', 'nose radius tools', 'chip flow angle', 'uncut chip area', 'shear surface', 'shear velocity', 'chip velocity', 'friction area']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['upper bound analysis', 'oblique cutting', 'nose radius tool', 'chip flow angle', 'uncut chip area', 'shear surface', 'shear velocity', 'chip velocity', 'friction area']","['curve shear surface', 'oblique cutting', 'cut edge', 'chip flow angle', 'cut velocity', 'uncut chip area', 'total shear surface area', 'shear surface', 'shear velocity', 'chip velocity']"
198,560,Citizen centric identity management: chip tricks?,accelerating and harmonizing the diffusion and acceptance of electronic services in europe in a secure and practical way has become a priority of several initiatives in the past few years and a critical factor for citizen and business information society services. as identification and authentication is a critical element in accessing public services the combination of public key infrastructure (pki) and smart cards emerges as the solution of choice for egovernment in europe. national governments and private initiatives alike vouch their support for this powerful combination to deliver an essential layer of reliable electronic services and address identity requirements in a broad range of application areas. a recent study suggests that several egovernment implementations point to the direction of electronic citizen identity management as an up and coming challenge. the paper discusses the egovernment needs for user identification applicability and the need for standardization,"['citizen centric identity management', 'electronic services', 'authentication', 'public key infrastructure', 'smart cards', 'government', 'user identification', 'standardization', 'business information services', 'legal framework', 'public information services']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'R']","['citizen centric identity management', 'electronic service', 'authentication', 'public key infrastructure', 'smart card', 'government', 'user identification', 'standardization', 'business information service', 'legal framework', 'public information service']","['electronic citizen identity management', 'address identity requirement', 'user identification applicability', 'business information society service', 'access public service', 'reliable electronic service', 'public key infrastructure', 'several egovernment implementation point', 'authentication', 'electronic service']"
199,1108,The visible cement data set,"with advances in x-ray microtomography, it is now possible to obtain three-dimensional representations of a material's microstructure with a voxel size of less than one micrometer. the visible cement data set represents a collection of 3-d data sets obtained using the european synchrotron radiation facility in grenoble, france in september 2000. most of the images obtained are for hydrating portland cement pastes, with a few data sets representing hydrating plaster of paris and a common building brick. all of these data sets are being made available on the visible cement data set website at http://visiblecement.nist.gov. the website includes the raw 3-d datafiles, a description of the material imaged for each data set, example two-dimensional images and visualizations for each data set, and a collection of c language computer programs that will be of use in processing and analyzing the 3-d microstructural images. this paper provides the details of the experiments performed at the esrf, the analysis procedures utilized in obtaining the data set files, and a few representative example images for each of the three materials investigated","['x-ray microtomography', 'microstructure', 'voxel size', 'european synchrotron radiation facility', 'hydrating portland cement pastes', 'plaster of paris', 'building brick', 'two-dimensional images', 'microstructural images', 'esrf', '3d representations', 'cement hydration']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R']","['x - ray microtomography', 'microstructure', 'voxel size', 'european synchrotron radiation facility', 'hydrate portland cement paste', 'plaster of paris', 'building brick', 'two - dimensional image', 'microstructural image', 'esrf', '3d representation', 'cement hydration']","['visible cement datum set represent', 'visible cement datum set website', 'microstructural image', 'hydrate portland cement paste', 'ray microtomography', 'datum set file', 'dimensional image', 'datum set obtain use', 'european synchrotron radiation facility', 'material image']"
200,134,A model of periodic oscillation for genetic regulatory systems,"in this paper, we focus on modeling and explaining periodic oscillations in gene-protein systems with a simple nonlinear model and on analyzing effects of time delay on the stability of oscillations. our main model of genetic regulation comprises of a two-gene system with an autoregulatory feedback loop. we exploit multiple time scales and hysteretic properties of the model to construct periodic oscillations with jumping dynamics and analyze the possible mechanism according to the singular perturbation theory. as shown in this paper, periodic oscillations are mainly generated by nonlinearly negative and positive feedback loops in gene regulatory systems, whereas the jumping dynamics is generally caused by time scale differences among biochemical reactions. this simple model may actually act as a genetic oscillator or switch in gene-protein networks because the dynamics are robust for parameter perturbations or environment variations. we also explore effects of time delay on the stability of the dynamics, showing that the time delay generally increases the stability region of the oscillations, thereby making the oscillations robust to parameter changes. two examples are also provided to numerically demonstrate our theoretical results","['modeling', 'periodic oscillations', 'genetic regulation', 'genetic regulatory system', 'gene-protein systems', 'nonlinear model', 'time delay', 'two-gene system', 'autoregulatory feedback loop', 'hysteretic properties', 'jumping dynamics', 'singular perturbation theory', 'biochemical reactions', 'stability region', 'oscillations stability', 'nonlinearly negative feedback loops', 'nonlinearly positive feedback loops', 'bifurcation', 'circadian rhythm', 'relaxation oscillator']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'U', 'U', 'M']","['model', 'periodic oscillation', 'genetic regulation', 'genetic regulatory system', 'gene - protein system', 'nonlinear model', 'time delay', 'two - gene system', 'autoregulatory feedback loop', 'hysteretic property', 'jump dynamic', 'singular perturbation theory', 'biochemical reaction', 'stability region', 'oscillation stability', 'nonlinearly negative feedback loop', 'nonlinearly positive feedback loop', 'bifurcation', 'circadian rhythm', 'relaxation oscillator']","['explain periodic oscillation', 'periodic oscillation', 'genetic oscillator', 'oscillation robust', 'jump dynamic', 'gene regulatory system', 'oscillation', 'autoregulatory feedback loop', 'positive feedback loop', 'nonlinear model']"
201,977,Behavior of Runge-Kutta discretizations near equilibria of index 2 differential algebraic systems,"we analyze runge-kutta discretizations applied to index 2 differential algebraic equations (dae's) near equilibria. we compare the geometric properties of the numerical and the exact solutions. it is shown that projected and half-explicit runge-kutta methods reproduce the qualitative features of the continuous system in the vicinity of an equilibrium correctly. the proof combines cut-off and scaling techniques for index 2 differential algebraic equations with some invariant manifold results of schropp (geometric properties of runge-kutta discretizations for index 2 differential algebraic equations, konstanzer schriften in mathematik und informatik 128) and classical results for discretized ordinary differential equations","['runge-kutta discretizations', 'equilibria', 'index 2 differential algebraic systems', 'geometric properties', 'half-explicit runge-kutta methods', 'continuous system', 'scaling techniques', 'invariant manifold', 'discretized ordinary differential equations', 'cut-off techniques']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['runge - kutta discretization', 'equilibrium', 'index 2 differential algebraic system', 'geometric property', 'half - explicit runge - kutta method', 'continuous system', 'scale technique', 'invariant manifold', 'discretize ordinary differential equation', 'cut - off technique']","['kutta discretization', 'differential algebraic equation', 'kutta method', 'numerical', 'analyze runge', 'scale technique', 'explicit runge', 'equilibrium', 'invariant manifold result', 'index']"
202,932,Modeling of torsional vibration induced by extension-twisting coupling of anisotropic composite laminates with piezoelectric actuators,"in this paper we present a dynamic analytical model for the torsional vibration of an anisotropic piezoelectric laminate induced by the extension-twisting coupling effect. in the present approach, we use the hamilton principle and a reduced bending stiffness method for the derivation of equations of motion. as a result, the in-plane displacements are not involved and the out-of-plane displacement of the laminate is the only quantity to be calculated. therefore, the proposed method turns the twisting of a laminate with structural coupling into a simplified problem without losing its features. we give analytical solutions of the present model with harmonic excitation. a parametric study is performed to demonstrate the present approach","['torsional vibration', 'twisting', 'anisotropic composite laminates', 'composite laminate', 'piezoelectric actuators', 'dynamic analytical model', 'anisotropic piezoelectric laminate', 'extension-twisting coupling effect', 'hamilton principle', 'reduced bending stiffness', 'equations of motion', 'in-plane displacements', 'out-of-plane displacement', 'structural coupling', 'harmonic excitation', 'parametric study', 'extension -twisting coupling', 'material anisotropy', 'pzt']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U', 'U']","['torsional vibration', 'twist', 'anisotropic composite laminate', 'composite laminate', 'piezoelectric actuator', 'dynamic analytical model', 'anisotropic piezoelectric laminate', 'extension - twisting coupling effect', 'hamilton principle', 'reduce bend stiffness', 'equation of motion', 'in - plane displacement', 'out - of - plane displacement', 'structural coupling', 'harmonic excitation', 'parametric study', 'extension -twiste coupling', 'material anisotropy', 'pzt']","['anisotropic piezoelectric laminate', 'torsional vibration', 'bend stiffness method', 'twist coupling effect', 'harmonic excitation', 'dynamic analytical model', 'twist', 'laminate', 'structural coupling', 'parametric']"
203,1209,High-level language support for user-defined reductions,"the optimized handling of reductions on parallel supercomputers or clusters of workstations is critical to high performance because reductions are common in scientific codes and a potential source of bottlenecks. yet in many high-level languages, a mechanism for writing efficient reductions remains surprisingly absent. further, when such mechanisms do exist, they often do not provide the flexibility a programmer needs to achieve a desirable level of performance. in this paper, we present a new language construct for arbitrary reductions that lets a programmer achieve a level of performance equal to that achievable with the highly flexible, but low-level combination of fortran and mpi. we have implemented this construct in the zpl language and evaluate it in the context of the initialization of the nas mg benchmark. we show a 45 times speedup over the same code written in zpl without this construct. in addition, performance on a large number of processors surpasses that achieved in the nas implementation showing that our mechanism provides programmers with the needed flexibility","['reductions', 'parallel supercomputers', 'clusters of workstations', 'language construct', 'parallel programming', 'scientific computing']","['P', 'P', 'P', 'P', 'M', 'M']","['reduction', 'parallel supercomputer', 'cluster of workstation', 'language construct', 'parallel programming', 'scientific computing']","['write efficient reduction', 'parallel supercomputer', 'nas mg benchmark', 'zpl language', 'arbitrary reduction', 'optimize handle', 'nas implementation', 'processor surpass', 'zpl', 'bottleneck']"
204,66,Regression testing of database applications,"database applications features such as structured query language or sql, exception programming, integrity constraints, and table triggers pose difficulties for maintenance activities; especially for regression testing that follows modifications to database applications. in this work, we address these difficulties and propose a two phase regression testing methodology. in phase 1, we explore control flow and data flow analysis issues of database applications. then, we propose an impact analysis technique that is based on dependencies that exist among the components of database applications. this analysis leads to selecting test cases from the initial test suite for regression testing the modified application. in phase 2, further reduction in the regression test cases is performed by using reduction algorithms. we present two such algorithms. the graph walk algorithm walks through the control flow graph of database modules and selects a safe set of test cases to retest. the call graph firewall algorithm uses a firewall for the inter procedural level. finally, a maintenance environment for database applications is described. our experience with this regression testing methodology shows that the impact analysis technique is adequate for selecting regression tests and that phase 2 techniques can be used for further reduction in the number of theses tests","['database applications', 'structured query language', 'sql', 'exception programming', 'integrity constraints', 'table triggers', 'two phase regression testing methodology', 'data flow analysis', 'impact analysis', 'reduction algorithms', 'graph walk algorithm', 'control flow graph', 'call graph firewall algorithm', 'control flow analysis']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['database application', 'structure query language', 'sql', 'exception programming', 'integrity constraint', 'table trigger', 'two phase regression testing methodology', 'datum flow analysis', 'impact analysis', 'reduction algorithm', 'graph walk algorithm', 'control flow graph', 'call graph firewall algorithm', 'control flow analysis']","['phase regression testing methodology', 'regression testing methodology', 'database application feature such', 'regression test case', 'regression testing', 'regression test', 'graph firewall algorithm use', 'database application', 'test case', 'database module']"
205,619,Wavelet-based image segment representation,"an efficient representation method for arbitrarily shaped image segments is proposed. this method includes a smart way to select a wavelet basis to approximate the given image segment, with improved image quality and reduced computational load","['image segment representation', 'arbitrarily shaped image segments', 'wavelet basis', 'improved image quality', 'reduced computational load', 'discrete wavelet transform', 'dwt']","['P', 'P', 'P', 'P', 'P', 'M', 'U']","['image segment representation', 'arbitrarily shape image segment', 'wavelet basis', 'improve image quality', 'reduce computational load', 'discrete wavelet transform', 'dwt']","['shape image segment', 'wavelet basis', 'image segment', 'image quality', 'efficient representation method', 'approximate', 'method include', 'smart', 'select']"
206,1439,On-line robust processing techniques for elimination of measurement drop-out,"when processing measurement data, it is usually assumed that some amount of normally distributed measurement noise is present. in some situations, outliers are present in the measurements and consequently the noise is far from normally distributed. in this case classical least-squares procedures for estimating fourier spectra (or derived quantities like the frequency response function) can give results which are inaccurate or even useless. in this paper, a novel technique for the on-line processing of measurement outliers will be proposed. both the computation speed and the accuracy of the technique presented will be compared with different classical approaches for handling outliers in measurement data (i.e. filtering techniques, outlier rejection techniques and robust regression techniques). in particular, all processing techniques will be validated by applying them to the problem of speckle drop-out in optical vibration measurements (performed with a laser doppler vibrometer), which typically causes outliers in the measurements","['on-line robust processing techniques', 'normally distributed measurement noise', 'classical least-squares procedures', 'fourier spectra', 'frequency response function', 'measurement outliers', 'computation speed', 'robust regression', 'optical vibration measurements', 'laser doppler vibrometer', 'measurement dropout elimination', 'speckle dropout', 'laser interferometer', 'modal analysis', 'vibration velocity', 'iterative technique', 'low-pass filtering', 'median filtering', 'signal sampling', 'order statistics', 'sinusoidal excitation', 'broadband excitation', 'frequency spectra']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'M', 'U', 'M', 'M', 'M', 'M', 'U', 'U', 'U', 'U', 'R']","['on - line robust processing technique', 'normally distribute measurement noise', 'classical least - square procedure', 'fouri spectra', 'frequency response function', 'measurement outlier', 'computation speed', 'robust regression', 'optical vibration measurement', 'laser doppler vibrometer', 'measurement dropout elimination', 'speckle dropout', 'laser interferometer', 'modal analysis', 'vibration velocity', 'iterative technique', 'low - pass filtering', 'median filtering', 'signal sampling', 'order statistic', 'sinusoidal excitation', 'broadband excitation', 'frequency spectra']","['estimate fouri spectra', 'laser doppler vibrometer', 'measurement outlier', 'robust regression technique', 'outli rejection technique', 'optical vibration measurement', 'handle outlier', 'outlier', 'processing measurement datum', 'distribute measurement noise']"
207,741,Mothball mania [3G licences],"telefonica moviles has frozen its 3g operations in germany, austria, italy and switzerland. with other 3g licence holders questioning the logic of entering already saturated markets with unproven technology, emma mcclune asks if the mothball effect is set to snowball any further","['mothball', '3g licence holders', 'saturated markets', 'mobile telephony']","['P', 'P', 'P', 'U']","['mothball', '3 g licence holder', 'saturate market', 'mobile telephony']","['telefonica movile', 'emma mcclune ask', 'mothball effect', 'unproven technology', 'frozen', 'snowball', 'germany', 'switzerland', 'italy', 'austria']"
208,704,Multicell converters: active control and observation of flying-capacitor voltages,the multicell converters introduced more than ten years ago make it possible to distribute the voltage constraints among series-connected switches and to improve the output waveforms (increased number of levels and apparent frequency). the balance of the constraints requires an appropriate distribution of the flying voltages. this paper presents some solutions for the active control of the voltages across the flying capacitors in the presence of rapid variation of the input voltage. the latter part of this paper is dedicated to the observation of these voltages using an original modeling of the converter,"['multicell converters', 'active control', 'flying-capacitor voltages', 'series-connected switches', 'input voltage', 'kalman filtering', 'multilevel systems', 'nonlinear systems', 'power electronics', 'power systems harmonics', 'output waveforms improvement']","['P', 'P', 'P', 'P', 'P', 'U', 'U', 'U', 'U', 'U', 'R']","['multicell converter', 'active control', 'fly - capacitor voltage', 'series - connect switch', 'input voltage', 'kalman filtering', 'multilevel system', 'nonlinear system', 'power electronic', 'power system harmonic', 'output waveforms improvement']","['multicell converter', 'fly voltage', 'fly capacitor', 'voltage', 'voltage constraint', 'voltage', 'switch', 'control', 'output waveform', 'apparent frequency']"
209,1351,Analytic PCA construction for theoretical analysis of lighting variability in images of a Lambertian object,"we analyze theoretically the subspace best approximating images of a convex lambertian object taken from the same viewpoint, but under different distant illumination conditions. we analytically construct the principal component analysis for images of a convex lambertian object, explicitly taking attached shadows into account, and find the principal eigenmodes and eigenvalues with respect to lighting variability. our analysis makes use of an analytic formula for the irradiance in terms of spherical-harmonic coefficients of the illumination and shows, under appropriate assumptions, that the principal components or eigenvectors are identical to the spherical harmonic basis functions evaluated at the surface normal vectors. our main contribution is in extending these results to the single-viewpoint case, showing how the principal eigenmodes and eigenvalues are affected when only a limited subset (the upper hemisphere) of normals is available and the spherical harmonics are no longer orthonormal over the restricted domain. our results are very close, both qualitatively and quantitatively, to previous empirical observations and represent the first essentially complete theoretical explanation of these observations","['lighting variability', 'convex lambertian object', 'principal eigenmodes', 'irradiance', 'spherical harmonics', 'surface normal vectors', 'analytic principal component analysis', 'five-dimensional subspace', 'principal eigenvalues', 'radiance']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'R', 'U']","['light variability', 'convex lambertian object', 'principal eigenmode', 'irradiance', 'spherical harmonic', 'surface normal vector', 'analytic principal component analysis', 'five - dimensional subspace', 'principal eigenvalue', 'radiance']","['distant illumination condition', 'spherical harmonic basis function evaluate', 'convex lambertian object take', 'convex lambertian object', 'spherical harmonic', 'illumination', 'light variability', 'take attach shadow', 'principal eigenmode', 'surface normal vector']"
210,1314,Multi-timescale Internet traffic engineering,"the internet is a collection of packet-based hop-by-hop routed networks. internet traffic engineering is the process of allocating resources to meet the performance requirements of users and operators for their traffic. current mechanisms for doing so, exemplified by tcp's congestion control or the variety of packet marking disciplines, concentrate on allocating resources on a per-packet basis or at data timescales. this article motivates the need for traffic engineering in the internet at other timescales, namely control and management timescales, and presents three mechanisms for this. it also presents a scenario to show how these mechanisms increase the flexibility of operators' service offerings and potentially also ease problems of internet management","['multi-timescale internet traffic engineering', 'packet-based hop-by-hop routed networks', 'packet marking disciplines', 'internet management', 'tcp congestion control', 'resource allocation', 'control timescale', 'operator services', 'admission control', 'ecn proxy', 'bgp routing protocol']","['P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'M', 'U', 'M']","['multi - timescale internet traffic engineering', 'packet - base hop - by - hop route network', 'packet mark discipline', 'internet management', 'tcp congestion control', 'resource allocation', 'control timescale', 'operator service', 'admission control', 'ecn proxy', 'bgp route protocol']","['internet traffic engineering', 'hop route network', 'packet mark discipline', 'traffic engineering', 'congestion control', 'packet basis', 'traffic', 'tcp', 'management timescale', 'internet']"
211,897,Optimization of advertising expenses in the functioning of an insurance company,"with the use of pontryagin's maximum principle, a problem of optimal time distribution of advertising expenses in the functioning of an insurance company is solved","['optimization', 'advertising expenses', 'insurance company', 'optimal time distribution', 'pontryagin maximum principle', 'differential equations']","['P', 'P', 'P', 'P', 'R', 'U']","['optimization', 'advertising expense', 'insurance company', 'optimal time distribution', 'pontryagin maximum principle', 'differential equation']","['optimal time distribution', 'advertising expense', 'insurance company', 'maximum principle', 'pontryagin', 'problem', 'function', 'use']"
212,1050,Secrets of the Glasgow Haskell compiler inliner,"higher-order languages such as haskell encourage the programmer to build abstractions by composing functions. a good compiler must inline many of these calls to recover an efficiently executable program. in principle, inlining is dead simple: just replace the call of a function by an instance of its body. but any compiler-writer will tell you that inlining is a black art, full of delicate compromises that work together to give good performance without unnecessary code bloat. the purpose of this paper is, therefore, to articulate the key lessons we learned from a full-scale ""production"" inliner, the one used in the glasgow haskell compiler. we focus mainly on the algorithmic aspects, but we also provide some indicative measurements to substantiate the importance of various aspects of the inliner","['glasgow haskell compiler inliner', 'higher-order languages', 'abstractions', 'executable program', 'performance', 'algorithmic aspects', 'functional programming', 'functional language', 'optimising compiler']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M']","['glasgow haskell compiler inliner', 'high - order language', 'abstraction', 'executable program', 'performance', 'algorithmic aspect', 'functional programming', 'functional language', 'optimise compiler']","['glasgow haskell compiler', 'good compiler', 'build abstraction', 'compose function', 'compiler', 'executable program', 'inline', 'haskell encourage', 'inline many', 'inliner']"
213,1015,Scalable techniques from nonparametric statistics for real time robot learning,"locally weighted learning (lwl) is a class of techniques from nonparametric statistics that provides useful representations and training algorithms for learning about complex phenomena during autonomous adaptive control of robotic systems. the paper introduces several lwl algorithms that have been tested successfully in real-time learning of complex robot tasks. we discuss two major classes of lwl, memory-based lwl and purely incremental lwl that does not need to remember any data explicitly. in contrast to the traditional belief that lwl methods cannot work well in high-dimensional spaces, we provide new algorithms that have been tested on up to 90 dimensional learning problems. the applicability of our lwl algorithms is demonstrated in various robot learning examples, including the learning of devil-sticking, pole-balancing by a humanoid robot arm, and inverse-dynamics learning for a seven and a 30 degree-of-freedom robot. in all these examples, the application of our statistical neural networks techniques allowed either faster or more accurate acquisition of motor control than classical control engineering","['scalable techniques', 'nonparametric statistics', 'real time robot learning', 'locally weighted learning', 'training algorithms', 'complex phenomena', 'autonomous adaptive control', 'devil-sticking', 'pole-balancing', 'humanoid robot arm', 'inverse-dynamics learning', 'statistical neural networks techniques', 'memory-based learning', 'purely incremental learning', 'nonparametric regression']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M']","['scalable technique', 'nonparametric statistic', 'real time robot learning', 'locally weight learn', 'training algorithm', 'complex phenomenon', 'autonomous adaptive control', 'devil - stick', 'pole - balancing', 'humanoid robot arm', 'inverse - dynamic learning', 'statistical neural network technique', 'memory - base learning', 'purely incremental learning', 'nonparametric regression']","['various robot learn example', 'autonomous adaptive control', 'statistical neural network technique allow', 'humanoid robot arm', 'weight learn', 'dynamic learn', 'dimensional learning problem', 'complex robot task', 'motor control', 'robotic system']"
214,1268,Reachability in contextual nets,"contextual nets, or petri nets with read arcs, are models of concurrent systems with context dependent actions. the problem of reachability in such nets consists in finding a sequence of transitions that leads from the initial marking of a given contextual net to a given goal marking. the solution to this problem that is presented in this paper consists in constructing a finite complete prefix of the unfolding of the given contextual net, that is a finite prefix in which all the markings that are reachable from the initial marking are present, and in searching in each branch of this prefix for the goal marking by solving an appropriate linear programming problem","['petri nets', 'concurrent systems', 'context dependent actions', 'goal marking', 'finite prefix', 'linear programming', 'contextual nets reachability']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['petri net', 'concurrent system', 'context dependent action', 'goal mark', 'finite prefix', 'linear programming', 'contextual net reachability']","['give contextual net', 'concurrent system', 'petri net', 'contextual net', 'such net consist', 'context dependent action', 'finite complete prefix', 'give goal mark', 'finite prefix', 'reachability']"
215,678,Marketing in CSIR libraries and information centres: a study on promotional efforts,this paper examines the attitudes of librarians towards the promotional aspects in several csir libraries and information centres of india. the issues related to promotional activities of these libraries have been evaluated to determine the extent to which they are being practised. librarians hold positive attitudes about promotional aspects of libraries and often practise them without knowing they are practising marketing concepts. suggestions and strategies for improving the promotional activities in libraries and information services are put forth so as to meet the information needs and demands of clientele,"['marketing', 'csir libraries', 'information centres', 'india', 'promotional activities', 'information needs']","['P', 'P', 'P', 'P', 'P', 'P']","['marketing', 'csir library', 'information centre', 'india', 'promotional activity', 'information need']","['practise marketing concept', 'promotional activity', 'promotional aspect', 'librarian', 'several csir librarie', 'information service', 'librarie', 'positive attitude', 'information centre', 'attitude']"
216,110,A switching synchronization scheme for a class of chaotic systems,"in this letter, we propose an observer-based synchronization scheme for a class of chaotic systems. this class of systems are given by piecewise-linear dynamics. by using some properties of such systems, we give a procedure to construct the gain of the observer. we prove various stability results and comment on the robustness of the proposed scheme. we also present some simulation results","['switching synchronization scheme', 'chaotic systems', 'piecewise-linear dynamics', 'robustness', 'state observers']","['P', 'P', 'P', 'P', 'M']","['switch synchronization scheme', 'chaotic system', 'piecewise - linear dynamic', 'robustness', 'state observer']","['chaotic system', 'base synchronization scheme', 'linear dynamic', 'observer', 'piecewise', 'robustness', 'system', 'class', 'comment', 'construct']"
217,953,Take it to the next level [law firm innovation],it's called innovating. our clients do it. our culture worships it. our future hinges on it. why is it so difficult in law firms? how can we make it easier? viva la difference!,"['law firms', 'innovation']","['P', 'P']","['law firm', 'innovation']","['law firm', 'innovate', 'client do', 'culture worship', 'difficult', 'easy', 'future hinge', 'make', 'difference']"
218,916,Attribute generation based on association rules,"a decision tree is considered to be appropriate (1) if the tree can classify the unseen data accurately, and (2) if the size of the tree is small. one of the approaches to induce such a good decision tree is to add new attributes and their values to enhance the expressiveness of the training data at the data pre-processing stage. there are many existing methods for attribute extraction and construction, but constructing new attributes is still an art. these methods are very time consuming, and some of them need a priori knowledge of the data domain. they are not suitable for data mining dealing with large volumes of data. we propose a novel approach that the knowledge on attributes relevant to the class is extracted as association rules from the training data. the new attributes and the values are generated from the association rules among the originally given attributes. we elaborate on the method and investigate its feature. the effectiveness of our approach is demonstrated through some experiments","['attribute generation', 'association rules', 'decision tree', 'training data', 'attribute extraction', 'data mining', 'experiments', 'large database']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['attribute generation', 'association rule', 'decision tree', 'training datum', 'attribute extraction', 'datum mining', 'experiment', 'large database']","['construct new attribute', 'attribute relevant', 'add new attribute', 'new attribute', 'attribute extraction', 'give attribute', 'training datum', 'datum mining dealing', 'association rule', 'unseen datum']"
219,584,Hybrid fuzzy modeling of chemical processes,"fuzzy models have been proved to have the ability of modeling all plants without any priori information. however, the performance of conventional fuzzy models can be very poor in the case of insufficient training data due to their poor extrapolation capacity. in order to overcome this problem, a hybrid grey-box fuzzy modeling approach is proposed in this paper to combine expert experience, local linear models and historical data into a uniform framework. it consists of two layers. the expert fuzzy model constructed from linguistic information, the local linear model and the t-s type fuzzy model constructed from data are all put in the first layer. layer 2 is a fuzzy decision module that is used to decide which model in the first layer should be employed to make the final prediction. the output of the second layer is the output of the hybrid fuzzy model. with the help of the linguistic information, the poor extrapolation capacity problem caused by sparse training data for conventional fuzzy models can be overcome. simulation result for ph neutralization process demonstrates its modeling ability over the linear models, the expert fuzzy model and the conventional fuzzy model","['fuzzy modeling', 'chemical processes', 'expert fuzzy model', 'fuzzy decision module', 'process modeling']","['P', 'P', 'P', 'P', 'R']","['fuzzy modeling', 'chemical process', 'expert fuzzy model', 'fuzzy decision module', 'process model']","['expert fuzzy model', 'hybrid fuzzy model', 'box fuzzy modeling approach', 'conventional fuzzy model', 'type fuzzy model', 'fuzzy model', 'fuzzy decision module', 'local linear model', 'ph neutralization process', 'local linear model']"
220,1194,New methods for oscillatory problems based on classical codes,"the numerical integration of differential equations with oscillatory solutions is a very common problem in many fields of the applied sciences. some methods have been specially devised for this kind of problem. in most of them, the calculation of the coefficients needs more computational effort than the classical codes because such coefficients depend on the step-size in a not simple manner. on the contrary, in this work we present new algorithms specially designed for perturbed oscillators whose coefficients have a simple dependence on the step-size. the methods obtained are competitive when comparing with classical and special codes","['oscillatory problems', 'classical codes', 'numerical integration', 'differential equations', 'oscillatory solutions', 'perturbed oscillators']","['P', 'P', 'P', 'P', 'P', 'P']","['oscillatory problem', 'classical code', 'numerical integration', 'differential equation', 'oscillatory solution', 'perturb oscillator']","['perturb oscillator', 'numerical integration', 'oscillatory solution', 'differential equation', 'more computational effort', 'coefficient', 'algorithm', 'classical code', 'method', 'step']"
221,1169,An efficient algorithm for sequential generation of failure states in a network with multi-mode components,"in this work, a new algorithm for the sequential generation of failure states in a network with multi-mode components is proposed. the algorithm presented in the paper transforms the state enumeration problem into a k-shortest paths problem. taking advantage of the inherent efficiency of an algorithm for shortest paths enumeration and also of the characteristics of the reliability problem in which it will be used, an algorithm with lower complexity than the best algorithm in the literature for solving this problem, was obtained. computational results will be presented for comparing the efficiency of both algorithms in terms of cpu time and for problems of different size","['state enumeration problem', 'k-shortest paths problem', 'cpu time', 'multi-mode components reliability', 'sequential failure states generation algorithm', 'network failure states']","['P', 'P', 'P', 'R', 'R', 'R']","['state enumeration problem', 'k - short path problem', 'cpu time', 'multi - mode component reliability', 'sequential failure state generation algorithm', 'network failure state']","['short path enumeration', 'short path problem', 'state enumeration problem', 'failure state', 'good algorithm', 'reliability problem', 'algorithm', 'sequential generation', 'algorithm', 'mode component']"
222,579,Steinmetz system design under unbalanced conditions,"this paper studies and develops general analytical expressions to obtain three-phase current symmetrization under unbalanced voltage conditions. it proposes two procedures for this symmetrization: the application of the traditional expressions assuming symmetry conditions and the use of optimization methods based on the general analytical equations. specifically, the paper applies and evaluates these methods to analyze the steinmetz system design. several graphics evaluating the error introduced by assumption of balanced voltage in the design are plotted and an example is studied to compare both procedures. in the example the necessity to apply the optimization techniques in highly unbalanced conditions is demonstrated","['steinmetz system design', 'three-phase current symmetrization', 'unbalanced voltage conditions', 'optimization methods', 'general analytical equations', 'power system control design', 'balanced voltage assumption']","['P', 'P', 'P', 'P', 'P', 'M', 'R']","['steinmetz system design', 'three - phase current symmetrization', 'unbalanced voltage condition', 'optimization method', 'general analytical equation', 'power system control design', 'balanced voltage assumption']","['phase current symmetrization', 'unbalanced voltage condition', 'balanced voltage', 'symmetry condition', 'symmetrization', 'unbalanced condition', 'general analytical equation', 'steinmetz system', 'general analytical expression', 'optimization method']"
223,685,Robotically enhanced placement of left ventricular epicardial electrodes during implantation of a biventricular implantable cardioverter defibrillator system,biventricular pacing has gained increasing acceptance in advanced heart failure patients. one major limitation of this therapy is positioning the left ventricular stimulation lead via the coronary sinus. this report demonstrates the feasibility of totally endoscopic direct placement of an epicardial stimulation lead on the left ventricle using the davinci surgical system,"['left ventricular epicardial electrodes', 'advanced heart failure patients', 'coronary sinus', 'totally endoscopic direct placement', 'davinci surgical system', 'epicardial leads', 'left ventricular pacing', 'biventricular implantable cardioverter defibrillator system implantation', 'left ventricular stimulation lead positioning']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R']","['leave ventricular epicardial electrode', 'advanced heart failure patient', 'coronary sinus', 'totally endoscopic direct placement', 'davinci surgical system', 'epicardial lead', 'leave ventricular pacing', 'biventricular implantable cardioverter defibrillator system implantation', 'leave ventricular stimulation lead position']","['leave ventricular stimulation lead', 'epicardial stimulation lead', 'biventricular pacing', 'leave ventricle use', 'endoscopic direct placement', 'coronary sinus', 'advanced heart failure patient', 'position', 'report demonstrate', 'therapy']"
224,1295,Development of visual design steering as an aid in large-scale multidisciplinary design optimization. II. Method validation,"for pt. i see ibid., pp. 412-24. graph morphing, the first concept developed under the newly proposed paradigm of visual design steering (vds), is applied to optimal design problems. graph morphing, described in part i of this paper, can be used to provide insights to a designer to improve efficiency, reliability, and accuracy of an optimal design in less cycle time. it is demonstrated in this part of the paper that graph morphing can be used to provide insights into design variable impact, constraint redundancy, reasonable values for constraint allowable limits, and function smoothness, that otherwise might not be attainable","['visual design steering', 'large-scale multidisciplinary design optimization', 'method validation', 'graph morphing', 'optimal design problems', 'reliability', 'accuracy', 'cycle time', 'design variable impact', 'constraint redundancy', 'constraint allowable limits', 'function smoothness']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['visual design steering', 'large - scale multidisciplinary design optimization', 'method validation', 'graph morph', 'optimal design problem', 'reliability', 'accuracy', 'cycle time', 'design variable impact', 'constraint redundancy', 'constraint allowable limit', 'function smoothness']","['visual design steering', 'graph morph', 'optimal design problem', 'optimal design', 'design variable impact', 'constraint redundancy', 'constraint allowable limit', 'improve efficiency', 'less cycle time', 'designer']"
225,1074,Inhibiting decoherence via ancilla processes,general conditions are derived for preventing the decoherence of a single two-state quantum system (qubit) in a thermal bath. the employed auxiliary systems required for this purpose are merely assumed to be weak for the general condition while various examples such as extra qubits and extra classical fields are studied for applications in quantum information processing. the general condition is confirmed by well known approaches toward inhibiting decoherence. an approach to decoherence-free quantum memories and quantum operations is presented by placing the qubit into the center of a sphere with extra qubits on its surface,"['decoherence', 'ancilla processes', 'general condition', 'single two-state quantum system', 'qubit', 'thermal bath', 'auxiliary systems', 'extra qubits', 'extra classical fields', 'quantum information processing', 'decoherence-free quantum memories', 'quantum operations', 'decoherence inhibition', 'sphere surface']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['decoherence', 'ancilla process', 'general condition', 'single two - state quantum system', 'qubit', 'thermal bath', 'auxiliary system', 'extra qubit', 'extra classical field', 'quantum information processing', 'decoherence - free quantum memory', 'quantum operation', 'decoherence inhibition', 'sphere surface']","['state quantum system', 'quantum information processing', 'free quantum memory', 'quantum operation', 'inhibit decoherence', 'extra qubit', 'qubit', 'decoherence', 'thermal bath', 'sphere']"
226,1031,Noise-constrained hyperspectral data compression,"storage and transmission requirements for hyperspectral data sets are significant. to reduce hardware costs, well-designed compression techniques are needed to preserve information content while maximizing compression ratios. lossless compression techniques maintain data integrity, but yield small compression ratios. we present a slightly lossy compression algorithm that uses the noise statistics of the data to preserve information content while maximizing compression ratios. the adaptive principal components analysis (apca) algorithm uses noise statistics to determine the number of significant principal components and selects only those that are required to represent each pixel to within the noise level. we demonstrate the effectiveness of these methods with airborne visible/infrared spectrometer (aviris), hyperspectral digital imagery collection experiment (hydice), hyperspectral mapper (hymap), and hyperion datasets","['noise-constrained hyperspectral data compression', 'transmission requirements', 'hyperspectral data sets', 'hardware costs', 'information content', 'compression ratios', 'lossless compression techniques', 'data integrity', 'slightly lossy compression algorithm', 'noise statistics', 'noise level', 'hyperspectral mapper', 'hymap', 'hyperion datasets', 'storage requirements', 'adaptive principal components analysis algorithm', 'airborne visible/infrared spectrometer hyperspectral digital imagery collection experiment', 'aviris hydice', 'gaussian statistics']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'M']","['noise - constrain hyperspectral datum compression', 'transmission requirement', 'hyperspectral datum set', 'hardware cost', 'information content', 'compression ratio', 'lossless compression technique', 'datum integrity', 'slightly lossy compression algorithm', 'noise statistic', 'noise level', 'hyperspectral mapper', 'hymap', 'hyperion dataset', 'storage requirement', 'adaptive principal component analysis algorithm', 'airborne visible / infrared spectrometer hyperspectral digital imagery collection experiment', 'aviris hydice', 'gaussian statistic']","['lossless compression technique maintain datum integrity', 'hyperspectral digital imagery collection', 'hyperspectral datum set', 'hyperspectral mapper', 'lossy compression algorithm', 'infrare spectrometer', 'adaptive principal component analysis', 'compression technique', 'algorithm use noise statistic', 'preserve information content']"
227,798,"ClioWeb, ClioRequest, and Clio database: enhancing patron and staff satisfaction","faced with increased demand from students and faculty for a speedier and more user-friendly method of obtaining materials from other institutions, the interlibrary loan (ill) department sought to implement a management system which would accomplish the task. students wanted remote interconnectivity to the system and staff wanted increased workflow efficiency, reduced paper work, and better data management. this paper focuses on washington college's experience in selecting and implementing an interlibrary loan system, which would enhance student satisfaction as well as that of the library staff","['clioweb', 'cliorequest', 'clio database', 'staff satisfaction', 'students', 'faculty', 'user-friendly method', 'management system', 'remote interconnectivity', 'workflow efficiency', 'data management', 'washington college', 'patron satisfaction', 'interlibrary loan department']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['clioweb', 'cliorequest', 'clio database', 'staff satisfaction', 'student', 'faculty', 'user - friendly method', 'management system', 'remote interconnectivity', 'workflow efficiency', 'datum management', 'washington college', 'patron satisfaction', 'interlibrary loan department']","['interlibrary loan system', 'interlibrary loan', 'student want remote interconnectivity', 'enhance student satisfaction', 'staff want increase workflow efficiency', 'well datum management', 'washington college', 'management system', 'other institution', 'department seek']"
228,765,Simulating fermions on a quantum computer,"the real-time probabilistic simulation of quantum systems in classical computers is known to be limited by the so-called dynamical sign problem, a problem leading to exponential complexity. in 1981 richard feynman raised some provocative questions in connection to the ""exact imitation"" of such systems using a special device named a ""quantum computer"". feynman hesitated about the possibility of imitating fermion systems using such a device. here we address some of his concerns and, in particular, investigate the simulation of fermionic systems. we show how quantum computers avoid the sign problem in some cases by reducing the complexity from exponential to polynomial. our demonstration is based upon the use of isomorphisms of algebras. we present specific quantum algorithms that illustrate the main points of our algebraic approach","['quantum computer', 'real-time probabilistic simulation', 'classical computers', 'dynamical sign problem', 'sign problem', 'exponential complexity', 'fermion systems', 'isomorphisms', 'algebras', 'fermions simulation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['quantum computer', 'real - time probabilistic simulation', 'classical computer', 'dynamical sign problem', 'sign problem', 'exponential complexity', 'fermion system', 'isomorphism', 'algebra', 'fermion simulation']","['quantum algorithm', 'quantum system', 'quantum computer', 'imitate fermion system', 'quantum computer', 'time probabilistic simulation', 'exponential complexity', 'call dynamical sign problem', 'fermionic system', 'classical computer']"
229,720,19in monitors [CRT survey],"upgrade your monitor from as little as pounds 135. with displays on test and ranging up to pounds 400, whether you're after the last word in quality or simply looking for again, this labs holds the answer. looks at adi microscan m900, ctx pr960f, eizo flexscan t766, hansol 920d, hansol920p, hitachi cm715et, hitachi cm721fet, liyama vision master pro 454, lg flatron 915ft plus, mitsubishi diamond pro 920, nec multisync fe950+, philips 109s40, samsung syncmaster 959nf, sony multiscan cpd-g420, and viewsonic g90f","['19in monitors', '19 in', 'crt survey', 'adi microscan m900', 'ctx pr960f', 'eizo flexscan t766', 'hansol 920d', 'hansol920p', 'hitachi cm715et', 'hitachi cm721fet', 'liyama vision master pro 454', 'lg flatron 915ft plus', 'mitsubishi diamond pro 920', 'nec multisync fe950', 'philips 109s40', 'samsung syncmaster 959nf', 'sony multiscan cpd-g420', 'viewsonic g90f']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['19 in monitor', '19 in', 'crt survey', 'adi microscan m900', 'ctx pr960f', 'eizo flexscan t766', 'hansol 920d', 'hansol920p', 'hitachi cm715et', 'hitachi cm721fet', 'liyama vision master pro 454', 'lg flatron 915 ft plus', 'mitsubishi diamond pro 920', 'nec multisync fe950', 'philips 109s40', 'samsung syncmaster 959nf', 'sony multiscan cpd - g420', 'viewsonic g90f']","['adi microscan m900', 'sony multiscan cpd', 'samsung syncmaster 959nf', 'monitor', 'display', 'flexscan t766', 'hitachi cm715et', 'ctx pr960f', 'viewsonic', 'nec multisync fe950']"
230,1375,Evaluation of the usability of digital maintenance manuals developed without either user input or a task analysis,"the primary objective was to investigate the value that can be added to a low-cost digital maintenance manual by the addition of a navigational aid. two versions of a digital maintenance manual were developed, the difference between them being the number of design heuristics observed when designing navigational aids. neither version was based on an analysis of the tasks carried out by users, nor were users involved in the design process. instead, the manuals were developed directly from the digital information used to produce the existing paper manual. usability trials were carried out to test both versions according to the time taken and errors committed by users during typical information retrieval tasks. users were questioned to determine their ease of use (eou) perceptions for each manual. the main outcomes were that the navigation aid used in the second version reduced the time taken to use the manual but increased the number of errors made by users. the navigational aid also seemed to reduce the perceived eou compared with the first version. in both cases, the perceived eou was lower than for a previous digital manual that had been developed using a task analysis and user input. the paper concludes by recommending the development of a generic task model of user interaction with digital maintenance manuals","['task analysis', 'navigational aid', 'usability trials', 'information retrieval', 'generic task model', 'user interaction', 'digital maintenance manuals usability']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['task analysis', 'navigational aid', 'usability trial', 'information retrieval', 'generic task model', 'user interaction', 'digital maintenance manual usability']","['cost digital maintenance manual', 'digital maintenance manual', 'typical information retrieval task', 'previous digital manual', 'exist paper manual', 'usability trial', 'design navigational', 'digital information use', 'design heuristic observe', 'generic task model']"
231,1330,Strobbe Graphics' next frontier: CTP for commercial printers,"strobbe is one of the more successful makers of newspaper platesetters, which are sold by agfa under the polaris name. but the company also has a growing presence in commercial printing markets, where it sells under its own name","['strobbe graphics', 'commercial printing', 'platesetters', 'agfa', 'polaris', 'punch international', 'workflow']","['P', 'P', 'P', 'P', 'P', 'U', 'U']","['strobbe graphic', 'commercial printing', 'platesetter', 'agfa', 'polaris', 'punch international', 'workflow']","['newspaper platesetter', 'commercial printing market', 'strobbe', 'polaris name', 'successful maker', 'sell', 'company', 'agfa', 'sell', 'have']"
232,1458,Direct gear tooth contact analysis for hypoid bevel gears,a new methodology for tooth contact analysis based on a very general mathematical model of the generating process is proposed. considering the line of action as a first order singularity of a certain operator equation we develop first and second order conditions for a pair of generated gear tooth flanks to be in contact. the constructive approach allows the direct computation of the paths of contact as the solution of a nonlinear equation system including the exact determination of the bounds of the paths of contact. the transmission error as well as curvature properties in the contact points are obtained in a convenient way. the resulting contact ellipses approximate the bearing area. through the use of automatic differentiation all the geometric quantities are calculable within the machine accuracy of the computer,"['direct gear tooth contact analysis', 'hypoid bevel gears', 'mathematical model', 'generating process', 'first order singularity', 'operator equation', 'second order conditions', 'generated gear tooth flanks', 'computer', 'nonlinear equation system', 'transmission error', 'curvature properties', 'contact ellipses', 'bearing area', 'automatic differentiation', 'geometric quantities', 'machine accuracy', 'first order conditions', 'contact paths', 'exact bound determination']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['direct gear tooth contact analysis', 'hypoid bevel gear', 'mathematical model', 'generating process', 'first order singularity', 'operator equation', 'second order condition', 'generate gear tooth flank', 'computer', 'nonlinear equation system', 'transmission error', 'curvature property', 'contact ellipsis', 'bear area', 'automatic differentiation', 'geometric quantity', 'machine accuracy', 'first order condition', 'contact path', 'exact bind determination']","['generate gear tooth flank', 'tooth contact analysis', 'result contact ellipsis approximate', 'nonlinear equation system include', 'curvature', 'operator equation', 'bear area', 'mathematical model', 'geometric quantity', 'computation']"
233,1089,Accuracy and stability of splitting with Stabilizing Corrections,"this paper contains a convergence analysis for the method of stabilizing corrections, which is an internally consistent splitting scheme for initial-boundary value problems. to obtain more accuracy and a better treatment of explicit terms several extensions are regarded and analyzed. the relevance of the theoretical results is tested for convection-diffusion-reaction equations","['stability', 'stabilizing corrections', 'convergence analysis', 'splitting scheme', 'initial-boundary value problems', 'convection-diffusion-reaction equations']","['P', 'P', 'P', 'P', 'P', 'P']","['stability', 'stabilize correction', 'convergence analysis', 'splitting scheme', 'initial - boundary value problem', 'convection - diffusion - reaction equation']","['consistent splitting scheme', 'stabilize correction', 'convection', 'diffusion', 'convergence analysis', 'boundary', 'method', 'initial', 'accuracy', 'explicit term']"
234,758,Four-terminal quantum resistor network for electron-wave computing,"interconnected ultrathin conducting wires or, equivalently, interconnected quasi-one-dimensional electron waveguides, which form a quantum resistor network, are presented here in four-terminal configurations. the transmission behaviors through such four-terminal networks are evaluated and classified. in addition, we show that such networks can be used as the basic building blocks for a possible massive wave computing machine in the future. in a network, each interconnection, a node point, is an elastic scatterer that routes the electron wave. routing and rerouting of electron waves in a network is described in the framework of quantum transport from landauer-buttiker theory in the presence of multiple elastic scatterers. transmissions through various types of four-terminal generalized clean aharonov-bohm rings are investigated at zero temperature. useful logic functions are gathered based on the transmission probability to each terminal with the use of the buttiker symmetry rule. in the generalized rings, even and odd numbers of terminals can possess some distinctly different transmission characteristics as we have shown here and earlier. just as an even or odd number of atoms in a ring is an important quantity for classifying the transmission behavior, we show here that whether the number of terminals is an even or an odd number is just as important in understanding the physics of transmission through such a ring. furthermore, we show that there are three basic classes of four-terminal rings and the scaling relation for each class is provided. in particular, the existence of equitransmission among all four terminals is shown here. this particular physical phenomena cannot exist in any three-terminal ring. comparisons and discussions of transmission characteristics between three-terminal and four-terminal rings are also presented. the node-equation approach by considering the kirchhoff current conservation law at each node point is used for this analysis. many useful logic functions for electron-wave computing are shown here. in particular, we show that a full adder can be constructed very simply using the equitransmission property of the four-terminal ring. this is in sharp contrast with circuits based on transistor logic","['four-terminal quantum resistor network', 'electron-wave computing', 'interconnected ultrathin conducting wires', 'transmission behavior', 'rerouting', 'landauer-buttiker theory', 'multiple elastic scatterers', 'aharonov-bohm rings', 'logic functions', 'transmission probability', 'buttiker symmetry rule', 'kirchhoff current conservation law', 'equitransmission property', 'quasi1d electron waveguides']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['four - terminal quantum resistor network', 'electron - wave computing', 'interconnect ultrathin conduct wire', 'transmission behavior', 'reroute', 'landauer - buttiker theory', 'multiple elastic scatterer', 'aharonov - bohm ring', 'logic function', 'transmission probability', 'buttiker symmetry rule', 'kirchhoff current conservation law', 'equitransmission property', 'quasi1d electron waveguide']","['interconnect ultrathin conduct wire', 'dimensional electron waveguide', 'quantum resistor network', 'quantum transport', 'electron wave', 'electron wave', 'massive wave computing machine', 'multiple elastic scatterer', 'bohm ring', 'transmission characteristic']"
235,1348,Reconstructing surfaces by volumetric regularization using radial basis functions,"we present a new method of surface reconstruction that generates smooth and seamless models from sparse, noisy, nonuniform, and low resolution range data. data acquisition techniques from computer vision, such as stereo range images and space carving, produce 3d point sets that are imprecise and nonuniform when compared to laser or optical range scanners. traditional reconstruction algorithms designed for dense and precise data do not produce smooth reconstructions when applied to vision-based data sets. our method constructs a 3d implicit surface, formulated as a sum of weighted radial basis functions. we achieve three primary advantages over existing algorithms: (1) the implicit functions we construct estimate the surface well in regions where there is little data, (2) the reconstructed surface is insensitive to noise in data acquisition because we can allow the surface to approximate, rather than exactly interpolate, the data, and (3) the reconstructed surface is locally detailed, yet globally smooth, because we use radial basis functions that achieve multiple orders of smoothness","['volumetric regularization', 'radial basis functions', 'surfaces reconstruction', 'low resolution range data', 'data acquisition techniques', 'computer vision', 'stereo range images', 'space carving', '3d point sets', 'vision-based data sets', '3d implicit surface', 'weighted radial basis functions', 'sparse range data', 'noisy data', 'nonuniform data']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['volumetric regularization', 'radial basis function', 'surface reconstruction', 'low resolution range datum', 'datum acquisition technique', 'computer vision', 'stereo range image', 'space carving', '3d point set', 'vision - base data set', '3d implicit surface', 'weight radial basis function', 'sparse range datum', 'noisy datum', 'nonuniform datum']","['3d implicit surface', 'reconstruct surface', 'stereo range image', 'surface reconstruction', 'produce 3d point set', 'produce smooth reconstruction', 'low resolution range datum', 'use radial basis function', 'optical range scanner', 'radial basis function']"
236,1420,PDF subscriptions bolster revenue,"in 1999 sd times offered prospective subscribers the option of receiving their issues as adobe acrobat pdf files. what set the proposal apart from what other publishers were doing electronically on the web was that readers would get the entire version of the paper-including both advertising and editorial just as it looked when it was laid out and went to press. sd times is only one of a small, but growing, number of publications that are taking on the electronic world and finding success. in the past six months alone, the new york times, popular mechanics, trade magazine electronic buyers' news, and the harvard business review have launched digital versions of their newspapers and magazines to augment their online and print versions. the reasons are as varied as the publishers themselves. some companies are finding that readers don't like their web-based versions either due to poor navigation or missing graphics and images. others want to expand their publications nationally and internationally, but don't want the added cost of postage and printing. still others are looking for ways to give advertisers additional visibility and boost advertising and subscription revenues. no matter what the reason, it's a trend worth watching","['pdf subscriptions', 'sd times', 'adobe acrobat pdf files', 'magazines', 'digital versions', 'newspaper', 'electronic issue']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['pdf subscription', 'sd time', 'adobe acrobat pdf file', 'magazine', 'digital version', 'newspaper', 'electronic issue']","['adobe acrobat pdf file', 'magazine electronic buyer', 'launch digital version', 'other publisher', 'advertiser additional visibility', 'print version', 'subscription revenue', 'publisher', 'newspaper', 'magazine']"
237,836,Recruitment and retention of women graduate students in computer science and engineering: results of a workshop organized by the Computing Research Association,"this document is the report of a workshop that convened a group of experts to discuss the recruitment and retention of women in computer science and engineering (cse) graduate programs. participants included long-time members of the cse academic and research communities, social scientists engaged in relevant research, and directors of successful retention efforts. the report is a compendium of the experience and expertise of workshop participants, rather than the result of a full-scale, scholarly study into the range of issues. its goal is to provide departments with practical advice on recruitment and retention in the form of a set of specific recommendations","['recruitment', 'retention', 'women graduate students', 'computer science', 'engineering', 'computing research association', 'research communities', 'social scientists', 'directors', 'workshop participants', 'academic communities']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['recruitment', 'retention', 'woman graduate student', 'computer science', 'engineering', 'compute research association', 'research community', 'social scientist', 'director', 'workshop participant', 'academic community']","['cse academic', 'successful retention effort', 'graduate program', 'social scientist engage', 'recruitment', 'scholarly study', 'workshop participant', 'research community', 'participant include long', 'cse']"
238,873,Programmatic efforts encouraging women to enter the information technology workforce,"for over a decade the national science foundation (nsf) has been supporting projects designed to improve opportunities for women in computing. from an initial emphasis on increasing the number of women in graduate school studying computer science and engineering, nsf's current emphasis has broadened to include research studies examining the underlying reasons why women are underrepresented in the information technology (it) workforce. this paper describes the recent history of nsf's activities in this area and the subsequent emergence of a research portfolio addressing the underrepresentation issue","['women', 'national science foundation', 'computing', 'graduate school', 'engineering', 'history', 'it workforce']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['woman', 'national science foundation', 'compute', 'graduate school', 'engineering', 'history', 'it workforce']","['graduate school study computer science', 'include research study examine', 'research portfolio address', 'national science foundation', 'support project design', 'information technology', 'workforce', 'woman', 'improve opportunity', 'underrepresented']"
239,1049,A typed representation for HTML and XML documents in Haskell,"we define a family of embedded domain specific languages for generating html and xml documents. each language is implemented as a combinator library in haskell. the generated html/xml documents are guaranteed to be well-formed. in addition, each library can guarantee that the generated documents are valid xml documents to a certain extent (for html only a weaker guarantee is possible). on top of the libraries, haskell serves as a meta language to define parameterized documents, to map structured documents to html/xml, to define conditional content, or to define entire web sites. the combinator libraries support element-transforming style, a programming style that allows programs to have a visual appearance similar to html/xml documents, without modifying the syntax of haskell","['typed representation', 'xml documents', 'haskell', 'embedded domain specific languages', 'combinator library', 'meta language', 'parameterized documents', 'conditional content', 'web sites', 'element-transforming style', 'syntax', 'html documents', 'software libraries', 'functional programming']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M']","['type representation', 'xml document', 'haskell', 'embed domain specific language', 'combinator library', 'meta language', 'parameterized document', 'conditional content', 'web site', 'element - transform style', 'syntax', 'html document', 'software librarie', 'functional programming']","['combinator librarie support element', 'embed domain specific language', 'map structured document', 'valid xml document', 'generate html', 'generate html', 'xml document', 'haskell serve', 'define entire web site', 'haskell']"
240,1111,The contiguity in R/M,"an r.e. degree c is contiguous if deg/sub wtt/(a)=deg/sub wtt/(b) for any r.e. sets a,b in c. in this paper, we generalize the notation of contiguity to the structure r/m, the upper semilattice of the r.e. degree set r modulo the cappable r.e. degree set m. an element [c] in r/m is contiguous if [deg/sub wtt/(a)]=[deg/sub wtt/(b)] for any r.e. sets a, b such that deg/sub t/(a),deg/sub t/(b) in [c]. it is proved in this paper that every nonzero element in r/m is not contiguous, i.e., for every element [c] in r/m, if [c] not=[o] then there exist at least two r.e. sets a, b such that deg/sub t/(a), deg/sub t/(b) in [c] and [deg/sub wtt/(a)] not=[deg/sub wtt/(b)]","['contiguity', 'upper semilattice', 'nonzero element', 'turing degree', 'recursively enumerable set', 'recursion theory']","['P', 'P', 'P', 'M', 'M', 'U']","['contiguity', 'upper semilattice', 'nonzero element', 'ture degree', 'recursively enumerable set', 'recursion theory']","['upper semilattice', 'contiguous', 'structure', 'degree set', 'nonzero element', 'set', 'contiguity', 'degree', 'sub', 'notation']"
241,1154,The effect of voxel size on the accuracy of dose-volume histograms of prostate /sup 125/I seed implants,"cumulative dose-volume histograms (dvh) are crucial in evaluating the quality of radioactive seed prostate implants. when calculating dvhs, the choice of voxel size is a compromise between computational speed (larger voxels) and accuracy (smaller voxels). we quantified the effect of voxel size on the accuracy of dvhs using an in-house computer program. the program was validated by comparison with a hand-calculated dvh for a single 0.4-u iodine-125 model 6711 seed. we used the program to find the voxel size required to obtain accurate dvhs of five iodine-125 prostate implant patients at our institution. one-millimeter cubes were sufficient to obtain dvhs that are accurate within 5% up to 200% of the prescription dose. for the five patient plans, we obtained good agreement with the variseed (version 6.7, varian, usa) treatment planning software's dvh algorithm by using voxels with a sup-inf dimension equal to the spacing between successive transverse seed implant planes (5 mm). the volume that receives at least 200% of the target dose, v/sub 200/, calculated by variseed was 30% to 43% larger than that calculated by our program with small voxels. the single-seed dvh calculated by variseed fell below the hand calculation by up to 50% at low doses (30 gy), and above it by over 50% at high doses (>250 gy)","['voxel size', 'i', 'prostate /sup 125/i seed implants', 'cumulative dose-volume histograms', 'radioactive seed prostate implants', 'computational speed', 'in-house computer program', 'hand-calculated dose-volume histograms', 'single-seed dose-volume histograms', '/sup 125/i model', '/sup 125/i prostate implant patients', ""variseed treatment planning software's dose-volume histogram algorithm""]","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'R']","['voxel size', 'I', 'prostate /sup 125 / I seed implant', 'cumulative dose - volume histogram', 'radioactive seed prostate implant', 'computational speed', 'in - house computer program', 'hand - calculate dose - volume histogram', 'single - seed dose - volume histogram', '/sup 125 / I model', '/sup 125 / I prostate implant patient', ""variseed treatment planning software 's dose - volume histogram algorithm""]","['radioactive seed prostate implant', 'seed dvh calculate', 'volume histogram', 'prostate implant patient', 'prescription dose', 'calculate dvh', 'cumulative dose', 'dvh algorithm', 'successive transverse seed implant', 'calculate dvhs']"
242,993,A large deviations analysis of the transient of a queue with many Markov fluid inputs: approximations and fast simulation,"this article analyzes the transient buffer content distribution of a queue fed by a large number of markov fluid sources. we characterize the probability of overflow at time t, given the current buffer level and the number of sources in the on-state. after scaling buffer and bandwidth resources by the number of sources n, we can apply large deviations techniques. the transient overflow probability decays exponentially in n. in the case of exponential on/off sources, we derive an expression for the decay rate of the rare event probability under consideration. for general markov fluid sources, we present a plausible conjecture. we also provide the ""most likely path"" from the initial state to overflow (at time t). knowledge of the decay rate and the most likely path to overflow leads to (i) approximations of the transient overflow probability and (ii) efficient simulation methods of the rare event of buffer overflow. the simulation methods, based on importance sampling, give a huge speed-up compared to straightforward simulations. the approximations are of low computational complexity and are accurate, as verified by means of simulation experiments","['large deviations analysis', 'markov fluid inputs', 'approximations', 'transient buffer content distribution', 'bandwidth resources', 'transient overflow probability', 'simulation methods', 'importance sampling', 'computational complexity', 'buffer resources', 'atm multiplexers', 'ip routers', 'queuing theory']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'U', 'U']","['large deviation analysis', 'markov fluid input', 'approximation', 'transient buffer content distribution', 'bandwidth resource', 'transient overflow probability', 'simulation method', 'importance sample', 'computational complexity', 'buffer resource', 'atm multiplexer', 'ip router', 'queue theory']","['transient overflow probability decay', 'transient buffer content distribution', 'transient overflow probability', 'markov fluid source', 'buffer overflow', 'rare event probability', 'queue fed', 'decay rate', 'scale buffer', 'efficient simulation']"
243,544,Virtual reality treatment of flying phobia,"flying phobia (fp) might become a very incapacitating and disturbing problem in a person's social, working, and private areas. psychological interventions based on exposure therapy have proved to be effective, but given the particular nature of this disorder they bear important limitations. exposure therapy for fp might be excessively costly in terms of time, money, and efforts. virtual reality (vr) overcomes these difficulties as different significant environments might be created, where the patient can interact with what he or she fears while in a totally safe and protected environment, the therapist's consulting room. this paper intends, on one hand, to show the different scenarios designed by our team for the vr treatment of fp, and on the other, to present the first results supporting the effectiveness of this new tool for the treatment of fp in a multiple baseline study","['flying phobia', 'psychology', 'psychological interventions', 'exposure therapy', 'medical virtual reality', 'patient treatment', 'anxiety disorders', 'virtual exposure']","['P', 'P', 'P', 'P', 'M', 'R', 'M', 'R']","['fly phobia', 'psychology', 'psychological intervention', 'exposure therapy', 'medical virtual reality', 'patient treatment', 'anxiety disorder', 'virtual exposure']","['fly phobia', 'psychological intervention base', 'vr treatment', 'exposure therapy', 'virtual reality', 'vr', 'different scenario design', 'protect environment', 'fear', 'different significant environment']"
244,82,Bit-serial AB/sup 2/ multiplier using modified inner product,"this paper presents a new multiplication algorithm and, based on this algorithm, proposes a hardware architecture, called modified inner-product multiplier (mipm), which computes ab/sup 2/ multiplication based on a linear feedback shift register (lfsr). the algorithm is based on the property of the irreducible all one polynomial (aop) over the finite field gf(2/sup m/). the proposed architecture reduces the time and space complexity for computing ab/sup 2/. the proposed architecture has a potential application to implementing exponentiation architecture for a public-key cryptosystem","['bit-serial ab/sup 2/ multiplier', 'modified inner product', 'multiplication algorithm', 'hardware architecture', 'modified inner-product multiplier', 'linear feedback shift register', 'irreducible all one polynomial', 'space complexity', 'public-key cryptosystem', 'time complexity']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['bit - serial ab / sup 2/ multiplier', 'modify inner product', 'multiplication algorithm', 'hardware architecture', 'modify inner - product multiplier', 'linear feedback shift register', 'irreducible all one polynomial', 'space complexity', 'public - key cryptosystem', 'time complexity']","['new multiplication algorithm', 'implement exponentiation architecture', 'product multiplier', 'compute ab', 'computing ab', 'hardware architecture', 'algorithm', 'polynomial', 'propose architecture reduce', 'shift register']"
245,1210,Adaptive optimizing compilers for the 21st century,"historically, compilers have operated by applying a fixed set of optimizations in a predetermined order. we call such an ordered list of optimizations a compilation sequence. this paper describes a prototype system that uses biased random search to discover a program-specific compilation sequence that minimizes an explicit, external objective function. the result is a compiler framework that adapts its behavior to the application being compiled, to the pool of available transformations, to the objective function, and to the target machine. this paper describes experiments that attempt to characterize the space that the adaptive compiler must search. the preliminary results suggest that optimal solutions are rare and that local minima are frequent. if this holds true, biased random searches, such as a,genetic algorithm, should find good solutions more quickly than simpler strategies, such as hill climbing","['optimizations', 'optimizing compilers', 'compilers', 'compilation sequence', 'biased random search', 'adaptive compiler', 'configurable compilers']","['P', 'P', 'P', 'P', 'P', 'P', 'M']","['optimization', 'optimize compiler', 'compiler', 'compilation sequence', 'bias random search', 'adaptive compiler', 'configurable compiler']","['adaptive compiler', 'use bias random search', 'compiler framework', 'specific compilation sequence', 'bias random search', 'genetic algorithm', 'compiler', 'compilation sequence', 'optimization', 'external objective function']"
246,1255,Succession in standardization: grafting XML onto SGML,"succession in standardization is often a problem. the advantages of improvements must be weighed against those of compatibility. if compatibility considerations dominate, a grafting process takes place. according to our taxonomy of succession, there are three types of outcomes. a type i succession, where grafting is successful, entails compatibility between successors, technical paradigm compliance and continuity in the standards trajectory. in this paper, we examine issues of succession and focus on the extensible markup language (xml). it was to be grafted on the standard generalized markup language (sgml), a stable standard since 1988. however, xml was a profile, a subset and an extension of sgml (1988). adaptation of sgml was needed (sgml 1999) to forge full (downward) compatibility with xml (1998). we describe the grafting efforts and analyze their outcomes. our conclusion is that although sgml was a technical exemplar for xml developers, full compatibility was not achieved. the widespread use of hypertext mark-up language (html) exemplified the desirability of simplicity in xml, standardization. this and html's user market largely explain the discontinuity in sgml-xml succession","['standardization', 'xml', 'sgml', 'grafting process', 'type i succession', 'extensible markup language', 'standard generalized markup language']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['standardization', 'xml', 'sgml', 'grafting process', 'type I succession', 'extensible markup language', 'standard generalize markup language']","['standard generalize markup language', 'extensible markup language', 'technical paradigm compliance', 'xml developer', 'compatibility consideration dominate', 'xml', 'stable standard', 'hypertext mark', 'standardization', 'sgml']"
247,600,Development of railway VR safety simulation system,"abnormal conditions occur in railway transportation due to trouble or accidents and it affects a number of passengers. it is very important, therefore, to quickly recover and return to normal train operation. for this purpose we developed a system, ""computer vr simulation system for the safety of railway transportation."" it is a new type simulation system to evaluate measures to be taken under abnormal conditions. users of this simulation system cooperate with one another to correct the abnormal conditions that have occurred in virtual reality. this paper reports the newly developed simulation system","['railway transportation', 'accidents', 'normal train operation', 'computer vr simulation system', 'virtual reality simulation system', 'abnormal conditions correction']","['P', 'P', 'P', 'P', 'R', 'R']","['railway transportation', 'accident', 'normal train operation', 'computer vr simulation system', 'virtual reality simulation system', 'abnormal condition correction']","['computer vr simulation system', 'new type simulation system', 'railway transportation', 'simulation system cooperate', 'virtual reality', 'normal train operation', 'passenger', 'abnormal condition occur', 'abnormal condition', 'safety']"
248,645,Oxygen-enhanced MRI of the brain,"blood oxygenation level-dependent (bold) contrast mri is a potential method for a physiological characterization of tissue beyond mere morphological representation. the purpose of this study was to develop evaluation techniques for such examinations using a hyperoxia challenge. administration of pure oxygen was applied to test these techniques, as pure oxygen can be expected to induce relatively small signal intensity (si) changes compared to co/sub 2/-containing gases and thus requires very sensitive evaluation methods. fourteen volunteers were investigated by alternating between breathing 100% o/sub 2/ and normal air, using two different paradigms of administration. changes ranged from >30% in large veins to 1.71%+or-0.14% in basal ganglia and 0.82%+or-0.08% in white matter. to account for a slow physiological response function, a reference for correlation analysis was derived from the venous reaction. an objective method is presented that allows the adaptation of the significance threshold to the complexity of the paradigm used. reference signal characteristics in representative brain tissue regions were established. as the presented evaluation scheme proved its applicability to small si changes induced by pure oxygen, it can readily be used for similar experiments with other gases","['oxygen-enhanced mri', 'brain', 'hyperoxia', 'physiological response function', 'correlation analysis', 'venous reaction', 'significance threshold', 'bold contrast mri', 'oxygen breathing', 'normal air breathing', 'paradigm complexity', 'mri contrast agent', 'functional imaging', 'fourier transform analysis']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'M', 'M', 'M']","['oxygen - enhance mri', 'brain', 'hyperoxia', 'physiological response function', 'correlation analysis', 'venous reaction', 'significance threshold', 'bold contrast mri', 'oxygen breathing', 'normal air breathing', 'paradigm complexity', 'mri contrast agent', 'functional imaging', 'fouri transform analysis']","['blood oxygenation level', 'contrast mri', 'physiological characterization', 'slow physiological response function', 'hyperoxia', 'brain tissue region', 'signal intensity', 'pure oxygen', 'breathe', 'correlation analysis']"
249,1396,Construction of double sampling s-control charts for agile manufacturing,"double sampling (ds) x-control charts are designed to allow quick detection of a small shift of process mean and provides a quick response in an agile manufacturing environment. however, the ds x-control charts assume that the process standard deviation remains unchanged throughout the entire course of the statistical process control. therefore, a complementary ds chart that can be used to monitor the process variation caused by changes in process standard deviation should be developed. in this paper, the development of the ds s-charts for quickly detecting small shift in process standard deviation for agile manufacturing is presented. the construction of the ds s-charts is based on the same concepts in constructing the ds x-charts and is formulated as an optimization problem and solved with a genetic algorithm. the efficiency of the ds s-control chart is compared with that of the traditional s-control chart. the results show that the ds s-control charts can be a more economically preferable alternative in detecting small shifts than traditional s-control charts","['double sampling s-control charts', 'agile manufacturing', 'process standard deviation', 'statistical process control', 'genetic algorithm', 'double sampling x-control charts', 'process mean shift detection']","['P', 'P', 'P', 'P', 'P', 'R', 'R']","['double sample s - control chart', 'agile manufacturing', 'process standard deviation', 'statistical process control', 'genetic algorithm', 'double sample x - control chart', 'process mean shift detection']","['process standard deviation', 'statistical process control', 'ds chart', 'agile manufacturing', 'process variation cause', 'control chart', 'control chart assume', 'control chart', 'detect small shift', 'process mean']"
250,7,Anti-spam suit attempts to hold carriers accountable,a lawsuit alleges that sprint has violated utah's new anti-spam act. the action could open the door to new regulations on telecom service providers,"['lawsuit', 'sprint', 'anti-spam act', 'regulations', 'telecom service providers']","['P', 'P', 'P', 'P', 'P']","['lawsuit', 'sprint', 'anti - spam act', 'regulation', 'telecom service provider']","['lawsuit allege', 'violate utah', 'sprint', 'new regulation', 'new anti', 'action', 'open', 'door']"
251,1403,IT: Utilities,"a look at five utilities to make your pcs more, efficient, effective, and efficacious","['utilities', 'pcs', 'mobilemessenger', 'post-it software', 'easynotes', 'print shop pro', 'download accelerator plus']","['P', 'P', 'U', 'U', 'U', 'U', 'U']","['utility', 'pc', 'mobilemesseng', 'post - it software', 'easynote', 'print shop pro', 'download accelerator plus']","['utility', 'efficient', 'pc', 'effective', 'look', 'make']"
252,1097,A study on an automatic seam tracking system by using an electromagnetic sensor for sheet metal arc welding of butt joints,"many sensors, such as the vision sensor and the laser displacement sensor, have been developed to automate the arc welding process. however, these sensors have some problems due to the effects of arc light, fumes and spatter. an electromagnetic sensor, which utilizes the generation of an eddy current, was developed for detecting the weld line of a butt joint in which the root gap size was zero. an automatic seam tracking system designed for sheet metal arc welding was constructed with a sensor. through experiments, it was revealed that the system had an excellent seam tracking accuracy of the order of +or-0.2 mm","['automatic seam tracking system', 'electromagnetic sensor', 'sheet metal arc welding', 'butt joints', 'root gap size', 'seam tracking accuracy', 'eddy current generation', 'weld line detection']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['automatic seam tracking system', 'electromagnetic sensor', 'sheet metal arc welding', 'butt joint', 'root gap size', 'seam track accuracy', 'eddy current generation', 'weld line detection']","['sheet metal arc welding', 'arc welding process', 'seam track accuracy', 'laser displacement sensor', 'automatic seam tracking system', 'vision sensor', 'weld line', 'electromagnetic sensor', 'arc light', 'sensor']"
253,1446,The Tattletale technique,"practical experience has taught many java developers one thing: critical resources (mutexes, database connections, transactions, file handles, etc.) require timely and systematic release. unfortunately, java's garbage collector is not up to that job. according to the java language specification, there are no guarantees when a garbage collector will run, when it will collect an object, or when it will finalize an object - if ever. even more unfortunately, java's counterpart to the c++ destructor (the finally block) is both tedious and error-prone, requiring developers to constantly remember and duplicate resource-releasing code. consequently, even good java developers can forget to release critical resources. there is a light at the end of the tunnel. java may make it easier to leak critical resources, but it also provides the necessary mechanisms to easily track them down. the tattletale technique is a simple method for designing new classes and retrofitting existing classes to quickly and easily detect the offending code responsible for leaking resources","['tattletale technique', 'java', 'critical resources', 'mutexes', 'database connections', 'transactions', 'file handles', 'garbage collector', 'resource-releasing code', 'resources leaking']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['tattletale technique', 'java', 'critical resource', 'mutexe', 'database connection', 'transaction', 'file handle', 'garbage collector', 'resource - release code', 'resource leak']","['teach many java developer', 'java developer', 'java language specification', 'leak critical resource', 'release critical resource', 'garbage collector', 'java', 'release code', 'destructor', 'critical resource']"
254,850,Encouraging women in computer science,"at a cost to both their own opportunities and society's ability to produce people with much-needed technical skills, women continue to be underrepresented in computer science degree programs at both the undergraduate and graduate level. although some of the barriers that women face have their foundations in cultural expectations established well before the college level, we believe that departments can take effective steps to increase recruitment and retention of women students. this paper describes several strategies we have adopted at stanford over the past decade","['technical skills', 'computer science degree programs', 'graduate level', 'cultural expectations', 'undergraduate level', 'women student recruitment', 'women student retention']","['P', 'P', 'P', 'P', 'R', 'R', 'R']","['technical skill', 'computer science degree program', 'graduate level', 'cultural expectation', 'undergraduate level', 'woman student recruitment', 'woman student retention']","['computer science degree program', 'woman student', 'woman continue', 'increase recruitment', 'woman face have', 'cultural expectation establish', 'college level', 'technical skill', 'paper describe several strategy', 'undergraduate']"
255,815,The canonical dual frame of a wavelet frame,"we show that there exist wavelet frames that have nice dual wavelet frames, but for which the canonical dual frame does not consist of wavelets, i.e., cannot be generated by the translates and dilates of a single function","['canonical dual frame', 'wavelet frame', 'gabor frames', 'multiresolution hierarchy', 'compact support']","['P', 'P', 'M', 'U', 'U']","['canonical dual frame', 'wavelet frame', 'gabor frame', 'multiresolution hierarchy', 'compact support']","['have nice dual wavelet frame', 'exist wavelet frame', 'canonical dual frame', 'wavelet', 'translate', 'dilate', 'generate', 'show', 'consist']"
256,1276,A comparative study of some generalized rough approximations,"in this paper we focus upon a comparison of some generalized rough approximations of sets, where the classical indiscernibility relation is generalized to any binary reflexive relation. we aim at finding the best of several candidates for generalized rough approximation mappings, where both definability of sets by elementary granules of information as well as the issue of distinction among positive, negative, and border regions of a set are taken into account","['generalized rough approximations', 'classical indiscernibility relation', 'binary reflexive relation', 'generalized rough approximation mappings', 'elementary granules']","['P', 'P', 'P', 'P', 'P']","['generalize rough approximation', 'classical indiscernibility relation', 'binary reflexive relation', 'generalize rough approximation mapping', 'elementary granule']","['generalize rough approximation mapping', 'generalize rough approximation', 'classical indiscernibility relation', 'binary reflexive relation', 'set', 'definability', 'generalize', 'elementary granule', 'distinction', 'set']"
257,1233,Advanced optimization strategies in the Rice dHPF compiler,"high-performance fortran (hpf) was envisioned as a vehicle for modernizing legacy fortran codes to achieve scalable parallel performance. to a large extent, today's commercially available hpf compilers have failed to deliver scalable parallel performance for a broad spectrum of applications because of insufficiently powerful compiler analysis and optimization. substantial restructuring and hand-optimization can be required to achieve acceptable performance with an hpf port of an existing fortran application, even for regular data-parallel applications. a key goal of the rice dhpf compiler project has been to develop optimization techniques that enable a wide range of existing scientific applications to be ported easily to efficient hpf with minimal restructuring. this paper describes the challenges to effective parallelization presented by complex (but regular) data-parallel applications, and then describes how the novel analysis and optimization technologies in the dhpf compiler address these challenges effectively, without major rewriting of the applications. we illustrate the techniques by describing their use for parallelizing the nas sp and bt benchmarks. the dhpf compiler generates multipartitioned parallelizations of these codes that are approaching the scalability and efficiency of sophisticated hand-coded parallelizations","['rice dhpf compiler', 'hpf compilers', 'legacy fortran codes', 'parallel performance', 'compiler analysis', 'multipartitioning', 'mgh-performance fortran', 'compiler optimization', 'automatic parallelization']","['P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'M']","['rice dhpf compiler', 'hpf compiler', 'legacy fortran code', 'parallel performance', 'compiler analysis', 'multipartitione', 'mgh - performance fortran', 'compiler optimization', 'automatic parallelization']","['dhpf compiler generate multipartitioned parallelization', 'achieve scalable parallel performance', 'deliver scalable parallel performance', 'rice dhpf compiler project', 'available hpf compiler', 'modernize legacy fortran code', 'dhpf compiler address', 'performance fortran', 'effective parallelization present', 'powerful compiler analysis']"
258,623,Stochastic recurrences of Jackpot Keno,"we describe a mathematical model and simulation study for jackpot keno, as implemented by jupiters network gaming (jng) in the australian state of queensland, and as controlled by the queensland office of gaming regulation (qogr) (http://www.qogr.qld.gov.au/keno.shtml). the recurrences for the house net hold are derived and it is seen that these are piecewise linear with a ternary domain split, and further, the split points are stochastic in nature. since this structure is intractable (brockett and levine, statistics & probability & their applications, cbs college publishing, 1984), estimation of house net hold obtained through an appropriately designed simulator using a random number generator with desirable properties is described. since the model and simulation naturally derives hold given payscale, but jng and qogr require payscale given hold, an inverse problem was required to be solved. this required development of a special algorithm, which may be described as a stochastic binary search. experimental results are presented, in which the simulator is used to determine jackpot pay-scales so as to satisfy legal requirements of approximately 75% of net revenue returned to the players, i.e., 25% net hold for the house (jng). details of the algorithm used to solve this problem are presented, and notwithstanding the stochastic nature of the simulation, convergence to a specified hold for the inverse problem has been achieved to within 0.1% in all cases of interest to date","['stochastic recurrences', 'jackpot keno', 'mathematical model', 'simulation', 'jupiters network gaming', 'house net hold', 'piecewise linear', 'ternary domain split', 'probability', 'random number generator', 'inverse problem', 'stochastic binary search', 'experimental results', 'legal requirement', 'chinese lottery game']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['stochastic recurrence', 'jackpot keno', 'mathematical model', 'simulation', 'jupiters network gaming', 'house net hold', 'piecewise linear', 'ternary domain split', 'probability', 'random number generator', 'inverse problem', 'stochastic binary search', 'experimental result', 'legal requirement', 'chinese lottery game']","['determine jackpot pay', 'stochastic binary search', 'qogr require payscale give hold', 'net revenue return', 'random number generator', 'house net hold obtain', 'jackpot keno', 'house net hold', 'hold give payscale', 'net hold']"
259,908,Multivariable H/sub infinity // mu feedback control design for high-precision wafer stage motion,"conventional pid-like siso controllers are still the most common in industry, but with performance requirements becoming tighter there is a growing need for advanced controllers. for the positioning devices in ic-manufacturing, plant interaction is a major performance-limiting factor. mimo control can be invoked to tackle this problem. a practically feasible procedure is presented to design mimo feedback controllers for electromechanical positioning devices, using h/sub infinity // mu techniques. weighting filters are proposed to straightforwardly and effectively impose performance and uncertainty specifications. experiments show that mimo control can considerably improve upon the performance with multiloop siso control. some problems are highlighted that are important for industrial practice, but lacking a workable solution","['feedback', 'weighting filters', 'ic manufacture', 'multivariable control systems', 'mimo systems', 'h/sub infinity / control', 'servo systems', 'model uncertainty', 'motion control', 'mechatronics', 'mu synthesis']","['P', 'P', 'U', 'M', 'M', 'R', 'U', 'M', 'R', 'U', 'M']","['feedback', 'weight filter', 'ic manufacture', 'multivariable control system', 'mimo system', 'h / sub infinity / control', 'servo system', 'model uncertainty', 'motion control', 'mechatronic', 'mu synthesis']","['design mimo feedback controller', 'electromechanical positioning device', 'mimo control', 'multiloop siso control', 'siso controller', 'position device', 'advanced controller', 'weight filter', 'uncertainty specification', 'mu technique']"
260,1177,Comparative statistical analysis of hole taper and circularity in laser percussion drilling,"investigates the relationships and parameter interactions between six controllable variables on the hole taper and circularity in laser percussion drilling. experiments have been conducted on stainless steel workpieces and a comparison was made between stainless steel and mild steel. the central composite design was employed to plan the experiments in order to achieve required information with reduced number of experiments. the process performance was evaluated. the ratio of minimum to maximum feret's diameter was considered as circularity characteristic of the hole. the models of these three process characteristics were developed by linear multiple regression technique. the significant coefficients were obtained by performing analysis of variance (anova) at 1, 5 and 7% levels of significance. the final models were checked by complete residual analysis and finally were experimentally verified. it was found that the pulse frequency had a significant effect on the hole entrance diameter and hole circularity in drilling stainless steel unlike the drilling of mild steel where the pulse frequency had no significant effect on the hole characteristics","['comparative statistical analysis', 'hole taper', 'circularity', 'laser percussion drilling', 'stainless steel workpieces', 'mild steel', 'central composite design', 'process performance', 'linear multiple regression technique', 'analysis of variance', 'anova', 'complete residual analysis', 'pulse frequency', 'laser peak power', 'laser pulse width', 'assist gas pressure', 'focal plane position', 'equivalent entrance diameter', 'ferets diameter', 'least squares procedure', 'stepwise regression method']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'U', 'U', 'M', 'R', 'U', 'M']","['comparative statistical analysis', 'hole taper', 'circularity', 'laser percussion drill', 'stainless steel workpiece', 'mild steel', 'central composite design', 'process performance', 'linear multiple regression technique', 'analysis of variance', 'anova', 'complete residual analysis', 'pulse frequency', 'laser peak power', 'laser pulse width', 'assist gas pressure', 'focal plane position', 'equivalent entrance diameter', 'feret diameter', 'least square procedure', 'stepwise regression method']","['drill stainless steel', 'laser percussion drill', 'stainless steel workpiece', 'stainless steel', 'hole circularity', 'drill', 'hole taper', 'linear multiple regression technique', 'pulse frequency', 'process performance']"
261,1132,Semidefinite programming vs. LP relaxations for polynomial programming,"we consider the global minimization of a multivariate polynomial on a semi-algebraic set omega defined with polynomial inequalities. we then compare two hierarchies of relaxations, namely, lp relaxations based on products of the original constraints, in the spirit of the rlt procedure of sherali and adams (1990), and recent semidefinite programming (sdp) relaxations introduced by the author. the comparison is analyzed in light of recent results in real algebraic geometry on various representations of polynomials, positive on a compact semi-algebraic set","['lp relaxations', 'polynomial programming', 'global minimization', 'multivariate polynomial', 'semi-algebraic set', 'polynomial inequalities', 'rlt procedure', 'real algebraic geometry', 'semidefinite programming relaxations', 'reformulation linearization technique', 'constraint products']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'R']","['lp relaxation', 'polynomial programming', 'global minimization', 'multivariate polynomial', 'semi - algebraic set', 'polynomial inequality', 'rlt procedure', 'real algebraic geometry', 'semidefinite programming relaxation', 'reformulation linearization technique', 'constraint product']","['recent semidefinite programming', 'lp relaxation', 'algebraic set omega define', 'global minimization', 'polynomial inequality', 'multivariate polynomial', 'algebraic geometry', 'relaxation', 'constraint', 'polynomial']"
262,567,Hidden Markov model-based tool wear monitoring in turning,this paper presents a new modeling framework for tool wear monitoring in machining processes using hidden markov models (hmms). feature vectors are extracted from vibration signals measured during turning. a codebook is designed and used for vector quantization to convert the feature vectors into a symbol sequence for the hidden markov model. a series of experiments are conducted to evaluate the effectiveness of the approach for different lengths of training data and observation sequence. experimental results show that successful tool state detection rates as high as 97% can be achieved by using this approach,"['hidden markov models', 'tool wear monitoring', 'machining processes', 'vibration signals', 'codebook', 'vector quantization', 'tool state detection', 'feature extraction', 'turning process', 'hmm training', 'discrete wavelet transform']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'U']","['hide markov model', 'tool wear monitor', 'machining process', 'vibration signal', 'codebook', 'vector quantization', 'tool state detection', 'feature extraction', 'turn process', 'hmm training', 'discrete wavelet transform']","['machining process use hidden markov model', 'tool wear monitor', 'tool state detection', 'hide markov model', 'vibration signal measure', 'vector quantization', 'feature vector', 'new modeling framework', 'training datum', 'symbol sequence']"
263,61,Application of time-frequency principal component analysis to text-independent speaker identification,"we propose a formalism, called vector filtering of spectral trajectories, that allows the integration of a number of speech parameterization approaches (cepstral analysis, delta and delta delta parameterizations, auto-regressive vector modeling, ...) under a common formalism. we then propose a new filtering, called contextual principal components (cpc) or time-frequency principal components (tfpc). this filtering consists in extracting the principal components of the contextual covariance matrix, which is the covariance matrix of a sequence of vectors expanded by their context. we apply this new filtering in the framework of closed-set speaker identification, using a subset of the polycost database. when using speaker-dependent tfpc filters, our results show a relative improvement of approximately 20% compared to the use of the classical cepstral coefficients augmented by their delta -coefficients, which is significantly better with a 90% confidence level","['time-frequency principal component analysis', 'text-independent speaker identification', 'vector filtering', 'spectral trajectories', 'speech parameterization', 'cepstral analysis', 'delta delta parameterization', 'delta parameterization', 'auto-regressive vector modeling', 'contextual principal components', 'contextual covariance matrix', 'closed-set speaker identification', 'polycost database', 'cepstral coefficients', 'delta -coefficients', 'confidence level']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['time - frequency principal component analysis', 'text - independent speaker identification', 'vector filtering', 'spectral trajectory', 'speech parameterization', 'cepstral analysis', 'delta delta parameterization', 'delta parameterization', 'auto - regressive vector modeling', 'contextual principal component', 'contextual covariance matrix', 'close - set speaker identification', 'polycost database', 'cepstral coefficient', 'delta -coefficient', 'confidence level']","['set speaker identification', 'speech parameterization approach', 'call contextual principal component', 'call vector filtering', 'contextual covariance matrix', 'tfpc filter', 'spectral trajectory', 'delta delta parameterization', 'frequency principal component', 'regressive vector modeling']"
264,935,Experimental feedforward and feedback control of a one-dimensional SMA composite,"the control of embedded shape memory alloy (sma) actuators has recently become a topic of interest in the field of smart structures. the inherent difficulties associated with sma actuators has resulted in a variety of approaches. homogenization provides a simplified, yet mathematically rigorous, method of determining average stress and strain fields in a composite. a modified constitutive model is presented based on experimental results demonstrating the inability of most simple phenomenological models to capture the effective behavior of smas during thermal activation. a feedforward controller is presented for a sma composite based on the homogenization of a modified phenomenological model for smas in a linear matrix","['sma', 'embedded shape memory alloy', 'smart structures', 'sma actuators', 'homogenization', 'models', 'thermal activation', 'linear matrix']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['sma', 'embed shape memory alloy', 'smart structure', 'sma actuator', 'homogenization', 'model', 'thermal activation', 'linear matrix']","['embed shape memory alloy', 'sma actuator', 'actuator', 'sma composite', 'smart structure', 'sma', 'sma', 'constitutive model', 'thermal', 'strain field']"
265,970,Complex dynamics in nearly symmetric three-cell cellular neural networks,"the paper introduces a class of third-order nonsymmetric cellular neural networks (cnns), and shows through computer simulations that they undergo a cascade of period doubling bifurcations which leads to the birth of a large-size complex attractor. a major point is that these bifurcations and complex dynamics happen in a small neighborhood of a particular cnn with a symmetric interconnection matrix","['complex dynamics', 'nearly symmetric three-cell cellular neural networks', 'cnn', 'period doubling bifurcations', 'large-size complex attractor', 'symmetric interconnection matrix', 'robustness', 'complete stability', 'perturbations', 'stable limit cycles', 'differential equations', 'neuron interconnection matrix']","['P', 'P', 'P', 'P', 'P', 'P', 'U', 'U', 'U', 'U', 'U', 'M']","['complex dynamic', 'nearly symmetric three - cell cellular neural network', 'cnn', 'period double bifurcation', 'large - size complex attractor', 'symmetric interconnection matrix', 'robustness', 'complete stability', 'perturbation', 'stable limit cycle', 'differential equation', 'neuron interconnection matrix']","['order nonsymmetric cellular neural network', 'period double bifurcation', 'size complex attractor', 'complex dynamic', 'bifurcation', 'cnns', 'computer simulation', 'cnn', 'cascade', 'paper introduce']"
266,133,L/sub p/ stability and linearization,"a theorem by hadamard gives a two-part condition under which a map from one banach space to another is a homeomorphism. the theorem, while often very useful, is incomplete in the sense that it does not explicitly specify the family of maps for which the condition is met. recently, under a typically weak additional assumption on the map, it was shown that hadamard's condition is met if and only if the map is a homeomorphism with a lipschitz continuous inverse. here, an application is given concerning the relation between the l/sub p/ stability (with 1 <or= p < infinity ) of a nonlinear system and the stability of related linear systems. we also give a result that directs attention to a fundamental limitation concerning what can be proved about linearization and stability for a related familiar family of feedback systems","['l/sub p/ stability', 'banach space', ""hadamard's condition"", 'lipschitz continuous inverse', 'nonlinear system', 'linear systems', 'feedback systems']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['l / sub p/ stability', 'banach space', ""hadamard 's condition"", 'lipschitz continuous inverse', 'nonlinear system', 'linear system', 'feedback system']","['lipschitz continuous inverse', 'nonlinear system', 'linear system', 'banach space', 'stability', 'homeomorphism', 'linearization', 'map', 'map', 'hadamard']"
267,703,Direct self control with minimum torque ripple and high dynamics for a double three-level GTO inverter drive,"a highly dynamic control scheme with very low torque ripple-direct self control (dsc) with torque hysteresis control-for very high-power medium-voltage induction motor drives fed by a double three-level inverter (d3li) is presented. in this arrangement, two three-level inverters that are connected in parallel at their dc sides are feeding the open motor windings. the dsc, well known from two- and three-level inverters, is adapted to the d3li and optimized for a minimum torque ripple. an 18-corner trajectory is chosen for the stator flux of the induction machine since it is approaching the ideal circle much better than the hexagon known from dsc for two-level inverters, without any detriment to the torque ripple. the machine and inverter control are explained and the proposed torque quality and dynamics are verified by measurements on a 180-kw laboratory drive","['direct self control', 'highly dynamic control scheme', 'medium-voltage induction motor drives', 'double three-level inverter', 'open motor windings', 'stator flux', 'torque quality', 'very low torque ripple', 'torque hysteresis control', 'parallel connected inverters', 'variable-speed drives', 'multilevel converters', 'machine observer', '180 kw']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'U', 'M', 'U']","['direct self control', 'highly dynamic control scheme', 'medium - voltage induction motor drive', 'double three - level inverter', 'open motor winding', 'stator flux', 'torque quality', 'very low torque ripple', 'torque hysteresis control', 'parallel connected inverter', 'variable - speed drive', 'multilevel converter', 'machine observer', '180 kw']","['voltage induction motor drive feed', 'level inverter', 'level inverter', 'low torque ripple', 'torque hysteresis control', 'inverter control', 'motor winding', 'torque ripple', 'stator flux', 'direct self control']"
268,746,Real-time transmission of pediatric echocardiograms using a single ISDN line,"we tested the adequacy of a videoconferencing system using a single integrated systems digital network (isdn) line (128 kilobits per second) for the remote diagnosis of children with suspected congenital heart disease (chd). real-time echocardiogram interpretation was compared to subsequent videotape review in 401 studies with concordance in 383 (95.5%) studies. a new diagnosis of chd was made in 98 studies. immediate patient transfer was arranged based upon a real-time diagnosis in five studies. in 300 studies, a normal diagnosis obviated further evaluation. a single isdn line is adequate for transmission of pediatric echocardiograms and it allows for remote management of patients with chd","['single isdn line', 'videoconferencing system', 'remote diagnosis', 'children', 'suspected congenital heart disease', 'real-time echocardiogram interpretation', 'videotape review', 'immediate patient transfer', 'real-time pediatric echocardiogram transmission', 'remote patient management']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['single isdn line', 'videoconferencing system', 'remote diagnosis', 'child', 'suspect congenital heart disease', 'real - time echocardiogram interpretation', 'videotape review', 'immediate patient transfer', 'real - time pediatric echocardiogram transmission', 'remote patient management']","['pediatric echocardiogram', 'integrate system digital network', 'congenital heart disease', 'echocardiogram', 'videoconferencing system use', 'remote diagnosis', 'isdn line', 'normal diagnosis', 'isdn', 'new diagnosis']"
269,1313,A collocation formulation of multistep methods for variable step-size extensions,"multistep methods are classically constructed by specially designed difference operators on an equidistant time grid. to make them practically useful, they have to be implemented by varying the step-size according to some error-control algorithm. it is well known how to extend adams and bdf formulas to a variable step-size formulation. in this paper we present a collocation approach to construct variable step-size formulas. we make use of piecewise polynomials to show that every k-step method of order k+1 has a variable step-size polynomial collocation formulation","['collocation formulation', 'multistep methods', 'variable step-size extensions', 'difference operators', 'equidistant time grid', 'error-control algorithm', 'piecewise polynomials', 'k-step method', 'variable step-size polynomial collocation formulation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['collocation formulation', 'multistep method', 'variable step - size extension', 'difference operator', 'equidistant time grid', 'error - control algorithm', 'piecewise polynomial', 'k - step method', 'variable step - size polynomial collocation formulation']","['multistep method', 'piecewise polynomial', 'step method', 'construct variable step', 'bdf formula', 'variable step', 'equidistant time grid', 'design difference operator', 'size formula', 'step']"
270,1356,Five-axis NC milling of ruled surfaces: optimal geometry of a conical tool,"the side milling of ruled surfaces using a conical milling cutter was studied. this is a field that has largely been ignored by research scientists, but it is much used in industry, especially to machine turbine blades. we first suggest an improved positioning with respect to the directrices of the ruled surface. as compared with the methods already developed for the cylindrical cutter, this positioning enables the error between the cutter and the work-piece to be reduced. an algorithm is then introduced to calculate error so one can determine the cutter dimensions (cone radius and angle) in order to respect the tolerance interval imposed by the design office. this study provides an opportunity to determine cutters with greater dimensions, thus alleviating bending problems during milling","['five-axis nc milling', 'ruled surfaces', 'optimal geometry', 'conical', 'side milling', 'conical milling cutter', 'positioning', 'cutter dimensions', 'tolerance interval']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['five - axis nc milling', 'rule surface', 'optimal geometry', 'conical', 'side milling', 'conical milling cutter', 'position', 'cutter dimension', 'tolerance interval']","['conical milling cutter', 'machine turbine blade', 'cylindrical cutter', 'cutter dimension', 'side milling', 'cone radius', 'determine cutter', 'cutter', 'rule surface use', 'bend problem']"
271,828,Verizon leapfrogs Sprint PCS with Q2 subscriber numbers,the wireless carrier industry's second-quarter results showed a surprising shift in market share as sprint pcs fell from grace after a nearly four-year lead in subscriber additions and verizon wireless added considerably more customers than analysts expected,"['sprint pcs', 'wireless carrier industry', 'verizon wireless']","['P', 'P', 'P']","['sprint pc', 'wireless carrier industry', 'verizon wireless']","['wireless carrier industry', 'sprint pc fall', 'verizon wireless add', 'market share', 'more customer', 'surprising shift', 'quarter result show', 'year lead', 'subscriber addition', 'grace']"
272,890,Multiple criteria decision making without optimization,"we present a development intended to make interactive decision making schemes accessible for a wider spectrum of decision makers. to this aim we propose to eliminate the need to solve optimization problems at successive iterations of interactive decision processes. we show that the need for optimization can be eliminated by the ability of establishing sufficiently tight bounds on criteria values for efficient decisions prior to explicit identification of such decisions. we present a technique, fully operational and numerically simple, for establishing such bounds. bounds are dynamic, i.e., they become stronger with the growing number of decisions explicitly identified. they are also parametric with respect to weighting coefficients. we also point out how this technique can enhance the existing interactive decision making methods","['multiple criteria decision making', 'interactive decision making schemes', 'decision makers', 'efficient decisions', 'criteria values bounds']","['P', 'P', 'P', 'P', 'R']","['multiple criterion decision make', 'interactive decision make scheme', 'decision maker', 'efficient decision', 'criterion value bound']","['make interactive decision make scheme accessible', 'interactive decision process', 'efficient decision', 'such decision', 'solve optimization problem', 'decision maker', 'criterion value', 'establish such bound', 'decision', 'explicit identification']"
273,1012,Evolving receptive-field controllers for mobile robots,"the use of evolutionary methods to generate controllers for real-world autonomous agents has attracted attention. most of the pertinent research has employed genetic algorithms or variations thereof. research has applied an alternative evolutionary method, evolution strategies, to the generation of simple braitenberg vehicles. this application accelerates the development of such controllers by more than an order of magnitude (a few hours compared to more than two days). motivated by this useful speedup, the paper investigates the evolution of more complex architectures, receptive-field controllers, that can employ nonlinear interactions and, therefore, can yield more complex behavior. it is interesting to note that the evolution strategy yields the same efficacy in terms of function evaluations, even though the second class of controllers requires up to 10 times more parameters than the simple braitenberg architecture. in addition to the speedup, there is an important theoretical reason for preferring an evolution strategy over a genetic algorithm for this problem, namely the presence of epistasis","['receptive-field controllers', 'mobile robots', 'evolutionary methods', 'real-world autonomous agents', 'evolution strategies', 'simple braitenberg vehicles', 'nonlinear interactions', 'complex behavior', 'radial basis functions', 'scalability']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U']","['receptive - field controller', 'mobile robot', 'evolutionary method', 'real - world autonomous agent', 'evolution strategy', 'simple braitenberg vehicle', 'nonlinear interaction', 'complex behavior', 'radial basis function', 'scalability']","['evolution strategy yield', 'generate controller', 'evolution strategy', 'world autonomous agent', 'evolution strategy', 'genetic algorithm', 'field controller', 'evolutionary method', 'alternative evolutionary method', 'genetic algorithm']"
274,1057,Acceptance of a price discount: the role of the semantic relatedness between purchases and the comparative price format,"two studies are reported where people are asked to accept or not a price reduction on a target product. in the high (low) relative saving version, the regular price of the target product is low (high). in both versions, the absolute value of the price reduction is the same as well as the total of regular prices of planned purchases. as first reported by tversky and kahneman (1981), findings show that the majority of people accept the price discount in the high-relative saving version whereas the minority do it in the low one. in study 1, findings show that the previous preference reversal disappears when planned purchases are strongly related. also, a previously unreported preference reversal is found. the majority of people accept the price discount when the products are weakly related whereas the minority accept when the products are strongly related. in study 2, findings show that the classic preference reversal disappears as a function of the comparative price format. also, another previously unreported preference reversal is found. when the offered price reduction relates to a low-priced product, people are more inclined to accept it with a control than a minimal comparative price format. findings reported in studies 1 and 2 are interpreted in terms of mental accounting shifts","['comparative price format', 'planned purchases', 'preference reversal', 'low-priced product', 'mental accounting shifts', 'price discount acceptance', 'semantic relatedness hypothesis', 'high relative saving version', 'low relative saving version']","['P', 'P', 'P', 'P', 'P', 'R', 'M', 'R', 'R']","['comparative price format', 'plan purchase', 'preference reversal', 'low - price product', 'mental accounting shift', 'price discount acceptance', 'semantic relatedness hypothesis', 'high relative save version', 'low relative save version']","['previous preference reversal', 'classic preference reversal', 'unreporte preference reversal', 'price discount', 'minimal comparative price format', 'offer price reduction relate', 'price product', 'relative save version', 'comparative price format', 'regular price']"
275,911,Scheduling schemes for an integrated flight and propulsion control system,"we describe two schemes for scheduling an integrated flight and propulsion control system for an experimental vertical/short take-off and landing (v/stol) aircraft concept in the acceleration from hover (0-120 kn) flight phase. multivariable integrated flight and propulsion controllers are designed at several points over the v/stol envelope and implemented as exact plant observers with state feedback. in the first scheduling scheme, the values of the state feedback and observer gain matrices are interpolated between the fixed-point designs as a function of aircraft speed. in the second approach, the control signals produced by the different fixed-point controllers are blended, allowing a significant reduction in the order of the scheduled controllers. both scheduling schemes are shown in nonlinear simulation to provide excellent handling qualities as the aircraft accelerates from the hover","['scheduling', 'propulsion control', 'observers', 'state feedback', 'fixed-point controllers', 'vertical short take-off landing aircraft', 'vstol aircraft', 'flight control', 'multivariable control systems']","['P', 'P', 'P', 'P', 'P', 'R', 'M', 'R', 'R']","['scheduling', 'propulsion control', 'observer', 'state feedback', 'fix - point controller', 'vertical short take - off landing aircraft', 'vstol aircraft', 'flight control', 'multivariable control system']","['aircraft accelerate', 'propulsion control system', 'propulsion controller', 'schedule controller', 'aircraft speed', 'multivariable integrate flight', 'integrate flight', 'aircraft', 'point controller', 'flight']"
276,583,Neural networks in optimal filtration,the combined use and mutual influence of neural networks and optimal filtering is considered; the neural-network and filtering approaches are compared by solving two simple optimal-filtering problems: linear filtering and the filtering of a binary telegraph signal corresponding to observations in discrete white noise,"['neural networks', 'optimal filtering', 'linear filtering', 'binary telegraph signal', 'observations', 'discrete white noise']","['P', 'P', 'P', 'P', 'P', 'P']","['neural network', 'optimal filtering', 'linear filter', 'binary telegraph signal', 'observation', 'discrete white noise']","['binary telegraph signal corresponding', 'optimal filtering', 'neural network', 'linear filter', 'filter approach', 'filter problem', 'filter', 'simple optimal', 'neural', 'network']"
277,954,Caring for your new lawyers,"in any given year, a striking number of lawyers are in a state of flux, from newly minted law school graduates looking for their first job, to senior litigators migrating to new challenges with new firms. the one certainty is that lawyers new to any firm need care and feeding in myriad ways. all of them need to know and understand three things: (1) the firm's culture; (2) the resources available to help them develop their practices; and (3) where to get help and guidance for research and practice purposes. obtaining a thorough understanding of a new firm's workings may be the greatest research project lawyers face. how can a firm help its new lawyers learn what they need to know? to offer an example, here are programs in place at my firm","['new lawyers', ""firm's culture"", 'resources']","['P', 'P', 'P']","['new lawyer', ""firm 's culture"", 'resource']","['new lawyer learn', 'research project lawyer face', 'lawyer new', 'law school graduate look', 'lawyer', 'new firm', 'senior litigator migrate', 'practice purpose', 'firm need care', 'new firm']"
278,117,Multiresolution Markov models for signal and image processing,"reviews a significant component of the rich field of statistical multiresolution (mr) modeling and processing. these mr methods have found application and permeated the literature of a widely scattered set of disciplines, and one of our principal objectives is to present a single, coherent picture of this framework. a second goal is to describe how this topic fits into the even larger field of mr methods and concepts-in particular, making ties to topics such as wavelets and multigrid methods. a third goal is to provide several alternate viewpoints for this body of work, as the methods and concepts we describe intersect with a number of other fields. the principle focus of our presentation is the class of mr markov processes defined on pyramidally organized trees. the attractiveness of these models stems from both the very efficient algorithms they admit and their expressive power and broad applicability. we show how a variety of methods and models relate to this framework including models for self-similar and 1/f processes. we also illustrate how these methods have been used in practice","['multiresolution markov models', 'wavelets', 'multigrid methods', 'pyramidally organized trees', '1/f processes', 'statistical multiresolution modeling', 'self-similar processes']","['P', 'P', 'P', 'P', 'P', 'R', 'R']","['multiresolution markov model', 'wavelet', 'multigrid method', 'pyramidally organize tree', '1 / f process', 'statistical multiresolution model', 'self - similar process']","['mr markov process define', 'statistical multiresolution', 'organize tree', 'multigrid method', 'efficient algorithm', 'wavelet', 'model stem', 'framework include model', 'process', 'model relate']"
279,1193,Operator splitting and approximate factorization for taxis-diffusion-reaction models,"in this paper we consider the numerical solution of 2d systems of certain types of taxis-diffusion-reaction equations from mathematical biology. by spatial discretization these pde systems are approximated by systems of positive, nonlinear odes (method of lines). the aim of this paper is to examine the numerical integration of these ode systems for low to moderate accuracy by means of splitting techniques. an important consideration is maintenance of positivity. we apply operator splitting and approximate matrix factorization using low order explicit runge-kutta methods and linearly implicit runge-kutta-rosenbrock methods. as a reference method the general purpose solver vodpk is applied","['operator splitting', 'approximate factorization', 'taxis-diffusion-reaction models', 'numerical solution', 'mathematical biology', 'spatial discretization', 'pde systems', 'nonlinear odes', 'numerical integration', 'approximate matrix factorization', 'runge-kutta methods', 'linearly implicit runge-kutta-rosenbrock methods']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['operator splitting', 'approximate factorization', 'taxis - diffusion - reaction model', 'numerical solution', 'mathematical biology', 'spatial discretization', 'pde system', 'nonlinear ode', 'numerical integration', 'approximate matrix factorization', 'runge - kutta method', 'linearly implicit runge - kutta - rosenbrock method']","['nonlinear ode', 'spatial discretization', 'solver vodpk', 'kutta method', 'pde system', 'numerical integration', 'approximate matrix factorization', 'numerical solution', 'rosenbrock method', 'ode system']"
280,682,Information and information technology,"this paper reveals the concepts of information and information technology. it also describes the close relationship between information and information technology. it explains a basic mechanism of different devices of information technology and connotes how they are useful to store, process and retrieve the information. in addition of this, the paper shows the present status of information technology and indian universities","['information', 'information technology', 'indian universities', 'information storage', 'information processing', 'information retrieval']","['P', 'P', 'P', 'M', 'R', 'R']","['information', 'information technology', 'indian university', 'information storage', 'information processing', 'information retrieval']","['information technology', 'information', 'basic mechanism', 'device', 'process', 'concept', 'present status', 'paper reveal', 'retrieve', 'useful']"
281,1292,The heat is on [building automation systems],"integrating building automation systems (bass) can result in systems that have the ability to sense changes in the air temperature through a building's heating, ventilation, and air conditioning (hvac) systems. taking advantages of the internet, using remote monitoring, and building interoperability through open protocol systems are some of the issues discussed throughout the bas/hvac community. by putting information over the internet, facility managers get real-time data on energy usage and performance issues","['heating', 'building automation systems', 'ventilation', 'air conditioning', 'hvac', 'internet', 'remote monitoring', 'interoperability', 'real-time data']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['heat', 'build automation system', 'ventilation', 'air conditioning', 'hvac', 'internet', 'remote monitoring', 'interoperability', 'real - time datum']","['integrate building automation system', 'use remote monitoring', 'build interoperability', 'open protocol system', 'hvac community', 'hvac', 'facility manager get real', 'air temperature', 'energy usage', 'heat']"
282,1036,Nonlinear control of a shape memory alloy actuated manipulator,"this paper presents a nonlinear, robust control algorithm for accurate positioning of a single degree of freedom rotary manipulator actuated by shape memory alloy (sma). a model for an sma actuated manipulator is presented. the model includes nonlinear dynamics of the manipulator, a constitutive model of shape memory alloy, and electrical and heat transfer behavior of sma wire. this model is used for open and closed loop motion simulations of the manipulator. experiments are presented that show results similar to both closed and open loop simulation results. due to modeling uncertainty and nonlinear behavior of the system, classic control methods such as proportional-integral-derivative control are not able to present fast and accurate performance. hence a nonlinear, robust control algorithm is presented based on variable structure control. this algorithm is a control gain switching technique based on the weighted average of position and velocity feedbacks. this method has been designed through simulation and tested experimentally. results show fast, accurate, and robust performance of the control system. computer simulation and experimental results for different stabilization and tracking situations are also presented","['nonlinear control', 'shape memory alloy', 'manipulator', 'positioning', 'nonlinear dynamics', 'closed loop', 'open loop', 'variable structure control', 'control gain switching', 'feedback', 'stabilization', 'tracking']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['nonlinear control', 'shape memory alloy', 'manipulator', 'position', 'nonlinear dynamic', 'close loop', 'open loop', 'variable structure control', 'control gain switch', 'feedback', 'stabilization', 'track']","['freedom rotary manipulator actuate', 'sma actuate manipulator', 'nonlinear dynamic', 'shape memory alloy', 'robust control algorithm', 'manipulator', 'loop motion simulation', 'derivative control', 'loop simulation', 'different stabilization']"
283,1073,Quantum retrodiction in open systems,"quantum retrodiction involves finding the probabilities for various preparation events given a measurement event. this theory has been studied for some time but mainly as an interesting concept associated with time asymmetry in quantum mechanics. recent interest in quantum communications and cryptography, however, has provided retrodiction with a potential practical application. for this purpose quantum retrodiction in open systems should be more relevant than in closed systems isolated from the environment. in this paper we study retrodiction in open systems and develop a general master equation for the backward time evolution of the measured state, which can be used for calculating preparation probabilities. we solve the master equation, by way of example, for the driven two-level atom coupled to the electromagnetic field","['quantum retrodiction', 'open systems', 'probabilities', 'preparation events', 'measurement event', 'time asymmetry', 'quantum mechanics', 'quantum communications', 'cryptography', 'backward time evolution', 'preparation probabilities', 'retrodictive master equation', 'driven two level atom-electromagnetic field coupling']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['quantum retrodiction', 'open system', 'probability', 'preparation event', 'measurement event', 'time asymmetry', 'quantum mechanic', 'quantum communication', 'cryptography', 'backward time evolution', 'preparation probability', 'retrodictive master equation', 'drive two level atom - electromagnetic field coupling']","['quantum retrodiction involve find', 'quantum retrodiction', 'backward time evolution', 'quantum communication', 'quantum mechanic', 'level atom couple', 'study retrodiction', 'provide retrodiction', 'cryptography', 'measure state']"
284,849,Ten years of strategies to increase participation of women in computing programs. The Central Queensland University experience: 1999-2001,"in the late eighties, the participation rate of women in information technology courses in most australian universities was around 25%. this low level of women's participation in computing courses occurs not only in australia but also overseas. more studies indicate that the participation rates have not improved and in fact may be even further in decline. participation rates in the workforce also appear to be in decline. concerned at the imbalance within australia, the federal government directed all australian universities to increase the number of women in courses leading to a professional computing qualification (i.e., information technology courses) to 40% of students by 1995. this paper details one australian university's approach, over a 10 year period (1991-2001), to redress this imbalance. we provide examples of intervention strategies developed and the outcomes for these strategies. we present the outcomes against a background frame of the australian higher education scene of that decade which was influenced by funding levels to universities in general and to equity programs in particular. we present data related to the participation of women in computing programs along with snapshots of the overall changing student demographics over this period","['women', 'computing programs', 'central queensland university', 'australian higher education', 'demographics']","['P', 'P', 'P', 'P', 'P']","['woman', 'compute program', 'central queensland university', 'australian high education', 'demographic']","['most australian university', 'overall change student demographic', 'australian high education scene', 'information technology course', 'compute course occur', 'professional computing qualification', 'australian university', 'australian university', 'compute program', 'more study indicate']"
285,727,Life after bankruptcy [telecom carriers],"how comeback telecom carriers are changing industry economics, and why others may have no choice but to follow their lead","['bankruptcy', 'telecom carriers', 'industry economics', 'restructured companies', 'debt levels']","['P', 'P', 'P', 'U', 'U']","['bankruptcy', 'telecom carrier', 'industry economic', 'restructure company', 'debt level']","['comeback telecom carrier', 'change industry economic', 'choice', 'follow', 'other', 'have']"
286,762,Quantum computing with spin qubits in semiconductor structures,we survey recent work on designing and evaluating quantum computing implementations based on nuclear or bound-electron spins in semiconductor heterostructures at low temperatures and in high magnetic fields. general overview is followed by a summary of results of our theoretical calculations of decoherence time scales and spin-spin interactions. the latter were carried out for systems for which the two-dimensional electron gas provides the dominant carrier for spin dynamics via exchange of spin-excitons in the integer quantum hall regime,"['quantum computing', 'spin qubits', 'semiconductor structures', 'semiconductor heterostructures', 'low temperatures', 'high magnetic fields', 'spin-spin interactions', 'dominant carrier', 'spin dynamics', 'integer quantum hall regime', '2d electron gas', '2deg', 'spin-excitons exchange', 'integer qhe']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U', 'R', 'M']","['quantum computing', 'spin qubit', 'semiconductor structure', 'semiconductor heterostructure', 'low temperature', 'high magnetic field', 'spin - spin interaction', 'dominant carrier', 'spin dynamic', 'integer quantum hall regime', '2d electron gas', '2deg', 'spin - exciton exchange', 'integer qhe']","['evaluate quantum computing implementation', 'electron spin', 'semiconductor heterostructure', 'dimensional electron gas', 'spin interaction', 'spin dynamic', 'decoherence time scale', 'spin', 'high magnetic field', 'low temperature']"
287,1337,Some properties of Hadamard matrices coming from dihedral groups,h. kimura (1996) introduced a method to construct hadamard matrices of degree 8n + 4 from the dihedral group of order 2n. in this paper we study some properties of this construction,"['hadamard matrices', 'dihedral groups']","['P', 'P']","['hadamard matrix', 'dihedral group']","['construct hadamard matrix', 'dihedral group', 'degree 8n', 'introduce', 'method', 'order', 'property', 'kimura', 'paper']"
288,1372,Knowledge acquisition and ontology modelling for construction of a control and monitoring expert system,"this paper presents the processes of knowledge acquisition and ontology development for structuring the knowledge base of an expert system. ontological engineering is a process that facilitates construction of the knowledge base of an intelligent system. ontology is the study of the organization and classification of knowledge. ontological engineering in artificial intelligence has the practical goal of constructing frameworks for knowledge that allow computational systems to tackle knowledge-intensive problems and it supports knowledge sharing and reuse. to illustrate the process of conceptual modelling using the inferential modelling technique as a basis for ontology construction, the tool and processes are applied to build an expert system in the domain of monitoring of a petroleum-production facility","['knowledge acquisition', 'ontology modelling', 'control and monitoring expert system', 'knowledge base', 'ontological engineering', 'intelligent system', 'artificial intelligence', 'inferential modelling technique', 'petroleum-production facility', 'knowledge reuse']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['knowledge acquisition', 'ontology modelling', 'control and monitor expert system', 'knowledge base', 'ontological engineering', 'intelligent system', 'artificial intelligence', 'inferential modelling technique', 'petroleum - production facility', 'knowledge reuse']","['ontological engineering', 'ontology construction', 'ontology development', 'conceptual modelling use', 'ontology', 'expert system', 'knowledge acquisition', 'knowledge base', 'support knowledge sharing', 'inferential modelling technique']"
289,1427,Training for trouble,"in a security context, one example of digitized video's integration into a networked knowledge base is found in the accident response group (arg) at sandia national labs. a ""national security laboratory"" headquartered in albuquerque, new mexico, sandia is operated by lockheed martin and primarily funded by the u.s. department of energy. the organization handles research, design and development of all non-nuclear components used in u.s. nuclear weapons programs, and is involved as well in programs related to energy, critical infrastructure, non-proliferation, materials control, and emerging threats. arg's searchable video database has been implemented using the screening room package of applications from convera in vienna, virginia. formed in december 2000 from excalibur technologies and intel's interactive media services division, convera targets corporate and institutional markets with products for securely accessing, indexing, and searching rich media content-text, images, audio, and video-across interconnected computer networks. among its public-sector clients are the fbi, nasa, the nuclear regulatory commission, u.s. military services, the departments of justice and state, and various domestic and foreign intelligence agencies","['networked knowledge base', 'accident response group', 'sandia national labs', 'national security laboratory', 'u.s. nuclear weapons programs', 'searchable video database', 'screening room package', 'public-sector clients', 'digitized video integration', 'rich media content']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['network knowledge base', 'accident response group', 'sandia national labs', 'national security laboratory', 'u.s . nuclear weapon program', 'searchable video database', 'screen room package', 'public - sector client', 'digitize video integration', 'rich medium content']","['sandia national labs', 'national security laboratory', 'searchable video database', 'interactive medium service', 'convera target corporate', 'nuclear weapon program', 'screen room package', 'interconnect computer network', 'network knowledge base', 'nuclear regulatory commission']"
290,874,"The curious ways of professional cultures and the ""two-body opportunity""","when two professionals are a couple, we sometimes refer to them as having a ""two-body problem."" however, when each partner of a couple exists in the same cultures, they also have an opportunity for deeply shared understanding and empathy, simply because each understands at a deep level the culture in which the other works. i explore this notion. a couple has what we call the ""two-body problem"" when both are professionals who are qualified for a kind of position that is relatively rare and who are very selective about the positions that they accept. for example, there are relatively scant numbers of jobs as a computer science professor-at any level. an individual considering an academic job may only be interested in research universities, or in teaching universities, restricting the choice of open positions substantially. the classic two-body ""problem"" arises when one partner wants to accept a new position that requires geographical relocation. then, the other partner also needs to find a new position. moreover, it can be very difficult to find a suitable position when they are naturally scarce","['professional cultures', 'two-body opportunity', 'computer science', 'academics']","['P', 'P', 'P', 'P']","['professional culture', 'two - body opportunity', 'computer science', 'academic']","['require geographical relocation', 'computer science professor', 'research university', 'teach university', 'academic job', 'other partner', 'couple exist', 'body problem', 'partner want', 'open position']"
291,831,Software vendors' failure fuels consolidation theories [telecom interconnection and billing],"as independent software vendors like ap engines fall by the wayside as independent entities, attrition could accelerate consolidation in the oss space","['consolidation', 'telecom interconnection', 'ap engines', 'telecom billing', 'operations supports systems', 'quintessent']","['P', 'P', 'P', 'R', 'U', 'U']","['consolidation', 'telecom interconnection', 'ap engine', 'telecom billing', 'operation support system', 'quintessent']","['independent software vendor', 'accelerate consolidation', 'ap engine fall', 'independent entity', 'attrition', 'wayside']"
292,889,Synthesis of the control systems via reflection onto auxiliary surfaces,"an approach to robust control systems synthesis, both linear and nonlinear, and nonstationary is offered. the control is carried out, providing the given phase constraints varied in acceptable limits, in view of constraints on its value and incompleteness of the information about functioning disturbances. the approach is based on the introduction of auxiliary integral surfaces, on which the initial moving is projected. as a result the reduced equivalent moving is formed, being described by the scalar equation which in many important cases can be integrated directly. on the basis of the equation obtained solving a synthesis task is carried out and can be reduced to algebraic or integral inequalities. the final relations defined for linear equivalent moving are presented","['auxiliary surfaces', 'robust control systems', 'control systems synthesis', 'integral inequalities', 'linear equivalent moving', 'linear systems', 'nonlinear systems', 'algebraic inequalities']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['auxiliary surface', 'robust control system', 'control system synthesis', 'integral inequality', 'linear equivalent move', 'linear system', 'nonlinear system', 'algebraic inequality']","['robust control system synthesis', 'phase constraint', 'function disturbance', 'control', 'synthesis task', 'auxiliary integral surface', 'linear equivalent move', 'constraint', 'nonlinear', 'relation define']"
293,85,Strategic implementation of IT/IS projects in construction: a case study,"the need for improved implementation of information technology (it) and information systems (is) has been emphasised in both empirical and prescriptive research studies. this problem is magnified in the construction industry, which has been slow to embrace and utilise new technologies with negative consequences on productivity and innovation. this paper presents a strategic implementation framework for it/is projects in construction. the framework builds upon recent published works and encompasses well-documented predictors for effective it/is implementation. a case study with a large multi-national construction organisation is used to demonstrate the strategic implementation of a project management information system (pmis) used for the construction of a mobile phone telecommunications network in the south east of queensland, australia","['strategic implementation', 'information technology', 'information systems', 'construction industry', 'strategic implementation framework', 'predictors', 'large multi-national construction organisation', 'project management information system', 'mobile phone telecommunications network', 'swot analysis', 'analytical hierarchy process']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'U']","['strategic implementation', 'information technology', 'information system', 'construction industry', 'strategic implementation framework', 'predictor', 'large multi - national construction organisation', 'project management information system', 'mobile phone telecommunication network', 'swot analysis', 'analytical hierarchy process']","['mobile phone telecommunication network', 'project management information system', 'national construction organisation', 'construction industry', 'strategic implementation framework', 'framework build', 'information technology', 'strategic implementation', 'construction', 'prescriptive research study']"
294,1153,Direct aperture optimization: A turnkey solution for step-and-shoot IMRT,"imrt treatment plans for step-and-shoot delivery have traditionally been produced through the optimization of intensity distributions (or maps) for each beam angle. the optimization step is followed by the application of a leaf-sequencing algorithm that translates each intensity map into a set of deliverable aperture shapes. in this article, we introduce an automated planning system in which we bypass the traditional intensity optimization, and instead directly optimize the shapes and the weights of the apertures. we call this approach ""direct aperture optimization."" this technique allows the user to specify the maximum number of apertures per beam direction, and hence provides significant control over the complexity of the treatment delivery. this is possible because the machine dependent delivery constraints imposed by the mlc are enforced within the aperture optimization algorithm rather than in a separate leaf-sequencing step. the leaf settings and the aperture intensities are optimized simultaneously using a simulated annealing algorithm. we have tested direct aperture optimization on a variety of patient cases using the egs4/beam monte carlo package for our dose calculation engine. the results demonstrate that direct aperture optimization can produce highly conformal step-and-shoot treatment plans using only three to five apertures per beam direction. as compared with traditional optimization strategies, our studies demonstrate that direct aperture optimization can result in a significant reduction in both the number of beam segments and the number of monitor units. direct aperture optimization therefore produces highly efficient treatment deliveries that maintain the full dosimetric benefits of imrt","['direct aperture optimization', 'turnkey solution', 'step-and-shoot imrt', 'imrt treatment plans', 'intensity distributions', 'maps', 'beam angle', 'optimization step', 'leaf-sequencing algorithm', 'intensity map', 'deliverable aperture shapes', 'aperture shapes', 'automated planning system', 'machine dependent delivery constraints', 'mlc', 'aperture optimization algorithm', 'leaf settings', 'aperture intensities', 'simulated annealing algorithm', 'patient cases', 'egs4/beam monte carlo package', 'dose calculation engine', 'highly conformal step-and-shoot treatment plans', 'beam segments', 'monitor units', 'highly efficient treatment deliveries', 'full dosimetric benefits', 'aperture weights', 'treatment delivery complexity']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['direct aperture optimization', 'turnkey solution', 'step - and - shoot imrt', 'imrt treatment plan', 'intensity distribution', 'map', 'beam angle', 'optimization step', 'leaf - sequence algorithm', 'intensity map', 'deliverable aperture shape', 'aperture shape', 'automate planning system', 'machine dependent delivery constraint', 'mlc', 'aperture optimization algorithm', 'leaf setting', 'aperture intensity', 'simulate annealing algorithm', 'patient case', 'egs4 / beam monte carlo package', 'dose calculation engine', 'highly conformal step - and - shoot treatment plan', 'beam segment', 'monitor unit', 'highly efficient treatment delivery', 'full dosimetric benefit', 'aperture weight', 'treatment delivery complexity']","['aperture optimization algorithm', 'direct aperture optimization', 'deliverable aperture shape', 'intensity optimization', 'simulate annealing algorithm', 'sequence algorithm', 'aperture intensity', 'imrt treatment plan', 'aperture', 'beam segment']"
295,1116,An interlingua-based Chinese-English MT system,"chinese-english machine translation is a significant and challenging problem in information processing. the paper presents an interlingua-based chinese-english natural language translation system (icent). it introduces the realization mechanism of chinese language analysis, which contains syntactic parsing and semantic analyzing and gives the design of interlingua in details. experimental results and system evaluation are given. the result is satisfying","['information processing', 'natural language translation system', 'syntactic parsing', 'semantic analyzing', 'interlingua-based chinese-english machine translation system']","['P', 'P', 'P', 'P', 'R']","['information processing', 'natural language translation system', 'syntactic parsing', 'semantic analyzing', 'interlingua - base chinese - english machine translation system']","['english natural language translation system', 'contain syntactic parsing', 'chinese language analysis', 'english machine translation', 'semantic analyzing', 'base chinese', 'information processing', 'chinese', 'icent', 'system evaluation']"
296,543,The development of virtual reality therapy (VRT) system for the treatment of acrophobia and therapeutic case,"virtual reality therapy (vrt), based on this sophisticated technology, has been used in the treatment of subjects diagnosed with acrophobia, a disorder that is characterized by marked anxiety upon exposure to heights and avoidance of heights. conventional vr systems for the treatment of acrophobia have limitations, over-costly devices or somewhat unrealistic graphic scenes. the goal of this study was to develop an inexpensive and more realistic virtual environment (ve) in which to perform exposure therapy for acrophobia. it is based on a personal computer, and a virtual scene of a bunge-jump tower in the middle of a large city. the virtual scenario includes an open lift surrounded by props beside a tower, which allows the patient to feel a sense of heights. the effectiveness of the ve was evaluated through the clinical treatment of a subject who was suffering from the fear of heights. as a result, it was proved that this vr environment was effective and realistic at overcoming acrophobia according not only to the comparison results of a variety of questionnaires before and after treatment but also to the subject's comments that the ve seemed to evoke more fearful feelings than the real situation","['therapeutic case', 'realistic virtual environment', 'exposure therapy', 'personal computer', 'virtual scene', 'clinical treatment', 'virtual reality therapy system', 'acrophobia treatment', 'patient anxiety', 'patient treatment', 'psychotherapy', 'heights phobia']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'U', 'M']","['therapeutic case', 'realistic virtual environment', 'exposure therapy', 'personal computer', 'virtual scene', 'clinical treatment', 'virtual reality therapy system', 'acrophobia treatment', 'patient anxiety', 'patient treatment', 'psychotherapy', 'height phobia']","['virtual reality therapy', 'realistic virtual environment', 'vr environment', 'perform exposure therapy', 'overcome acrophobia', 'conventional vr system', 'acrophobia have limitation', 'clinical treatment', 'fearful feeling', 'jump tower']"
297,994,Design and implementation of a flexible manufacturing control system using neural network,"design and implementation of a sequential controller based on the concept of artificial neural networks for a flexible manufacturing system are presented. the recurrent neural network (rnn) type is used for such a purpose. contrary to the programmable controller, an rnn-based sequential controller is based on a definite mathematical model rather than depending on the experience and trial and error techniques. the proposed controller is also more flexible because it is not limited by the restrictions of the finite state automata theory. adequate guidelines of how to construct an rnn-based sequential controller are presented. these guidelines are applied to different case studies. the proposed controller is tested by simulations and real-time experiments. these tests prove the successfulness of the proposed controller performances. theoretical as well as experimental results are presented and discussed indicating that the proposed design procedure using elman's rnn can be effective in designing a sequential controller for event-based type manufacturing systems. in addition, the simulation results assure the effectiveness of the proposed controller to overcome the effect of noisy inputs","['sequential control', 'flexible manufacturing systems', 'recurrent neural network', 'programmable controller', 'finite state automata', 'noisy inputs', 'elman network', 'ladder language', 'pneumatic system', 'learning', 'fms']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'M', 'U', 'U']","['sequential control', 'flexible manufacturing system', 'recurrent neural network', 'programmable controller', 'finite state automata', 'noisy input', 'elman network', 'ladder language', 'pneumatic system', 'learn', 'fms']","['sequential controller base', 'base sequential controller', 'recurrent neural network', 'programmable controller', 'sequential controller', 'artificial neural network', 'base type manufacturing system', 'finite state automata theory', 'propose design procedure use elman', 'flexible manufacturing system']"
298,969,Controlled projective synchronization in nonpartially-linear chaotic systems,"projective synchronization (ps), in which the state vectors synchronize up to a scaling factor, is usually observable only in partially linear systems. we show that ps could, by means of control, be extended to general classes of chaotic systems with nonpartial linearity. performance of ps may also be manipulated by controlling the scaling factor to any desired value. in numerical experiments, we illustrate the applications to a rossler system and a chua's circuit. the feasibility of the control for high dimensional systems is demonstrated in a hyperchaotic system","['control', 'projective synchronization', 'nonpartially-linear chaotic systems', 'scaling factor', 'rossler system', ""chua's circuit"", 'hyperchaotic system']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['control', 'projective synchronization', 'nonpartially - linear chaotic system', 'scale factor', 'rossler system', ""chua 's circuit"", 'hyperchaotic system']","['projective synchronization', 'chaotic system', 'state vector synchronize', 'linear system', 'rossler system', 'high dimensional system', 'nonpartial linearity', 'scale factor', 'control', 'control']"
299,1252,An agent-oriented and service-oriented environment for deploying dynamic distributed systems,"this paper presents jase, a java-based agent-oriented and service-oriented environment for deploying dynamic distributed systems. jase utilizes two important concepts in the field of distributed computing: the concept of services and remote programming with mobile agents. in jase, mobile agents are used to support applications, and service interface agents are used to wrap services. service inter-face agents can dynamically register their services in service server. mobile agent locates a specific service interface agent by submitting requests to the service server with descriptions of required services. jase uses xml to describe both service descriptions and the mobile agent's queries. jase supports two kinds of communication facility: tuple space and asynchronous messages. in this paper, the design and implementation of jase are described. an application shows the suitability and the effectiveness of the jase and performance evaluation is also made. finally, related work and some conclusions are given","['service-oriented environment', 'dynamic distributed systems', 'jase', 'java-based agent-oriented and service-oriented environment', 'remote programming', 'mobile agents', 'performance evaluation', 'agent-oriented environment']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['service - orient environment', 'dynamic distribute system', 'jase', 'java - base agent - orient and service - orient environment', 'remote programming', 'mobile agent', 'performance evaluation', 'agent - orient environment']","['deploy dynamic distribute system', 'specific service interface agent', 'service interface agent', 'mobile agent locate', 'jase use xml', 'service server', 'mobile agent', 'mobile agent', 'distribute computing', 'asynchronous message']"
300,1217,A knowledge-based approach for managing urban infrastructures,"this paper presents a knowledge e-based approach dedicated to the efficient management, regulation, interactive and dynamic monitoring of urban infrastructures. this approach identifies the data and related treatments common to several municipal activities and defines the requirements and functionalities of the computer tools developed to improve the delivery and coordination of municipal services to the population. the resulting cooperative system called sigiu is composed of a set of integrated operating systems (sydex) and the global planning and coordination system (sygec). the objective is to integrate the set of sydex and the sygec into a single coherent system for all the sigiu's users according to their tasks, their roles, and their responsibilities within the municipal administration. sigiu is provided by different measurement and monitoring instruments installed on some system's elements to be supervised. in this context, the information can be presented in different forms: video, pictures, data and alarms. one of sigiu's objectives is the real-time management of urban infrastructures' control mechanisms. to carry out this process, the alarm control agent creates a mobile agent associated with the alarm, which is sent to a mobile station and warns an operator. preliminary implementation results show that sigiu supports effectively and efficiently the decision making process related to managing urban infrastructures","['knowledge-based approach', 'regulation', 'dynamic monitoring', 'municipal activities', 'cooperative system', 'sigiu', 'integrated operating systems', 'sydex', 'coordination system', 'sygec', 'video', 'real-time management', 'alarm control agent', 'mobile agent', 'urban infrastructure management', 'global planning system', 'intelligent decision support system', 'urban planning', 'multi-agent systems']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'R', 'M']","['knowledge - base approach', 'regulation', 'dynamic monitoring', 'municipal activity', 'cooperative system', 'sigiu', 'integrate operating system', 'sydex', 'coordination system', 'sygec', 'video', 'real - time management', 'alarm control agent', 'mobile agent', 'urban infrastructure management', 'global planning system', 'intelligent decision support system', 'urban planning', 'multi - agent system']","['alarm control agent create', 'cooperative system call sigiu', 'integrate operating system', 'monitor instrument instal', 'dynamic monitoring', 'municipal administration', 'urban infrastructure', 'municipal service', 'several municipal activity', 'mobile agent associate']"
301,642,Reconstruction of MR images from data acquired on an arbitrary k-space trajectory using the same-image weight,"a sampling density compensation function denoted ""same-image (si) weight"" is proposed to reconstruct mr images from the data acquired on an arbitrary k-space trajectory. an equation for the si weight is established on the si criterion and an iterative scheme is developed to find the weight. the si weight is then used to reconstruct images from the data calculated on a random trajectory in a numerical phantom case and from the data acquired on interleaved spirals in an in vivo experiment, respectively. in addition, pipe and menon's weight (mrm 1999;41:179-186) is also used in the reconstructions to make a comparison. the images obtained with the si weight were found to be slightly more accurate than those obtained with pipe's weight","['arbitrary k-space trajectory', 'same-image weight', 'sampling density compensation', 'random trajectory', 'numerical phantom', 'mri image reconstruction', 'spiral trajectory', 'convolution function', 'nyquist sampling conditions', 'iterative algorithm', 'weighting function']","['P', 'P', 'P', 'P', 'P', 'M', 'R', 'M', 'M', 'M', 'R']","['arbitrary k - space trajectory', 'same - image weight', 'sample density compensation', 'random trajectory', 'numerical phantom', 'mri image reconstruction', 'spiral trajectory', 'convolution function', 'nyquist sample condition', 'iterative algorithm', 'weighting function']","['sample density compensation function', 'reconstruct mr image', 'reconstruct image', 'numerical phantom', 'vivo experiment', 'interleave spiral', 'reconstruction', 'image obtain', 'datum calculate', 'space trajectory']"
302,607,A building block approach to automated engineering,"shenandoah valley electric cooperative (svec, mt. crawford, virginia, us) recognized the need to automate engineering functions and create an interactive model of its distribution system in the early 1990s. it had used milsoft's da software for more than 10 years to make engineering studies, and had a landis and gyr scada system and a hybrid load management system for controlling water heater switches. with the development of gis and facilities management (fm) applications, svec decided this should be the basis for an information system that would model its physical plant and interface with its accounting and billing systems. it could add applications such as outage management, staking, line design and metering to use this information and interface with these databases. however, based on svec's size it was not feasible to implement a sophisticated and expensive gis/fm system. over the past nine years, svec has had success with a building block approach, and its customers and employees are realizing the benefits of the automated applications. this building block approach is discussed in this article including the gis, outage management system, mapviewer and a staking package. the lessons learned and future expansion are discussed","['building block approach', 'gis', 'shenandoah valley electric cooperative', 'interactive model', 'distribution system', 'billing systems', 'outage management', 'staking', 'line design', 'metering', 'databases', 'mapviewer', 'engineering functions automation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['building block approach', 'gi', 'shenandoah valley electric cooperative', 'interactive model', 'distribution system', 'billing system', 'outage management', 'stake', 'line design', 'meter', 'database', 'mapviewer', 'engineering function automation']","['shenandoah valley electric cooperative', 'outage management system', 'hybrid load management system', 'gyr scada system', 'facility management', 'billing system', 'automate application', 'automate engineering function', 'outage management', 'control water heater switch']"
303,78,Applying genetic algorithms to solve the fuzzy optimal profit problem,"this study investigated the application of genetic algorithms in solving a fuzzy optimization problem that arises in business and economics. in this problem, a fuzzy price is determined using a linear or a quadratic fuzzy demand function as well as a linear cost function. the objective is to find the optimal fuzzy profit, which is derived from the fuzzy price and fuzzy cost. traditional methods for solving this problem are (1) the extension principle, and (2) using interval arithmetic and alpha -cuts. however, we argue that traditional methods for solving this problem are too restrictive to produce an optimal solution, and that an alternative approach is possibly needed. we use genetic algorithms to obtain an approximate solution for this fuzzy optimal profit problem without using membership functions. we not only give empirical examples to show the effectiveness of this approach, but also give theoretical proofs to validate correctness of the algorithm. we conclude that genetic algorithms can produce good approximate solutions when applied to solve fuzzy optimization problems","['genetic algorithms', 'fuzzy optimal profit problem', 'fuzzy optimization problem', 'business', 'economics', 'fuzzy price', 'quadratic fuzzy demand function', 'linear cost function', 'approximate solution', 'theoretical proofs', 'linear fuzzy demand function', 'algorithm correctness validation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['genetic algorithm', 'fuzzy optimal profit problem', 'fuzzy optimization problem', 'business', 'economic', 'fuzzy price', 'quadratic fuzzy demand function', 'linear cost function', 'approximate solution', 'theoretical proof', 'linear fuzzy demand function', 'algorithm correctness validation']","['fuzzy optimal profit problem', 'optimal fuzzy profit', 'quadratic fuzzy demand function', 'fuzzy optimization problem', 'linear cost function', 'fuzzy cost', 'fuzzy price', 'optimal solution', 'produce good approximate solution', 'genetic algorithm']"
304,1009,Robust output feedback model predictive control using off-line linear matrix inequalities,"a fundamental question about model predictive control (mpc) is its robustness to model uncertainty. in this paper, we present a robust constrained output feedback mpc algorithm that can stabilize plants with both polytopic uncertainty and norm-bound uncertainty. the design procedure involves off-line design of a robust constrained state feedback mpc law and a state estimator using linear matrix inequalities (lmis). since we employ an off-line approach for the controller design which gives a sequence of explicit control laws, we are able to analyze the robust stabilizability of the combined control laws and estimator, and by adjusting the design parameters, guarantee robust stability of the closed-loop system in the presence of constraints. the algorithm is illustrated with two examples","['robust output feedback model predictive control', 'off-line linear matrix inequalities', 'robust constrained output feedback mpc algorithm', 'polytopic uncertainty', 'norm-bound uncertainty', 'robust constrained state feedback mpc law', 'state estimator', 'closed-loop system', 'model uncertainty robustness', 'controller design procedure', 'explicit control law sequence', 'asymptotically stable invariant ellipsoid']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'U']","['robust output feedback model predictive control', 'off - line linear matrix inequality', 'robust constrained output feedback mpc algorithm', 'polytopic uncertainty', 'norm - bind uncertainty', 'robust constrained state feedback mpc law', 'state estimator', 'close - loop system', 'model uncertainty robustness', 'controller design procedure', 'explicit control law sequence', 'asymptotically stable invariant ellipsoid']","['robust constrained output feedback mpc algorithm', 'robust constrained state feedback mpc', 'robust stabilizability', 'model predictive control', 'guarantee robust stability', 'polytopic uncertainty', 'stabilize plant', 'model uncertainty', 'robustness', 'linear matrix inequality']"
305,718,New water management system begins operation at US projects,"the us army corps of engineers has developed a new automated information system to support its water control management mission. the new system provides a variety of decision support tools, enabling water control managers to acquire, transform, verify, store, display, analyse, and disseminate data and information efficiently and around the clock","['water management system', 'us projects', 'us army corps of engineers', 'automated information system', 'water control management mission', 'water control managers', 'decision support tools', 'watershed modelling', 'data dissemination', 'data acquisition', 'data storage', 'data verification', 'data display', 'data analysis', 'data visualization', 'decision support system', 'corps water management system']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'R', 'M', 'M', 'M', 'R', 'M', 'M', 'R', 'R']","['water management system', 'us project', 'we army corps of engineer', 'automate information system', 'water control management mission', 'water control manager', 'decision support tool', 'watershe model', 'datum dissemination', 'datum acquisition', 'datum storage', 'datum verification', 'datum display', 'datum analysis', 'datum visualization', 'decision support system', 'corps water management system']","['new automate information system', 'water control management mission', 'enable water control manager', 'us army corps', 'decision support tool', 'new system provide', 'disseminate datum', 'information', 'engineer', 'analyse']"
306,1308,SPTL/BIALL academic law library survey 2000/2001,the paper outlines the activities and funding of academic law libraries in the uk and ireland in the academic year 2000/2001. the figures have been taken from the results of a postal questionnaire undertaken by information services staff at cardiff university on behalf of biall,"['sptl/biall', 'academic law libraries', 'survey', 'funding', 'uk', 'ireland', 'postal questionnaire', 'information services', 'cardiff university']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['sptl / biall', 'academic law librarie', 'survey', 'funding', 'uk', 'ireland', 'postal questionnaire', 'information service', 'cardiff university']","['academic law librarie', 'information service staff', 'academic year', 'postal questionnaire undertake', 'cardiff university', 'ireland', 'uk', 'funding', 'paper outline', 'activity']"
307,1425,Kontiki. Shortcuts for content's trip to the edge,"when electronic files get zapped from one location to another, you probably aren't thinking about the physical distance they must travel-or how that distance might affect the time it takes to get there. but if you work for cdn company kontiki, this is just about all you think about. championing a p2p-like ""bandwidth harvesting"" technology, kontiki has figured out how to not only quickly distribute content to the ""edge"" but to utilize a combination of centralized servers and a network of enduser machines to collect, or ""harvest,"" underutilized bandwidth and make redundant file requests more efficient","['kontiki', 'electronic files', 'centralized servers', 'enduser machines', 'underutilized bandwidth', 'redundant file requests', 'p2p-like bandwidth harvesting technology']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['kontiki', 'electronic file', 'centralize server', 'enduser machine', 'underutilize bandwidth', 'redundant file request', 'p2p - like bandwidth harvesting technology']","['bandwidth harvesting', 'underutilize bandwidth', 'electronic file', 'centralize server', 'p2p', 'distribute content', 'network', 'cdn company kontiki', 'redundant file request', 'technology']"
308,1460,Detection of flaws in composites from scattered elastic-wave field using an improved mu GA and a local optimizer,"an effective technique for flaw detection of composites is proposed. in this technique, the detection problem is formulated as an optimization problem minimizing the difference between the measured and calculated surface displacement response derived from scattered elastic-wave fields. a combined optimization technique using an improved mu ga and a local optimizer is developed to solve the optimization problem so as to obtain the flaw parameters defining flaw configurations. guidelines for implementing the detection technique, including formulation of the objective function of the optimization problem using different error norms, improvement of mu ga convergence performance, switching from mu ga to local optimizer in the optimization process, and suppression of the effect of noise on detection results, are addressed in detail. numerical examples are presented to demonstrate the effectiveness and efficiency of the proposed detection technique","['composites', 'scattered elastic-wave field', 'improved mu ga', 'local optimizer', 'flaw detection', 'optimization problem', 'surface displacement response', 'flaw configurations', 'objective function', 'error norms', 'convergence', 'noise effect suppression']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['composite', 'scatter elastic - wave field', 'improve mu ga', 'local optimizer', 'flaw detection', 'optimization problem', 'surface displacement response', 'flaw configuration', 'objective function', 'error norm', 'convergence', 'noise effect suppression']","['optimization problem minimize', 'flaw detection', 'scatter elastic', 'optimization technique', 'optimization problem', 'optimization', 'surface displacement', 'detection technique', 'detection problem', 'flaw parameter']"
309,876,Perspectives on academic vs. industry environments for women in computer science,"the authors were tenure track faculty members at the colorado school of mines and later moved into senior positions at software companies. both are part of two-career couples as well, and both have two children. in this article, they discuss their impressions and share anecdotes regarding the differing experiences of women and families in these two environments","['industry environment', 'women', 'computer science', 'faculty members', 'software companies', 'children', 'academic environments', 'career', 'gender gap']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'U']","['industry environment', 'woman', 'computer science', 'faculty member', 'software company', 'child', 'academic environment', 'career', 'gender gap']","['tenure track faculty member', 'career couple', 'software company', 'differ experience', 'senior position', 'share anecdote regard', 'colorado school', 'family', 'woman', 'author']"
310,833,Packet promises past & present [IP switching],"with the death of the competitive carrier market and the significant slashing of rboc capex budgets, softswitch vendors have been forced to retrench. now instead of focusing primarily on limited internet off-load applications, packet-based softswitches are set to gel around real user needs for services such as voice over ip and ip centrex","['softswitch vendors', 'voice over ip', 'ip centrex']","['P', 'P', 'P']","['softswitch vendor', 'voice over ip', 'ip centrex']","['softswitch vendor', 'rboc capex budget', 'base softswitche', 'competitive carrier market', 'load application', 'limit internet', 'service such', 'real user need', 'ip', 'voice']"
311,1250,The impact and implementation of XML on business-to-business commerce,"this paper discusses the impact analysis of the extensible markup language (xml). each business partner within a supply chain will be allowed to generate its own data exchange format by adopting an xml meta-data management system in the local side. followed after a brief introduction of the information technology for business to customer (b2c) and business to business (b2b) electronic commerce (ec), the impact of xml on the tomorrow business world is discussed. a real case study for impact analysis on information exchange platform, microsoft's biztalk platform which is actually an xml schema builder and the implementation of xml commerce application will provide an interest insight for users' future implementation","['xml', 'extensible markup language', 'business to customer', 'business to business', 'electronic commerce', 'biztalk', 'xml schema builder', 'electronic data interchange', 'enterprise resources planning']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U']","['xml', 'extensible markup language', 'business to customer', 'business to business', 'electronic commerce', 'biztalk', 'xml schema builder', 'electronic datum interchange', 'enterprise resource plan']","['xml commerce application', 'xml schema builder', 'data exchange format', 'extensible markup language', 'biztalk platform', 'information exchange platform', 'impact analysis', 'xml meta', 'datum management system', 'electronic commerce']"
312,1215,"A knowledge-based approach for business process reengineering, SHAMASH","we present an overview of shamash, a process modelling tool for business process reengineering. the main features that differentiate it from most current related tools are its ability to define and use organisation standards, functional structure, and develop automatic model simulation and optimisation. shamash is a knowledge-based system, and we include a discussion on how knowledge acquisition takes place. furthermore, we introduce a high level description of the architecture, the conceptual model, and other important modules of the system","['knowledge-based approach', 'business process reengineering', 'shamash', 'process modelling tool', 'organisation standards', 'functional structure', 'automatic model simulation', 'optimisation', 'knowledge-based system', 'knowledge acquisition', 'conceptual model']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['knowledge - base approach', 'business process reengineere', 'shamash', 'process model tool', 'organisation standard', 'functional structure', 'automatic model simulation', 'optimisation', 'knowledge - base system', 'knowledge acquisition', 'conceptual model']","['business process reengineere', 'process model tool', 'develop automatic model simulation', 'knowledge acquisition take place', 'conceptual model', 'use organisation standard', 'relate tool', 'high level description', 'architecture', 'knowledge']"
313,640,Scribe: a large-scale and decentralized application-level multicast infrastructure,"this paper presents scribe, a scalable application-level multicast infrastructure. scribe supports large numbers of groups, with a potentially large number of members per group. scribe is built on top of pastry, a generic peer-to-peer object location and routing substrate overlayed on the internet, and leverages pastry's reliability, self-organization, and locality properties. pastry is used to create and manage groups and to build efficient multicast trees for the dissemination of messages to each group. scribe provides best-effort reliability guarantees, and we outline how an application can extend scribe to provide stronger reliability. simulation results, based on a realistic network topology model, show that scribe scales across a wide range of groups and group sizes. also, it balances the load on the nodes while achieving acceptable delay and link stress when compared with internet protocol multicast","['scribe', 'decentralized application-level multicast infrastructure', 'scalable application-level multicast infrastructure', 'pastry', 'generic peer-to-peer object location', 'internet', 'self-organization', 'locality properties', 'best-effort reliability guarantees', 'simulation results', 'network topology model', 'group size', 'delay', 'link stress', 'internet protocol multicast', 'generic routing substrate', 'discrete event simulator', 'network nodes']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'R']","['scribe', 'decentralize application - level multicast infrastructure', 'scalable application - level multicast infrastructure', 'pastry', 'generic peer - to - peer object location', 'internet', 'self - organization', 'locality property', 'good - effort reliability guarantee', 'simulation result', 'network topology model', 'group size', 'delay', 'link stress', 'internet protocol multicast', 'generic routing substrate', 'discrete event simulator', 'network nod']","['level multicast infrastructure', 'build efficient multicast tree', 'scribe support large', 'paper present scribe', 'peer object location', 'generic peer', 'scribe provide good', 'scribe scale', 'effort reliability guarantee', 'route substrate overlay']"
314,605,HEW selects network management software,"for more than 100 years, hamburgische electricitats-werke ag (hew) has provided a reliable electricity service to the city of hamburg, germany. today, the company supplies electricity to some 1.7 million inhabitants via 285000 connections. during 1999, the year the energy market was started in germany, hew needed to operate and maintain a safe and reliable network cheaply. the development and implementation of a distribution management system (dms) is key to the success of hew. hew's strategy was to obtain efficient new software for network management that also offered a good platform for future applications. following a pilot and prequalification phase, hew invited several companies to process the requirements catalog and to submit a detailed tender. the network information management system, xpower, developed by tekla oyj, successfully passed hew's test program and satisfied all the performance and system capacity requirements. the system met all hew's conditions by presenting the reality of a network with the attributes of the operating resources. xpower platform provides the ability to integrate future applications","['network management software', 'hamburgische electricitats-werke', 'hamburg', 'germany', 'distribution management system', 'xpower', 'tekla oyj']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['network management software', 'hamburgische electricitats - werke', 'hamburg', 'germany', 'distribution management system', 'xpower', 'tekla oyj']","['network information management system', 'distribution management system', 'reliable electricity service', 'company supply electricity', 'xpower platform provide', 'system capacity requirement', 'network management', 'hew invite several company', 'hamburgische electricitats', 'obtain efficient new software']"
315,128,A new result on the global convergence of Hopfield neural networks,"in this work, we discuss hopfield neural networks, investigating their global stability. some sufficient conditions for a class of hopfield neural networks to be globally stable and globally exponentially stable are given","['hopfield neural networks', 'global stability', 'sufficient conditions', 'globally exponentially stable networks']","['P', 'P', 'P', 'R']","['hopfield neural network', 'global stability', 'sufficient condition', 'globally exponentially stable network']","['hopfield neural network', 'global stability', 'stable', 'sufficient condition', 'class']"
316,1151,A method for geometrical verification of dynamic intensity modulated radiotherapy using a scanning electronic portal imaging device,"in order to guarantee the safe delivery of dynamic intensity modulated radiotherapy (imrt), verification of the leaf trajectories during the treatment is necessary. our aim in this study is to develop a method for on-line verification of leaf trajectories using an electronic portal imaging device with scanning read-out, independent of the multileaf collimator. examples of such scanning imagers are electronic portal imaging devices (epids) based on liquid-filled ionization chambers and those based on amorphous silicon. portal images were acquired continuously with a liquid-filled ionization chamber epid during the delivery, together with the signal of treatment progress that is generated by the accelerator. for each portal image, the prescribed leaf and diaphragm positions were computed from the dynamic prescription and the progress information. motion distortion effects of the leaves are corrected based on the treatment progress that is recorded for each image row. the aperture formed by the prescribed leaves and diaphragms is used as the reference field edge, while the actual field edge is found using a maximum-gradient edge detector. the errors in leaf and diaphragm position are found from the deviations between the reference field edge and the detected field edge. earlier measurements of the dynamic epid response show that the accuracy of the detected field edge is better than 1 mm. to ensure that the verification is independent of inaccuracies in the acquired progress signal, the signal was checked with diode measurements beforehand. the method was tested on three different dynamic prescriptions. using the described method, we correctly reproduced the distorted field edges. verifying a single portal image took 0.1 s on an 866 mhz personal computer. two flaws in the control system of our experimental dynamic multileaf collimator were correctly revealed with our method. first, the errors in leaf position increase with leaf speed, indicating a delay of approximately 0.8 s in the control system. second, the accuracy of the leaves and diaphragms depends on the direction of motion. in conclusion, the described verification method is suitable for detailed verification of leaf trajectories during dynamic imrt","['dynamic intensity modulated radiotherapy', 'safe delivery', 'leaf trajectories', 'on-line verification', 'scanning read-out', 'liquid-filled ionization chambers', 'diaphragm positions', 'motion distortion effects', 'reference field edge', 'distorted field edges', 'control system', 'dynamic multileaf collimator', 'leaf positions', 'geometrical verification method', 'dose distributions', 'treatment planning']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'M']","['dynamic intensity modulate radiotherapy', 'safe delivery', 'leaf trajectory', 'on - line verification', 'scan read - out', 'liquid - fill ionization chamber', 'diaphragm position', 'motion distortion effect', 'reference field edge', 'distort field edge', 'control system', 'dynamic multileaf collimator', 'leaf position', 'geometrical verification method', 'dose distribution', 'treatment planning']","['electronic portal imaging device', 'dynamic intensity modulate radiotherapy', 'electronic portal imaging device', 'ionization chamber epid', 'scan imager', 'experimental dynamic multileaf collimator', 'portal image', 'gradient edge detector', 'portal image', 'prescribe leaf']"
317,1114,A new algebraic modelling approach to distributed problem-solving in MAS,"this paper is devoted to a new algebraic modelling approach to distributed problem-solving in multi-agent systems (mas), which is featured by a unified framework for describing and treating social behaviors, social dynamics and social intelligence. a conceptual architecture of algebraic modelling is presented. the algebraic modelling of typical social behaviors, social situation and social dynamics is discussed in the context of distributed problem-solving in mas. the comparison and simulation on distributed task allocations and resource assignments in mas show more advantages of the algebraic approach than other conventional methods","['algebraic modelling approach', 'distributed problem-solving', 'multi-agent systems', 'unified framework', 'social behaviors', 'social dynamics', 'social intelligence', 'distributed task allocations', 'resource assignments']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['algebraic modelling approach', 'distribute problem - solve', 'multi - agent system', 'unified framework', 'social behavior', 'social dynamic', 'social intelligence', 'distribute task allocation', 'resource assignment']","['distribute task allocation', 'algebraic modelling approach', 'agent system', 'treat social behavior', 'algebraic modelling', 'distribute problem', 'social behavior', 'algebraic approach', 'social dynamic', 'social intelligence']"
318,541,Virtual-reality-based multidimensional therapy for the treatment of body image disturbances in binge eating disorders: a preliminary controlled study,"the main goal of this paper is to preliminarily evaluate the efficacy of a virtual-reality (vr)-based multidimensional approach in the treatment of body image attitudes and related constructs. the female binge eating disorder (bed) patients (n=20), involved in a residential weight control treatment including low-calorie diet (1200 cal/day) and physical training, were randomly assigned either to the multidimensional vr treatment or to psychonutritional groups based on the cognitive-behavior approach. patients were administered a battery of outcome measures assessing eating disorders symptomathology, attitudes toward food, body dissatisfaction, level of anxiety, motivation for change, level of assertiveness, and general psychiatric symptoms. in the short term, the vr treatment was more effective than the traditional cognitive-behavioral psychonutritional groups in improving the overall psychological state of the patients. in particular, the therapy was more effective in improving body satisfaction, self-efficacy, and motivation for change. no significant differences were found in the reduction of the binge eating behavior. the possibility of inducing a significant change in body image and its associated behaviors using a vr-based short-term therapy can be useful to improve the body satisfaction in traditional weight reduction programs. however, given the nature of this research that does not include a followup study, the obtained results are preliminary only","['multidimensional therapy', 'body image disturbances', 'binge eating disorders', 'residential weight control treatment', 'psychonutritional groups', 'cognitive-behavior approach', 'anxiety', 'psychiatric symptoms', 'virtual reality', 'obesity', 'patient therapy']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'U', 'R']","['multidimensional therapy', 'body image disturbance', 'binge eat disorder', 'residential weight control treatment', 'psychonutritional group', 'cognitive - behavior approach', 'anxiety', 'psychiatric symptom', 'virtual reality', 'obesity', 'patient therapy']","['outcome measure assess eat disorder symptomathology', 'female binge eat disorder', 'binge eat behavior', 'behavioral psychonutritional group', 'multidimensional vr treatment', 'residential weight control treatment', 'calorie diet', 'improve body satisfaction', 'vr treatment', 'body image attitude']"
319,996,Flexible air-jet tooling for vibratory bowl feeder systems,"vibratory bowl feeders (vbfs) are machines that feed various small parts in large volume automatic assembly systems. their shortcomings, like inflexibility and the propensity to jam, stem from the use of mechanical orienting devices. air jet based orienting devices can be implemented to overcome these limitations. applications of passive and active air jet based orienting devices that replace conventional devices for the vbf are discussed. passive devices, which reject incorrectly oriented parts, are discussed first. active air jet based orienting devices are then introduced to further improve the flexibility of vbfs. since active devices reorient parts into a desired orientation, the part motion under their influence is analyzed. a number of tests demonstrate the feasibility and advantages of these new orienting devices","['vibratory bowl feeders', 'automatic assembly systems', 'orienting devices', 'active air jet', 'passive air jet', 'parts feeding']","['P', 'P', 'P', 'P', 'R', 'R']","['vibratory bowl feeder', 'automatic assembly system', 'orient device', 'active air jet', 'passive air jet', 'part feed']","['mechanical orienting device', 'vibratory bowl feeder', 'volume automatic assembly system', 'orient part', 'active air jet', 'air jet', 'desire orientation', 'active device reorient part', 'part motion', 'machine']"
320,87,Positional control of pneumatic manipulators for construction tasks,"this paper describes solutions that can be applied to pneumatic manipulator problems in positioning, both for angle trajectories and for long linear trajectories, used in construction tasks. optimal positioning of a pneumatic manipulator along angle trajectories with minimum control energy consumption is given. the implementation of the control system is presented. control algorithms for a long linear trajectory manipulator based on two-phase and three-phase motion modes of the end-effector are investigated. conventional and fuzzy logic controls of a pneumatic manipulator were applied and experimental testing was carried out. the obtained results allow widening the application range of pneumatic manipulators in construction, particularly in gantry type machines","['positioning', 'positional control', 'pneumatic manipulators', 'construction tasks', 'angle trajectories', 'long linear trajectory manipulator', 'three-phase motion modes', 'fuzzy logic controls', 'gantry type machines', 'two-phase motion modes']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['position', 'positional control', 'pneumatic manipulator', 'construction task', 'angle trajectory', 'long linear trajectory manipulator', 'three - phase motion mode', 'fuzzy logic control', 'gantry type machine', 'two - phase motion mode']","['linear trajectory manipulator base', 'pneumatic manipulator', 'pneumatic manipulator', 'optimal positioning', 'fuzzy logic control', 'angle trajectory', 'position', 'motion mode', 'construction task', 'linear trajectory']"
321,1129,Computing stationary Nash equilibria of undiscounted single-controller stochastic games,"given a two-person, nonzero-sum stochastic game where the second player controls the transitions, we formulate a linear complementarity problem lcp(q, m) whose solution gives a nash equilibrium pair of stationary strategies under the limiting average payoff criterion. the matrix m constructed is of the copositive class so that lemke's algorithm will process it. we will also do the same for a special class of n-person stochastic games called polymatrix stochastic games","['stationary nash equilibria', 'undiscounted single-controller stochastic games', 'linear complementarity problem', 'stationary strategies', 'limiting average payoff criterion', 'n-person stochastic games', 'polymatrix stochastic games', 'two-person nonzero-sum stochastic game', 'copositive class matrix', 'lemke algorithm']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['stationary nash equilibrium', 'undiscounted single - controller stochastic game', 'linear complementarity problem', 'stationary strategy', 'limit average payoff criterion', 'n - person stochastic game', 'polymatrix stochastic game', 'two - person nonzero - sum stochastic game', 'copositive class matrix', 'lemke algorithm']","['nash equilibrium pair', 'sum stochastic game', 'limit average payoff criterion', 'linear complementarity problem', 'copositive class', 'second player control', 'stationary strategy', 'special class', 'person', 'transition']"
322,539,Perfusion quantification using Gaussian process deconvolution,"the quantification of perfusion using dynamic susceptibility contrast mri (dsc-mri) requires deconvolution to obtain the residual impulse response function (irf). in this work, a method using the gaussian process for deconvolution (gpd) is proposed. the fact that the irf is smooth is incorporated as a constraint in the method. the gpd method, which automatically estimates the noise level in each voxel, has the advantage that model parameters are optimized automatically. the gpd is compared to singular value decomposition (svd) using a common threshold for the singular values, and to svd using a threshold optimized according to the noise level in each voxel. the comparison is carried out using artificial data as well as data from healthy volunteers. it is shown that gpd is comparable to svd with a variable optimized threshold when determining the maximum of the irf, which is directly related to the perfusion. gpd provides a better estimate of the entire irf. as the signal-to-noise ratio (snr) increases or the time resolution of the measurements increases, gpd is shown to be superior to svd. this is also found for large distribution volumes","['perfusion quantification', 'gaussian process deconvolution', 'dynamic susceptibility contrast mri', 'residual impulse response function', 'noise level', 'singular value decomposition', 'optimized model parameters', 'capillary blood flow', 'mean transit time', 'optimized joint gaussian distribution', 'correlation length', 'likelihood function']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'M', 'M', 'U', 'M']","['perfusion quantification', 'gaussian process deconvolution', 'dynamic susceptibility contrast mri', 'residual impulse response function', 'noise level', 'singular value decomposition', 'optimize model parameter', 'capillary blood flow', 'mean transit time', 'optimize joint gaussian distribution', 'correlation length', 'likelihood function']","['dynamic susceptibility contrast mri', 'singular value decomposition', 'deconvolution', 'mri', 'residual impulse response function', 'gaussian process', 'voxel', 'svd', 'threshold optimize', 'optimize threshold']"
323,680,Information needs of the working journalists in Orissa: a study,"provides an insight into the various information needs of working journalists in orissa. analyses data received from 226 working journalists representing 40 newspaper organisations. also depicts the specialisation of working journalists, their frequency of information requirement, mode of dissemination preferred, information sources explored, mode of services opted, and their information privations. the study asserts that subjects primarily concerned with the professional work and image of the working journalists are rated utmost significant","['information needs', 'working journalists', 'newspaper organisations', 'information requirement', 'information sources', 'professional work', 'data analysis', 'information dissemination']","['P', 'P', 'P', 'P', 'P', 'P', 'M', 'R']","['information need', 'work journalist', 'newspaper organisation', 'information requirement', 'information source', 'professional work', 'datum analysis', 'information dissemination']","['work journalist represent', 'work journalist', 'newspaper organisation', 'various information need', 'information requirement', 'information source explore', 'information privation', 'orissa', 'analysis datum', 'professional work']"
324,1290,Making the MIS integration process work,"focused, cross-functional teams that implement flexible and scalable information systems (is) can deliver a smooth, lean manufacturing process. when integrating new technology into an existing facility, one should always consider three things: the hard infrastructure, the soft infrastructure, and information flow. hard infrastructure includes client and server hardware and network infrastructure. soft infrastructure includes operating systems, existing or legacy software, needed code customizations, and the human resources to run/support the system. information flow includes how data in the new system interacts with legacy systems and what legacy data the new system will require, as well as who will want to receive/access the information that is held by the system","['scalable information systems', 'lean manufacturing process', 'information flow', 'network infrastructure', 'legacy software', 'human resources', 'management information systems', 'client server hardware']","['P', 'P', 'P', 'P', 'P', 'P', 'M', 'R']","['scalable information system', 'lean manufacturing process', 'information flow', 'network infrastructure', 'legacy software', 'human resource', 'management information system', 'client server hardware']","['soft infrastructure include operating system', 'scalable information system', 'lean manufacturing process', 'hard infrastructure include client', 'soft infrastructure', 'network infrastructure', 'server hardware', 'legacy system', 'legacy software', 'information flow include']"
325,1228,Outsourced backup saves time,"to increase the efficiency of its data backup and to free staff to concentrate on core business, the gadget shop is relying on a secure, automated system hosted by a third party","['outsourced', 'data backup', 'the gadget shop', 'e-business']","['P', 'P', 'P', 'U']","['outsource', 'datum backup', 'the gadget shop', 'e - business']","['gadget shop', 'automate system host', 'datum backup', 'free staff', 'core business', 'secure', 'efficiency', 'rely', 'increase']"
326,638,Scalable secure group communication over IP multicast,"we introduce and analyze a scalable rekeying scheme for implementing secure group communications internet protocol multicast. we show that our scheme incurs constant processing, message, and storage overhead for a rekey operation when a single member joins or leaves the group, and logarithmic overhead for bulk simultaneous changes to the group membership. these bounds hold even when group dynamics are not known a priori. our rekeying algorithm requires a particular clustering of the members of the secure multicast group. we describe a protocol to achieve such clustering and show that it is feasible to efficiently cluster members over realistic internet-like topologies. we evaluate the overhead of our own rekeying scheme and also of previously published schemes via simulation over an internet topology map containing over 280 000 routers. through analysis and detailed simulations, we show that this rekeying scheme performs better than previous schemes for a single change to group membership. further, for bulk group changes, our algorithm outperforms all previously known schemes by several orders of magnitude in terms of actual bandwidth usage, processing costs, and storage requirements","['scalable secure group communication', 'ip multicast', 'internet protocol multicast', 'storage overhead', 'overhead', 'logarithmic overhead', 'simulation', 'group membership', 'group dynamics', 'rekeying algorithm', 'secure multicast group', 'internet-like topologies', 'internet topology map', 'bandwidth usage', 'processing costs', 'storage requirements', 'cryptography', 'access control server', 'authentication', 'network routers']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'U', 'U', 'M']","['scalable secure group communication', 'ip multicast', 'internet protocol multicast', 'storage overhead', 'overhead', 'logarithmic overhead', 'simulation', 'group membership', 'group dynamic', 'rekeye algorithm', 'secure multicast group', 'internet - like topology', 'internet topology map', 'bandwidth usage', 'processing cost', 'storage requirement', 'cryptography', 'access control server', 'authentication', 'network router']","['implement secure group communication internet protocol multicast', 'secure multicast group', 'scalable rekeying scheme', 'own rekeying scheme', 'cluster member', 'rekeye scheme', 'rekeying algorithm require', 'group membership', 'single member join', 'bulk group change']"
327,913,Control of a coupled map lattice model for vortex shedding in the wake of a cylinder,"the flow behind a vibrating flexible cable at low reynolds numbers can exhibit complex wake structures such as lace-like patterns, vortex dislocations and frequency cells. these structures have been observed in experiments and numerical simulations, and are predicted by a previously developed low-order coupled map lattice (cml). the discrete (in time and space) cml models consist of a series of diffusively coupled circle map oscillators along the cable span. motivated by a desire to modify the complex wake patterns behind flexible vibrating cables, we have studied the addition of control terms into the highly efficient cml models and explored the resulting dynamics. proportional, adaptive proportional and discontinuous non-linear (dnl) control methods were used to derive the control laws. the first method employed occasional proportional feedback. the adaptive method used spatio-temporal feedback control. the dnl method used a discontinuous feedback linearization procedure, and the controller was designed for the resulting linearized system using eigenvalue assignment. these techniques were applied to a modeled vortex dislocation structure in the wake of a vibrating cable in uniform freestream flow. parallel shedding patterns were achieved for a range of forcing frequency-forcing amplitude combinations studied to validate the control theory. the adaptive proportional and dnl methods were found to be more effective than the proportional control method due to the incorporation of a spatially varying feedback gain across the cylinder span. the dnl method was found to be the most efficient controller of the low-order cml model. the required control level across the cable span was correlated to the 1/1 lock-on behavior of the temporal circle map","['coupled map lattice', 'vortex shedding', 'wake', 'cylinder', 'vibrating flexible cable', 'low reynolds numbers', 'vortex dislocation', 'vortex dislocation', 'coupled circle map oscillators', 'proportional feedback', 'spatio-temporal feedback control', '1/1 lock-on', 'temporal circle map', 'discontinuous nonlinear control', 'vortex dislocations']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'P']","['couple map lattice', 'vortex shedding', 'wake', 'cylinder', 'vibrate flexible cable', 'low reynold number', 'vortex dislocation', 'vortex dislocation', 'couple circle map oscillator', 'proportional feedback', 'spatio - temporal feedback control', '1/1 lock - on', 'temporal circle map', 'discontinuous nonlinear control', 'vortex dislocation']","['flexible vibrate cable', 'vibrate flexible cable', 'couple circle map oscillator', 'model vortex dislocation structure', 'vibrate cable', 'complex wake structure', 'complex wake pattern', 'dynamic', 'vortex dislocation', 'couple map lattice']"
328,581,Successive expansion method of network planning applying symbolic analysis method,"the conventional power system network successive expansion planning method is discussed in the context of the new paradigm of competitive electric power, energy and service market. in sequel, the paper presents an application of the conceptually new computer program, based on the symbolic analysis of load flows in power system networks. the network parameters and variables are defined as symbols. the symbolic analyzer, which models analytically the power system dc load flows, enables the sensitivity analysis of the power system to parameter and variable variations (costs, transfers, injections), a valuable tool for the expansion planning analysis. that virtue could not be found within the conventional approach, relying on compensation methods, precalculated distribution factors, and so on. this novel application sheds some light on the traditional power system network expansion planning method, as well as on its possible application within the system network expansion planning in the new environment assuming the competitive electric power market","['symbolic analysis', 'power system network successive expansion planning', 'computer program', 'load flows', 'symbolic analyzer', 'power system dc load flows', 'sensitivity analysis', 'compensation methods', 'precalculated distribution factors', 'power system network expansion planning method', 'competitive electric power market', 'competitive electric energy market', 'competitive electric service market']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['symbolic analysis', 'power system network successive expansion plan', 'computer program', 'load flow', 'symbolic analyzer', 'power system dc load flow', 'sensitivity analysis', 'compensation method', 'precalculate distribution factor', 'power system network expansion planning method', 'competitive electric power market', 'competitive electric energy market', 'competitive electric service market']","['power system network successive expansion planning method', 'power system network expansion planning method', 'system network expansion planning', 'power system dc load flow', 'expansion planning analysis', 'network parameter', 'power system network', 'variable variation', 'symbolic analysis', 'symbolic analyzer']"
329,956,Do you see what I see? [visual technology in law firms],"think of how well-done computer presentations can aid in the learning experience. they are, however, less common in client meetings, settlement conferences and the courtroom. and you have to wonder why, when the same benefits of attention focus and visual learning apply in those legal communication settings. the software and hardware components are easy to use, and they're increasingly affordable to boot. the next time you need to convey a point to an audience (be it one person or many), think of how you might benefit from the visual impact available through presentation software like powerpoint. anyone will understand you more easily when assisted by visual input, and it may make all the difference in reaching visual-focused learners","['visual technology', 'law firms', 'computer presentations', 'powerpoint']","['P', 'P', 'P', 'P']","['visual technology', 'law firm', 'computer presentation', 'powerpoint']","['visual learning apply', 'attention focus', 'do computer presentation', 'presentation software', 'visual impact available', 'visual input', 'reach visual', 'learn experience', 'legal communication', 'powerpoint']"
330,115,Non-optimal universal quantum deleting machine,"we verify the non-existence of some standard universal quantum deleting machine. then a non-optimal universal quantum deleting machine is constructed and we emphasize the difficulty for improving its fidelity. in a way, our results complement the universal quantum cloning machine established by buzek and hillery (1996), and manifest some of their distinctions","['fidelity', 'universal quantum cloning machine', 'nonoptimal universal quantum deleting machine', 'nuqdm']","['P', 'P', 'M', 'U']","['fidelity', 'universal quantum cloning machine', 'nonoptimal universal quantum delete machine', 'nuqdm']","['universal quantum cloning machine establish', 'standard universal quantum delete machine', 'optimal universal quantum delete machine', 'fidelity', 'result complement', 'construct', 'buzek', 'emphasize', 'manifest', 'non']"
331,1191,On the monotonicity conservation in numerical solutions of the heat equation,"it is important to choose such numerical methods in practice that mirror the characteristic properties of the described process beyond the stability and convergence. the investigated qualitative property in this paper is the conservation of the monotonicity in space of the initial heat distribution. we prove some statements about the monotonicity conservation and total monotonicity of one-step vector-iterations. then, applying these results, we consider the numerical solutions of the one-dimensional heat equation. our main theorem formulates the necessary and sufficient condition of the uniform monotonicity conservation. the sharpness of the conditions is demonstrated by numerical examples","['monotonicity conservation', 'numerical solutions', 'heat equation', 'characteristic properties', 'qualitative property', 'one-step vector-iterations', 'necessary and sufficient condition']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['monotonicity conservation', 'numerical solution', 'heat equation', 'characteristic property', 'qualitative property', 'one - step vector - iteration', 'necessary and sufficient condition']","['initial heat distribution', 'numerical method', 'uniform monotonicity conservation', 'monotonicity conservation', 'dimensional heat equation', 'numerical solution', 'iteration', 'convergence', 'monotonicity', 'step vector']"
332,725,Banks pin their back-office hopes on successors to screen scrapers,"the big name in account aggregation has been yodlee, based in redwood shores, ca. it pioneered the art of screen scraping, or pulling data off web sites and aggregating it into a single statement. that data, however, is a snapshot and does not include a customer's investment history. also, because web sites update data at different times, scraping them can provide an inaccurate picture of a customer's financial situation, making it difficult for reps seeking to provide timely and accurate advice. the objective is to access both fresh and historical data across a client's financial spectrum, from investments to checking accounts and loans to insurance policies, a complete customer balance sheet. at least two technology vendors are progressing in that direction, each coming from different directions. one is advent, based in san francisco, another is fincentric, out of vancouver","['screen scraping', 'account aggregation', 'yodlee', 'web sites', 'investment', 'checking', 'loans', 'insurance', 'advent', 'fincentric', 'bankers']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U']","['screen scrape', 'account aggregation', 'yodlee', 'web site', 'investment', 'check', 'loan', 'insurance', 'advent', 'fincentric', 'banker']","['web site update datum', 'account aggregation', 'complete customer balance sheet', 'check account', 'historical datum', 'investment history', 'technology vendor', 'pull data', 'web site', 'financial situation']"
333,760,An improved fuzzy MCDM model based on ideal and anti-ideal concepts,"liang presented (1999) a fuzzy multiple criteria decision making (mcdm) method based on the concepts of ideal and anti-ideal points. despite its merits, liang method has the following limitations: (i) the objective criteria are converted into dimensionless indices and the subjective criteria are not converted, which may prevent compatibility for these criteria, (ii) the formulas for converting objective criteria are not reliable, and (iii) an unreliable ranking method, i.e. maximizing set and minimizing set, is applied to rank the fuzzy numbers. this paper applies the hsu and chen method and suggests a fuzzy number ranking method to propose an improved fuzzy mcdm model based on ideal and anti-ideal concepts to overcome the shortcomings of the liang method. numerical examples demonstrate the effectiveness and feasibility of the proposed ranking method and the improved model, respectively","['fuzzy mcdm model', 'anti-ideal concepts', 'dimensionless indices', 'fuzzy number ranking', 'ideal concepts', 'multicriterion decision-making']","['P', 'P', 'P', 'P', 'R', 'U']","['fuzzy mcdm model', 'anti - ideal concept', 'dimensionless index', 'fuzzy number rank', 'ideal concept', 'multicriterion decision - making']","['fuzzy number rank method', 'fuzzy multiple criterion decision', 'improve fuzzy mcdm model base', 'fuzzy number', 'unreliable ranking method', 'propose rank method', 'subjective criterion', 'convert objective criterion', 'objective criterion', 'rank']"
334,1335,Arranging solid balls to represent a graph,"by solid balls, we mean a set of balls in r/sup 3/ no two of which can penetrate each other. every finite graph g can be represented by arranging solid balls in the following way: put red balls in r/sup 3/, one for each vertex of g, and connect two red balls by a chain when they correspond to a pair of adjacent vertices of g, where a chain means a finite sequence of blue solid balls in which each consecutive balls are tangent. (we may omit the chain if the two red balls are already tangent.) the ball number b(g) of g is the minimum number of balls (red and blue) necessary to represent g. if we put the balls and chains on a table so that all balls sit on the table, then the minimum number of balls for g is denoted by bt(g). among other things, we prove that b(k/sub 6/) = 8, b(k/sub 7/) = 13 and b/sub t/(k/sub 5/) = 8,b/sub t/(k/sub 6/) = 14. we also prove that c/sub 1/n/sup 3/ < b(k/sub n/) < c/sub 2/n/sup 3/ log n, c/sub 3/n/sup 4//log n < b/sub t/(k/sub n/) < c/sub 4/n/sup 4/","['solid balls', 'finite graph', 'adjacent vertices', 'finite sequence', 'graph representation']","['P', 'P', 'P', 'P', 'M']","['solid ball', 'finite graph', 'adjacent vertex', 'finite sequence', 'graph representation']","['arrange solid ball', 'blue solid ball', 'put red ball', 'consecutive ball', 'solid ball', 'finite graph', 'adjacent vertex', 'red ball', 'ball sit', 'finite sequence']"
335,1370,"Integrated support based on task models for the design, evaluation, and documentation of interactive safety-critical systems: a case study in the air-traffic control domain","this paper presents an approach to using task models in both the design and the evaluation phases of interactive safety-critical applications. we explain how it is possible to use information contained in task models to support the design and development of effective user interfaces. moreover, we show how task models can also support a systematic inspection-based usability assessment by examining possible deviations that can occur while users interact with the system, an important issue especially when coping with the peculiar requirements of safety-critical applications. such evaluation provides useful technical documentation to help users achieve an in-depth understanding of the system and its design rationale. lastly, a description of the application of our approach to a real case study in the air-traffic control domain will illustrate the main features of the proposed method. in particular, we discuss examples taken from an application for air-traffic controllers in an aerodrome supported by graphical user interfaces for data-link communications with pilots","['integrated support', 'task models', 'interactive safety-critical systems', 'air-traffic control domain', 'user interfaces', 'inspection-based usability assessment', 'technical documentation', 'graphical user interfaces', 'data-link communications']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['integrate support', 'task model', 'interactive safety - critical system', 'air - traffic control domain', 'user interface', 'inspection - base usability assessment', 'technical documentation', 'graphical user interface', 'data - link communication']","['such evaluation provide useful technical documentation', 'base usability assessment', 'interactive safety', 'use task model', 'graphical user interface', 'critical application', 'user interact', 'traffic controller', 'effective user interface', 'traffic control domain']"
336,1418,Documentum completes CM Trifecta,"daily, people participating in clinical trials for drug companies fill out forms describing how they feel physically and emotionally. for some trials, there are hundreds, possibly thousands, of participants. the drug companies must compile all the forms and submit them electronically to the fda. that's where documentum comes in. ""we've streamlined the whole process of managing clinical trial content for companies, such as johnson & johnson, bristol myers squibb, and pfizer,"" notes documentum's president and ceo dave de walt. ""and by the way, the fda also is one of our customers, as well as the epa and the faa."" and there are about 1,300 other organizations in various industries worldwide that rely on documentum's technologies, consulting, and training services. the company's products are designed to manage digital content and facilitate online transactions, partner and supplier relationships, and ebusiness interactions","['documentum', 'clinical trials', 'drug companies', 'fda', 'clinical trial content', 'training services', 'consulting services']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['documentum', 'clinical trial', 'drug company', 'fda', 'clinical trial content', 'training service', 'consult service']","['manage clinical trial content', 'note documentum', 'clinical trial', 'manage digital content', 'drug company fill', 'documentum come', 'drug company', 'facilitate online transaction', 'documentum', 'other organization']"
337,1034,Vibration control of the rotating flexible-shaft/multi-flexible-disk system with the eddy-current damper,"in this paper, the rotating flexible-timoshenko-shaft/flexible-disk coupling system is formulated by applying the assumed-mode method into the kinetic and strain energies, and the virtual work done by the eddy-current damper. from lagrange's equations, the resulting discretized equations of motion can be simplified as a bilinear system (bls). introducing the control laws, including the quadratic, nonlinear and optimal feedback control laws, into the bls, it is found that the eddy-current damper can be used to suppress flexible and shear vibrations simultaneously, and the system is globally asymptotically stable. numerical results are provided to validate the theoretical analysis","['rotating flexible-shaft/multi-flexible-disk system', 'eddy-current damper', 'rotating flexible-timoshenko-shaft/flexible-disk coupling system', 'assumed-mode method', 'virtual work', ""lagrange's equations"", 'discretized equations of motion', 'bilinear system', 'optimal feedback control laws', 'shear vibrations', 'quadratic feedback control laws', 'nonlinear feedback control laws', 'flexible vibrations']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['rotate flexible - shaft / multi - flexible - disk system', 'eddy - current damper', 'rotate flexible - timoshenko - shaft / flexible - disk coupling system', 'assume - mode method', 'virtual work', ""lagrange 's equation"", 'discretized equation of motion', 'bilinear system', 'optimal feedback control law', 'shear vibration', 'quadratic feedback control law', 'nonlinear feedback control law', 'flexible vibration']","['rotate flexible', 'shear vibration', 'damper', 'flexible', 'eddy', 'timoshenko', 'nonlinear', 'shaft', 'disk coupling', 'lagrange']"
338,1071,Dense coding in entangled states,"we consider the dense coding of entangled qubits shared between two parties, alice and bob. the efficiency of classical information gain through quantum entangled qubits is also considered for the case of pairwise entangled qubits and maximally entangled qubits. we conclude that using the pairwise entangled qubits can be more efficient when two parties communicate whereas using the maximally entangled qubits can be more efficient when the n parties communicate","['dense coding', 'entangled states', 'alice', 'bob', 'pairwise entangled qubits', 'maximally entangled qubits', 'classical information gain efficiency', 'quantum information processing', 'quantum communication']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'R']","['dense coding', 'entangle state', 'alice', 'bob', 'pairwise entangle qubit', 'maximally entangle qubit', 'classical information gain efficiency', 'quantum information processing', 'quantum communication']","['quantum entangle qubit', 'pairwise entangle qubit', 'entangle qubit share', 'entangle qubit', 'classical information gain', 'dense coding', 'party communicate', 'efficient', 'efficiency', 'alice']"
339,937,Use of neural networks in the analysis of particle size distribution by laser diffraction: tests with different particle systems,"the application of forward light scattering methods for estimating the particle size distribution (psd) is usually limited by the occurrence of multiple scattering, which affects the angular distribution of light in highly concentrated suspensions, thus resulting in false calculations by the conventionally adopted algorithms. in this paper, a previously proposed neural network-based method is tested with different particle systems, in order to evaluate its applicability. in the first step of the study, experiments were carried out with solid-liquid suspensions having different characteristics of particle shape and size distribution, under varying solid concentrations. the experimental results, consisting of the angular distribution of light intensity, particle shape and suspension concentration, were used as input data in the fitting of neural network models (nn) that replaced the optical model to provide the psd. the reference values of particle shape and psd for the nn fitting were based on image analysis. comparisons between the psd values computed by the nn model and the reference values indicate that the method can be used in monitoring the psd of particles with different shapes in highly concentrated suspensions, thus extending the range of application of forward laser diffraction to a number of systems with industrial interest","['particle size distribution', 'laser diffraction', 'forward light scattering', 'multiple scattering', 'angular distribution of light', 'solid-liquid suspensions', 'neural network modeling', 'image analysis', 'particle shape distribution', 'pattern recognition', 'powdered materials', 'backpropagation algorithm', 'fraunhofer optical model', 'fluidized catalytic cracking']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'U', 'M', 'M', 'U']","['particle size distribution', 'laser diffraction', 'forward light scatter', 'multiple scattering', 'angular distribution of light', 'solid - liquid suspension', 'neural network model', 'image analysis', 'particle shape distribution', 'pattern recognition', 'powdered material', 'backpropagation algorithm', 'fraunhofer optical model', 'fluidize catalytic cracking']","['forward light scatter method', 'forward laser diffraction', 'particle size distribution', 'particle shape', 'neural network model', 'scatter', 'optical model', 'particle system', 'vary solid concentration', 'liquid suspension']"
340,972,VoIP: leveraging existing cable architecture,"as operators prepare to enter the voice-over-ip fray, they are searching for ways to leverage their existing two-way, interactive infrastructure. there are several approaches for supporting voip on top of the core ip transport network. the one garnering the most interest, especially in the united states, is based on the packetcable 1.x architecture. this article discusses the packetcable-based approach","['voip', 'cable architecture', 'voice-over-ip', 'core ip transport network', 'united states', 'packetcable 1.x architecture', 'packetcable-based approach', 'two-way interactive infrastructure']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['voip', 'cable architecture', 'voice - over - ip', 'core ip transport network', 'united states', 'packetcable 1.x architecture', 'packetcable - base approach', 'two - way interactive infrastructure']","['core ip transport network', 'support voip', 'packetcable', 'interactive infrastructure', 'ip fray', 'voice', 'article discuss', 'operator', 'be several approach', 'exist']"
341,131,On biorthogonal nonuniform filter banks and tree structures,"this paper concerns biorthogonal nonuniform filter banks. it is shown that a tree structured filter bank is biorthogonal if it is equivalent to a tree structured filter bank whose matching constituent levels on the analysis and synthesis sides are themselves biorthogonal pairs. we then show that a stronger statement can be made about dyadic filter banks in general: that a dyadic filter bank is biorthogonal if both the analysis and synthesis banks can be decomposed into dyadic trees. we further show that these decompositions are stability and fir preserving. these results, derived for filter banks having filters with rational transfer functions, thus extend some of the earlier comparable results for orthonormal filter banks","['biorthogonal nonuniform filter banks', 'tree structured filter bank', 'biorthogonal pairs', 'dyadic filter banks', 'dyadic trees', 'fir preserving', 'rational transfer functions', 'stability preserving']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['biorthogonal nonuniform filter bank', 'tree structure filter bank', 'biorthogonal pair', 'dyadic filter bank', 'dyadic tree', 'fir preserve', 'rational transfer function', 'stability preserve']","['paper concern biorthogonal nonuniform filter bank', 'filter bank have filter', 'tree structure filter bank', 'dyadic filter bank', 'dyadic filter bank', 'synthesis bank', 'fir preserve', 'rational transfer function', 'dyadic tree', 'match constituent level']"
342,1249,Aggregators versus disintermediators: battling it out in the information superhighstreet,"perhaps the future of large-scale content aggregators is now no longer in doubt but this was not the case 10 years ago, when many leading industry experts were much more pessimistic in their predictions. in the year that dialog celebrates its thirtieth anniversary as the world's oldest and largest professional online information service, it is appropriate to look back at these changing perceptions, the reasons for these changes, and why the experts got it wrong. we also look at the present day; the value that large-scale content aggregators bring to the information supply chain; and we discuss why users would choose to use aggregators as opposed to going directly to the publishers","['disintermediators', 'large-scale content aggregators', 'online information service', 'information supply chain']","['P', 'P', 'P', 'P']","['disintermediator', 'large - scale content aggregator', 'online information service', 'information supply chain']","['scale content aggregator', 'large professional online information service', 'use aggregator', 'many lead industry expert', 'information supply chain', 'dialog celebrate', 'change perception', 'user', 'change', 'future']"
343,63,Geometric source separation: merging convolutive source separation with geometric beamforming,convolutive blind source separation and adaptive beamforming have a similar goal-extracting a source of interest (or multiple sources) while reducing undesired interferences. a benefit of source separation is that it overcomes the conventional cross-talk or leakage problem of adaptive beamforming. beamforming on the other hand exploits geometric information which is often readily available but not utilized in blind algorithms. we propose to join these benefits by combining cross-power minimization of second-order source separation with geometric linear constraints used in adaptive beamforming. we find that the geometric constraints resolve some of the ambiguities inherent in the independence criterion such as frequency permutations and degrees of freedom provided by additional sensors. we demonstrate the new method in performance comparisons for actual room recordings of two and three simultaneous acoustic sources,"['geometric source separation', 'geometric beamforming', 'convolutive blind source separation', 'adaptive beamforming', 'cross-talk', 'leakage problem', 'blind algorithms', 'cross-power minimization', 'second-order source separation', 'geometric linear constraints', 'frequency permutations', 'degrees of freedom', 'sensors', 'room recordings', 'acoustic sources']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['geometric source separation', 'geometric beamforming', 'convolutive blind source separation', 'adaptive beamforming', 'cross - talk', 'leakage problem', 'blind algorithm', 'cross - power minimization', 'second - order source separation', 'geometric linear constraint', 'frequency permutation', 'degree of freedom', 'sensor', 'room recording', 'acoustic source']","['convolutive blind source separation', 'adaptive beamforming', 'room recording', 'blind algorithm', 'reduce undesired interference', 'beamforme', 'geometric linear constraint', 'source separation', 'geometric constraint', 'power minimization']"
344,659,Integration - no longer a barrier? [agile business],web services will be a critical technology for enabling the 'agile business',"['agile business', 'web services', 'integration middleware', 'iona', 'amr research']","['P', 'P', 'M', 'U', 'U']","['agile business', 'web service', 'integration middleware', 'iona', 'amr research']","['agile business', 'web service', 'critical technology', 'enable']"
345,1148,Benchmarking of the Dose Planning Method (DPM) Monte Carlo code using electron beams from a racetrack microtron,"a comprehensive set of measurements and calculations has been conducted to investigate the accuracy of the dose planning method (dpm) monte carlo code for dose calculations from 10 and 50 mev scanned electron beams produced from a racetrack microtron. central axis depth dose measurements and a series of profile scans at various depths were acquired in a water phantom using a scanditronix type rk ion chamber. source spatial distributions for the monte carlo calculations were reconstructed from in-air ion chamber measurements carried out across the two-dimensional beam profile at 100 cm downstream from the source. the in-air spatial distributions were found to have full width at half maximum of 4.7 and 1.3 cm, at 100 cm from the source, for the 10 and 50 mev beams, respectively. energy spectra for the 10 and 50 mev beams were determined by simulating the components of the microtron treatment head using the code mcnp4b. dpm calculations are on average within +or-2% agreement with measurement for all depth dose and profile comparisons conducted in this study. the accuracy of the dpm code illustrated in this work suggests that dpm may be used as a valuable tool for electron beam dose calculations","['benchmarking', 'racetrack microtron', '50 mev', 'scanned electron beams', 'central axis depth dose measurements', 'profile scans', 'water phantom', 'ion chamber', 'source spatial distributions', 'two-dimensional beam profile', 'in-air spatial distributions', 'electron beam dose calculations', 'dose planning method monte carlo code', 'mcnp4b', 'radiotherapy treatment planning', 'electron transport', 'scoring parameters', '10 mev']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'M', 'M', 'U', 'R']","['benchmarke', 'racetrack microtron', '50 mev', 'scan electron beam', 'central axis depth dose measurement', 'profile scan', 'water phantom', 'ion chamber', 'source spatial distribution', 'two - dimensional beam profile', 'in - air spatial distribution', 'electron beam dose calculation', 'dose planning method monte carlo code', 'mcnp4b', 'radiotherapy treatment planning', 'electron transport', 'scoring parameter', '10 mev']","['mev scan electron beam', 'ion chamber measurement', 'rk ion chamber', 'axis depth dose measurement', 'monte carlo calculation', 'dose calculation', 'dpm calculation', 'mev beam', 'depth dose', 'beam']"
346,558,OS porting and application development for SoC,"to deliver improved usability in high-end portable consumer products, the use of an appropriate consumer operating system (os) is becoming far more widespread. using a commercially supported os also vastly increases the availability of supported applications. for the device developer, this trend adds major complexity to the problem of system implementation. porting a complete operating system to a new hardware design adds significantly to the development burden, increasing both time-to-market and expense. even for those familiar with the integration of a real-time os, the porting, validation and support of a complex platform os is a formidable task","['os porting', 'application development', 'consumer operating system', 'hardware design']","['P', 'P', 'P', 'P']","['os port', 'application development', 'consumer operating system', 'hardware design']","['appropriate consumer operating system', 'end portable consumer product', 'new hardware design', 'complete operating system', 'device developer', 'deliver improved usability', 'support application', 'complex platform', 'system implementation', 'port']"
347,892,Dementing disorders: volumetric measurement of cerebrospinal fluid to distinguish normal from pathologic finding - feasibility study,we have demonstrated that automated methods to describe the severity and distribution of cerebral atrophy are capable of providing diagnostic information in the classification of neurodegenerative diseases,"['dementing disorders', 'automated methods', 'diagnostic information', 'cerebrospinal fluid volumetric measurement', 'magnetic resonance imaging technique', 'medical diagnostic imaging', 'healthy subjects', 'normal-pathologic findings distinguishing', 'neurodegenerative diseases classification', 'cerebral atrophy distribution', 'cerebral atrophy severity']","['P', 'P', 'P', 'R', 'U', 'M', 'U', 'M', 'R', 'R', 'R']","['demente disorder', 'automate method', 'diagnostic information', 'cerebrospinal fluid volumetric measurement', 'magnetic resonance imaging technique', 'medical diagnostic imaging', 'healthy subject', 'normal - pathologic finding distinguish', 'neurodegenerative disease classification', 'cerebral atrophy distribution', 'cerebral atrophy severity']","['cerebral atrophy', 'diagnostic information', 'automate method', 'classification', 'severity', 'describe', 'distribution', 'demonstrate']"
348,1010,Robust self-tuning PID controller for nonlinear systems,"in this paper, we propose a robust self-tuning pid controller suitable for nonlinear systems. the control system employs a preload relay (p_relay) in series with a pid controller. the p_relay ensures a high gain to yield a robust performance. however, it also incurs a chattering phenomenon. in this paper, instead of viewing the chattering as an undesirable yet inevitable feature, we use it as a naturally occurring signal for tuning and re-tuning the pid controller as the operating regime digresses. no other explicit input signal is required. once the pid controller is tuned for a particular operating point, the relay may be disabled and chattering ceases correspondingly. however, it is invoked when there is a change in setpoint to another operating regime. in this way, the approach is also applicable to time-varying systems as the pid tuning can be continuous, based on the latest set of chattering characteristics. analysis is provided on the stability properties of the control scheme. simulation results for the level control of fluid in a spherical tank using the scheme are also presented","['robust self-tuning pid controller', 'nonlinear systems', 'preload relay', 'robust performance', 'chattering phenomenon', 'naturally occurring signal', 'operating regime', 'time-varying systems', 'stability properties', 'simulation results', 'spherical tank', 'controller tuning', 'controller re-tuning', 'relay disabling', 'continuous tuning', 'fluid level control']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'R']","['robust self - tune pid controller', 'nonlinear system', 'preload relay', 'robust performance', 'chatter phenomenon', 'naturally occur signal', 'operate regime', 'time - vary system', 'stability property', 'simulation result', 'spherical tank', 'controller tuning', 'controller re - tune', 'relay disable', 'continuous tuning', 'fluid level control']","['tune pid controller suitable', 'pid controller', 'pid tuning', 'preload relay', 'control system', 'p_relay ensure', 'nonlinear system', 'p_relay', 'level control', 'relay']"
349,1055,A re-examination of probability matching and rational choice,"in a typical probability learning task participants are presented with a repeated choice between two response alternatives, one of which has a higher payoff probability than the other. rational choice theory requires that participants should eventually allocate all their responses to the high-payoff alternative, but previous research has found that people fail to maximize their payoffs. instead, it is commonly observed that people match their response probabilities to the payoff probabilities. we report three experiments on this choice anomaly using a simple probability learning task in which participants were provided with (i) large financial incentives, (ii) meaningful and regular feedback, and (iii) extensive training. in each experiment large proportions of participants adopted the optimal response strategy and all three of the factors mentioned above contributed to this. the results are supportive of rational choice theory","['probability matching', 'rationality', 'probability learning task', 'payoff probability', 'rational choice theory', 'response probabilities', 'choice anomaly', 'large financial incentives', 'feedback', 'extensive training', 'optimal response strategy', 'meaningful regular feedback']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['probability match', 'rationality', 'probability learn task', 'payoff probability', 'rational choice theory', 'response probability', 'choice anomaly', 'large financial incentive', 'feedback', 'extensive training', 'optimal response strategy', 'meaningful regular feedback']","['typical probability learn task participant', 'simple probability learn task', 'optimal response strategy', 'rational choice theory', 'large financial incentive', 'high payoff probability', 'payoff probability', 'repeat choice', 'payoff alternative', 'response probability']"
350,701,High dynamic control of a three-level voltage-source-converter drive for a main strip mill,"a high dynamic control system for the alspa vdm 7000 medium-voltage drive was implemented, which provides fast torque response times of a few milliseconds despite the typically low switching frequency of gate-turn-off thyristors which is necessary to achieve high efficiency. the drive system consists of a three-level voltage-source converter with active front end and a synchronous motor. the drive has most recently been applied to a main strip mill. it provides a maximum of 8.3-mw mechanical power with a rated motor voltage of 3 kv. besides motor torque as the main control objective, the control system has to comply with a number of additional objectives and constraints like dc-link voltage regulation and balancing, current and torque harmonics, motor flux, and excitation","['strip mill', 'high dynamic control system', 'medium-voltage drive', 'switching frequency', 'gate-turn-off thyristors', 'efficiency', 'three-level voltage-source converter', 'synchronous motor', 'mechanical power', 'motor voltage', 'control objective', 'dc-link voltage regulation', 'torque harmonics', 'motor flux', 'excitation', 'dc-link voltage balancing', 'current harmonics', '8.3 mw', '3 kv']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U', 'M']","['strip mill', 'high dynamic control system', 'medium - voltage drive', 'switch frequency', 'gate - turn - off thyristor', 'efficiency', 'three - level voltage - source converter', 'synchronous motor', 'mechanical power', 'motor voltage', 'control objective', 'dc - link voltage regulation', 'torque harmonic', 'motor flux', 'excitation', 'dc - link voltage balancing', 'current harmonic', '8.3 mw', '3 kv']","['motor torque', 'rate motor voltage', 'voltage drive', 'high dynamic control system', 'torque harmonic', 'fast torque', 'level voltage', 'motor flux', 'alspa vdm', 'drive system']"
351,744,A virtual victory [virtual networks],newly fashionable virtual network operators look all set to clean up in the corporate sector,"['virtual network operators', 'corporate sector']","['P', 'P']","['virtual network operator', 'corporate sector']","['fashionable virtual network operator look', 'clean']"
352,1311,Blended implementation of block implicit methods for ODEs,"in this paper we further develop a new approach for naturally defining the nonlinear splittings needed for the implementation of block implicit methods for odes, which has been considered by brugnano [j. comput. appl. math. 116 (2000) 41] and by brugnano and trigiante [in: recent trends in numerical analysis, nova science, new york, 2000, pp. 81-105]. the basic idea is that of defining the numerical method as the combination (blending) of two suitable component methods. by carefully choosing such methods, it is shown that very efficient implementations can be obtained. moreover, some of them, characterized by a diagonal splitting, are well suited for parallel computers. numerical tests comparing the performances of the proposed implementation with existing ones are also presented, in order to make evident the potential of the approach","['blended implementation', 'block implicit methods', 'odes', 'nonlinear splittings', 'numerical method', 'diagonal splitting', 'parallel computers', 'numerical tests']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['blend implementation', 'block implicit method', 'ode', 'nonlinear splitting', 'numerical method', 'diagonal splitting', 'parallel computer', 'numerical test']","['block implicit method', 'numerical method', 'nonlinear splitting', 'efficient implementation', 'diagonal splitting', 'numerical analysis', 'parallel computer', 'numerical', 'component method', 'ode']"
353,1354,Design and analysis of optimal material distribution policies in flexible manufacturing systems using a single AGV,"modern automated manufacturing processes employ automated guided vehicles (agvs) for material handling, which serve several machine centres (mc) in a factory. optimal scheduling of agvs can significantly help to increase the efficiency of the manufacturing process by minimizing the idle time of mcs waiting for the raw materials. we analyse the requirements for an optimal schedule and then provide a mathematical framework for an efficient schedule of material delivery by an agv. a mathematical model is developed and then a strategy for optimal material distribution of the available raw material to the mcs is derived. with this model, the optimal number of mcs to be utilized is also determined. finally, the material delivery schedule employing multiple journeys to the mcs by the agv is carried out. through rigorous analysis and simulation experiments, we show that such a delivery strategy will optimize the overall performance","['optimal material distribution policies', 'flexible manufacturing systems', 'agv', 'automated guided vehicle', 'material handling', 'machine centres', 'optimal scheduling', 'material delivery', 'waiting time', 'manufacturing lead time', 'idle time minimization']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'R']","['optimal material distribution policy', 'flexible manufacturing system', 'agv', 'automate guide vehicle', 'material handling', 'machine centre', 'optimal scheduling', 'material delivery', 'wait time', 'manufacture lead time', 'idle time minimization']","['automate manufacturing process employ automate guide vehicle', 'material delivery schedule employ multiple journey', 'optimal scheduling', 'optimal schedule', 'optimal material distribution', 'serve several machine centre', 'efficient schedule', 'material delivery', 'manufacturing process', 'delivery strategy']"
354,1095,Development of a real-time monitoring system,"this paper describes a pattern recognition (pr) technique, which uses learning vector quantization (lvq). this method is adapted for practical application to solve problems in the area of condition monitoring and fault diagnosis where a number of fault signatures are involved. in these situations, the aim is health monitoring, including identification of deterioration of the healthy condition and identification of causes of the failure in real-time. for this reason a fault database is developed which contains the collected information about various states of operation of the system in the form of pattern vectors. the task of the real-time monitoring system is to correlate patterns of unknown faults with the known fault signatures in the fault database. this will determine cause of failure and degree of deterioration of the system under test. the problem of fault diagnosis may involve a large number of patterns and large sampling time, which affects the learning stage of neural networks. the study here also aims to find a fast learning model of neural networks for instances when a high number of patterns and numerous processing elements are involved. it begins searching for an appropriate solution. the study is extended to the enforcement learning models and considers lvq as a network emerged from the competitive learning model through enforcement training. finally, tests show an accuracy of 92.3 per cent in the fault diagnostic capability of the technique","['real-time monitoring system', 'learning vector quantization', 'lvq', 'condition monitoring', 'fault diagnosis', 'fault signatures', 'health monitoring', 'fault database', 'pattern vectors', 'large sampling time', 'neural networks', 'fast learning model', 'competitive learning model', 'enforcement training', 'fault diagnostic capability', 'pattern recognition technique', 'deterioration identification', 'real-time failure cause identification', 'pattern correlation', 'cnc machine centre', 'coolant system']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'U', 'M']","['real - time monitoring system', 'learn vector quantization', 'lvq', 'condition monitoring', 'fault diagnosis', 'fault signature', 'health monitoring', 'fault database', 'pattern vector', 'large sampling time', 'neural network', 'fast learning model', 'competitive learn model', 'enforcement training', 'fault diagnostic capability', 'pattern recognition technique', 'deterioration identification', 'real - time failure cause identification', 'pattern correlation', 'cnc machine centre', 'coolant system']","['use learn vector quantization', 'enforcement learning model', 'pattern recognition', 'neural network', 'pattern vector', 'competitive learn model', 'learn model', 'time monitor system', 'fault database', 'health monitoring']"
355,1444,Adaptable dialog boxes for cross-platform programming,"the author presents a framework for building dialog boxes that adapt to the look and feel of their platform. this method also helps with a few related problems: specifying cross-platform resources and handling dialog size changes due to localization. he uses a combination of xml, automatic layout, and run-time dialog creation to give you most of the benefits of platform-specific resources, without the associated pain. source code with an implementation of the layout engine for mac os 9.1 (""carbon""), mac os x, and microsoft windows can be downloaded from the cuj website at <www.cuj.com/code>. you can use this code as is, or as a starting point for your own more complete implementation","['adaptable dialog boxes', 'dialog boxes', 'cross-platform programming', 'cross-platform resources', 'dialog size changes', 'localization', 'xml', 'automatic layout', 'run-time dialog creation', 'platform-specific resources', 'mac os 9.1', 'mac os x', 'microsoft windows']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['adaptable dialog box', 'dialog box', 'cross - platform programming', 'cross - platform resource', 'dialog size change', 'localization', 'xml', 'automatic layout', 'run - time dialog creation', 'platform - specific resource', 'mac os 9.1', 'mac os x', 'microsoft window']","['build dialog box', 'dialog size change', 'time dialog creation', 'mac os', 'automatic layout', 'layout engine', 'platform resource', 'microsoft window', 'platform', 'framework']"
356,852,Building an effective computer science student organization: the Carnegie Mellon Women@SCS action plan,"this paper aims to provide a practical guide for building a student organization and designing activities and events that can encourage and support a community of women in computer science. this guide is based on our experience in building women@scs, a community of women in the school of computer science (scs) at carnegie mellon university. rather than provide an abstract ""to-do"" or ""must-do"" list, we present a sampling of concrete activities and events in the hope that these might suggest possibilities for a likeminded student organization. however, since we have found it essential to have a core group of activist students at the helm, we provide a ""to-do"" list of features that we feel are essential for forming, supporting and sustaining creative and effective student leadership","['computer science student organization', 'women@scs action plan', 'women', 'carnegie mellon university', 'student leadership', 'gender issues', 'computer science education']","['P', 'P', 'P', 'P', 'P', 'U', 'M']","['computer science student organization', 'women@scs action plan', 'woman', 'carnegie mellon university', 'student leadership', 'gender issue', 'computer science education']","['likeminde student organization', 'student organization', 'activist student', 'carnegie mellon university', 'design activity', 'core group', 'computer science', 'paper aim', 'sustain creative', 'woman']"
357,817,Summarization beyond sentence extraction: A probabilistic approach to sentence compression,"when humans produce summaries of documents, they do not simply extract sentences and concatenate them. rather, they create new sentences that are grammatical, that cohere with one another, and that capture the most salient pieces of information in the original document. given that large collections of text/abstract pairs are available online, it is now possible to envision algorithms that are trained to mimic this process. in this paper, we focus on sentence compression, a simpler version of this larger challenge. we aim to achieve two goals simultaneously: our compressions should be grammatical, and they should retain the most important pieces of information. these two goals can conflict. we devise both a noisy-channel and a decision-tree approach to the problem, and we evaluate results against manual compressions and a simple baseline","['sentence compression', 'grammatical', 'noisy-channel', 'decision-tree', 'document summarization']","['P', 'P', 'P', 'P', 'R']","['sentence compression', 'grammatical', 'noisy - channel', 'decision - tree', 'document summarization']","['sentence compression', 'extract sentence', 'create new sentence', 'human produce summary', 'manual compression', 'compression', 'abstract pair', 'original document', 'salient piece', 'tree approach']"
358,779,Domesticating computers and the Internet,"the people who use computers and the ways they use them have changed substantially over the past 25 years. in the beginning highly educated people, mostly men, in technical professions used computers for work, but over time a much broader range of people are using computers for personal and domestic purposes. this trend is still continuing, and over a shorter time scale has been replicated with the use of the internet. the paper uses data from four national surveys to document how personal computers and the internet have become increasingly domesticated since 1995 and to explore the mechanisms for this shift. now people log on more often from home than from places of employment and do so for pleasure and for personal purposes rather than for their jobs. analyses comparing veteran internet users to novices in 1998 and 2000 and analyses comparing the change in use within a single sample between 1995 and 1996 support two complementary explanations for how these technologies have become domesticated. women, children, and less well-educated individuals are increasingly using computers and the internet and have a more personal set of motives than well-educated men. in addition, the widespread diffusion of the pc and the internet and the response of the computing industry to the diversity in consumers has led to a rich set of personal and domestic services","['internet', 'highly educated people', 'technical professions', 'domestic purposes', 'national surveys', 'personal computers', 'veteran internet users', 'novices', 'women', 'children', 'computing industry', 'domestic services', 'computer domestication', 'personal usage', 'personal motives', 'pc diffusion', 'demographics', 'online behavior']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'R', 'R', 'U', 'U']","['internet', 'highly educate people', 'technical profession', 'domestic purpose', 'national survey', 'personal computer', 'veteran internet user', 'novice', 'woman', 'child', 'compute industry', 'domestic service', 'computer domestication', 'personal usage', 'personal motive', 'pc diffusion', 'demographic', 'online behavior']","['analysis compare veteran internet user', 'technical profession use computer', 'use computer', 'personal computer', 'use computer', 'paper use datum', 'domestic purpose', 'national survey', 'compute industry', 'personal purpose']"
359,1369,Use of Bayesian Belief Networks when combining disparate sources of information in the safety assessment of software-based systems,"the paper discusses how disparate sources of information can be combined in the safety assessment of software-based systems. the emphasis is put on an emerging methodology, relevant for intelligent product-support systems, to combine information about disparate evidences systematically based on bayesian belief networks. the objective is to show the link between basic information and the confidence one can have in a system. how one combines the bayesian belief net (bbn) method with a software safety standard (rtca/do-178b,) for safety assessment of software-based systems is also discussed. finally, the applicability of the bbn methodology and experiences from cooperative research work together with kongsberg defence & aerospace and det norske veritas, and ongoing research with vtt automation are presented","['bayesian belief networks', 'safety assessment', 'software-based systems', 'intelligent product-support systems', 'software safety standard']","['P', 'P', 'P', 'P', 'P']","['bayesian belief network', 'safety assessment', 'software - base system', 'intelligent product - support system', 'software safety standard']","['bayesian belief network', 'software safety standard', 'bayesian belief net', 'vtt automation', 'base system', 'safety assessment', 'support system', 'software', 'bbn methodology', 'intelligent product']"
360,1394,Subject access to government documents in an era of globalization: intellectual bundling of entities affected by the decisions of supranational organizations,"as a result of the growing influence of supranational organizations, there is a need for a new model for subject access to government information in academic libraries. rulings made by supranational bodies such as the world trade organization (wto) and rulings determined under the auspices of transnational economic agreements such as the north american free trade agreement (nafta) often supersede existing law, resulting in obligatory changes to national, provincial, state, and municipal legislation. just as important is the relationship among private sector companies, third party actors such as nongovernmental organizations (ngos), and governments. the interaction among the various entities affected by supranational rulings could potentially form the basis of a new model for subject access to government information","['government documents', 'globalization', 'intellectual bundling', 'supranational organizations', 'academic libraries', 'world trade organization', 'transnational economic agreements', 'north american free trade agreement', 'municipal legislation', 'national legislation', 'provincial legislation', 'state legislation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['government document', 'globalization', 'intellectual bundling', 'supranational organization', 'academic library', 'world trade organization', 'transnational economic agreement', 'north american free trade agreement', 'municipal legislation', 'national legislation', 'provincial legislation', 'state legislation']","['transnational economic agreement such', 'nongovernmental organization', 'government information', 'supranational organization', 'private sector company', 'supranational ruling', 'municipal legislation', 'world trade organization', 'academic library', 'supersede exist law']"
361,784,Where tech is cheap [servers],"talk, consultancy, support, not tech is the expensive part of network installations. it's a good job that small-scale servers can either be remotely managed, or require little actual management","['network installations', 'small-scale servers', 'management']","['P', 'P', 'P']","['network installation', 'small - scale server', 'management']","['network installation', 'scale server', 'tech', 'consultancy', 'expensive part', 'job', 'manage', 'small', 'support', 'talk']"
362,1068,Quantum phase gate for photonic qubits using only beam splitters and postselection,we show that a beam splitter of reflectivity one-third can be used to realize a quantum phase gate operation if only the outputs conserving the number of photons on each side are postselected,"['quantum phase gate', 'photonic qubits', 'postselection', 'reflectivity', 'quantum phase gate operation', 'outputs', 'multiqubit networks', 'postselected quantum gate', 'optical quantum gate operations', 'photon number conservation', 'postselected photon number conserving outputs', 'quantum computation', 'quantum information processing', 'postselected quantum phase gate', 'polarization beam splitters']","['P', 'P', 'P', 'P', 'P', 'P', 'U', 'R', 'M', 'R', 'R', 'M', 'M', 'R', 'M']","['quantum phase gate', 'photonic qubit', 'postselection', 'reflectivity', 'quantum phase gate operation', 'output', 'multiqubit network', 'postselecte quantum gate', 'optical quantum gate operation', 'photon number conservation', 'postselecte photon number conserve output', 'quantum computation', 'quantum information processing', 'postselecte quantum phase gate', 'polarization beam splitter']","['quantum phase gate operation', 'beam splitter', 'photon', 'reflectivity', 'output conserve', 'third', 'side', 'show', 'number', 'realize']"
363,699,Novel line conditioner with voltage up/down capability,"in this paper, a novel pulsewidth-modulated line conditioner with fast output voltage control is proposed. the line conditioner is made up of an ac chopper with reversible voltage control and a transformer for series voltage compensation. in the ac chopper, a proper switching operation is achieved without the commutation problem. to absorb energy stored in line stray inductance, a regenerative dc snubber can be utilized which has only one capacitor without discharging resistors or complicated regenerative circuit for snubber energy. therefore, the proposed ac chopper gives high efficiency and reliability. the output voltage of the line conditioner is controlled using a fast sensing technique of the output voltage. it is also shown via some experimental results that the presented line conditioner gives good dynamic and steady-state performance for high quality of the output voltage","['pulsewidth-modulated line conditioner', 'output voltage control', 'ac chopper', 'reversible voltage control', 'switching operation', 'commutation', 'line stray inductance', 'regenerative dc snubber', 'steady-state performance', 'series voltage compensation transformer', 'dynamic performance']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['pulsewidth - modulate line conditioner', 'output voltage control', 'ac chopper', 'reversible voltage control', 'switch operation', 'commutation', 'line stray inductance', 'regenerative dc snubber', 'steady - state performance', 'series voltage compensation transformer', 'dynamic performance']","['ac chopper give', 'modulate line conditioner', 'ac chopper', 'line conditioner give', 'output voltage control', 'line conditioner', 'reversible voltage control', 'dc snubber', 'output voltage', 'series voltage compensation']"
364,1289,Combining PC control and HMI,"integrating pc-based control with human machine interface (hmi) technology can benefit a plant floor system. however, before one decides on pc-based control, there are many things one should consider, especially when using a soft programmable logic controller (plc) to command the input/output. there are three strategies to integrate a pc-based control system with an hmi: treat the pc running the control application as if it were a plc, integrate the system using standard pc interfaces; or using application programming interfaces","['human machine interface', 'programmable logic controller', 'pc-based control system', 'pc interfaces', 'application programming interfaces', 'shop floor system']","['P', 'P', 'P', 'P', 'P', 'M']","['human machine interface', 'programmable logic controller', 'pc - base control system', 'pc interface', 'application programming interface', 'shop floor system']","['system use standard pc interface', 'soft programmable logic controller', 'human machine interface', 'base control system', 'plant floor system', 'control application', 'plc', 'integrate pc', 'base control', 'pc run']"
365,1175,Prediction of tool and chip temperature in continuous and interrupted machining,"a numerical model based on the finite difference method is presented to predict tool and chip temperature fields in continuous machining and time varying milling processes. continuous or steady state machining operations like orthogonal cutting are studied by modeling the heat transfer between the tool and chip at the tool-rake face contact zone. the shear energy created in the primary zone, the friction energy produced at the rake face-chip contact zone and the heat balance between the moving chip and stationary tool are considered. the temperature distribution is solved using the finite difference method. later, the model is extended to milling where the cutting is interrupted and the chip thickness varies with time. the proposed model combines the steady-state temperature prediction in continuous machining with transient temperature evaluation in interrupted cutting operations where the chip and the process change in a discontinuous manner. the mathematical models and simulation results are in satisfactory agreement with experimental temperature measurements reported in the literature","['interrupted machining', 'numerical model', 'finite difference method', 'continuous machining', 'time varying milling processes', 'orthogonal cutting', 'heat transfer', 'tool-rake face contact zone', 'shear energy', 'primary zone', 'friction energy', 'temperature distribution', 'tool temperature prediction', 'chip temperature prediction', 'first-order dynamic system', 'thermal properties']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U', 'U']","['interrupt machining', 'numerical model', 'finite difference method', 'continuous machining', 'time vary milling process', 'orthogonal cutting', 'heat transfer', 'tool - rake face contact zone', 'shear energy', 'primary zone', 'friction energy', 'temperature distribution', 'tool temperature prediction', 'chip temperature prediction', 'first - order dynamic system', 'thermal property']","['continuous machining', 'chip temperature', 'machine operation', 'milling process', 'interrupt cut operation', 'temperature prediction', 'transient temperature', 'mill', 'temperature', 'chip contact zone']"
366,1130,Node-capacitated ring routing,"we consider the node-capacitated routing problem in an undirected ring network along with its fractional relaxation, the node-capacitated multicommodity flow problem. for the feasibility problem, farkas' lemma provides a characterization for general undirected graphs, asserting roughly that there exists such a flow if and only if the so-called distance inequality holds for every choice of distance functions arising from nonnegative node weights. for rings, this (straightforward) result will be improved in two ways. we prove that, independent of the integrality of node capacities, it suffices to require the distance inequality only for distances arising from (0-1-2)-valued node weights, a requirement that will be called the double-cut condition. moreover, for integer-valued node capacities, the double-cut condition implies the existence of a half-integral multicommodity flow. in this case there is even an integer-valued multicommodity flow that violates each node capacity by at most one. our approach gives rise to a combinatorial, strongly polynomial algorithm to compute either a violating double-cut or a node-capacitated multicommodity flow. a relation of the problem to its edge-capacitated counterpart will also be explained","['node-capacitated ring routing', 'node-capacitated routing problem', 'undirected ring network', 'fractional relaxation', 'node-capacitated multicommodity flow problem', 'feasibility problem', 'undirected graphs', 'distance inequality', 'distance functions', 'nonnegative node weights', 'double-cut condition', 'integer-valued node capacities', 'half-integral multicommodity flow', 'integer-valued multicommodity flow', 'violating double-cut', 'farkas lemma', 'node capacity integrality', 'combinatorial strongly polynomial algorithm', 'edge-cut criterion']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'U']","['node - capacitate ring route', 'node - capacitate routing problem', 'undirected ring network', 'fractional relaxation', 'node - capacitate multicommodity flow problem', 'feasibility problem', 'undirected graph', 'distance inequality', 'distance function', 'nonnegative node weight', 'double - cut condition', 'integer - value node capacity', 'half - integral multicommodity flow', 'integer - value multicommodity flow', 'violate double - cut', 'farkas lemma', 'node capacity integrality', 'combinatorial strongly polynomial algorithm', 'edge - cut criterion']","['capacitate multicommodity flow problem', 'capacitate multicommodity flow', 'value node capacity', 'value multicommodity flow', 'nonnegative node weight', 'node capacity', 'multicommodity flow', 'capacitate route problem', 'node capacity', 'node weight']"
367,565,Control of thin film growth in chemical vapor deposition manufacturing systems: a feasibility study,"a study is carried out to design and optimize chemical vapor deposition (cvd) systems for material fabrication. design and optimization of the cvd process is necessary to satisfying strong global demand and ever increasing quality requirements for thin film production. advantages of computer aided optimization include high design turnaround time, flexibility to explore a larger design space and the development and adaptation of automation techniques for design and optimization. a cvd reactor consisting of a vertical impinging jet at atmospheric pressure, for growing titanium nitride films, is studied for thin film deposition. numerical modeling and simulation are used to determine the rate of deposition and film uniformity over a wide range of design variables and operating conditions. these results are used for system design and optimization. the optimization procedure employs an objective function characterizing film quality, productivity and operational costs based on reactor gas flow rate, susceptor temperature and precursor concentration. parameter space mappings are used to determine the design space, while a minimization algorithm, such as the steepest descent method, is used to determine optimal operating conditions for the system. the main features of computer aided design and optimization using these techniques are discussed in detail","['thin film growth', 'chemical vapor deposition', 'optimization', 'material fabrication', 'titanium nitride films', 'film quality', 'operational costs', 'reactor gas flow rate', 'susceptor temperature', 'precursor concentration', 'parameter space mappings', 'tin']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U']","['thin film growth', 'chemical vapor deposition', 'optimization', 'material fabrication', 'titanium nitride film', 'film quality', 'operational cost', 'reactor gas flow rate', 'susceptor temperature', 'precursor concentration', 'parameter space mapping', 'tin']","['optimize chemical vapor deposition', 'titanium nitride film', 'optimization procedure employ', 'cvd reactor', 'thin film deposition', 'computer aid optimization include', 'thin film production', 'minimization algorithm', 'optimization', 'reactor gas flow rate']"
368,598,From FREE to FEE [online advertising market],"as the online advertising market continues to struggle, many online content marketers are wrestling with the issue of how to add at least some level of paid subscription income to their revenue mix in order to reach or improve profitability. since the business of selling content online is still in its infancy, and many consumers clearly still think of web content as simply and rightfully free, few roadmaps are available to show the way to effective marketing strategies, but some guiding principles have emerged","['online advertising market', 'paid subscription income', 'selling content online', 'marketing strategies']","['P', 'P', 'P', 'P']","['online advertising market', 'pay subscription income', 'sell content online', 'marketing strategy']","['online advertising market continue', 'many online content marketer', 'effective marketing strategy', 'pay subscription income', 'sell content', 'web content', 'improve profitability', 'revenue mix', 'many consumer', 'business']"
369,1188,It's time to buy,"there is an upside to a down economy: over-zealous suppliers are willing to make deals that were unthinkable a few years ago. that's because vendors are experiencing the same money squeeze as manufacturers, which makes the year 2002 the perfect time to invest in new technology. the author states that when negotiating the deal, provisions for unexpected costs, an exit strategy, and even shared risk with the vendor should be on the table","['suppliers', 'vendor', 'money squeeze', 'negotiation', 'unexpected costs', 'exit strategy', 'shared risk', 'buyers market', 'bargaining power']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'U']","['supplier', 'vendor', 'money squeeze', 'negotiation', 'unexpected cost', 'exit strategy', 'share risk', 'buyer market', 'bargaining power']","['zealous supplier', 'down economy', 'make deal', 'vendor', 'manufacturer', 'new technology', 'unexpected cost', 'vendor', 'exit strategy', 'negotiate']"
370,1274,Bounded model checking for the universal fragment of CTL,bounded model checking (bmc) has been recently introduced as an efficient verification method for reactive systems. bmc based on sat methods consists in searching for a counterexample of a particular length and generating a propositional formula that is satisfiable iff such a counterexample-exists. this new technique has been introduced by e. clarke et al. for model checking of linear time temporal logic (ltl). our paper shows how the concept of bounded model checking can be extended to actl (the universal fragment of ctl). the implementation of the algorithm for elementary net systems is described together with the experimental results,"['bounded model checking', 'model checking', 'universal fragment', 'verification method', 'reactive systems', 'sat methods', 'propositional formula', 'linear time temporal logic', 'elementary net systems', 'bounded semantics']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['bound model check', 'model check', 'universal fragment', 'verification method', 'reactive system', 'sit method', 'propositional formula', 'linear time temporal logic', 'elementary net system', 'bound semantic']","['linear time temporal logic', 'bound model check', 'model check', 'reactive system', 'elementary net system', 'satisfiable iff', 'efficient verification method', 'sit method consist', 'ltl', 'propositional formula']"
371,1231,Efficient parallel programming on scalable shared memory systems with High Performance Fortran,"openmp offers a high-level interface for parallel programming on scalable shared memory (smp) architectures. it provides the user with simple work-sharing directives while it relies on the compiler to generate parallel programs based on thread parallelism. however, the lack of language features for exploiting data locality often results in poor performance since the non-uniform memory access times on scalable smp machines cannot be neglected. high performance fortran (hpf), the de-facto standard for data parallel programming, offers a rich set of data distribution directives in order to exploit data locality, but it has been mainly targeted towards distributed memory machines. in this paper we describe an optimized execution model for hpf programs on smp machines that avails itself with mechanisms provided by openmp for work sharing and thread parallelism, while exploiting data locality based on user-specified distribution directives. data locality does not only ensure that most memory accesses are close to the executing threads and are therefore faster, but it also minimizes synchronization overheads, especially in the case of unstructured reductions. the proposed shared memory execution model for hpf relies on a small set of language extensions, which resemble the openmp work-sharing features. these extensions, together with an optimized shared memory parallelization and execution model, have been implemented in the adaptor hpf compilation system and experimental results verify the efficiency of the chosen approach","['parallel programming', 'scalable shared memory', 'high performance fortran', 'multiprocessor architectures', 'scalable hardware', 'shared memory multiprocessor']","['P', 'P', 'P', 'M', 'M', 'M']","['parallel programming', 'scalable share memory', 'high performance fortran', 'multiprocessor architecture', 'scalable hardware', 'share memory multiprocessor']","['optimize share memory parallelization', 'propose share memory execution', 'scalable share memory', 'distribute memory machine', 'datum parallel programming', 'scalable smp machine', 'adaptor hpf compilation system', 'exploit datum locality', 'high performance fortran', 'exploit datum locality']"
372,664,The agile revolution [business agility],"there is a new business revolution in the air. the theory is there, the technology is evolving, fast. it is all about agility","['business agility', 'software design', 'software deployment', 'organisational structures', 'supply chains']","['P', 'U', 'U', 'U', 'U']","['business agility', 'software design', 'software deployment', 'organisational structure', 'supply chain']","['new business revolution', 'technology', 'evolve', 'theory', 'air', 'be']"
373,621,MPEG-4 video object-based rate allocation with variable temporal rates,"in object-based coding, bit allocation is performed at the object level and temporal rates of different objects may vary. the proposed algorithm deals with these two issues when coding multiple video objects (mvos). the proposed algorithm is able to successfully achieve the target bit rate, effectively code arbitrarily shaped mvos with different temporal rates, and maintain a stable buffer level","['object-based rate allocation', 'variable temporal rates', 'bit allocation', 'multiple video objects', 'mpeg-4 video coding', 'rate-distortion encoding']","['P', 'P', 'P', 'P', 'R', 'U']","['object - base rate allocation', 'variable temporal rate', 'bit allocation', 'multiple video object', 'mpeg-4 video coding', 'rate - distortion encoding']","['code multiple video object', 'bit allocation', 'base code', 'target bit rate', 'different object', 'shape mvos', 'different temporal rate', 'object level', 'propose algorithm deal', 'code']"
374,1438,Three-dimensional particle image tracking for dilute particle-liquid flows in a pipe,"a three-dimensional (3d) particle image tracking technique was used to study the coarse spherical particle-liquid flows in a pipe. the flow images from both the front view and the normal side view, which was reflected into the front view by a mirror, were recorded with a ccd camera and digitized by a pc with an image grabber card. an image processing program was developed to enhance and segment the flow image, and then to identify the particles. over 90% of all the particles can be identified and located from the partially overlapped particle images using the circular hough transform. then the 3d position of each detected particle was determined by matching its front view image to its side view image. the particle velocity was then obtained by pairing its images in successive video fields. the measurements for the spherical expanded polystyrene particle-oil flows show that the particles, like the spherical bubbles in laminar bubbly flows, tend to conglomerate near the pipe wall and to line up to form the particle clusters. as liquid velocity decreases, the particle clusters disperse and more particles are distributed in the pipe centre region","['three-dimensional particle image tracking', 'dilute particle-liquid flows', 'ccd camera', 'hough transform', '3d position', 'spherical bubble', 'particle clusters', 'two-phase flow', 'pipe flow', 'stereo-imaging technique', 'phase distribution', 'spherical expanded polystyrene particle', 'wiener filter', 'image segmentation', 'region growing technique', 'image recognition', 'image matching']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'M', 'M', 'R', 'U', 'R', 'M', 'M', 'R']","['three - dimensional particle image tracking', 'dilute particle - liquid flow', 'ccd camera', 'hough transform', '3d position', 'spherical bubble', 'particle cluster', 'two - phase flow', 'pipe flow', 'stereo - imaging technique', 'phase distribution', 'spherical expand polystyrene particle', 'wiener filter', 'image segmentation', 'region grow technique', 'image recognition', 'image matching']","['particle image tracking technique', 'overlap particle image use', 'coarse spherical particle', 'liquid flow', 'particle cluster disperse', 'flow image', 'laminar bubbly flow', 'flow image', 'polystyrene particle', 'oil flow show']"
375,705,Use of extra degrees of freedom in multilevel drives,"multilevel converters with series connection of semiconductors allow power electronics to reach medium voltages (1-10 kv) with relatively standard components. the increase of the number of semiconductors provides extra degrees of freedom, which can be used to improve different characteristics. this paper is focused on variable-speed drives and it is shown that with the proposed multilevel direct torque control strategy (dicoif) the tradeoff between the performances of the drive (harmonic distortions, torque dynamics, voltage step gradients, etc.) and the switching frequency of the semiconductors is improved. then, a slightly modified strategy reducing common-mode voltage and bearing currents is presented","['degrees of freedom', 'multilevel drives', 'series connection', 'semiconductors', 'power electronics', 'medium voltages', 'variable-speed drives', 'multilevel direct torque control strategy', 'harmonic distortions', 'torque dynamics', 'voltage step gradients', 'switching frequency', 'bearing currents', 'common-mode voltage reduction', 'delay estimation', 'industrial power systems', 'insulated gate bipolar transistors', 'state estimation', 'fixed-frequency dynamic control', '1 to 10 kv']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U', 'M', 'U', 'U', 'M', 'R']","['degree of freedom', 'multilevel drive', 'series connection', 'semiconductor', 'power electronic', 'medium voltage', 'variable - speed drive', 'multilevel direct torque control strategy', 'harmonic distortion', 'torque dynamic', 'voltage step gradient', 'switch frequency', 'bear current', 'common - mode voltage reduction', 'delay estimation', 'industrial power system', 'insulate gate bipolar transistor', 'state estimation', 'fix - frequency dynamic control', '1 to 10 kv']","['multilevel converter', 'drive', 'mode voltage', 'torque control', 'medium voltage', 'power electronic', 'drive', 'voltage', 'switch', 'standard component']"
376,740,The Malaysian model,"japan's first third generation service, foma, is unlikely to be truly attractive to consumers until 2005. that still falls well within the financial planning of its operator docomo. but where does that leave european 3g operators looking for reassurance? malaysia, says simon marshall","['malaysia', '3g operators', 'maxis communications', 'telekom malaysia']","['P', 'P', 'U', 'M']","['malaysia', '3 g operator', 'maxis communication', 'telekom malaysia']","['first third generation service', 'foma', 'financial planning', 'japan', 'malaysia', 'operator docomo', 'consumer', 'reassurance', 'leave european', 'operator look']"
377,1315,Traffic engineering with traditional IP routing protocols,"traffic engineering involves adapting the routing of traffic to network conditions, with the joint goals of good user performance and efficient use of network resources. we describe an approach to intradomain traffic engineering that works within the existing deployed base of interior gateway protocols, such as open shortest path first and intermediate system-intermediate system. we explain how to adapt the configuration of link weights, based on a networkwide view of the traffic and topology within a domain. in addition, we summarize the results of several studies of techniques for optimizing ospf/is-is weights to the prevailing traffic. the article argues that traditional shortest path routing protocols are surprisingly effective for engineering the flow of traffic in large ip networks","['ip routing protocols', 'network conditions', 'user performance', 'network resources', 'intradomain traffic engineering', 'interior gateway protocols', 'ospf/is-is weights', 'shortest path routing protocols', 'ip networks', 'link weights configuration', 'traffic routing', 'network topology', 'tcp', 'transmission control protocol', 'open shortest path first protocol', 'intermediate system-intermediate system protocol']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'U', 'M', 'R', 'R']","['ip route protocol', 'network condition', 'user performance', 'network resource', 'intradomain traffic engineering', 'interior gateway protocol', 'ospf / be - be weight', 'short path route protocol', 'ip network', 'link weight configuration', 'traffic route', 'network topology', 'tcp', 'transmission control protocol', 'open short path first protocol', 'intermediate system - intermediate system protocol']","['traditional short path route protocol', 'traffic engineering involve adapt', 'intradomain traffic engineering', 'interior gateway protocol', 'optimize ospf', 'open short path first', 'prevail traffic', 'network resource', 'route', 'traffic']"
378,1350,Generalized mosaicing: wide field of view multispectral imaging,"we present an approach to significantly enhance the spectral resolution of imaging systems by generalizing image mosaicing. a filter transmitting spatially varying spectral bands is rigidly attached to a camera. as the system moves, it senses each scene point multiple times, each time in a different spectral band. this is an additional dimension of the generalized mosaic paradigm, which has demonstrated yielding high radiometric dynamic range images in a wide field of view, using a spatially varying density filter. the resulting mosaic represents the spectrum at each scene point. the image acquisition is as easy as in traditional image mosaics. we derive an efficient scene sampling rate, and use a registration method that accommodates the spatially varying properties of the filter. using the data acquired by this method, we demonstrate scene rendering under different simulated illumination spectra. we are also able to infer information about the scene illumination. the approach was tested using a standard 8-bit black/white video camera and a fixed spatially varying spectral (interference) filter","['generalized mosaicing', 'wide field of view multispectral imaging', 'spatially varying spectral bands', 'spatially varying density filter', 'image acquisition', 'scene sampling rate', 'registration method', 'scene rendering', 'simulated illumination spectra', 'scene illumination', 'hyperspectral imaging', 'color balance', 'image fusion', 'physics-based vision', 'image-based rendering']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U', 'M', 'U', 'M']","['generalize mosaicing', 'wide field of view multispectral imaging', 'spatially vary spectral band', 'spatially vary density filter', 'image acquisition', 'scene sample rate', 'registration method', 'scene render', 'simulate illumination spectra', 'scene illumination', 'hyperspectral imaging', 'color balance', 'image fusion', 'physics - base vision', 'image - base render']","['different simulated illumination spectra', 'high radiometric dynamic range image', 'generalize image mosaice', 'demonstrate scene render', 'spectral resolution', 'scene illumination', 'image mosaic', 'white video camera', 'generalize mosaic paradigm', 'vary spectral band']"
379,896,Calculation of the probability of survival of an insurance company with allowance for the rate of return for a Poisson stream of premiums,the probability of survival of an insurance company with the working capital is calculated for a poisson stream of premiums,"['insurance company', 'survival probability', 'return rate', 'poisson premium stream', 'probability density function']","['P', 'R', 'R', 'R', 'M']","['insurance company', 'survival probability', 'return rate', 'poisson premium stream', 'probability density function']","['insurance company', 'poisson stream', 'work capital', 'probability', 'survival', 'calculate']"
380,1014,"Modelling of complete robot dynamics based on a multi-dimensional, RBF-like neural architecture","a neural network based identification approach of manipulator dynamics is presented. for a structured modelling, rbf-like static neural networks are used in order to represent and adapt all model parameters with their non-linear dependences on the joint positions. the neural architecture is hierarchically organised to reach optimal adjustment to structural a priori-knowledge about the identification problem. the model structure is substantially simplified by general system analysis independent of robot type. but also a lot of specific features of the utilised experimental robot are taken into account. a fixed, grid based neuron placement together with application of b-spline polynomial basis functions is utilised favourably for a very effective recursive implementation of the neural architecture. thus, an online identification of a dynamic model is submitted for a complete 6 joint industrial robot","['complete robot dynamics', 'neural architecture', 'manipulator dynamics', 'static neural networks', 'general system analysis', 'b-spline polynomial basis functions', 'recursive implementation', 'online identification', 'dynamic model', 'complete 6 joint industrial robot', 'multi-dimensional rbf-like neural architecture', 'fixed grid based neuron placement', 'online learning']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M']","['complete robot dynamic', 'neural architecture', 'manipulator dynamic', 'static neural network', 'general system analysis', 'b - spline polynomial basis function', 'recursive implementation', 'online identification', 'dynamic model', 'complete 6 joint industrial robot', 'multi - dimensional rbf - like neural architecture', 'fix grid base neuron placement', 'online learning']","['manipulator dynamic', 'neural network base identification', 'static neural network', 'grid base neuron', 'dynamic model', 'neural architecture', 'model parameter', 'spline polynomial basis function', 'structure modelling', 'robot']"
381,1051,Faking it: simulating dependent types in Haskell,"dependent types reflect the fact that validity of data is often a relative notion by allowing prior data to affect the types of subsequent data. not only does this make for a precise type system, but also a highly generic one: both the type and the program for each instance of a family of operations can be computed from the data which codes for that instance. recent experimental extensions to the haskell type class mechanism give us strong tools to relativize types to other types. we may simulate some aspects of dependent typing by making counterfeit type-level copies of data, with type constructors simulating data constructors and type classes simulating datatypes. this paper gives examples of the technique and discusses its potential","['dependent types', 'dependent types', 'haskell', 'precise type system', 'type class mechanism', 'counterfeit type-level copies', 'type constructors', 'data constructors', 'datatypes', 'data validity', 'dependent typing', 'functional programming']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'P', 'M']","['dependent type', 'dependent type', 'haskell', 'precise type system', 'type class mechanism', 'counterfeit type - level copy', 'type constructor', 'datum constructor', 'datatype', 'datum validity', 'dependent typing', 'functional programming']","['type constructor simulate data constructor', 'type class simulate datatype', 'haskell type class mechanism give', 'dependent type reflect', 'relativize type', 'make counterfeit type', 'other type', 'precise type system', 'type', 'allow prior datum']"
382,1109,The existence condition of gamma -acyclic database schemes with MVDs constraints,"it is very important to use database technology for a large-scale system such as erp and mis. a good database design may improve the performance of the system. some research shows that a gamma -acyclic database scheme has many good properties, e.g., each connected join expression is monotonous, which helps to improve query performance of the database system. thus what conditions are needed to generate a gamma -acyclic database scheme for a given relational scheme? in this paper, the sufficient and necessary condition of the existence of gamma -acyclic, join-lossless and dependencies-preserved database schemes meeting 4nf is given","['existence condition', 'gamma -acyclic database schemes', 'mvds constraints', 'database technology', 'large-scale system', 'connected join expression', 'query performance', 'sufficient and necessary condition']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['existence condition', 'gamma -acyclic database scheme', 'mvds constraints', 'database technology', 'large - scale system', 'connect join expression', 'query performance', 'sufficient and necessary condition']","['preserve database scheme meet 4nf', 'database scheme have many good property', 'give relational scheme', 'database scheme', 'use database technology', 'good database design', 'database system', 'improve query performance', 'connect join expression', 'gamma']"
383,933,Real-time estimations of multi-modal frequencies for smart structures,"in this paper, various methods for the real-time estimation of multi-modal frequencies are realized in real time and compared through numerical and experimental tests. these parameter-based frequency estimation methods can be applied to various engineering fields such as communications, radar and adaptive vibration and noise control. well-known frequency estimation methods are introduced and explained. the bairstow method is introduced to find the roots of a characteristic equation for estimations of multi-modal frequencies, and the computational efficiency of the bairstow method is shown quantitatively. for a simple numerical test, we consider two sinusoids of the same amplitudes mixed with various amounts of white noise. the test results show that the auto regressive (ar) and auto regressive and moving average (arma) methods are unsuitable in noisy environments. the other methods apart from the ar method have fast tracking capability. from the point of view of computational efficiency, the results reveal that the arma method is inefficient, while the cascade notch filter method is very effective. the linearized adaptive notch filter and recursive maximum likelihood methods have average performances. experimental tests are devised to confirm the feasibility of real-time computations and to impose the severe conditions of drastically different amplitudes and of considerable changes of natural frequencies. we have performed experiments to extract the natural frequencies from the vibration signal of wing-like composite plates in real time. the natural frequencies of the specimen are changed by added masses. especially, the ar method exhibits a remarkable performance in spite of the severe conditions. this study will be helpful to anyone who needs a frequency estimation algorithm for real-time applications","['real-time estimation', 'multi-modal frequencies', 'smart structures', 'frequency estimation', 'noise control', 'bairstow method', 'characteristic equation', 'arma', 'cascade notch filter', 'linearized adaptive notch filter', 'recursive maximum likelihood methods', 'real-time computations', 'vibration signal', 'wing-like composite plates', 'frequency estimation algorithm', 'real-time applications', 'adaptive vibration control', 'auto regressive and moving average methods']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['real - time estimation', 'multi - modal frequency', 'smart structure', 'frequency estimation', 'noise control', 'bairstow method', 'characteristic equation', 'arma', 'cascade notch filter', 'linearize adaptive notch filter', 'recursive maximum likelihood method', 'real - time computation', 'vibration signal', 'wing - like composite plate', 'frequency estimation algorithm', 'real - time application', 'adaptive vibration control', 'auto regressive and move average method']","['frequency estimation algorithm', 'linearize adaptive notch filter', 'base frequency estimation method', 'frequency estimation method', 'modal frequency', 'cascade notch filter method', 'adaptive vibration', 'vibration signal', 'natural frequency', 'time estimation']"
384,976,Completion to involution and semidiscretisations,"we discuss the relation between the completion to involution of linear over-determined systems of partial differential equations with constant coefficients and the properties of differential algebraic equations obtained by their semidiscretisation. for a certain class of ""weakly over-determined"" systems, we show that the differential algebraic equations do not contain hidden constraints, if and only if the original partial differential system is involutive. we also demonstrate how the formal theory can be used to obtain an existence and uniqueness theorem for smooth solutions of strongly hyperbolic systems and to estimate the drift off the constraints, if an underlying equation is numerically solved. finally, we show for general linear systems how the index of differential algebraic equations obtained by semidiscretisations can be predicted from the result of a completion of the partial differential system","['completion', 'involution', 'semidiscretisations', 'linear over-determined systems', 'partial differential equations', 'constant coefficients', 'differential algebraic equations', 'uniqueness theorem', 'strongly hyperbolic systems', 'index', 'matrices']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U']","['completion', 'involution', 'semidiscretisation', 'linear over - determine system', 'partial differential equation', 'constant coefficient', 'differential algebraic equation', 'uniqueness theorem', 'strongly hyperbolic system', 'index', 'matrix']","['partial differential equation', 'partial differential system', 'differential algebraic equation obtain', 'differential algebraic equation', 'hyperbolic system', 'general linear system', 'contain hidden constraint', 'semidiscretisation', 'semidiscretisation', 'determine system']"
385,135,Hysteretic threshold logic and quasi-delay insensitive asynchronous design,"we introduce the class of hysteretic linear-threshold (hlt) logic functions as a novel extension of linear threshold logic, and prove their general applicability for constructing state-holding boolean functions. we then demonstrate a fusion of hlt logic with the quasi-delay insensitive style of asynchronous circuit design, complete with logical design examples. future research directions are also identified","['state-holding boolean functions', 'hlt logic', 'quasi-delay insensitive style', 'asynchronous circuit design', 'logic design', 'hysteretic linear-threshold logic functions', 'digital logic', 'cmos implementation']","['P', 'P', 'P', 'P', 'P', 'R', 'M', 'U']","['state - hold boolean function', 'hlt logic', 'quasi - delay insensitive style', 'asynchronous circuit design', 'logic design', 'hysteretic linear - threshold logic function', 'digital logic', 'cmos implementation']","['linear threshold logic', 'hold boolean function', 'asynchronous circuit design', 'hysteretic linear', 'logic function', 'delay insensitive style', 'threshold', 'logical design', 'logic', 'hlt']"
386,1208,A Virtual Test Facility for the simulation of dynamic response in materials,"the center for simulating dynamic response of materials at the california institute of technology is constructing a virtual shock physics facility for studying the response of various target materials to very strong shocks. the virtual test facility (vtf) is an end-to-end, fully three-dimensional simulation of the detonation of high explosives (he), shock wave propagation, solid material response to pressure loading, and compressible turbulence. the vtf largely consists of a parallel fluid solver and a parallel solid mechanics package that are coupled together by the exchange of boundary data. the eulerian fluid code and lagrangian solid mechanics model interact via a novel approach based on level sets. the two main computational packages are integrated through the use of pyre, a problem solving environment written in the python scripting language. pyre allows application developers to interchange various computational models and solver packages without recompiling code, and it provides standardized access to several data visualization engines and data input mechanisms. in this paper, we outline the main components of the vtf, discuss their integration via pyre, and describe some recent accomplishments in large-scale simulation using the vtf","['virtual test facility', 'virtual shock physics facility', 'high explosives', 'shock wave propagation', 'solid material response', 'pressure loading', 'compressible turbulence', 'parallel fluid solver', 'parallel solid mechanics', 'pyre', 'problem solving environment', 'python scripting language', 'data visualization', 'shock physics simulation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['virtual test facility', 'virtual shock physics facility', 'high explosive', 'shock wave propagation', 'solid material response', 'pressure loading', 'compressible turbulence', 'parallel fluid solver', 'parallel solid mechanic', 'pyre', 'problem solve environment', 'python scripting language', 'datum visualization', 'shock physics simulation']","['virtual shock physics facility', 'lagrangian solid mechanic model interact', 'python scripting language', 'shock wave propagation', 'various computational model', 'scale simulation use', 'parallel fluid solver', 'parallel solid mechanic package', 'dimensional simulation', 'simulate dynamic response']"
387,67,"Metaschemas for ER, ORM and UML data models: a comparison","this paper provides metaschemas for some of the main database modeling notations used in industry. two entity relationship (er) notations (information engineering and barker) are examined in detail, as well as object role modeling (orm) conceptual schema diagrams. the discussion of optionality, cardinality and multiplicity is widened to include unified modeling language (uml) class diagrams. issues addressed in the metamodel analysis include the normalization impact of non-derived constraints on derived associations, the influence of orthogonality on language transparency, and trade-offs between simplicity and expressibility. to facilitate comparison, the same modeling notation is used to display each metaschema. for this purpose, orm is used because of its greater expressibility and clarity","['metaschemas', 'orm', 'uml', 'data models', 'database modeling notations', 'information engineering', 'object role modeling', 'conceptual schema diagrams', 'optionality', 'cardinality', 'multiplicity', 'unified modeling language', 'class diagrams', 'normalization', 'orthogonality', 'language transparency', 'entity relationship modeling', 'barker notation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['metaschema', 'orm', 'uml', 'datum model', 'database model notation', 'information engineering', 'object role model', 'conceptual schema diagram', 'optionality', 'cardinality', 'multiplicity', 'unify modeling language', 'class diagram', 'normalization', 'orthogonality', 'language transparency', 'entity relationship model', 'barker notation']","['main database modeling notation use', 'conceptual schema diagram', 'include unified modeling language', 'same modeling notation', 'object role model', 'entity relationship', 'derive association', 'paper provide metaschema', 'class diagram', 'notation']"
388,618,Blind source separation applied to image cryptosystems with dual encryption,blind source separation (bss) is explored to add another encryption level besides the existing encryption methods for image cryptosystems. the transmitted images are covered with a noise image by specific mixing before encryption and then recovered through bss after decryption. simulation results illustrate the validity of the proposed method,"['blind source separation', 'image cryptosystems', 'dual encryption', 'transmitted images', 'noise image']","['P', 'P', 'P', 'P', 'P']","['blind source separation', 'image cryptosystem', 'dual encryption', 'transmit image', 'noise image']","['blind source separation', 'image cryptosystem', 'encryption method', 'encryption', 'decryption', 'transmit image', 'noise image', 'bss', 'recover', 'cover']"
389,108,Exploiting randomness in quantum information processing,"we consider how randomness can be made to play a useful role in quantum information processing-in particular, for decoherence control and the implementation of quantum algorithms. for a two-level system in which the decoherence channel is non-dissipative, we show that decoherence suppression is possible if memory is present in the channel. random switching between two potentially harmful noise sources can then provide a source of stochastic control. such random switching can also be used in an advantageous way for the implementation of quantum algorithms","['randomness', 'quantum information processing', 'decoherence control', 'quantum algorithms', 'two-level system', 'random switching', 'noise', 'stochastic control']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['randomness', 'quantum information processing', 'decoherence control', 'quantum algorithm', 'two - level system', 'random switching', 'noise', 'stochastic control']","['quantum information processing', 'decoherence channel', 'decoherence suppression', 'decoherence control', 'quantum algorithm', 'stochastic control', 'random switching', 'randomness', 'harmful noise source', 'channel']"
390,1270,A comparison of different decision algorithms used in volumetric storm cells classification,decision algorithms useful in classifying meteorological volumetric radar data are discussed. such data come from the radar decision support system (rdss) database of environment canada and concern summer storms created in this country. some research groups used the data completed by rdss for verifying the utility of chosen methods in volumetric storm cells classification. the paper consists of a review of experiments that were made on the data from rdss database of environment canada and presents the quality of particular classifiers. the classification accuracy coefficient is used to express the quality. for five research groups that led their experiments in a similar way it was possible to compare received outputs. experiments showed that the support vector machine (svm) method and rough set algorithms which use object oriented reducts for rule generation to classify volumetric storm data perform better than other classifiers,"['decision algorithms', 'volumetric storm cells classification', 'meteorological volumetric radar data', 'radar decision support system', 'summer storms', 'classification accuracy', 'support vector machine', 'rough set algorithms', 'object oriented reducts']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['decision algorithm', 'volumetric storm cell classification', 'meteorological volumetric radar datum', 'radar decision support system', 'summer storm', 'classification accuracy', 'support vector machine', 'rough set algorithm', 'object orient reduct']","['classify meteorological volumetric radar datum', 'classify volumetric storm datum', 'volumetric storm cell classification', 'classification accuracy coefficient', 'radar decision support system', 'classifier', 'decision algorithm useful', 'summer storm create', 'svm', 'rough set algorithm']"
391,1235,Finding performance bugs with the TNO HPF benchmark suite,"high-performance fortran (hpf) has been designed to provide portable performance on distributed memory machines. an important aspect of portable performance is the behavior of the available hpf compilers. ideally, a programmer may expect comparable performance between different hpf compilers, given the same program and the same machine. to test the performance portability between compilers, we have designed a special benchmark suite, called the tno hpf benchmark suite. it consists of a set of hpf programs that test various aspects of efficient parallel code generation. the benchmark suite consists of a number of template programs that are used to generate test programs with different array sizes, alignments, distributions, and iteration spaces. it ranges from very simple assignments to more complex assignments such as triangular iteration spaces, convex iteration spaces, coupled subscripts, and indirection arrays. we have run the tno hpf benchmark suite on three compilers: the prepare prototype compiler, the pgi-hpf compiler, and the gmd adaptor hpf compiler. results show performance differences that can be quite large (up to two orders of magnitude for the same test program). closer inspection reveals that the origin of most of the differences in performance is due to differences in local enumeration and storage of distributed array elements","['benchmark suite', 'high-performance fortran', 'portable performance', 'distributed memory machines', 'hpf compilers', 'performance portability', 'parallel compilers', 'compiler optimizations']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['benchmark suite', 'high - performance fortran', 'portable performance', 'distribute memory machine', 'hpf compiler', 'performance portability', 'parallel compiler', 'compiler optimization']","['tno hpf benchmark suite', 'gmd adaptor hpf compiler', 'different hpf compiler', 'performance fortran', 'available hpf compiler', 'hpf compiler', 'efficient parallel code generation', 'prepare prototype compiler', 'special benchmark suite', 'benchmark suite']"
392,660,At your service [agile businesses],"senior software executives from three of the world's leading software companies, and one smaller, entrepreneurial software developer, explain the impact that web services, business process management and integrated application architectures are having on their product development plans, and share their vision of the roles these products will play in creating agile businesses","['agile businesses', 'software companies', 'web services', 'business process management', 'integrated application architectures']","['P', 'P', 'P', 'P', 'P']","['agile business', 'software company', 'web service', 'business process management', 'integrate application architecture']","['entrepreneurial software developer', 'senior software executive', 'product development plan', 'business process management', 'lead software company', 'integrate application architecture', 'web service', 'role', 'product', 'impact']"
393,625,Identifying multivariate discordant observations: a computer-intensive approach,"the problem of identifying multiple outliers in a multivariate normal sample is approached via successive testing using p-values rather than tabled critical values. caroni and prescott (appl. statist. 41, p.355, 1992) proposed a generalization of the edr-esd procedure of rosner (technometrics, 25, 1983)). venter and viljoen (comput. statist. data anal. 29, p.261, 1999) introduced a computer intensive method to identify outliers in a univariate outlier situation. we now generalize this method to the multivariate outlier situation and compare this new procedure with that of caroni and prescott (appl. statist. 4, p.355, 1992)","['multivariate discordant observations', 'computer-intensive approach', 'multiple outliers', 'multivariate normal sample', 'p-values', 'tabled critical values', 'univariate outlier', 'multivariate outlier', 'data analysis', 'edr-ehd procedure', 'stepwise testing approach']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'M']","['multivariate discordant observation', 'computer - intensive approach', 'multiple outlier', 'multivariate normal sample', 'p - value', 'table critical value', 'univariate outlier', 'multivariate outlier', 'datum analysis', 'edr - ehd procedure', 'stepwise testing approach']","['multivariate outlier situation', 'univariate outlier situation', 'identify multiple outlier', 'identify outlier', 'multivariate normal sample', 'table critical value', 'esd procedure', 'technometric', 'successive testing', 'statist']"
394,1171,Manufacturing data analysis of machine tool errors within a contemporary small manufacturing enterprise,"the main focus of the paper is directed at the determination of manufacturing errors within the contemporary smaller manufacturing enterprise sector. the manufacturing error diagnosis is achieved through the manufacturing data analysis of the results obtained from the inspection of the component on a co-ordinate measuring machine. this manufacturing data analysis activity adopts a feature-based approach and is conducted through the application of a forward chaining expert system, called the product data analysis distributed diagnostic expert system, which forms part of a larger prototype feedback system entitled the production data analysis framework. the paper introduces the manufacturing error categorisations that are associated with milling type operations, knowledge acquisition and representation, conceptual structure and operating procedure of the prototype manufacturing data analysis facility. the paper concludes with a brief evaluation of the logic employed through the simulation of manufacturing error scenarios. this prototype manufacturing data analysis expert system provides a valuable aid for the rapid diagnosis and elimination of manufacturing errors on a 3-axis vertical machining centre in an environment where operator expertise is limited","['manufacturing data analysis', 'machine tool errors', 'contemporary small manufacturing enterprise', 'inspection', 'co-ordinate measuring machine', 'feature-based approach', 'forward chaining expert system', 'product data analysis distributed diagnostic expert system', 'milling type operations', 'knowledge acquisition', 'conceptual structure', 'operating procedure', '3-axis vertical machining centre', 'fixturing errors', 'programming errors', '2 1/2d components', 'knowledge representation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'M', 'R']","['manufacture datum analysis', 'machine tool error', 'contemporary small manufacturing enterprise', 'inspection', 'co - ordinate measuring machine', 'feature - base approach', 'forward chain expert system', 'product datum analysis distribute diagnostic expert system', 'milling type operation', 'knowledge acquisition', 'conceptual structure', 'operate procedure', '3 - axis vertical machining centre', 'fixture error', 'programming error', '2 1/2d component', 'knowledge representation']","['prototype manufacture datum analysis expert system', 'product datum analysis distribute diagnostic expert system', 'prototype manufacture datum analysis facility', 'contemporary small manufacturing enterprise sector', 'production datum analysis framework', 'manufacture datum analysis activity', 'manufacture datum analysis', 'manufacture error diagnosis', 'manufacture error categorisation', 'manufacture error scenario']"
395,1134,"Relationship between strong monotonicity property, P/sub 2/-property, and the GUS-property in semidefinite linear complementarity problems","in a recent paper on semidefinite linear complementarity problems, gowda and song (2000) introduced and studied the p-property, p/sub 2/-property, gus-property, and strong monotonicity property for linear transformation l: s/sup n/ to s/sup n/, where s/sup n/ is the space of all symmetric and real n * n matrices. in an attempt to characterize the p/sub 2/-property, they raised the following two questions: (i) does the strong monotonicity imply the p/sub 2/-property? (ii) does the gus-property imply the p/sub 2/-property? in this paper, we show that the strong monotonicity property implies the p/sub 2/-property for any linear transformation and describe an equivalence between these two properties for lyapunov and other transformations. we show by means of an example that the gus-property need not imply the p/sub 2/-property, even for lyapunov transformations","['strong monotonicity property', 'p/sub 2/-property', 'gus-property', 'semidefinite linear complementarity problems', 'linear transformation', 'lyapunov transformations', 'symmetric real matrices']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['strong monotonicity property', 'p / sub 2/-property', 'gus - property', 'semidefinite linear complementarity problem', 'linear transformation', 'lyapunov transformation', 'symmetric real matrix']","['semidefinite linear complementarity problem', 'strong monotonicity property imply', 'strong monotonicity property', 'strong monotonicity imply', 'linear transformation', 'lyapunov', 'property imply', 'property need', 'other transformation', 'property']"
396,561,SubSeven's Honey Pot program,"a serious security threat today are malicious executables, especially new, unseen malicious executables often arriving as email attachments. these new malicious executables are created at the rate of thousands every year and pose a serious threat. current anti-virus systems attempt to detect these new malicious programs with heuristics generated by hand. this approach is costly and often ineffective. we introduce the trojan horse subseven, its capabilities and influence over intrusion detection systems. a honey pot program is implemented, simulating the subseven server. the honey pot program provides feedback and stores data to and from the subseven's client","['subseven', 'honey pot program', 'security threat', 'malicious executables', 'email attachments', 'anti-virus systems', 'trojan horse', 'intrusion detection systems']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['subseven', 'honey pot program', 'security threat', 'malicious executable', 'email attachment', 'anti - virus system', 'trojan horse', 'intrusion detection system']","['new malicious executable', 'unseen malicious executable', 'trojan horse subseven', 'malicious executable', 'new malicious program', 'honey pot program provide feedback', 'intrusion detection system', 'honey pot program', 'virus system attempt', 'security threat today']"
397,1390,Data quality - unlocking the ROI in CRM,"while many organisations realise their most valuable asset is their customers, many more fail to realise the importance of auditing, maintaining and updating the information contained in their customer databases. today's growing awareness in the importance of data quality in relation to crm and roi will help change this attitude. in response, crm vendors will follow suit and begin to differentiate themselves by offering data quality as part of an enterprise-wide data management methodology","['crm', 'customer databases', 'data management', 'customer relationships', 'return on investment']","['P', 'P', 'P', 'M', 'U']","['crm', 'customer database', 'datum management', 'customer relationship', 'return on investment']","['crm vendor', 'datum quality', 'customer database', 'crm', 'audit', 'customer', 'enterprise', 'many organisation realise', 'information', 'valuable asset']"
398,780,Failures and successes: notes on the development of electronic cash,"between 1997 and 2001, two mid-sized communities in canada hosted north america's most comprehensive experiment to introduce electronic cash and, in the process, replace physical cash for casual, low-value payments. the technology used was mondex, and its implementation was supported by all the country's major banks. it was launched with an extensive publicity campaign to promote mondex not only in the domestic but also in the global market, for which the canadian implementation was to serve as a ""showcase."" however, soon after the start of the first field test it became apparent that the new technology did not work smoothly. on the contrary, it created a host of controversies, in areas as varied as computer security, consumer privacy, and monetary policy. in the following years, few of these controversies could be resolved and mondex could not be established as a widely used payment mechanism. in 2001, the experiment was finally terminated. using the concepts developed in recent science and technology studies (sts), the article analyzes these controversies as resulting from the difficulties of fitting electronic cash, a new sociotechnical system, into the complex setting of the existing payment system. the story of mondex not only offers lessons on why technologies fail, but also offers insight into how short-term failures can contribute to long-term transformations. this suggests the need to rethink the dichotomy of success and failure","['electronic cash', 'canada', 'low-value payments', 'mondex', 'major banks', 'publicity campaign', 'global market', 'canadian implementation', 'computer security', 'consumer privacy', 'monetary policy', 'payment mechanism', 'science and technology studies', 'sociotechnical system', 'short-term failures', 'long-term transformations']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['electronic cash', 'canada', 'low - value payment', 'mondex', 'major bank', 'publicity campaign', 'global market', 'canadian implementation', 'computer security', 'consumer privacy', 'monetary policy', 'payment mechanism', 'science and technology study', 'sociotechnical system', 'short - term failure', 'long - term transformation']","['introduce electronic cash', 'fit electronic cash', 'exist payment system', 'new sociotechnical system', 'monetary policy', 'physical cash', 'technology study', 'promote mondex', 'use payment mechanism', 'value payment']"
399,1029,Effect of insulation layer on transcribability and birefringence distribution in optical disk substrate,"as the need for information storage media with high storage density increases, digital video disks (dvds) with smaller recording marks and thinner optical disk substrates than those of conventional dvds are being required. therefore, improving the replication quality of land-groove or pit structure and reducing the birefringence distribution are emerging as important criteria in the fabrication of high-density optical disk substrates. we control the transcribability and distribution of birefringence by inserting an insulation layer under the stamper during injection-compression molding of dvd ram substrates. the effects of the insulation layer on the geometrical and optical properties, such as transcribability and birefringence distribution, are examined experimentally. the inserted insulation layer is found to be very effective in improving the quality of replication and leveling out the first peak of the gapwise birefringence distribution near the mold wall and reducing the average birefringence value, because the insulation layer retarded the growth of the solidified layer","['insulation layer', 'transcribability', 'birefringence distribution', 'optical disk substrate', 'information storage media', 'high storage density', 'digital video disks', 'smaller recording marks', 'thinner optical disk substrates', 'replication quality', 'land-groove', 'pit structure', 'fabrication', 'stamper', 'injection-compression molding', 'dvd ram substrates', 'optical properties', 'gapwise birefringence distribution', 'mold wall', 'geometrical properties', 'solidified layer growth retardation', 'polyimide thermal insulation layer']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M']","['insulation layer', 'transcribability', 'birefringence distribution', 'optical disk substrate', 'information storage medium', 'high storage density', 'digital video disk', 'small recording mark', 'thin optical disk substrate', 'replication quality', 'land - groove', 'pit structure', 'fabrication', 'stamper', 'injection - compression molding', 'dvd ram substrate', 'optical property', 'gapwise birefringence distribution', 'mold wall', 'geometrical property', 'solidify layer growth retardation', 'polyimide thermal insulation layer']","['density optical disk substrate', 'optical disk substrate', 'digital video disk', 'dvd ram substrate', 'birefringence distribution', 'average birefringence', 'birefringence', 'optical property', 'storage density', 'dvds']"
400,1405,Winning post [mail systems],"businesses that take their mail for granted can end up wasting money as well as opportunities. mike stecyk, vp of marketing and lines of business at pitney bowes, suggests strategies for making more of a great opportunity","['mail', 'pitney bowes', 'strategies', 'franking machines', 'folders', 'inserters', 'direct mail shots']","['P', 'P', 'P', 'U', 'U', 'U', 'M']","['mail', 'pitney bowe', 'strategy', 'frank machine', 'folder', 'inserter', 'direct mail shot']","['pitney bowe', 'mike stecyk', 'marketing', 'business', 'waste money', 'business', 'opportunity', 'suggest strategy', 'mail', 'make more']"
401,1091,Car-caravan snaking. 1. The influence of pintle pin friction,"a brief review of knowledge of car-caravan snaking is carried out. against the background described, a fairly detailed mathematical model of a contemporary car-trailer system is constructed and a baseline set of parameter values is given. in reduced form, the model is shown to give results in accordance with literature. the properties of the baseline combination are explored using both linear and non-linear versions of the model. the influences of damping at the pintle joint and of several other design parameters on the stability of the linear system in the neighbourhood of the critical snaking speed are calculated and discussed. coulomb friction damping at the pintle pin is then included and simulations are used to indicate the consequent amplitude-dependent behaviour. the friction damping, especially when its level has to be chosen by the user, is shown to give dangerous characteristics, despite having some capacity for stabilization of the snaking motions. it is concluded that pintle pin friction damping does not represent a satisfactory solution to the snaking problem. the paper sets the scene for the development of an improved solution","['car-caravan snaking', 'pintle pin friction', 'mathematical model', 'car-trailer system', 'linear system', 'critical snaking speed', 'coulomb friction damping', 'amplitude-dependent behaviour']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['car - caravan snaking', 'pintle pin friction', 'mathematical model', 'car - trailer system', 'linear system', 'critical snaking speed', 'coulomb friction damp', 'amplitude - dependent behaviour']","['pintle pin friction damp', 'friction damp', 'snake motion', 'caravan snaking', 'snake speed', 'trailer system', 'snaking problem', 'damp', 'stabilization', 'linear system']"
402,1440,Application of ultrasonic sensors in the process industry,"continuous process monitoring in gaseous, liquid or molten media is a fundamental requirement for process control. besides temperature and pressure other process parameters such as level, flow, concentration and conversion are of special interest. more qualified information obtained from new or better sensors can significantly enhance the process quality and thereby product properties. ultrasonic sensors or sensor systems can contribute to this development. the state of the art of ultrasonic sensors and their advantages and disadvantages will be discussed. commercial examples will be presented. among others, applications in the food, chemical and pharmaceutical industries are described. possibilities and limitations of ultrasonic process sensors are discussed","['process industry', 'continuous process monitoring', 'process control', 'process quality', 'pharmaceutical industries', 'ultrasonic sensors application', 'food industries', 'chemical industries', 'acoustic microsensors', 'ultrasonic measurements', 'ultrasonic attenuation', 'acoustic impedance', 'temperature measurement', 'pressure measurement', 'level measurement', 'distance measurement', 'flow measurement']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'U', 'M', 'M', 'U', 'M', 'M', 'M', 'U', 'M']","['process industry', 'continuous process monitor', 'process control', 'process quality', 'pharmaceutical industry', 'ultrasonic sensor application', 'food industry', 'chemical industry', 'acoustic microsensor', 'ultrasonic measurement', 'ultrasonic attenuation', 'acoustic impedance', 'temperature measurement', 'pressure measurement', 'level measurement', 'distance measurement', 'flow measurement']","['ultrasonic process sensor', 'ultrasonic sensor', 'continuous process monitor', 'sensor system', 'sensor', 'process quality', 'molten medium', 'pharmaceutical industry', 'process parameter', 'process control']"
403,856,People who make a difference: mentors and role models,"the literature of gender issues in computing steadfastly and uniformly has advocated the use of mentors and role models (m&rm) for recruiting and retaining women in computer science. this paper, therefore, accepts the results of research studies and avoids reiterating details of the projects but offers instead a practical guide for using m&rm to recruit and retain women in computer science. the guide provides pragmatic advice, describing several different facets of the m&rm concept","['mentors', 'role models', 'gender issues', 'computing', 'computer science', 'women retention', 'women recruitment']","['P', 'P', 'P', 'P', 'P', 'M', 'R']","['mentor', 'role model', 'gender issue', 'compute', 'computer science', 'woman retention', 'woman recruitment']","['role model', 'retain woman', 'gender issue', 'retain woman', 'guide provide pragmatic advice', 'mentor', 'recruit', 'computer science', 'recruit', 'research study']"
404,813,On generalized Gaussian quadratures for exponentials and their applications,"we introduce new families of gaussian-type quadratures for weighted integrals of exponential functions and consider their applications to integration and interpolation of bandlimited functions. we use a generalization of a representation theorem due to caratheodory to derive these quadratures. for each positive measure, the quadratures are parameterized by eigenvalues of the toeplitz matrix constructed from the trigonometric moments of the measure. for a given accuracy epsilon , selecting an eigenvalue close to epsilon yields an approximate quadrature with that accuracy. to compute its weights and nodes, we present a new fast algorithm. these new quadratures can be used to approximate and integrate bandlimited functions, such as prolate spheroidal wave functions, and essentially bandlimited functions, such as bessel functions. we also develop, for a given precision, an interpolating basis for bandlimited functions on an interval","['generalized gaussian quadratures', 'weighted integrals', 'integration', 'exponential functions', 'interpolation', 'bandlimited functions', 'eigenvalues', 'toeplitz matrix', 'trigonometric moments', 'approximation', 'prolate spheroidal wave functions', 'bessel functions', 'caratheodory representation theorem']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['generalize gaussian quadrature', 'weight integral', 'integration', 'exponential function', 'interpolation', 'bandlimite function', 'eigenvalue', 'toeplitz matrix', 'trigonometric moment', 'approximation', 'prolate spheroidal wave function', 'bessel function', 'caratheodory representation theorem']","['approximate quadrature', 'prolate spheroidal wave function', 'integrate bandlimited function', 'gaussian', 'weight integral', 'interpolate basis', 'toeplitz matrix', 'quadrature', 'exponential function', 'bessel function']"
405,738,Playing for time [3G networks],the delays in rolling out 3g networks across europe should not always be seen with a negative slant,"['3g networks', 'delays', 'europe', 'mobile operators']","['P', 'P', 'P', 'U']","['3 g network', 'delay', 'europe', 'mobile operator']","['delay', 'network', 'europe', 'roll']"
406,1328,Tablet PCs on the way [publishing markets],previews of hardware and software look promising for publishing markets,"['tablet pc', 'publishing markets']","['P', 'P']","['tablet pc', 'publish market']","['software look promise', 'preview', 'hardware']"
407,1155,A leaf sequencing algorithm to enlarge treatment field length in IMRT,"with mlc-based imrt, the maximum usable field size is often smaller than the maximum field size for conventional treatments. this is due to the constraints of the overtravel distances of mlc leaves and/or jaws. using a new leaf sequencing algorithm, the usable imrt field length (perpendicular to the mlc motion) can be mostly made equal to the full length of the mlc field without violating the upper jaw overtravel limit. for any given intensity pattern, a criterion was proposed to assess whether an intensity pattern can be delivered without violation of the jaw position constraints. if the criterion is met, the new algorithm will consider the jaw position constraints during the segmentation for the step and shoot delivery method. the strategy employed by the algorithm is to connect the intensity elements outside the jaw overtravel limits with those inside the jaw overtravel limits. several methods were used to establish these connections during segmentation by modifying a previously published algorithm (areal algorithm), including changing the intensity level, alternating the leaf-sequencing direction, or limiting the segment field size. the algorithm was tested with 1000 random intensity patterns with dimensions of 21*27 cm/sup 2/, 800 intensity patterns with higher intensity outside the jaw overtravel limit, and three different types of clinical treatment plans that were undeliverable using a segmentation method from a commercial treatment planning system. the new algorithm achieved a success rate of 100% with these test patterns. for the 1000 random patterns, the new algorithm yields a similar average number of segments of 36.9+or-2.9 in comparison to 36.6+or-1.3 when using the areal algorithm. for the 800 patterns with higher intensities outside the jaw overtravel limits, the new algorithm results in an increase of 25% in the average number of segments compared to the areal algorithm. however, the areal algorithm fails to create deliverable segments for 90% of these patterns. using a single isocenter, the new algorithm provides a solution to extend the usable imrt field length from 21 to 27 cm for imrt on a commercial linear accelerator using the step and shoot delivery method","['leaf sequencing algorithm', 'treatment field length', 'overtravel distances', 'upper jaw overtravel limit', 'jaw overtravel limits', 'intensity pattern', 'jaw position constraints', 'step and shoot delivery method', 'intensity elements', 'areal algorithm', 'leaf-sequencing direction', 'segment field size', 'random intensity patterns', 'segmentation method', 'commercial treatment planning system', 'random patterns', 'deliverable segments', 'single isocenter', 'commercial linear accelerator', 'usable intensity modulated radiation therapy field length', 'multileaf-based collimators intensity modulated radiation therapy', 'conformal radiation therapy', 'multileaf collimators jaws', 'multileaf collimators leaves']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'U', 'M', 'M']","['leaf sequence algorithm', 'treatment field length', 'overtravel distance', 'upper jaw overtravel limit', 'jaw overtravel limit', 'intensity pattern', 'jaw position constraint', 'step and shoot delivery method', 'intensity element', 'areal algorithm', 'leaf - sequence direction', 'segment field size', 'random intensity pattern', 'segmentation method', 'commercial treatment planning system', 'random pattern', 'deliverable segment', 'single isocenter', 'commercial linear accelerator', 'usable intensity modulate radiation therapy field length', 'multileaf - base collimator intensity modulate radiation therapy', 'conformal radiation therapy', 'multileaf collimator jaw', 'multileaf collimator leave']","['leaf sequence algorithm', 'jaw position constraint', 'segmentation method', 'intensity level', 'segment field size', 'imrt field length', 'areal algorithm', 'intensity pattern', 'give intensity pattern', 'intensity pattern']"
408,1110,A hybrid model for smoke simulation,"a smoke simulation approach based on the integration of traditional particle systems and density functions is presented in this paper. by attaching a density function to each particle as its attribute, the diffusion of smoke can be described by the variation of particles' density functions, along with the effect on airflow by controlling particles' movement and fragmentation. in addition, a continuous density field for realistic rendering can be generated quickly through the look-up tables of particle's density functions. compared with traditional particle systems, this approach can describe smoke diffusion, and provide a continuous density field for realistic rendering with much less computation. a quick rendering scheme is also presented in this paper as a useful preview tool for tuning appropriate parameters in the smoke model","['hybrid model', 'smoke simulation', 'density functions', 'continuous density field', 'rendering', 'look-up tables']","['P', 'P', 'P', 'P', 'P', 'P']","['hybrid model', 'smoke simulation', 'density function', 'continuous density field', 'render', 'look - up table']","['smoke simulation approach base', 'describe smoke diffusion', 'realistic rendering', 'quick render', 'smoke', 'airflow', 'continuous density', 'density function', 'density function', 'traditional particle system']"
409,545,Interaction and presence in the clinical relationship: virtual reality (VR) as communicative medium between patient and therapist,"the great potential offered by virtual reality (vr) to clinical psychologists derives prevalently from the central role, in psychotherapy, occupied by the imagination and by memory. these two elements, which are fundamental in our life, present absolute and relative limits to the individual potential. using vr as an advanced imaginal system, an experience that is able to reduce the gap existing between imagination and reality, it is possible to transcend these limits. in this sense, vr can improve the efficacy of a psychological therapy for its capability of reducing the distinction between the computer's reality and the conventional reality. two are the core characteristics of this synthetic imaginal experience: the perceptual illusion of nonmediation and the possibility of building and sharing a common ground. in this sense, experiencing presence in a clinical virtual environment (ve), such as a shared virtual hospital, requires more than reproduction of the physical features of external reality. it requires the creation and sharing of the cultural web that makes meaningful, and therefore visible, both people and objects populating the environment. the paper outlines a framework for supporting the development and tuning of clinically oriented vr systems","['presence', 'virtual reality', 'psychotherapy', 'imagination', 'memory', 'psychological therapy', 'clinical virtual environment', 'shared virtual hospital', 'patient-therapist communication', 'clinical psychology']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R']","['presence', 'virtual reality', 'psychotherapy', 'imagination', 'memory', 'psychological therapy', 'clinical virtual environment', 'share virtual hospital', 'patient - therapist communication', 'clinical psychology']","['clinical virtual environment', 'share virtual hospital', 'experience presence', 'virtual reality', 'clinical psychologist derive', 'use vr', 'perceptual illusion', 'synthetic imaginal experience', 'psychological therapy', 'advance imaginal system']"
410,992,Cross-entropy and rare events for maximal cut and partition problems,"we show how to solve the maximal cut and partition problems using a randomized algorithm based on the cross-entropy method. for the maximal cut problem, the proposed algorithm employs an auxiliary bernoulli distribution, which transforms the original deterministic network into an associated stochastic one, called the associated stochastic network (asn). each iteration of the randomized algorithm for the asn involves the following two phases: (1) generation of random cuts using a multidimensional ber(p) distribution and calculation of the associated cut lengths (objective functions) and some related quantities, such as rare-event probabilities; (2) updating the parameter vector p on the basis of the data collected in the first phase. we show that the ber(p) distribution converges in distribution to a degenerated one, ber(p/sub d/*), p/sub d/* = (p/sub d/,/sub 1/, p/sub d,n/) in the sense that some elements of p/sub d/*, will be unities and the rest zeros. the unity elements of p/sub d/* uniquely define a cut which will be taken as the estimate of the maximal cut. a similar approach is used for the partition problem. supporting numerical results are given as well. our numerical studies suggest that for the maximal cut and partition problems the proposed algorithm typically has polynomial complexity in the size of the network","['partition problems', 'randomized algorithm', 'maximal cut problems', 'bernoulli distribution', 'deterministic network', 'associated stochastic network', 'random cuts', 'probability', 'numerical results', 'polynomial complexity', 'cross entropy method', 'rare event simulation', 'combinatorial optimization', 'importance sampling']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'U', 'U']","['partition problem', 'randomize algorithm', 'maximal cut problem', 'bernoulli distribution', 'deterministic network', 'associate stochastic network', 'random cut', 'probability', 'numerical result', 'polynomial complexity', 'cross entropy method', 'rare event simulation', 'combinatorial optimization', 'importance sample']","['randomize algorithm', 'associate stochastic network', 'random cut', 'original deterministic network', 'maximal cut problem', 'maximal cut', 'entropy method', 'associate cut length', 'associate stochastic', 'auxiliary bernoulli distribution']"
411,83,A distributed mobile agent framework for maintaining persistent distance education,"mobile agent techniques involve distributed control if communication is required among different types of agents, especially when mobile agents can migrate from station to station. this technique can be implemented in a distributed distance learning environment, which allows students or instructors to login from anywhere to a central server in an education center while still retaining the look-and-feel of personal setups. in this research paper, we propose a distributed agent framework along with its communication messages to facilitate mobile personal agents, which serve three different groups of distance education users: instructors, students, and system administrators. we propose an agent communication framework as well as agent evolution states of mobile agents. the communication architecture and message transmission protocols are illustrated. the system is implemented on the windows platform to support nomadic accessibility of remote distance learning users. personal data also migrate with the mobile agents, allowing users to maintain accessibility to some extent even when the internet connection is temperately disconnected. using user-friendly personal agents, a distance education platform can include different tools to meet different needs for users","['distributed mobile agent framework', 'persistent distance education', 'distributed control', 'central server', 'distributed agent framework', 'message transmission protocols', 'user-friendly personal agents']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['distribute mobile agent framework', 'persistent distance education', 'distribute control', 'central server', 'distribute agent framework', 'message transmission protocol', 'user - friendly personal agent']","['facilitate mobile personal agent', 'agent communication framework', 'distribute agent framework', 'mobile agent technique', 'distribute distance learning environment', 'remote distance learn user', 'distance education platform', 'mobile agent', 'message transmission protocol', 'communication message']"
412,1254,Supporting unified interface to wrapper generator in integrated information retrieval,"given the ever-increasing scale and diversity of information and applications on the internet, improving the technology of information retrieval is an urgent research objective. retrieved information is either semi-structured or unstructured in format and its sources are extremely heterogeneous. in consequence, the task of efficiently gathering and extracting information from documents can be both difficult and tedious. given this variety of sources and formats, many choose to use mediator/wrapper architecture, but its use demands a fast means of generating efficient wrappers. in this paper, we present a design for an automatic extensible markup language (xml)-based framework with which to generate wrappers rapidly. wrappers created with this framework support a unified interface for a meta-search information retrieval system based on the internet search service using the common object request broker architecture (corba) standard. greatly advantaged by the compatibility of corba and xml, a user can quickly and easily develop information-gathering applications, such as a meta-search engine or any other information source retrieval method. the two main things our design provides are a method of wrapper generation that is fast, simple, and efficient, and a wrapper generator that is corba and xml-compliant and that supports a unified interface","['unified interface', 'wrapper generator', 'integrated information retrieval', 'internet', 'automatic extensible markup language', 'corba', 'meta-search engine']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['unify interface', 'wrapper generator', 'integrate information retrieval', 'internet', 'automatic extensible markup language', 'corba', 'meta - search engine']","['search information retrieval system base', 'other information source retrieval method', 'internet search service use', 'automatic extensible markup language', 'information retrieval', 'common object request broker architecture', 'xml', 'extract information', 'retrieve information', 'wrapper architecture']"
413,1211,Hybrid decision tree,"in this paper, a hybrid learning approach named hybrid decision tree (hdt) is proposed. hdt simulates human reasoning by using symbolic learning to do qualitative analysis and using neural learning to do subsequent quantitative analysis. it generates the trunk of a binary hdt according to the binary information gain ratio criterion in an instance space defined by only original unordered attributes. if unordered attributes cannot further distinguish training examples falling into a leaf node whose diversity is beyond the diversity-threshold, then the node is marked as a dummy node. after all those dummy nodes are marked, a specific feedforward neural network named fannc that is trained in an instance space defined by only original ordered attributes is exploited to accomplish the learning task. moreover, this paper distinguishes three kinds of incremental learning tasks. two incremental learning procedures designed for example-incremental learning with different storage requirements are provided, which enables hdt to deal gracefully with data sets where new data are frequently appended. also a hypothesis-driven constructive induction mechanism is provided, which enables hdt to generate compact concept descriptions","['hybrid decision tree', 'hybrid learning approach', 'reasoning', 'symbolic learning', 'qualitative analysis', 'neural learning', 'quantitative analysis', 'binary information gain ratio criterion', 'feedforward neural network', 'fannc', 'incremental learning', 'storage requirements', 'data sets', 'hypothesis-driven constructive induction']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['hybrid decision tree', 'hybrid learn approach', 'reason', 'symbolic learning', 'qualitative analysis', 'neural learning', 'quantitative analysis', 'binary information gain ratio criterion', 'feedforward neural network', 'fannc', 'incremental learning', 'storage requirement', 'datum set', 'hypothesis - drive constructive induction']","['hybrid learn approach name hybrid decision tree', 'specific feedforward neural network name fannc', 'incremental learning task', 'incremental learning procedure', 'incremental learning', 'hdt simulate human reasoning', 'use neural learning', 'use symbolic learning', 'drive constructive induction mechanism', 'distinguish training example']"
414,644,Three-dimensional spiral MR imaging: application to renal multiphase contrast-enhanced angiography,"a fast mr pulse sequence with spiral in-plane readout and conventional 3d partition encoding was developed for multiphase contrast-enhanced magnetic resonance angiography (ce-mra) of the renal vasculature. compared to a standard multiphase 3d ce-mra with flash readout, an isotropic in-plane spatial resolution of 1.4*1.4 mm/sup 2/ over 2.0*1.4 mm/sup 2/ could be achieved with a temporal resolution of 6 sec. the theoretical gain of spatial resolution by using the spiral pulse sequence and the performance in the presence of turbulent flow was evaluated in phantom measurements. multiphase 3d ce-mra of the renal arteries was performed in five healthy volunteers using both techniques. a deblurring technique was used to correct the spiral raw data. thereby, the off-resonance frequencies were determined by minimizing the imaginary part of the data in image space. the chosen correction algorithm was able to reduce image blurring substantially in all mra phases. the image quality of the spiral ce-mra pulse sequence was comparable to that of the flash ce-mra with increased spatial resolution and a 25% reduced contrast-to-noise ratio. additionally, artifacts specific to spiral mri could be observed which had no impact on the assessment of the renal arteries","['renal multiphase contrast-enhanced angiography', 'spiral in-plane readout', '3d partition encoding', 'renal vasculature', 'spatial resolution', 'deblurring', 'off-resonance frequencies', 'image quality', 'reduced contrast-to-noise ratio', '3d spiral mri', 'flow artifacts', 'fast pulse sequence', 'image reconstruction', 'flash sequence']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'R']","['renal multiphase contrast - enhance angiography', 'spiral in - plane readout', '3d partition encoding', 'renal vasculature', 'spatial resolution', 'deblurre', 'off - resonance frequency', 'image quality', 'reduce contrast - to - noise ratio', '3d spiral mri', 'flow artifact', 'fast pulse sequence', 'image reconstruction', 'flash sequence']","['enhance magnetic resonance angiography', 'renal artery', 'spiral mri', 'renal vasculature', 'standard multiphase 3d ce', 'mra pulse sequence', 'multiphase contrast', 'spiral pulse sequence', 'multiphase 3d ce', 'mr pulse sequence']"
415,601,Recent researches of human science on railway systems,"this paper presents research of human science on railway systems at rtri. they are roughly divided into two categories: research to improve safety and those to improve comfort. on the former subject, for the safeguard against accidents caused by human errors, we have promoted studies of psychological aptitude test, various research to evaluate train drivers' working conditions and environments, and new investigations to minimize the risk of passenger casualties at train accidents. on the latter subject, we have developed new methods to evaluate the riding comfort including that of tilt train, and started research on the improvement of railway facilities for the aged and the disabled from the viewpoint of universal design","['human science', 'railway systems', 'rtri', 'accidents', 'human errors', 'psychological aptitude test', ""train drivers' working conditions"", 'train accidents', 'riding comfort', 'tilt train', 'railway facilities', 'safety improvement', 'comfort improvement', ""train drivers' working environments"", 'passenger casualties risk minimisation', 'aged persons', 'disabled persons', 'sight impaired', 'wakefulness level', 'ergonomics']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'M', 'M', 'U', 'U', 'U']","['human science', 'railway system', 'rtri', 'accident', 'human error', 'psychological aptitude test', ""train driver ' working condition"", 'train accident', 'ride comfort', 'tilt train', 'railway facility', 'safety improvement', 'comfort improvement', ""train driver ' work environment"", 'passenger casualty risk minimisation', 'aged person', 'disabled person', 'sight impair', 'wakefulness level', 'ergonomic']","['psychological aptitude test', 'evaluate train driver', 'train accident', 'railway system', 'railway facility', 'tilt train', 'improve safety', 'ride comfort', 'passenger casualty', 'human error']"
416,759,Mathematical properties of dominant AHP and concurrent convergence method,"this study discusses the mathematical structure of the dominant ahp and the concurrent convergence method which were originally developed by kinoshita and nakanishi. they introduced a new concept of a regulating alternative into an analyzing tool for a simple evaluation problem with a criterion set and an alternative set. although the original idea of the dominant ahp and the concurrent convergence method is unique, the dominant ahp and the concurrent convergence method are not sufficiently analyzed in mathematical theory. this study shows that the dominant ahp consists of a pair of evaluation rules satisfying a certain property of overall evaluation vectors. this study also shows that the convergence of concurrent convergence method is guaranteed theoretically","['dominant ahp', 'concurrent convergence method', 'overall evaluation vectors']","['P', 'P', 'P']","['dominant ahp', 'concurrent convergence method', 'overall evaluation vector']","['concurrent convergence method', 'simple evaluation problem', 'mathematical theory', 'evaluation rule satisfy', 'overall evaluation vector', 'analyze tool', 'criterion set', 'mathematical structure', 'dominant ahp consist', 'convergence']"
417,1349,Efficient simplicial reconstructions of manifolds from their samples,"an algorithm for manifold learning is presented. given only samples of a finite-dimensional differentiable manifold and no a priori knowledge of the manifold's geometry or topology except for its dimension, the goal is to find a description of the manifold. the learned manifold must approximate the true manifold well, both geometrically and topologically, when the sampling density is sufficiently high. the proposed algorithm constructs a simplicial complex based on approximations to the tangent bundle of the manifold. an important property of the algorithm is that its complexity depends on the dimension of the manifold, rather than that of the embedding space. successful examples are presented in the cases of learning curves in the plane, curves in space, and surfaces in space; in addition, a case when the algorithm fails is analyzed","['simplicial reconstructions', 'manifold learning', 'finite-dimensional differentiable manifold', 'learned manifold', 'true manifold', 'sampling density', 'simplicial complex']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['simplicial reconstruction', 'manifold learning', 'finite - dimensional differentiable manifold', 'learn manifold', 'true manifold', 'sample density', 'simplicial complex']","['dimensional differentiable manifold', 'manifold learning', 'learn manifold', 'true manifold', 'learn curve', 'simplicial complex base', 'embed space', 'manifold', 'propose algorithm construct', 'sample density']"
418,1421,Extracting linguistic DNA: NStein goes to work for UPI,"it's a tantalizing problem for categorization. united press international (upi) has more than 700 correspondents creating thousands of stories every week, running the gamut from business news to sports to entertainment to global coverage of america's war on terrorism. and while upi and others news services have mechanisms for adding keywords and categorizing their content, upi recognized a need to add more automation to the process. with the recent growth and improvement in tools for computer-aided indexing (cai), upi undertook a process of looking at its needs and evaluating the many cai tools out there. in the end, they chose technology from montreal-based nstein technologies. ""our main objective was to acquire the best cai tool to help improve our customers' access and interaction with our content,"" says steve sweet, cio at upi. ""we examined a number of solutions, and nstein's nserver suite clearly came out on top. the combination of speed, scalability, accuracy, and flexibility was what really sold us.""","['upi', 'united press international', 'computer-aided indexing', 'nstein technologies', 'electronic archive', 'wire service stories']","['P', 'P', 'P', 'P', 'U', 'M']","['upi', 'united press international', 'computer - aid indexing', 'nstein technology', 'electronic archive', 'wire service story']","['base nstein technology', 'many cai tool', 'other news service', 'aid indexing', 'good cai tool', 'correspondent create thousand', 'nserver suite', 'united press international', 'main objective', 'add more automation']"
419,872,Shortchanging the future of information technology: the untapped resource,"building on ideas from a virtual workshop and additional input from the scientific community, the cise directorate at the national science foundation established the information technology workforce program (itwf) in march 2000 to support a broad set of scientific research studies focused on the under-representation of women and minorities in the information technology workforce. in this paper, we explore various approaches that the funded researchers are taking to address the problem of women in information technology. we begin with a brief history of the itwf, and then focus on some of the research projects in terms of their goals, approaches, and expected outcomes","['untapped resources', 'virtual workshop', 'cise directorate', 'national science foundation', 'information technology workforce program', 'itwf', 'scientific research studies', 'history', 'information technology future', 'women under-representation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['untapped resource', 'virtual workshop', 'cise directorate', 'national science foundation', 'information technology workforce program', 'itwf', 'scientific research study', 'history', 'information technology future', 'woman under - representation']","['information technology workforce program', 'scientific research study focus', 'information technology workforce', 'research project', 'national science foundation establish', 'fund researcher', 'information technology', 'explore various approach', 'scientific community', 'cise directorate']"
420,837,Ten suggestions for a gender-equitable CS classroom,"though considerable attention has been paid to the creation of a nurturing environment for women in the field of computer science, proposed solutions have primarily focused on activities outside of the classroom. this paper presents a list of suggestions for modifications to both the pedagogy and content of cs courses designed to make the cs classroom environment more inviting for women students","['nurturing environment', 'computer science', 'pedagogy', 'cs classroom environment', 'women students', 'gender-equitable classroom', 'cs course content']","['P', 'P', 'P', 'P', 'P', 'R', 'R']","['nurture environment', 'computer science', 'pedagogy', 'cs classroom environment', 'woman student', 'gender - equitable classroom', 'cs course content']","['cs classroom environment', 'cs course design', 'nurture environment', 'computer science', 'pedagogy', 'classroom', 'woman', 'propose solution', 'activity', 'paper present']"
421,1048,Parallel and distributed Haskells,"parallel and distributed languages specify computations on multiple processors and have a computation language to describe the algorithm, i.e. what to compute, and a coordination language to describe how to organise the computations across the processors. haskell has been used as the computation language for a wide variety of parallel and distributed languages, and this paper is a comprehensive survey of implemented languages. it outlines parallel and distributed language concepts and classifies haskell extensions using them. similar example programs are used to illustrate and contrast the coordination languages, and the comparison is facilitated by the common computation language. a lazy language is not an obvious choice for parallel or distributed computation, and we address the question of why haskell is a common functional computation language","['distributed haskell', 'distributed languages', 'multiple processors', 'coordination language', 'lazy language', 'functional computation language', 'parallel haskell', 'parallel languages', 'functional programming']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['distribute haskell', 'distribute language', 'multiple processor', 'coordination language', 'lazy language', 'functional computation language', 'parallel haskell', 'parallel language', 'functional programming']","['distribute language specify computation', 'classifie haskell extension use', 'common computation language', 'distribute computation', 'computation language', 'distribute language', 'implement language', 'haskell', 'distribute language concept', 'coordination language']"
422,1030,Comparison of automated digital elevation model extraction results using along-track ASTER and across-track SPOT stereo images,"a digital elevation model (dem) can be extracted automatically from stereo satellite images. during the past decade, the most common satellite data used to extract dem was the across-track spot. recently, the addition of along-track aster data, which can be downloaded freely, provides another attractive alternative to extract dem data. this work compares the automated dem extraction results using an aster stereo pair and a spot stereo pair over an area of hilly mountains in drum mountain, utah, when compared to a usgs 7.5-min dem standard product. the result shows that spot produces better dem results in terms of accuracy and details, if the radiometric variations between the images, taken on subsequent satellite revolutions, are small. otherwise, the aster stereo pair is a better choice because of simultaneous along-track acquisition during a single pass. compared to the usgs 7.5-min dem, the aster and the spot extracted dems have a standard deviation of 11.6 and 4.6 m, respectively","['automated digital elevation model extraction', 'across-track spot stereo images', 'stereo satellite images', 'along-track aster data', 'aster stereo pair', 'radiometric variations', 'simultaneous along-track acquisition', 'spot stereo image pair']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['automate digital elevation model extraction', 'across - track spot stereo image', 'stereo satellite image', 'along - track aster datum', 'aster stereo pair', 'radiometric variation', 'simultaneous along - track acquisition', 'spot stereo image pair']","['stereo satellite image', 'automate dem extraction result use', 'digital elevation model', 'aster stereo pair', 'track aster datum', 'extract dem datum', 'hilly mountain', 'spot produce well dem result', 'common satellite datum', 'spot stereo pair']"
423,1075,Numerical simulation of information recovery in quantum computers,"decoherence is the main problem to be solved before quantum computers can be built. to control decoherence, it is possible to use error correction methods, but these methods are themselves noisy quantum computation processes. in this work, we study the ability of steane's and shor's fault-tolerant recovering methods, as well as a modification of steane's ancilla network, to correct errors in qubits. we test a way to measure correctly ancilla's fidelity for these methods, and state the possibility of carrying out an effective error correction through a noisy quantum channel, even using noisy error correction methods","['numerical simulation', 'information recovery', 'quantum computers', 'error correction methods', 'noisy quantum computation processes', 'fault-tolerant recovering methods', 'ancilla network', 'qubits', 'noisy quantum channel', 'noisy error correction methods', 'decoherence control', 'ancilla fidelity']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['numerical simulation', 'information recovery', 'quantum computer', 'error correction method', 'noisy quantum computation process', 'fault - tolerant recover method', 'ancilla network', 'qubit', 'noisy quantum channel', 'noisy error correction method', 'decoherence control', 'ancilla fidelity']","['noisy quantum computation process', 'noisy quantum channel', 'quantum computer', 'control decoherence', 'decoherence', 'tolerant recover method', 'qubit', 'error correction method', 'fidelity', 'effective error correction']"
424,1389,The case for activity based management,"in today's stormy economic climate businesses need activity based management (abm) more than ever before. in an economic downturn it is a vital tool for pinpointing a business' most profitable customers, products, regions or channels, as well as uncovering the costs of individual business processes that may need to be improved in order to drive higher profit levels. changes may be afoot in the abm market, but armstrong laing group ceo mike sherratt argues that businesses need specialists with an abm focus to keep up with their requirements in such a climate. he looks at what benefits a `best-of-breed' abm system can offer businesses and contends that businesses must choose carefully when going down the abm route - and also ask themselves the question whether 'generalist' organisations will be able to deliver the best possible abm solution","['activity based management', 'armstrong laing group', 'activity based costing', 'best-of-breed abm']","['P', 'P', 'R', 'R']","['activity base management', 'armstrong laing group', 'activity base cost', 'well - of - breed abm']","['stormy economic climate business need activity base management', 'armstrong laing group ceo mike sherratt argue', 'individual business process', 'business need specialist', 'abm market', 'profitable customer', 'abm system', 'abm focus', 'drive high profit level', 'abm route']"
425,799,Electronic reserves at University College London: understanding the needs of academic departments,"this article describes a recent project at university college london to explore the feasibility of providing a service to improve access to electronic course materials. funded by the higher education funding council for england (hefce), the project was not simply to set up an electronic reserve. by undertaking a needs analysis of academic departments, the project was able to tailor the design of the new service appropriately. while new initiatives in libraries are often established using project funding, this work was unique in being research-led. it also involved collaboration between library and computing staff and learning technologists","['electronic reserves', 'university college london', 'electronic course materials', 'higher education funding council for england', 'computing staff', 'learning technologists', 'academic department needs']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['electronic reserve', 'university college london', 'electronic course material', 'high education funding council for england', 'compute staff', 'learn technologist', 'academic department need']","['university college london', 'high education funding council', 'establish use project funding', 'electronic course material', 'academic department', 'electronic reserve', 'compute staff', 'librarie', 'library', 'involve collaboration']"
426,721,The results of experimental studies of the reflooding of fuel-rod assemblies from above and problems for future investigations,"problems in studying the reflooding of assemblies from above conducted at foreign and russian experimental installations are considered. the efficiency of cooling and flow reversal under countercurrent flow of steam and water, as well as the scale effect are analyzed. the tasks for future experiments that are necessary for the development of modern correlations for the loss-of-coolant accident (loca) computer codes are stated","['russian experimental installations', 'flow reversal', 'countercurrent flow', 'steam', 'water', 'fuel-rod assemblies reflooding', 'cooling efficiency', 'loss-of-coolant accident computer codes', 'loca computer codes']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R']","['russian experimental installation', 'flow reversal', 'countercurrent flow', 'steam', 'water', 'fuel - rod assembly refloode', 'cool efficiency', 'loss - of - coolant accident computer code', 'loca computer code']","['countercurrent flow', 'flow reversal', 'coolant accident', 'russian experimental installation', 'refloode', 'cool', 'assembly', 'computer code', 'correlation', 'experiment']"
427,764,Lattice Boltzmann schemes for quantum applications,"we review the basic ideas behind the quantum lattice boltzmann equation (lbe), and present a few thoughts on the possible use of such an equation for simulating quantum many-body problems on both (parallel) electronic and quantum computers","['lattice boltzmann schemes', 'quantum applications', 'quantum many-body problems', 'quantum computers', 'parallel computing']","['P', 'P', 'P', 'P', 'R']","['lattice boltzmann scheme', 'quantum application', 'quantum many - body problem', 'quantum computer', 'parallel computing']","['quantum lattice boltzmann equation', 'simulate quantum many', 'lbe', 'parallel', 'body problem', 'equation', 'few', 'basic idea', 'present', 'electronic']"
428,1331,Enterprise content integration III: Agari Mediaware's Media Star,"since we introduced the term enterprise content integration (eci) in january, the concept has gained momentum in the market. in addition to context media's interchange platform and savantech's photon commerce, agari mediaware's media star is in the fray. it is a middleware platform that allows large media companies to integrate their digital systems with great flexibility","['enterprise content integration', 'middleware', 'agari mediaware media star']","['P', 'P', 'R']","['enterprise content integration', 'middleware', 'agari mediaware medium star']","['term enterprise content integration', 'allow large medium company', 'middleware platform', 'medium star', 'interchange platform', 'context medium', 'digital system', 'photon commerce', 'eci', 'mediaware']"
429,1374,Using technology to facilitate the design and delivery of warnings,"this paper describes several ways in which new technologies can assist in the design and delivery of warnings. there are four discussion points: (1) current product information can be delivered via the internet; (2) computer software and hardware are available to assist in the design, construction, and production of visual and auditory warnings; (3) various detection devices can be used to recognize instances in which warnings might be delivered; and (4) a warning presentation can be modified to fit conditions and persons. implications, example applications and future prospects of these points are described","['product information', 'internet', 'computer software', 'auditory warnings', 'warning presentation', 'computer hardware']","['P', 'P', 'P', 'P', 'P', 'R']","['product information', 'internet', 'computer software', 'auditory warning', 'warn presentation', 'computer hardware']","['auditory warning', 'warn presentation', 'various detection device', 'warning', 'computer software', 'current product information', 'new technology', 'example application', 'paper describe several way', 'recognize instance']"
430,1459,Wave propagation related to high-speed train. A scaled boundary FE-approach for unbounded domains,"analysis of wave propagation in solid materials under moving loads is a topic of great interest in railway engineering. the objective of the paper is three-dimensional modelling of high-speed train related ground vibrations; in particular the question of how to account for the unbounded media is addressed. for efficient and accurate modelling of railway structural components taking the unbounded media into account, a hybrid method based on a combination of the conventional finite element method and scaled boundary finite element method is established. in the paper, element matrices and solution procedures for the scaled boundary finite element method (sbfem) are derived. a non-linear finite element iteration scheme using lagrange multipliers and coupling between the unbounded domain and the finite element domain are also discussed. two numerical examples including one example demonstrating the dynamical response of a railroad section are presented to demonstrate the performance of the proposed method","['wave propagation', 'solid materials', 'railway engineering', 'modelling', 'high-speed train related ground vibrations', 'unbounded media', 'railway structural components', 'scaled boundary finite element method', 'element matrices', 'solution procedures', 'lagrange multipliers', 'dynamical response', 'railroad section', '3d modelling', 'nonlinear finite element iteration scheme']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M']","['wave propagation', 'solid material', 'railway engineering', 'model', 'high - speed train relate ground vibration', 'unbounded medium', 'railway structural component', 'scale boundary finite element method', 'element matrix', 'solution procedure', 'lagrange multiplier', 'dynamical response', 'railroad section', '3d modelling', 'nonlinear finite element iteration scheme']","['scale boundary finite element method', 'railway structural component', 'railway engineering', 'wave propagation', 'linear finite element iteration', 'finite element method', 'railroad section', 'numerical', 'finite element domain', 'speed train']"
431,1088,Parallel implicit predictor corrector methods,"the performance of parallel codes for the solution of initial value problems is usually strongly sensitive to the dimension of the continuous problem. this is due to the overhead related to the exchange of information among the processors and motivates the problem of minimizing the amount of communications. according to this principle, we define the so called parallel implicit predictor corrector methods and in this class we derive a-stable, l-stable and numerically zero-stable formulas. the latter property refers to the zero-stability condition of a given formula when roundoff errors are introduced in its coefficients due to their representation in finite precision arithmetic. some numerical experiment show the potentiality of this approach","['parallel implicit predictor corrector methods', 'initial value problems', 'numerically zero-stable formulas', 'zero-stability condition', 'roundoff errors', 'finite precision arithmetic']","['P', 'P', 'P', 'P', 'P', 'P']","['parallel implicit predictor corrector method', 'initial value problem', 'numerically zero - stable formula', 'zero - stability condition', 'roundoff error', 'finite precision arithmetic']","['parallel implicit predictor corrector method', 'finite precision arithmetic', 'parallel code', 'numerical', 'roundoff error', 'stable formula', 'stability condition', 'initial value problem', 'processor', 'communication']"
432,1269,Minimizing the number of successor states in the stubborn set method,"combinatorial explosion which occurs in parallel compositions of ltss can be alleviated by letting the stubborn set method construct on-the-fly a reduced lts that is cffd- or csp-equivalent to the actual parallel composition. this article considers the problem of minimizing the number of successor states of a given state in the reduced lts. the problem can be solved by constructing an and/or-graph with weighted vertices and by finding a set of vertices that satisfies a certain constraint such that no set of vertices satisfying the constraint has a smaller sum of weights. without weights, the and/or-graph can be constructed in low-degree polynomial time w.r.t. the length of the input of the problem. however, since actions can be nondeterministic and transitions can share target states, it is not known whether the weights are generally computable in polynomial time. consequently, it is an open problem whether minimizing the number of successor states is as ""easy"" as minimizing the number of successor transitions","['stubborn set method', 'combinatorial explosion', 'csp-equivalence', 'weighted vertices', 'low-degree polynomial time']","['P', 'P', 'P', 'P', 'P']","['stubborn set method', 'combinatorial explosion', 'csp - equivalence', 'weight vertex', 'low - degree polynomial time']","['parallel composition', 'actual parallel composition', 'successor state', 'certain constraint such', 'stubborn set method construct', 'reduce lts', 'combinatorial explosion', 'vertice satisfy', 'weight vertex', 'constraint have']"
433,679,Himalayan information system: a proposed model,"the information explosion and the development in information technology force us to develop information systems in various fields. the research on himalaya has achieved phenomenal growth in recent years in india. the information requirements of himalayan researchers are divergent in nature. in order to meet these divergent needs, all information generated in various himalayan research institutions has to be collected and organized to facilitate free flow of information. this paper describes the need for a system for himalayan information. it also presents the objectives of himalayan information system (himis). it discusses in brief the idea of setting up a himis and explains its utility to the users. it appeals to the government for supporting the development of such system","['information explosion', 'information technology', 'india', 'information requirements', 'himis', 'government', 'himalayan information system model', 'information network']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['information explosion', 'information technology', 'india', 'information requirement', 'himis', 'government', 'himalayan information system model', 'information network']","['himalayan information system', 'various himalayan research institution have', 'himalayan information', 'develop information system', 'himalayan researcher', 'information technology', 'information requirement', 'information generate', 'himalaya', 'information explosion']"
434,917,Efficient transitive closure reasoning in a combined class/part/containment hierarchy,"class hierarchies form the backbone of many implemented knowledge representation and reasoning systems. they are used for inheritance, classification and transitive closure reasoning. part hierarchies are also important in artificial intelligence. other hierarchies, e.g. containment hierarchies, have received less attention in artificial intelligence. this paper presents an architecture and an implementation of a hierarchy reasoner that integrates a class hierarchy, a part hierarchy, and a containment hierarchy into one structure. in order to make an implemented reasoner useful, it needs to operate at least at speeds comparable to human reasoning. as real-world hierarchies are always large, special techniques need to be used to achieve this. we have developed a set of parallel algorithms and a data representation called maximally reduced tree cover for that purpose. the maximally reduced tree cover is an improvement of a materialized transitive closure representation which has appeared in the literature. our experiments with a medical vocabulary show that transitive closure reasoning for combined class/part/containment hierarchies in near constant time is possible for a fixed hardware configuration","['transitive closure reasoning', 'containment hierarchy', 'class hierarchy', 'knowledge representation', 'inheritance', 'classification', 'part hierarchy', 'part hierarchy', 'artificial intelligence', 'parallel algorithms', 'data representation', 'maximally reduced tree cover', 'materialized transitive closure representation', 'experiments', 'medical vocabulary', 'fixed hardware configuration', 'parallel reasoning', 'part hierarchies']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'P']","['transitive closure reason', 'containment hierarchy', 'class hierarchy', 'knowledge representation', 'inheritance', 'classification', 'part hierarchy', 'part hierarchy', 'artificial intelligence', 'parallel algorithm', 'datum representation', 'maximally reduce tree cover', 'materialize transitive closure representation', 'experiment', 'medical vocabulary', 'fix hardware configuration', 'parallel reasoning', 'part hierarchy']","['materialize transitive closure representation', 'transitive closure reason', 'hierarchy reasoner', 'containment hierarchy', 'containment hierarchy', 'many implement knowledge representation', 'implement reasoner useful', 'class hierarchy form', 'class hierarchy', 'part hierarchy']"
435,585,Fuzzy system modeling in pharmacology: an improved algorithm,"in this paper, we propose an improved fuzzy system modeling algorithm to address some of the limitations of the existing approaches identified during our modeling with pharmacological data. this algorithm differs from the existing ones in its approach to the cluster validity problem (i.e., number of clusters), the projection schema (i.e., input membership assignment and rule determination), and significant input determination. the new algorithm is compared with the bazoon-turksen model, which is based on the well-known sugeno-yasukawa approach. the comparison was made in terms of predictive performance using two different data sets. the first comparison was with a two variable nonlinear function prediction problem and the second comparison was with a clinical pharmacokinetic modeling problem. it is shown that the proposed algorithm provides more precise predictions. determining the degree of significance for each input variable, allows the user to distinguish their relative importance","['fuzzy system modeling', 'pharmacology', 'cluster validity problem', 'projection schema', 'significant input determination', 'predictive performance', 'pharmacokinetic modeling', 'fuzzy sets', 'fuzzy logic']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['fuzzy system modeling', 'pharmacology', 'cluster validity problem', 'projection schema', 'significant input determination', 'predictive performance', 'pharmacokinetic modeling', 'fuzzy set', 'fuzzy logic']","['improve fuzzy system model algorithm', 'clinical pharmacokinetic modeling problem', 'variable nonlinear function prediction problem', 'cluster validity problem', 'pharmacological datum', 'predictive performance use', 'algorithm differ', 'significant input determination', 'propose algorithm', 'different datum set']"
436,111,Modification for synchronization of Rossler and Chen chaotic systems,"active control is an effective method for making two identical rossler and chen systems be synchronized. however, this method works only for a certain class of chaotic systems with known parameters both in drive systems and response systems. modification based on lyapunov stability theory is proposed in order to overcome this limitation. an adaptive synchronization controller, which can make the states of two identical rossler and chen systems globally asymptotically synchronized in the presence of system's unknown constant parameters, is derived. especially, when some unknown parameters are positive, we can make the controller more simple, besides, the controller is independent of those positive uncertain parameters. at last, when the condition that arbitrary unknown parameters in two systems are identical constants is cancelled, we demonstrate that it is possible to synchronize two chaotic systems. all results are proved using a well-known lyapunov stability theorem. numerical simulations are given to validate the proposed synchronization approach","['synchronization', 'chen chaotic systems', 'active control', 'response systems', 'lyapunov stability theory', 'adaptive synchronization controller', 'global asymptotic synchronization', 'rossler chaotic systems']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['synchronization', 'chen chaotic system', 'active control', 'response system', 'lyapunov stability theory', 'adaptive synchronization controller', 'global asymptotic synchronization', 'rossler chaotic system']","['adaptive synchronization controller', 'lyapunov stability theory', 'know lyapunov stability theorem', 'chaotic system', 'synchronize', 'identical rossler', 'synchronize', 'chen systems', 'identical constant', 'unknown constant parameter']"
437,1195,Sharpening the estimate of the stability constant in the maximum-norm of the Crank-Nicolson scheme for the one-dimensional heat equation,"this paper is concerned with the stability constant c/sub infinity / in the maximum-norm of the crank-nicolson scheme applied. to the one-dimensional heat equation. a well known result due to s.j. serdyukova is that c/sub infinity / < 23. in the present paper, by using a sharp resolvent estimate for the discrete laplacian together with the cauchy formula, it is shown that 3 <or= c/sub infinity / < 4.325. this bound also holds when the heat equation is considered on a bounded interval along with dirichlet or neumann boundary conditions","['stability constant', 'crank-nicolson scheme', 'one-dimensional heat equation', 'sharp resolvent estimate', 'discrete laplacian', 'cauchy formula', 'neumann boundary conditions', 'dirichlet boundary conditions']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['stability constant', 'crank - nicolson scheme', 'one - dimensional heat equation', 'sharp resolvent estimate', 'discrete laplacian', 'cauchy formula', 'neumann boundary condition', 'dirichlet boundary condition']","['discrete laplacian', 'nicolson', 'resolvent estimate', 'dimensional heat equation', 'bound interval', 'stability constant', 'heat equation', 'maximum', 'cauchy formula', 'bind']"
438,1168,Computing failure probabilities. Applications to reliability analysis,"the paper presents one method for calculating failure probabilities with applications to reliability analysis. the method is based on transforming the initial set of variables to a n-dimensional uniform random variable in the unit hypercube, together with the limit condition set and calculating the associated probability using a recursive method based on the gauss-legendre quadrature formulas to calculate the resulting multiple integrals. an example of application is used to illustrate the proposed method","['n-dimensional uniform random variable', 'unit hypercube', 'limit condition', 'recursive method', 'gauss-legendre quadrature formulae', 'failure probabilities computation', 'reliability analysis applications', 'multiple integrals calculation', 'tail approximation']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'U']","['n - dimensional uniform random variable', 'unit hypercube', 'limit condition', 'recursive method', 'gauss - legendre quadrature formulae', 'failure probability computation', 'reliability analysis application', 'multiple integral calculation', 'tail approximation']","['calculate failure probability', 'reliability analysis', 'legendre quadrature formula', 'dimensional uniform random variable', 'unit hypercube', 'recursive method', 'probability use', 'calculate', 'gauss', 'method']"
439,578,New approach to standing phase angle reduction for power system restoration,"during power system restoration, it is necessary to check the phase angle between two buses before closing circuit breakers to connect a line between them. these angles may occur across a tie line between two systems or between two connected subsystems within a system. in case of large standing phase angle (spa) difference the synchro-check relay does not allow closing of the breaker for this line. therefore, this excessive spa has to be reduced before attempting to connect the line. in this paper, a new and fast method for reducing spa is presented. for this purpose, the standing phase angle difference between two specific buses is represented in terms of sensitivity factors associated with the change in active power generations and consumption at the buses. then, the proposed method reschedule generation of selected units or shed load of selected buses to reduce excessive spa difference between two buses based on sensitivity factors","['power system restoration', 'sensitivity factors', 'standing phase angle reduction approach', 'circuit breaker closing', 'synchrocheck relay', 'power line connection']","['P', 'P', 'R', 'R', 'M', 'R']","['power system restoration', 'sensitivity factor', 'stand phase angle reduction approach', 'circuit breaker closing', 'synchrocheck relay', 'power line connection']","['close circuit breaker', 'stand phase angle difference', 'propose method reschedule generation', 'stand phase angle', 'phase angle', 'relay', 'specific bus', 'breaker', 'bus', 'power system restoration']"
440,684,Individual decision making using fuzzy set theory,the paper shows the importance of decision making by an individual and highlights the prime domain of decision making where fuzzy set theory can be used as a tool. fuzzy set theory has been used on rational model of decision making to arrive at the desired conclusion,"['individual decision making', 'fuzzy set theory', 'rational decision making model']","['P', 'P', 'R']","['individual decision make', 'fuzzy set theory', 'rational decision make model']","['fuzzy set theory', 'decision make', 'rational model', 'prime domain', 'importance', 'individual', 'tool', 'show']"
441,1294,Multicriterion optimization of composite laminates for maximum failure margins with an interactive descent algorithm,"an interactive multicriterion optimization method for composite laminates subjected to multiple loading conditions is introduced. laminate margins to initial failure (first ply failure, fpf) with respect of the applied loading conditions are treated as criteria. the original problem is reduced to a, bicriterion problem by introducing parameters to combine criteria in a linear manner. the problem is solved by using an interactive descent algorithm. both the conditions required for a discrete procedure to converge towards a pareto optimum and numerical examples are given","['composite laminates', 'maximum failure margins', 'interactive descent algorithm', 'interactive multicriterion optimization', 'multiple loading conditions', 'first ply failure', 'bicriterion problem', 'discrete procedure', 'convergence', 'pareto optimum']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['composite laminate', 'maximum failure margin', 'interactive descent algorithm', 'interactive multicriterion optimization', 'multiple loading condition', 'first ply failure', 'bicriterion problem', 'discrete procedure', 'convergence', 'pareto optimum']","['interactive multicriterion optimization method', 'composite laminate subject', 'laminate margin', 'pareto optimum', 'interactive descent algorithm', 'multiple loading condition', 'apply loading condition', 'combine criterion', 'bicriterion problem', 'parameter']"
442,808,A novel control logic for fast valving operations,this letter proposes new control logic for operating parallel valves in fast valving schemes in order to improve the transient stability performance of power systems. a fast valving scheme using parallel valves overcomes many of the limitations of the conventional scheme. the proposed control logic for operating these valves has been applied to a typical single machine infinite bus system. single as well as multiple stroke operations for controlling the turbine power output have been studied with the new control sequences. encouraging results have been shown over the conventional schemes of fast valving,"['control logic', 'transient stability performance', 'transient stability', 'single machine infinite bus system', 'multiple stroke operations', 'parallel valves operation', 'single stroke operations', 'turbine power output control']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['control logic', 'transient stability performance', 'transient stability', 'single machine infinite bus system', 'multiple stroke operation', 'parallel valve operation', 'single stroke operation', 'turbine power output control']","['valve scheme use parallel valve overcome', 'operate parallel valve', 'turbine power output', 'single machine infinite bus system', 'valve', 'transient stability performance', 'multiple stroke operation', 'valve scheme', 'control logic', 'power system']"
443,723,Simulation of physicochemical processes of erosion-corrosion of metals in two-phase flows,"a computational model for the erosion-corrosion of the metals used in power equipment in two-phase flows (ramek-2) was developed. the results of calculations of the dependency of the intensity of the erosion-corrosion of structural steels as a function of the thermodynamic, hydrodynamic and water chemistry parameters of these flows in the working paths of thermal power stations and nuclear power stations are presented in a three-dimensional space. on the basis of mathematical models, application software was created for forecasting the erosion-corrosion resource and for optimizing the rules on diagnosis and protective maintenance of erosion-corrosion of the elements of the wet-steam path in power stations","['two-phase flows', 'ramek-2', 'structural steels', 'three-dimensional space', 'application software', 'protective maintenance', 'wet-steam path', 'erosion-corrosion computational model', 'computer simulation', 'thermodynamic parameters', 'hydrodynamic parameters', 'water-chemistry parameters', 'thermal power plants', 'nuclear power plants', 'fault diagnosis']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M']","['two - phase flow', 'ramek-2', 'structural steel', 'three - dimensional space', 'application software', 'protective maintenance', 'wet - steam path', 'erosion - corrosion computational model', 'computer simulation', 'thermodynamic parameter', 'hydrodynamic parameter', 'water - chemistry parameter', 'thermal power plant', 'nuclear power plant', 'fault diagnosis']","['corrosion', 'erosion', 'phase flow', 'water chemistry parameter', 'nuclear power station', 'hydrodynamic', 'steel', 'calculation', 'thermal power station', 'metal use']"
444,766,Physical quantum algorithms,"i review the differences between classical and quantum systems, emphasizing the connection between no-hidden variable theorems and superior computational power of quantum computers. using quantum lattice gas automata as examples, i describe possibilities for efficient simulation of quantum and classical systems with a quantum computer. i conclude with a list of research directions","['physical quantum algorithms', 'no-hidden variable theorems', 'quantum computers', 'quantum lattice gas automata', 'classical systems']","['P', 'P', 'P', 'P', 'P']","['physical quantum algorithm', 'no - hide variable theorem', 'quantum computer', 'quantum lattice gas automata', 'classical system']","['quantum lattice gas automata', 'quantum system', 'quantum computer', 'quantum computer', 'quantum', 'classical system', 'efficient simulation', 'superior computational', 'hide variable theorem', 'classical']"
445,1333,"The crossing number of P(N, 3)","it is proved that the crossing number of the generalized petersen graph p(3k + h, 3) is k + h if h in {0, 2} and k + 3 if h = 1, for each k >or= 3, with the single exception of p(9,3), whose crossing number is 2","['crossing number', 'generalized petersen graph']","['P', 'P']","['cross number', 'generalize petersen graph']","['generalize petersen graph', 'cross number', 'single exception', 'prove']"
446,1376,Enhanced product support through intelligent product manuals,"the scope of this paper is the provision of intelligent product support within the distributed intranet/internet environment. from the point of view of user requirements, the limitations of conventional product manuals and methods of authoring them are first outlined. it is argued that enhanced product support requires new technology solutions both for product manuals and for their authoring and presentation. the concept and the architecture of intelligent product manuals are then discussed. a prototype system called proartweb is presented to demonstrate advanced features of intelligent product manuals. next, the problem of producing such manuals in a cost-effective way is addressed and a concurrent engineering approach to their authoring is proposed. an integrated environment for collaborative authoring called proauthor is described to illustrate the approach suggested and to show how consistent, up-to-date and user-oriented-product manuals can be designed. the solutions presented here enable product knowledge to be captured and delivered to users and developers of product manuals when, where and in the form they need it","['intelligent product manuals', 'product manuals', 'intelligent product support', 'proartweb', 'concurrent engineering', 'product knowledge', 'technical information']","['P', 'P', 'P', 'P', 'P', 'P', 'U']","['intelligent product manual', 'product manual', 'intelligent product support', 'proartweb', 'concurrent engineering', 'product knowledge', 'technical information']","['enhance product support require new technology solution', 'collaborative author call proauthor', 'intelligent product manual', 'prototype system call proartweb', 'conventional product manual', 'produce such manual', 'product manual', 'intelligent product support', 'enable product knowledge', 'distribute intranet']"
447,1032,Satellite image collection optimization,"imaging satellite systems represent a high capital cost. optimizing the collection of images is critical for both satisfying customer orders and building a sustainable satellite operations business. we describe the functions of an operational, multivariable, time dynamic optimization system that maximizes the daily collection of satellite images. a graphical user interface allows the operator to quickly see the results of what if adjustments to an image collection plan. used for both long range planning and daily collection scheduling of space imaging's ikonos satellite, the satellite control and tasking (sct) software allows collection commands to be altered up to 10 min before upload to the satellite","['satellite image collection optimization', 'imaging satellite systems', 'graphical user interface', 'image collection plan', 'long range planning', 'daily collection scheduling', 'collection commands', 'multivariable time dynamic optimization system', 'space imaging ikonos satellite', 'satellite control tasking software']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['satellite image collection optimization', 'image satellite system', 'graphical user interface', 'image collection plan', 'long range planning', 'daily collection scheduling', 'collection command', 'multivariable time dynamic optimization system', 'space imaging ikonos satellite', 'satellite control task software']","['image satellite system represent', 'sustainable satellite operation business', 'software allow collection command', 'time dynamic optimization system', 'daily collection scheduling', 'satellite image', 'ikonos satellite', 'satellite control', 'image collection plan', 'space imaging']"
448,1077,Quantum learning and universal quantum matching machine,"suppose that three kinds of quantum systems are given in some unknown states |f>/sup (x)n/, |g/sub 1/>/sup (x)k/, and |g/sub 2/>/sup (x)k/, and we want to decide which template state |g/sub 1/> or |g/sub 2/>, each representing the feature of the pattern class c/sub 1/ or c/sub 2/, respectively, is closest to the input feature state |f>. this is an extension of the pattern matching problem into the quantum domain. assuming that these states are known a priori to belong to a certain parametric family of pure qubit systems, we derive two kinds of matching strategies. the first one is a semiclassical strategy that is obtained by the natural extension of conventional matching strategies and consists of a two-stage procedure: identification (estimation) of the unknown template states to design the classifier (learning process to train the classifier) and classification of the input system into the appropriate pattern class based on the estimated results. the other is a fully quantum strategy without any intermediate measurement, which we might call as the universal quantum matching machine. we present the bayes optimal solutions for both strategies in the case of k=1, showing that there certainly exists a fully quantum matching procedure that is strictly superior to the straightforward semiclassical extension of the conventional matching strategy based on the learning process","['quantum learning', 'universal quantum matching machine', 'pattern class', 'pattern matching problem', 'quantum domain', 'qubit systems', 'matching strategies', 'matching strategies', 'semiclassical strategy', 'two-stage procedure', 'learning process', 'quantum strategy', 'bayes optimal solutions', 'quantum matching procedure', 'semiclassical extension', 'matching strategy']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['quantum learn', 'universal quantum matching machine', 'pattern class', 'pattern matching problem', 'quantum domain', 'qubit system', 'match strategy', 'match strategy', 'semiclassical strategy', 'two - stage procedure', 'learn process', 'quantum strategy', 'bay optimal solution', 'quantum matching procedure', 'semiclassical extension', 'matching strategy']","['universal quantum matching machine', 'quantum matching procedure', 'quantum system', 'pure qubit system', 'pattern match', 'quantum strategy', 'conventional matching strategy base', 'conventional matching strategy', 'match strategy', 'quantum domain']"
449,686,Technology CAD of SiGe-heterojunction field effect transistors,a 2d virtual wafer fabrication simulation suite has been employed for the technology cad of sige channel heterojunction field effect transistors (hfets). complete fabrication process of sige p-hfets has been simulated. the sige material parameters and mobility model were incorporated to simulate si/sige p-hfets with a uniform germanium channel having an l/sub eff/ of 0.5 mu m. a significant improvement in linear transconductance is observed when compared to control-silicon p-mosfets,"['technology cad', 'sige', 'heterojunction field effect transistors', 'fabrication process', 'material parameters', 'mobility model', 'linear transconductance', 'uniform channel', '0.5 micron']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['technology cad', 'sige', 'heterojunction field effect transistor', 'fabrication process', 'material parameter', 'mobility model', 'linear transconductance', 'uniform channel', '0.5 micron']","['sige channel heterojunction field effect transistor', '2d virtual wafer fabrication simulation', 'hfet', 'sige', 'transconductance', 'simulate', 'simulate', 'silicon', 'technology cad', 'fabrication']"
450,1296,Development of visual design steering as an aid in large-scale multidisciplinary design optimization. I. Method development,"a modified paradigm of computational steering (cs), termed visual design steering (vds), is developed in this paper. the vds paradigm is applied to optimal design problems to provide a means for capturing and enabling designer insights. vds allows a designer to make decisions before, during or after an analysis or optimization via a visual environment, in order to effectively steer the solution process. the objective of vds is to obtain a better solution in less time through the use of designer knowledge and expertise. using visual representations of complex systems in this manner enables human experience and judgement to be incorporated into the optimal design process at appropriate steps, rather than having traditional black box solvers return solutions from a prescribed input set. part i of this paper focuses on the research issues pertaining to the graph morphing visualization method created to represent an n-dimensional optimization problem using 2-dimensional and 3-dimensional visualizations. part ii investigates the implementation of the vds paradigm, using the graph morphing approach, to improve an optimal design process. specifically, the following issues are addressed: impact of design variable changes on the optimal design space; identification of possible constraint redundancies; impact of constraint tolerances on the optimal solution: and smoothness of the objective function contours. it is demonstrated that graph morphing can effectively reduce the complexity and computational time associated with some optimization problems","['visual design steering', 'large-scale multidisciplinary design optimization', 'computational steering', 'optimal design problems', 'visual representations', 'complex systems', 'complexity', 'graph morphing visualization method', 'n-dimensional optimization', 'design variable changes', 'constraint redundancies', 'constraint tolerances', 'computational time', 'designer decision making', '3d visualizations', '2d visualizations', 'objective function contour smoothness']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M', 'R']","['visual design steering', 'large - scale multidisciplinary design optimization', 'computational steering', 'optimal design problem', 'visual representation', 'complex system', 'complexity', 'graph morph visualization method', 'n - dimensional optimization', 'design variable change', 'constraint redundancy', 'constraint tolerance', 'computational time', 'designer decision make', '3d visualization', '2d visualization', 'objective function contour smoothness']","['graph morph visualization method create', 'term visual design steering', 'graph morph approach', 'graph morph', 'dimensional visualization', 'optimal design space', 'optimal design problem', 'dimensional optimization problem use', 'optimal design process', 'use visual representation']"
451,915,A meteorological fuzzy expert system incorporating subjective user input,"we present a fuzzy expert system, medex, for forecasting gale-force winds in the mediterranean basin. the most successful local wind forecasting in this region is achieved by an expert human forecaster with access to numerical weather prediction products. that forecaster's knowledge is expressed as a set of 'rules-of-thumb'. fuzzy set methodologies have proved well suited for encoding the forecaster's knowledge, and for accommodating the uncertainty inherent in the specification of rules, as well as in subjective and objective input. medex uses fuzzy set theory in two ways: as a fuzzy rule base in the expert system, and for fuzzy pattern matching to select dominant wind circulation patterns as one input to the expert system. the system was developed, tuned, and verified over a two-year period, during which the weather conditions from 539 days were individually analyzed. evaluations of medex performance for both the onset and cessation of winter and summer winds are presented, and demonstrate that medex has forecasting skill competitive with the us navy's regional forecasting center in rota, spain","['meteorological fuzzy expert system', 'subjective user input', 'medex', 'mediterranean basin', 'numerical weather prediction products', 'rules-of-thumb', 'uncertainty', 'fuzzy set theory', 'fuzzy rule base', 'fuzzy pattern matching', 'wind circulation patterns', 'gale-force wind forecasting', 'subjective variables', 'rule specification']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'R']","['meteorological fuzzy expert system', 'subjective user input', 'medex', 'mediterranean basin', 'numerical weather prediction product', 'rule - of - thumb', 'uncertainty', 'fuzzy set theory', 'fuzzy rule base', 'fuzzy pattern match', 'wind circulation pattern', 'gale - force wind forecast', 'subjective variable', 'rule specification']","['expert human forecaster', 'fuzzy expert system', 'medex use fuzzy set theory', 'numerical weather prediction product', 'local wind forecast', 'select dominant wind circulation pattern', 'forecast skill competitive', 'fuzzy set methodology', 'forecast gale', 'fuzzy pattern match']"
452,587,An improved self-organizing CPN-based fuzzy system with adaptive back-propagation algorithm,"this paper describes an improved self-organizing cpn-based (counter-propagation network) fuzzy system. two self-organizing algorithms iusocpn and issocpn, being unsupervised and supervised respectively, are introduced. the idea is to construct the neural-fuzzy system with a two-phase hybrid learning algorithm, which utilizes a cpn-based nearest-neighbor clustering scheme for both structure learning and initial parameters setting, and a gradient descent method with adaptive learning rate for fine tuning the parameters. the obtained network can be used in the same way as a cpn to model and control dynamic systems, while it has a faster learning speed than the original back-propagation algorithm. the comparative results on the examples suggest that the method is fairly efficient in terms of simple structure, fast learning speed, and relatively high modeling accuracy","['counter-propagation network', 'neural-fuzzy system', 'hybrid learning', 'structure learning', 'initial parameters setting', 'gradient descent', 'self-organizing fuzzy system', 'back-propagation learning scheme']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['counter - propagation network', 'neural - fuzzy system', 'hybrid learning', 'structure learn', 'initial parameter set', 'gradient descent', 'self - organize fuzzy system', 'back - propagation learn scheme']","['organize algorithm iusocpn', 'phase hybrid learning algorithm', 'organize cpn', 'adaptive learning rate', 'propagation algorithm', 'structure learn', 'neighbor clustering scheme', 'propagation network', 'fuzzy system', 'control dynamic system']"
453,950,Quantum sensitive dependence,"wave functions of bounded quantum systems with time-independent potentials, being almost periodic functions, cannot have time asymptotics as in classical chaos. however, bounded quantum systems with time-dependent interactions, as used in quantum control, may have continuous spectrum and the rate of growth of observables is an issue of both theoretical and practical concern. rates of growth in quantum mechanics are discussed by constructing quantities with the same physical meaning as those involved in the classical lyapunov exponent. a generalized notion of quantum sensitive dependence is introduced and the mathematical structure of the operator matrix elements that correspond to different types of growth is characterized","['quantum sensitive dependence', 'wave functions', 'bounded quantum systems', 'time-independent potentials', 'periodic functions', 'time asymptotics', 'classical chaos', 'time-dependent interactions', 'quantum control', 'classical lyapunov exponent', 'operator matrix elements', 'quantum complexity']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['quantum sensitive dependence', 'wave function', 'bound quantum system', 'time - independent potential', 'periodic function', 'time asymptotic', 'classical chaos', 'time - dependent interaction', 'quantum control', 'classical lyapunov exponent', 'operator matrix element', 'quantum complexity']","['quantum sensitive dependence', 'bound quantum system', 'classical lyapunov exponent', 'quantum control', 'quantum mechanic', 'classical chaos', 'operator matrix', 'observable', 'periodic function', 'wave function']"
454,113,Quantum limit on computational time and speed,we investigate if physical laws can impose limits on computational time and speed of a quantum computer built from elementary particles. we show that the product of the speed and the running time of a quantum computer is limited by the type of fundamental interactions present inside the system. this will help us to decide as to what type of interaction should be allowed in building quantum computers in achieving the desired speed,"['quantum limit', 'computational time', 'quantum computer', 'fundamental interactions', 'computational speed']","['P', 'P', 'P', 'P', 'R']","['quantum limit', 'computational time', 'quantum computer', 'fundamental interaction', 'computational speed']","['quantum computer build', 'build quantum computer', 'quantum computer', 'elementary particle', 'fundamental interaction present', 'computational time', 'physical law', 'speed', 'run time', 'impose limit']"
455,1197,Numerical behaviour of stable and unstable solitary waves,"in this paper we analyse the behaviour in time of the numerical approximations to solitary wave solutions of the generalized benjamin-bona-mahony equation. this equation possesses an important property: the stability of these solutions depends on their velocity. we identify the error propagation mechanisms in both the stable and unstable case. in particular, we show that in the stable case, numerical methods that preserve some conserved quantities of the problem are more appropriate for the simulation of this kind of solutions","['numerical behaviour', 'unstable solitary waves', 'numerical approximations', 'generalized benjamin-bona-mahony equation', 'error propagation mechanisms', 'numerical methods', 'stable solitary waves']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['numerical behaviour', 'unstable solitary wave', 'numerical approximation', 'generalize benjamin - bona - mahony equation', 'error propagation mechanism', 'numerical method', 'stable solitary wave']","['solitary wave solution', 'numerical approximation', 'mahony equation', 'numerical method', 'generalize benjamin', 'equation possess', 'error propagation', 'conserve quantity', 'solution', 'bona']"
456,928,Weighted energy linear quadratic regulator vibration control of piezoelectric composite plates,"in this paper on finite element linear quadratic regulator (lqr) vibration control of smart piezoelectric composite plates, we propose the use of the total weighted energy method to select the weighting matrices. by constructing the optimal performance function as a relative measure of the total kinetic energy, strain energy and input energy of the system, only three design variables need to be considered to achieve a balance between the desired higher damping effect and lower input cost. modal control analysis is used to interpret the effects of three energy weight factors on the damping ratios and modal voltages and it is shown that the modal damping effect will increase with the kinetic energy weight factor, approaching square root (2/2) as the strain energy weight factor increases and decrease with the input energy weight factor. numerical results agree well with those from the modal control analysis. since the control problem is simplified to three design variables only, the computational cost will be greatly reduced and a more accurate structural control analysis becomes more attractive for large systems","['vibration control', 'finite element linear quadratic regulator', 'smart piezoelectric composite plates', 'total weighted energy', 'weighting matrices', 'optimal performance function', 'total kinetic energy', 'strain energy', 'damping effect', 'modal control analysis', 'damping ratios', 'strain energy weight factor', 'numerical results', 'computational cost', 'structural control analysis']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['vibration control', 'finite element linear quadratic regulator', 'smart piezoelectric composite plate', 'total weight energy', 'weight matrix', 'optimal performance function', 'total kinetic energy', 'strain energy', 'damp effect', 'modal control analysis', 'damp ratio', 'strain energy weight factor', 'numerical result', 'computational cost', 'structural control analysis']","['smart piezoelectric composite plate', 'vibration control', 'element linear quadratic regulator', 'modal damp effect', 'kinetic energy weight factor', 'damp ratio', 'energy weight factor', 'strain energy weight factor', 'energy weight factor', 'damp effect']"
457,1256,High-speed consistency checking for hypothetical reasoning systems using inference path network,"hypothetical reasoning is popular in fault diagnostics and design systems, but slow reasoning speed is its drawback. the goal of the current study is developing hypothetical reasoning based on an inference path network, which would overcome this drawback. in hypothetical reasoning systems based on an inference path network, there is much room for improvement regarding the computing costs of connotation processing and consistency checking. the authors of this study demonstrate improvement ideas regarding one of these problems, namely, consistency checking. first, the authors obtained necessary and sufficient conditions under which inconsistencies occur during hypothesis composition. based on the obtained results, the authors proposed an algorithm for speeding up the process of consistency checking. processing with this algorithm in its core consists of transforming the inference path network in such a way that inconsistencies do not occur during the hypothesis composition, under the condition of unchanged solution hypotheses. the efficiency of this algorithm was confirmed by tests","['high-speed consistency checking', 'hypothetical reasoning', 'inference path network', 'fault diagnostics', 'reasoning speed', 'inconsistencies', 'hypothesis composition', 'speed up']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['high - speed consistency checking', 'hypothetical reasoning', 'inference path network', 'fault diagnostic', 'reason speed', 'inconsistency', 'hypothesis composition', 'speed up']","['hypothetical reasoning system base', 'inference path network', 'develop hypothetical reasoning base', 'consistency checking', 'slow reasoning speed', 'hypothetical reasoning', 'connotation processing', 'fault diagnostic', 'study demonstrate improvement idea regard', 'hypothesis composition']"
458,1213,A knowledge intensive multi-agent framework for cooperative/collaborative design modeling and decision support of assemblies,"multi-agent modeling has emerged as a promising discipline for dealing with the decision making process in distributed information system applications. one of such applications is the modeling of distributed design or manufacturing processes which can link up various designs or manufacturing processes to form a virtual consortium on a global basis. this paper proposes a novel knowledge intensive multi-agent cooperative/collaborative framework for concurrent intelligent design and assembly planning, which integrates product design, design for assembly, assembly planning, assembly system design, and assembly simulation subjected to econo-technical evaluations. an ai protocol based method is proposed to facilitate the integration of intelligent agents for assembly design, planning, evaluation and simulation processes. a unified class of knowledge intensive petri nets is defined using the oo knowledge-based petri net approach and used as an ai protocol for handling both the integration and the negotiation problems among multi-agents. the detailed cooperative/collaborative mechanism and algorithms are given based on the knowledge object cooperation formalisms. as such, the assembly-oriented design system can easily be implemented under the multi-agent-based knowledge-intensive petri net framework with concurrent integration of multiple cooperative knowledge sources and software. thus, product design and assembly planning can be carried out simultaneously and intelligently in an entirely computer-aided concurrent design and assembly planning system","['knowledge intensive multi-agent framework', 'collaborative design modeling', 'decision support', 'distributed information system applications', 'distributed design', 'virtual consortium', 'concurrent intelligent design', 'assembly planning', 'product design', 'design for assembly', 'assembly simulation', 'ai protocol', 'knowledge intensive petri nets', 'knowledge object cooperation', 'cooperative framework', 'agent negotiation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['knowledge intensive multi - agent framework', 'collaborative design modeling', 'decision support', 'distribute information system application', 'distribute design', 'virtual consortium', 'concurrent intelligent design', 'assembly planning', 'product design', 'design for assembly', 'assembly simulation', 'ai protocol', 'knowledge intensive petri net', 'knowledge object cooperation', 'cooperative framework', 'agent negotiation']","['intensive petri net framework', 'knowledge intensive petri net', 'knowledge object cooperation formalism', 'base petri net approach', 'multiple cooperative knowledge', 'assembly system design', 'concurrent intelligent design', 'assembly planning', 'aid concurrent design', 'assembly simulation']"
459,646,Vibration control of structure by using tuned mass damper (development of system which suppress displacement of auxiliary mass),"in vibration control of a structure by using an active tuned mass damper (atmd), stroke of the auxiliary mass is so limited that it is difficult to control the vibration in the case of large disturbance input. in this paper, two methods are proposed for the problem. one of the methods is a switching control system by two types of controllers. one of the controllers is a normal controller under small relative displacement of the auxiliary mass, and the other is not effective only for first mode of vibration under large relative displacement of the auxiliary mass. new variable gain control system is constructed by switching these two controllers. the other method is the brake system. in active vibration control, it is necessary to use actuator for active control. by using the actuator, the proposed system puts on the brake to suppress displacement increase of the auxiliary mass under large disturbance input. finally, the systems are designed and the effectiveness of the systems is confirmed by the simulation","['vibration control', 'controllers', 'tuned mass damper', 'variable gain control system', 'brake system', 'actuator', 'active control', 'auxiliary mass displacement suppression']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['vibration control', 'controller', 'tune mass damper', 'variable gain control system', 'brake system', 'actuator', 'active control', 'auxiliary mass displacement suppression']","['active vibration control', 'new variable gain control system', 'vibration control', 'active tune mass damper', 'switch control system', 'vibration', 'large disturbance input', 'active control', 'use actuator', 'actuator']"
460,603,PGE helps customers reduce energy costs,"a new service from portland general electric (pge, portland, oregon, us) is saving customers tens of thousands of dollars in energy costs. pge created e-manager to allow facility managers to analyze their energy consumption online at 15-minute intervals. customers can go to the web for complete data, powerful analysis tools and charts, helping them detect abnormal energy use and focus on costly problem areas","['portland general electric', 'oregon', 'e-manager', 'energy costs reduction', 'online energy consumption analysis', 'abnormal energy use detection']","['P', 'P', 'P', 'M', 'R', 'R']","['portland general electric', 'oregon', 'e - manager', 'energy cost reduction', 'online energy consumption analysis', 'abnormal energy use detection']","['portland general electric', 'detect abnormal energy use', 'energy cost', 'energy consumption', 'allow facility manager', 'powerful analysis tool', 'save customer ten', 'pge create', 'pge', 'new service']"
461,81,A scalable and efficient systolic algorithm for the longest common subsequence problem,"a longest common subsequence (lcs) of two strings is a common subsequence of two strings of maximal length. the lcs problem is that of finding an lcs of two given strings and the length of the lcs. this problem has been the subject of much research because its solution can be applied in many areas. in this paper, a scalable and efficient systolic algorithm is presented. for two given strings of length m and n, where m>or=n, the algorithm can solve the lcs problem in m+2r-1 (respectively n+2r-1) time steps with r<n/2 (respectively r<m/2) processors. experimental results show that the algorithm can be faster on multicomputers than all the previous systolic algorithms for the same problem","['systolic algorithm', 'longest common subsequence problem', 'scalable algorithm', 'parallel algorithms']","['P', 'P', 'R', 'M']","['systolic algorithm', 'long common subsequence problem', 'scalable algorithm', 'parallel algorithm']","['efficient systolic algorithm', 'long common subsequence', 'previous systolic algorithm', 'common subsequence', 'algorithm', 'maximal length', 'give string', 'string', 'lcs problem', 'length']"
462,1157,Portal dose image prediction for dosimetric treatment verification in radiotherapy. II. An algorithm for wedged beams,"a method is presented for calculation of a two-dimensional function, t/sub wedge/(x,y), describing the transmission of a wedged photon beam through a patient. this in an extension of the method that we have published for open (nonwedged) fields [med. phys. 25, 830-840 (1998)]. transmission functions for open fields are being used in our clinic for prediction of portal dose images (pdi, i.e., a dose distribution behind the patient in a plane normal to the beam axis), which are compared with pdis measured with an electronic portal imaging device (epid). the calculations are based on the planning ct scan of the patient and on the irradiation geometry as determined in the treatment planning process. input data for the developed algorithm for wedged beams are derived from (the already available) measured input data set for transmission prediction in open beams, which is extended with only a limited set of measurements in the wedged beam. the method has been tested for a pdi plane at 160 cm from the focus, in agreement with the applied focus-to-detector distance of our fluoroscopic epids. for low and high energy photon beams (6 and 23 mv) good agreement (~1%) has been found between calculated and measured transmissions for a slab and a thorax phantom","['portal dose image prediction', 'dosimetric treatment verification', 'radiotherapy', 'two-dimensional function', 'wedged photon beam', 'electronic portal imaging devices', 'planning ct scan', 'irradiation geometry', 'open beams', 'high energy photon beams', '23 mv', 'thorax phantom', 'transmission dosimetry', 'wedged beams algorithm', 'low energy photon beams', 'slab phantom', 'in vivo dosimetry', 'fluoroscopic ccd camera', 'pencil beam algorithm', 'cadplan planning system', 'virtual wedges', '6 mv']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'R']","['portal dose image prediction', 'dosimetric treatment verification', 'radiotherapy', 'two - dimensional function', 'wedge photon beam', 'electronic portal imaging device', 'plan ct scan', 'irradiation geometry', 'open beam', 'high energy photon beam', '23 mv', 'thorax phantom', 'transmission dosimetry', 'wedge beam algorithm', 'low energy photon beam', 'slab phantom', 'in vivo dosimetry', 'fluoroscopic ccd camera', 'pencil beam algorithm', 'cadplan planning system', 'virtual wedge', '6 mv']","['wedge photon beam', 'photon beam', 'portal imaging device', 'wedge beam', 'beam axis', 'wedge beam', 'portal dose image', 'irradiation geometry', 'detector distance', 'fluoroscopic epid']"
463,1112,Blending parametric patches with subdivision surfaces,"in this paper the problem of blending parametric surfaces using subdivision patches is discussed. a new approach, named removing-boundary, is presented to generate piecewise-smooth subdivision surfaces through discarding the outmost quadrilaterals of the open meshes derived by each subdivision step. then the approach is employed both to blend parametric bicubic b-spline surfaces and to fill n-sided holes. it is easy to produce piecewise-smooth subdivision surfaces with both convex and concave corners on the boundary, and limit surfaces are guaranteed to be c/sup 2/ continuous on the boundaries except for a few singular points by the removing-boundary approach. thus the blending method is very efficient and the blending surface generated is of good effect","['subdivision surfaces', 'subdivision patches', 'piecewise-smooth subdivision surfaces', 'quadrilaterals', 'parametric bicubic b-spline surfaces', 'parametric surfaces blending', 'piecewise smooth subdivision surfaces']","['P', 'P', 'P', 'P', 'P', 'R', 'M']","['subdivision surface', 'subdivision patch', 'piecewise - smooth subdivision surface', 'quadrilateral', 'parametric bicubic b - spline surface', 'parametric surface blend', 'piecewise smooth subdivision surface']","['blend parametric surface use subdivision patch', 'smooth subdivision surface', 'blend surface generate', 'blend parametric bicubic', 'spline surface', 'blend method', 'subdivision step', 'concave corner', 'generate piecewise', 'mesh derive']"
464,547,Excess energy [cooling system],the designers retrofitting a comfort cooling system to offices in hertfordshire have been able to make use of the waste heat rejected. what's more they're now making it a standard solution for much larger projects,"['comfort cooling system', 'waste heat', 'nationwide trust', 'air conditioning']","['P', 'P', 'U', 'U']","['comfort cool system', 'waste heat', 'nationwide trust', 'air conditioning']","['comfort cool system', 'waste heat reject', 'designer retrofit', 'standard solution', 'make use', 'office', 'hertfordshire', 'make', 'able', 'more']"
465,990,Pipelined broadcast with enhanced wormhole routers,"this paper proposes a pipelined broadcast that broadcasts a message of size m in o(m+n-1) time in an n-dimensional hypercube. it is based on the replication tree, which is derived from reachable sets. it has greatly improved performance compared to ho-kao's (1995) algorithm with the time of o(m[n/log(n+1)]). the communication in the broadcast uses an all-port wormhole router with message replication capability. this paper includes the algorithm together with performance comparisons to previous schemes in a practical implementation","['pipelined broadcast', 'enhanced wormhole routers', 'n-dimensional hypercube', 'replication tree', 'reachable sets', 'performance', 'all-port wormhole router', 'message replication capability', 'message broadcast', 'communication complexity', 'intermediate reception']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'U']","['pipeline broadcast', 'enhance wormhole router', 'n - dimensional hypercube', 'replication tree', 'reachable set', 'performance', 'all - port wormhole router', 'message replication capability', 'message broadcast', 'communication complexity', 'intermediate reception']","['port wormhole router', 'pipeline broadcast', 'broadcast use', 'message replication capability', 'replication tree', 'dimensional hypercube', 'broadcast', 'reachable set', 'algorithm', 'communication']"
466,1423,"P2P is dead, long live P2P","picture the problem: a sprawling multinational has hundreds of offices, thousands of workers, and countless amounts of intellectual property scattered here, there, everywhere. in kuala lumpur an executive needs to see an internally-generated report on oil futures in central asia-but where is it? london? new york? moscow? with a few clicks of the mouse-and the right p2p technology deployed in-house-that executive will find and retrieve the report. without p2p that might be impossible-certainly it would be time-consuming-and, right there, the argument for p2p implementations inside enterprises becomes clear. who are the players? no companies have managed to stake out clear leads and the fact is that the p2p marketplace now is up for grabs-but the exciting news is that a range of small and startup businesses are trying to grab turf and quite probably, if the analysts are right, a few of these now little-known companies will emerge as digital content stars within the next few years. cases in point: groove networks, avaki, worldstreet, yaga, nextpage, and kontiki. very different companies-their approach to the markets radically differ-but, say the analysts, each is worth a close look because among them they are defining the future of p2p","['p2p technology', 'businesses', 'digital content', 'groove networks', 'avaki', 'worldstreet', 'yaga', 'nextpage', 'kontiki', 'content owners']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['p2p technology', 'business', 'digital content', 'groove network', 'avaki', 'worldstreet', 'yaga', 'nextpage', 'kontiki', 'content owner']","['p2p marketplace', 'p2p technology', 'p2p implementation', 'digital content star', 'oil future', 'p2p', 'kuala lumpur', 'sprawl multinational', 'startup business', 'groove network']"
467,870,Speaker identification from voice using neural networks,"the paper provides three different schemes for speaker identification of personnel from their voice using artificial neural networks. the first scheme recognizes speakers by employing the classical backpropagation algorithm pre-trained with known voice samples of the persons. the second scheme provides a framework for classifying the known training samples of the voice features using a hierarchical architecture realized with a self-organizing feature map neural net. the first scheme is highly robust as it is capable of identifying the personnel from their noisy voice samples, but because of its excessive training time it has limited applications for a large voice database. the second scheme though not so robust as the former, however, can classify an unknown voice sample to its nearest class. the time needed for classification by the first scheme is always unique irrespective of the voice sample. it is proportional to the number of feedforward layers in the network. the time-requirement of the second classification scheme, however, is not free from the voice features and is proportional to the number of 2d arrays traversed by the algorithm on the hierarchical structure. the third scheme is highly robust and mis-classification is as low as 0.2 per cent. the third scheme combines the composite benefits of a radial basis function neural net and backpropagation trained neural net","['speaker identification', 'personnel', 'artificial neural networks', 'backpropagation algorithm', 'pre-training', 'known voice samples', 'classification', 'hierarchical architecture', 'self-organizing feature map', 'feedforward layers', '2d arrays', 'radial basis function neural net']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['speaker identification', 'personnel', 'artificial neural network', 'backpropagation algorithm', 'pre - training', 'know voice sample', 'classification', 'hierarchical architecture', 'self - organize feature map', 'feedforward layer', '2d array', 'radial basis function neural net']","['voice use artificial neural network', 'organize feature map neural net', 'radial basis function neural net', 'voice feature use', 'noisy voice sample', 'voice feature', 'voice database', 'classical backpropagation algorithm pre', 'know voice sample', 'speaker identification']"
468,835,Pioneering women in computer science,"although their contributions are not well documented, women have played an important role in the development of computer science. a survey of women pioneers demonstrates their influence in designing and programming the first electronic computers and languages, while laying the groundwork for women's expanding involvement in science","['pioneering women', 'electronic computers', 'computer science development', 'programming languages', 'history']","['P', 'P', 'R', 'R', 'U']","['pioneer woman', 'electronic computer', 'computer science development', 'programming language', 'history']","['first electronic computer', 'woman pioneer demonstrate', 'computer science', 'programming', 'woman', 'design', 'expand involvement', 'important role', 'language', 'development']"
469,1173,A comprehensive chatter prediction model for face turning operation including tool wear effect,"presents a three-dimensional mechanistic frequency domain chatter model for face turning processes, that can account for the effects of tool wear including process damping. new formulations are presented to model the variation in process damping forces along nonlinear tool geometries such as the nose radius. the underlying dynamic force model simulates the variation in the chip cross-sectional area by accounting for the displacements in the axial and radial directions. the model can be used to determine stability boundaries under various cutting conditions and different states of flank wear. experimental results for different amounts of wear are provided as a validation for the model","['chatter prediction model', 'face turning operation', 'tool wear effect', 'three-dimensional mechanistic frequency domain chatter model', 'process damping', 'radial directions', 'stability boundaries', 'flank wear', 'axial directions']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['chatter prediction model', 'face turn operation', 'tool wear effect', 'three - dimensional mechanistic frequency domain chatter model', 'process damp', 'radial direction', 'stability boundary', 'flank wear', 'axial direction']","['tool wear include process damp', 'dimensional mechanistic frequency domain chatter model', 'nonlinear tool geometry such', 'face turn process', 'process damp force', 'underlie dynamic force model simulate', 'flank wear', 'cut condition', 'nose radius', 'displacement']"
470,1136,Q-learning for risk-sensitive control,"we propose for risk-sensitive control of finite markov chains a counterpart of the popular q-learning algorithm for classical markov decision processes. the algorithm is shown to converge with probability one to the desired solution. the proof technique is an adaptation of the o.d.e. approach for the analysis of stochastic approximation algorithms, with most of the work involved used for the analysis of the specific o.d.e.s that arise","['risk-sensitive control', 'finite markov chains', 'q-learning algorithm', 'classical markov decision processes', 'proof technique', 'stochastic approximation algorithms', 'algorithm convergence', 'reinforcement learning algorithms', 'dynamic programming', 'ordinary differential equations']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'U', 'U']","['risk - sensitive control', 'finite markov chain', 'q - learn algorithm', 'classical markov decision process', 'proof technique', 'stochastic approximation algorithm', 'algorithm convergence', 'reinforcement learning algorithm', 'dynamic programming', 'ordinary differential equation']","['stochastic approximation algorithm', 'classical markov decision process', 'finite markov chain', 'learn algorithm', 'sensitive control', 'risk', 'probability', 'algorithm', 'adaptation', 'proof technique']"
471,563,Getting the most out of intrusion detection systems,"intrusion detection systems (ids) can play a very valuable role in the defence of a network. however, it is important to understand not just what it will do (and how it does it) - but what it won't do (and why). this article does not go into the technical working of ids in too much detail, rather it limits itself to a discussion of some of the capabilities and failings of the technology","['intrusion detection systems', 'computer network security', 'network attacks', 'firewall']","['P', 'M', 'M', 'U']","['intrusion detection system', 'computer network security', 'network attack', 'firewall']","['intrusion detection system', 'id', 'defence', 'network', 'failing', 'technical working', 'capability', 'valuable role', 'detail', 'limit']"
472,1272,Global action rules in distributed knowledge systems,"previously z. ras and j.m. zytkow (2000) introduced and investigated query answering system based on distributed knowledge mining. the notion of an action rule was introduced by z. ras and a. wieczorkowska (2000) and its application domain e-business was taken. in this paper, we generalize the notion of action rules in a similar way to handling global queries. mainly, when values of attributes for a given customer, used in action rules, can not be easily changed by business user, definitions of these attributes are extracted from other sites of a distributed knowledge system. to be more precise, attributes at every site of a distributed knowledge system are divided into two sets: stable and flexible. values of flexible attributes, for a given consumer, sometime can be changed and this change can be influenced and controlled by a business user. however, some of these changes (for instance to the attribute ""profit') can not be done directly to a chosen attribute. in this case, definitions of such an attribute in terms of other attributes have to be learned. these new definitions are used to construct action rules showing what changes in values of flexible attributes, for a given consumer, are needed in order to re-classify this consumer the way business user wants. but, business user may be either unable or unwilling to proceed with actions leading to such changes. in all such cases we may search for definitions of these flexible attributes looking at either local or remote sites for help","['global action rules', 'action rules', 'query answering system', 'distributed knowledge mining', 'attributes', 'e-commerce']","['P', 'P', 'P', 'P', 'P', 'U']","['global action rule', 'action rule', 'query answer system', 'distribute knowledge mining', 'attribute', 'e - commerce']","['distribute knowledge mining', 'distribute knowledge system', 'investigate query answer system base', 'handle global query', 'other attribute have', 'flexible attribute look', 'construct action rule', 'flexible attribute', 'action rule', 'action rule']"
473,1237,High-performance numerical pricing methods,"the pricing of financial derivatives is an important field in finance and constitutes a major component of financial management applications. the uncertainty of future events often makes analytic approaches infeasible and, hence, time-consuming numerical simulations are required. in the aurora financial management system, pricing is performed on the basis of lattice representations of stochastic multidimensional scenario processes using the monte carlo simulation and backward induction methods, the latter allowing for the exploitation of shared-memory parallelism. we present the parallelization of a backward induction numerical pricing kernel on a cluster of smps using hpf+, an extended version of high-performance fortran. based on language extensions for specifying a hierarchical mapping of data onto an smp cluster, the compiler generates a hybrid-parallel program combining distributed-memory and shared-memory parallelism. we outline the parallelization strategy adopted by the vfc compiler and present an experimental evaluation of the pricing kernel on an nec sx-5 vector supercomputer and a linux smp cluster, comparing a pure mpi version to a hybrid-parallel mpi/openmp version","['pricing', 'finance', 'financial management', 'aurora financial management system', 'monte carlo simulation', 'backward induction methods', 'numerical pricing kernel', 'stochastic processes', 'derivative pricing', 'investment strategies']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M']","['pricing', 'finance', 'financial management', 'aurora financial management system', 'monte carlo simulation', 'backward induction method', 'numerical pricing kernel', 'stochastic process', 'derivative pricing', 'investment strategy']","['backward induction numerical pricing kernel', 'parallel program combine distribute', 'linux smp cluster', 'aurora financial management system', 'parallel mpi', 'parallelization strategy', 'pricing kernel', 'smp cluster', 'monte carlo simulation', 'stochastic multidimensional scenario process use']"
474,627,Comparison of non-stationary time series in the frequency domain,in this paper we compare two nonstationary time series using nonparametric procedures. evolutionary spectra are estimated for the two series. randomization tests are performed on groups of spectral estimates for both related and independent time series. simulation studies show that in certain cases the tests perform reasonably well. the tests are applied to observed geological and financial time series,"['nonstationary time series', 'nonparametric procedures', 'randomization tests', 'spectral estimates', 'independent time series', 'simulation', 'financial time series', 'evolutionary spectra estimation', 'related time series', 'lag window', 'time window', 'geological time series']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U', 'M', 'R']","['nonstationary time series', 'nonparametric procedure', 'randomization test', 'spectral estimate', 'independent time series', 'simulation', 'financial time series', 'evolutionary spectra estimation', 'relate time series', 'lag window', 'time window', 'geological time series']","['nonstationary time series', 'evolutionary spectra', 'independent time series', 'observe geological', 'spectral estimate', 'randomization test', 'series', 'simulation study', 'test perform', 'compare']"
475,58,Robust speech recognition using probabilistic union models,"this paper introduces a new statistical approach, namely the probabilistic union model, for speech recognition involving partial, unknown frequency-band corruption. partial frequency-band corruption accounts for the effect of a family of real-world noises. previous methods based on the missing feature theory usually require the identity of the noisy bands. this identification can be difficult for unexpected noise with unknown, time-varying band characteristics. the new model combines the local frequency-band information based on the union of random events, to reduce the dependence of the model on information about the noise. this model partially accomplishes the target: offering robustness to partial frequency-band corruption, while requiring no information about the noise. this paper introduces the theory and implementation of the union model, and is focused on several important advances. these new developments include a new algorithm for automatic order selection, a generalization of the modeling principle to accommodate partial feature stream corruption, and a combination of the union model with conventional noise reduction techniques to deal with a mixture of stationary noise and unknown, nonstationary noise. for the evaluation, we used the tidigits database for speaker-independent connected digit recognition. the utterances were corrupted by various types of additive noise, stationary or time-varying, assuming no knowledge about the noise characteristics. the results indicate that the new model offers significantly improved robustness in comparison to other models","['robust speech recognition', 'probabilistic union models', 'modeling', 'partial frequency-band corruption', 'missing feature theory', 'noisy bands', 'time-varying band characteristics', 'local frequency-band information', 'automatic order selection', 'partial feature stream corruption', 'noise reduction techniques', 'stationary noise', 'nonstationary noise', 'tidigits database', 'speaker-independent connected digit recognition', 'additive noise', 'noise characteristics', 'partial real-world noise']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['robust speech recognition', 'probabilistic union model', 'model', 'partial frequency - band corruption', 'miss feature theory', 'noisy band', 'time - vary band characteristic', 'local frequency - band information', 'automatic order selection', 'partial feature stream corruption', 'noise reduction technique', 'stationary noise', 'nonstationary noise', 'tidigit database', 'speaker - independent connect digit recognition', 'additive noise', 'noise characteristic', 'partial real - world noise']","['probabilistic union model', 'speech recognition', 'partial feature stream corruption', 'automatic order selection', 'independent connect digit recognition', 'noisy band', 'conventional noise reduction technique', 'union model', 'nonstationary noise', 'noise characteristic']"
476,949,"Reply to ""Comment on: Teleportation of an unknown state by W state"" [Phys. Lett. A 300 (2002) 324]","in our letter (see ibid., vol. 296, p. 161 (2002)), the main question we consider is whether a general three-particle w state can be used to realize the teleportation of an unknown qubit state. we give the positive answer to this question in our letter, and show that w state can be used to realize to do that probabilistically. we also discuss how to do it in detail in our letter. in the previous comment (see ibid., vol. 300, p. 324 (2002)), authors check carefully the mathematics calculation of our letter, find and point out a simple mathematics error about normalization coefficient of eq. (1). this mathematics error induces the incorrect probability calculation of eq. (6), and also an incorrect claim in first part of our letter","['teleportation', 'unknown state', 'three-particle w state', 'qubit state', 'normalization coefficient', 'probability calculation']","['P', 'P', 'P', 'P', 'P', 'P']","['teleportation', 'unknown state', 'three - particle w state', 'qubit state', 'normalization coefficient', 'probability calculation']","['unknown qubit state', 'teleportation', 'incorrect probability calculation', 'normalization coefficient', 'particle', 'mathematic calculation', 'mathematic error', 'state', 'eq', 'letter']"
477,1407,Soft options for software upgrades?,"several new products claim to take the work out of installing software and patches, and even migrating operating systems. software migration products fall into two broad categories. the drive imaging type is designed to make exact copies of a hard disk, either an entire drive or certain directories, so you can use it to back up data. the application management type is designed for more incremental upgrades and often provides additional features such as the ability to monitor or control users' access to applications","['software upgrades', 'software installation', 'microsoft windows', 'operating systems migration']","['P', 'R', 'U', 'R']","['software upgrade', 'software installation', 'microsoft window', 'operate system migration']","['software migration product', 'drive imaging type', 'migrate operating system', 'instal software', 'application management type', 'disk', 'provide additional feature such', 'more incremental upgrade', 'drive', 'several new product']"
478,1093,A fuzzy logic approach to accommodate thermal stress and improve the start-up phase in combined cycle power plants,"use of combined cycle power generation plant has increased dramatically over the last decade. a supervisory control approach based on a dynamic model is developed, which makes use of proportional-integral-derivative (pid), fuzzy logic and fuzzy pid schemes. the aim is to minimize the steam turbine plant start-up time, without violating maximum thermal stress limits. an existing start-up schedule provides the benchmark by which the performance of candidate controllers is assessed. improvements regarding possible reduced start-up times and satisfaction of maximum thermal stress restrictions have been realized using the proposed control scheme","['fuzzy logic approach', 'combined cycle power plants', 'supervisory control', 'dynamic model', 'fuzzy pid schemes', 'maximum thermal stress limits', 'start-up schedule', 'pid control', 'steam turbine plant start-up time minimization']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['fuzzy logic approach', 'combine cycle power plant', 'supervisory control', 'dynamic model', 'fuzzy pid scheme', 'maximum thermal stress limit', 'start - up schedule', 'pid control', 'steam turbine plant start - up time minimization']","['steam turbine plant start', 'fuzzy pid scheme', 'supervisory control approach base', 'maximum thermal stress restriction', 'maximum thermal stress limit', 'cycle power generation plant', 'fuzzy logic', 'candidate controller', 'dynamic model', 'pid']"
479,1442,Using constructed types in C++ unions,"the c++ standard states that a union type cannot have a member with a nontrivial constructor or destructor. while at first this seems unreasonable, further thought makes it clear why this is the case: the crux of the problem is that unions don't have built-in semantics for denoting when a member is the ""current"" member of the union. therefore, the compiler can't know when it's appropriate to call constructors or destructors on the union members. still, there are good reasons for wanting to use constructed object types in a union. for example, you might want to implement a scripting language with a single variable type that can either be an integer, a string, or a list. a union is the perfect candidate for implementing such a composite type, but the restriction on constructed union members may prevent you from using an existing string or list class (for example, from the stl) to provide the underlying functionality. luckily, a feature of c++ called placement new can provide a workaround","['c++ standard', 'union type', 'constructors', 'destructors', 'union members', 'scripting language', 'placement new']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['c++ standard', 'union type', 'constructor', 'destructor', 'union member', 'script language', 'placement new']","['construct union member', 'union type', 'construct object type', 'union member', 'nontrivial constructor', 'constructor', 'union', 'union', 'destructor', 'destructor']"
480,854,A conference's impact on undergraduate female students,"in september of 2000, the 3rd grace hopper celebration of women in computing was held in cape cod, massachusetts. along with a colleague from a nearby university, we accompanied seven of our female undergraduate students to this conference. this paper reports on how the conference experience immediately affected these students - what impressed them, what scared them, what it clarified for them. it also reports on how the context in which these students currently evaluate their ability, potential and opportunity in computer science is different now from what it was before the conference. hopefully, by understanding their experience, we can gain some insight into things we can do for all of our undergraduate female students to better support their computer science and engineering education","['conference', 'undergraduate female students', 'engineering education', 'computer science education', 'gender issues']","['P', 'P', 'P', 'R', 'U']","['conference', 'undergraduate female student', 'engineering education', 'computer science education', 'gender issue']","['female undergraduate student', 'undergraduate female student', '3rd grace hopper celebration', 'computer science', 'conference experience', 'student', 'woman', 'nearby university', 'compute', 'cape cod']"
481,811,"Integration, the Web are key this season [tax]",integration and the web are driving many of the enhancements planned by tax preparation software vendors for this coming season,"['accounting packages', 'tax packages', 'software integration', 'internet', 'cch', 'taxworks', ""people's choice"", 'visual tax', 'gosystem tax rs', 'drake', 'netconnection', 'atx', 'cpasoftware', 'intuit', 'petz', 'taxsimple', 'ria']","['U', 'M', 'R', 'U', 'U', 'U', 'U', 'M', 'M', 'U', 'U', 'U', 'U', 'U', 'U', 'U', 'U']","['accounting package', 'tax package', 'software integration', 'internet', 'cch', 'taxwork', ""people 's choice"", 'visual tax', 'gosystem tax rs', 'drake', 'netconnection', 'atx', 'cpasoftware', 'intuit', 'petz', 'taxsimple', 'ria']","['tax preparation software vendor', 'enhancement plan', 'web', 'integration', 'drive many']"
482,1392,Enlisting on-line residents: Expanding the boundaries of e-government in a Japanese rural township,"the purpose of this article is to analyze and learn from an unusual way in which local bureaucrats in a japanese rural township are using the internet to serve their constituents by enlisting the support of ""on-line residents."" successful e-government requires not only rethinking the potential uses of computer technology, but in adopting new patterns of decision-making, power sharing, and office management that many bureaucrats may not be predisposed to make. the main thesis of this article is that necessity and practicality can play a powerful motivational role in facilitating the incorporation of information technology (it) at the level of local government. this case study of how bureaucrats in towa-cho, a small, agricultural town in northeastern japan, have harnessed the internet demonstrates clearly the fundamentals of building a successful e-government framework in this rural municipality, similar to many communities in europe and north america today","['on-line residents', 'e-government', 'japanese rural township', 'local bureaucrats', 'internet', 'decision-making', 'power sharing', 'office management', 'towa-cho', 'rural municipality']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['on - line resident', 'e - government', 'japanese rural township', 'local bureaucrat', 'internet', 'decision - making', 'power sharing', 'office management', 'towa - cho', 'rural municipality']","['japanese rural township', 'rural municipality', 'local bureaucrat', 'government framework', 'local government', 'computer technology', 'information technology', 'office management', 'government require', 'many bureaucrat']"
483,782,Community technology and democratic rationalization,"the objective of the paper is to explore questions of human agency and democratic process in the technical sphere through the example of ""virtual community."" the formation of relatively stable long-term group associations (community in the broad sense of the term), is the scene on which a large share of human development occurs. as such it is a fundamental human value mobilizing diverse ideologies and sensitivities. the promise of realizing this value in a new domain naturally stirs up much excitement among optimistic observers of the internet. at the same time, the eagerness to place hopes for community in a technical system flies in the face of an influential intellectual tradition of technology criticism. this eagerness seems even more naive in the light of the recent commercialization of so much internet activity. despite the widespread skepticism, we believe the growth of virtual community is significant for an inquiry into the democratization of technology. we show that conflicting answers to the central question of the present theoretical debate - is community possible on computer networks? epsilon neralize from particular features of systems and software prevalent at different stages in the development of computer networking. we conclude that research should focus instead on how to design computer networks to better support community activities and values","['community technology', 'democratic rationalization', 'human agency', 'democratic process', 'technical sphere', 'virtual community', 'stable long-term group associations', 'human development', 'human value', 'diverse ideologies', 'optimistic observers', 'technical system', 'intellectual tradition', 'technology criticism', 'internet activity', 'conflicting answers', 'computer networks', 'computer networks', 'community activities', 'computer networking']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['community technology', 'democratic rationalization', 'human agency', 'democratic process', 'technical sphere', 'virtual community', 'stable long - term group association', 'human development', 'human value', 'diverse ideology', 'optimistic observer', 'technical system', 'intellectual tradition', 'technology criticism', 'internet activity', 'conflict answer', 'computer network', 'computer network', 'community activity', 'computer networking']","['fundamental human value mobilize diverse ideology', 'support community activity', 'design computer network', 'virtual community', 'much internet activity', 'computer networking', 'computer network', 'term group association', 'present theoretical debate', 'technical system fly']"
484,894,Improved detection of lung nodules by using a temporal subtraction technique,"the authors evaluated the effect of a temporal subtraction technique for digital chest radiography with regard to the accuracy of detection of lung nodules. twenty solitary lung nodules smaller than 30 mm in diameter, including 10 lung cancers and 10 benign nodules, were used. the nodules were grouped subjectively according to their subtlety. for nonnodular cases, 20 nodules without perceptible interval changes were selected. all chest radiographs were obtained by using a computed radiographic system, and temporal subtraction images were produced by using a program developed at the university of chicago. the effect of the temporal subtraction image was evaluated by using an observer performance study, with use of receiver operating characteristic analysis. observer performance with temporal subtraction images was substantially improved (a/sub z/ = 0.980 and 0.958), as compared with that without temporal subtraction images (a/sub z/ = 0.920 and 0.825) for the certified radiologists and radiology residents, respectively. the temporal subtraction technique clearly improved diagnostic accuracy for detecting lung nodules, especially subtle cases. in conclusion, the temporal subtraction technique is useful for improving detection accuracy for peripheral lung nodules on digital chest radiographs","['temporal subtraction technique', 'digital chest radiography', '30 mm', 'perceptible interval changes', 'computed radiographic system', 'university of chicago', 'observer performance', 'certified radiologists', 'radiology residents', 'subtle cases', 'peripheral lung nodules', 'improved lung nodules detection', 'medical diagnostic imaging']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['temporal subtraction technique', 'digital chest radiography', '30 mm', 'perceptible interval change', 'compute radiographic system', 'university of chicago', 'observer performance', 'certify radiologist', 'radiology resident', 'subtle case', 'peripheral lung nodule', 'improve lung nodule detection', 'medical diagnostic imaging']","['detect lung nodule', 'digital chest radiography', 'temporal subtraction image', 'temporal subtraction image', 'peripheral lung nodule', 'improve diagnostic accuracy', 'lung nodule small', 'improve detection accuracy', 'compute radiographic system', 'lung nodule']"
485,1016,A scalable model of cerebellar adaptive timing and sequencing: the recurrent slide and latch (RSL) model,"from the dawn of modern neural network theory, the mammalian cerebellum has been a favored object of mathematical modeling studies. early studies focused on the fanout, convergence, thresholding, and learned weighting of perceptual-motor signals within the cerebellar cortex. this led to the still viable idea that the granule cell stage in the cerebellar cortex performs a sparse expansive recoding of the time-varying input vector. this recoding reveals and emphasizes combinations in a distributed representation that serves as a basis for the learned, state-dependent control actions engendered by cerebellar outputs to movement related centers. to make optimal use of available signals, the cerebellum must be able to sift the evolving state representation for the most reliable predictors of the need for control actions, and to use those predictors even if they appear only transiently and well in advance of the optimal time for initiating the control action. the paper proposes a modification to prior, population, models for cerebellar adaptive timing and sequencing. since it replaces a population with a single element, the proposed rsl model is in one sense maximally efficient, and therefore optimal from the perspective of scalability","['scalable model', 'cerebellar adaptive timing', 'neural network theory', 'mammalian cerebellum', 'granule cell stage', 'sparse expansive recoding', 'time-varying input vector', 'distributed representation', 'cerebellar sequencing', 'recurrent slide and latch model', 'recurrent network']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['scalable model', 'cerebellar adaptive timing', 'neural network theory', 'mammalian cerebellum', 'granule cell stage', 'sparse expansive recoding', 'time - vary input vector', 'distribute representation', 'cerebellar sequence', 'recurrent slide and latch model', 'recurrent network']","['cerebellar cortex perform', 'cerebellar adaptive timing', 'cerebellar cortex', 'dependent control action engender', 'mammalian cerebellum', 'cerebellar output', 'granule cell stage', 'neural network', 'evolve state representation', 'cerebellum']"
486,1053,A static semantics for Haskell,"this paper gives a static semantics for haskell 98, a non-strict purely functional programming language. the semantics formally specifies nearly all the details of the haskell 98 type system, including the resolution of overloading, kind inference (including defaulting) and polymorphic recursion, the only major omission being a proper treatment of ambiguous overloading and its resolution. overloading is translated into explicit dictionary passing, as in all current implementations of haskell. the target language of this translation is a variant of the girard-reynolds polymorphic lambda calculus featuring higher order polymorphism. and explicit type abstraction and application in the term language. translated programs can thus still be type checked, although the implicit version of this system is impredicative. a surprising result of this formalization effort is that the monomorphism restriction, when rendered in a system of inference rules, compromises the principal type property","['static semantics', 'haskell 98', 'type system', 'overloading', 'kind inference', 'polymorphic recursion', 'explicit dictionary passing', 'polymorphic lambda calculus', 'higher order polymorphism', 'explicit type abstraction', 'term language', 'type checking', 'monomorphism restriction', 'inference rules', 'nonstrict purely functional programming language', 'formal specification']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M']","['static semantic', 'haskell 98', 'type system', 'overload', 'kind inference', 'polymorphic recursion', 'explicit dictionary pass', 'polymorphic lambda calculus', 'high order polymorphism', 'explicit type abstraction', 'term language', 'type checking', 'monomorphism restriction', 'inference rule', 'nonstrict purely functional programming language', 'formal specification']","['reynolds polymorphic lambda calculus feature high order polymorphism', 'explicit type abstraction', 'polymorphic recursion', 'explicit dictionary pass', 'functional programming language', 'monomorphism restriction', 'haskell', 'static semantic', 'ambiguous overloading', 'kind inference']"
487,707,Vector algebra proofs for geometry theorems,"vector mathematics can generate simple and powerful proofs of theorems in plane geometry. these proofs can also be used to generalize plane geometry theorems to higher dimensions. we present three vector proofs that show the power of this technique. 1. for any quadrilateral, the sum of the squares of the diagonals is less than or equal to the sum of the squares of the sides. 2. the area of a quadrilateral is half the product of the diagonals multiplied by the sine of an included angle. 3. one quarter of all triangles are acute (based upon the options detailed below, with respect to the relative lengths of the sides). this paper presents a set of examples of vector mathematics applied to geometry problems. some of the most beautiful and sophisticated proofs in mathematics involve using multiple representations of the same data. by leveraging the advantages of each representation one finds new and useful mathematical facts","['vector algebra proofs', 'proofs', 'vector mathematics', 'plane geometry', 'quadrilateral', 'multiple representations']","['P', 'P', 'P', 'P', 'P', 'P']","['vector algebra proof', 'proof', 'vector mathematic', 'plane geometry', 'quadrilateral', 'multiple representation']","['generalize plane geometry theorem', 'vector proof', 'plane geometry', 'vector mathematic apply', 'vector mathematic', 'mathematic involve use multiple representation', 'geometry problem', 'diagonal multiply', 'quadrilateral', 'theorem']"
488,742,Second term [International Telecommunication Union],"later this month yoshio utsumi is expected to be re-elected for a second four year term as secretary general of the international telecommunication union. here he talks to matthew may about getting involved in internet addressing, the prospects for 3g, the need for further reform of his organisation... and the translating telephone","['international telecommunication union', 'internet addressing', '3g', 'translating telephone']","['P', 'P', 'P', 'P']","['international telecommunication union', 'internet address', '3 g', 'translate telephone']","['month yoshio utsumi', 'international telecommunication union', 'secretary general', 'internet address', 'further reform', 'getting involve', 'matthew', 'year term', 'prospect', 'talk']"
489,1317,Dynamic spectrum management for next-generation DSL systems,"the performance of dsl systems is severely constrained by crosstalk due to the electromagnetic coupling among the multiple twisted pairs making up a phone cable. in order to reduce performance loss arising from crosstalk, dsl systems are currently designed under the assumption of worst-case crosstalk scenarios leading to overly conservative dsl deployments. this article presents a new paradigm for dsl system design, which takes into account the multi-user aspects of the dsl transmission environment. dynamic spectrum management (dsm) departs from the current design philosophy by enabling transceivers to autonomously and dynamically optimize their communication settings with respect to both the channel and the transmissions of neighboring systems. along with this distributed optimization, when an additional degree of coordination becomes available for future dsl deployment, dsm will allow even greater improvement in dsl performance. implementations are readily applicable without causing any performance degradation to the existing dsls under static spectrum management. after providing an overview of the dsm concept, this article reviews two practical dsm methods: iterative water-filling, an autonomous distributed power control method enabling great improvement in performance, which can be implemented through software options in some existing adsl and vdsl systems; and vectored-dmt, a coordinated transmission/reception technique achieving crosstalk-free communication for dsl systems, which brings within reach the dream of providing universal internet access at speeds close to 100 mb/s to 500 m on 1-2 lines and beyond 1 km on 2-4 lines. dsm-capable dsl thus enables the broadband age","['dynamic spectrum management', 'electromagnetic coupling', 'twisted pairs', 'phone cable', 'dsl system design', 'transceivers', 'distributed optimization', 'static spectrum management', 'iterative water-filling', 'autonomous distributed power control method', 'software options', 'vdsl systems', 'vectored-dmt', 'coordinated transmission/reception', 'crosstalk-free communication', 'universal internet access', '500 m', 'dsl systems performance', 'data transmission', 'adsl systems', 'broadband networks', '100 mbit/s']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'R', 'M', 'M']","['dynamic spectrum management', 'electromagnetic coupling', 'twist pair', 'phone cable', 'dsl system design', 'transceiver', 'distribute optimization', 'static spectrum management', 'iterative water - fill', 'autonomous distribute power control method', 'software option', 'vdsl system', 'vectore - dmt', 'coordinate transmission / reception', 'crosstalk - free communication', 'universal internet access', '500 m', 'dsl system performance', 'datum transmission', 'adsl system', 'broadband network', '100 mbit / s']","['dsl transmission environment', 'future dsl deployment', 'dsl system design', 'reception technique achieve crosstalk', 'dsl system', 'dsl deployment', 'dsl performance', 'capable dsl', 'dynamic spectrum management', 'practical dsm method']"
490,1352,Elastically adaptive deformable models,"we present a technique for the automatic adaptation of a deformable model's elastic parameters within a kalman filter framework for shape estimation applications. the novelty of the technique is that the model's elastic parameters are not constant, but spatio-temporally varying. the variation of the elastic parameters depends on the distance of the model from the data and the rate of change of this distance. each pass of the algorithm uses physics-based modeling techniques to iteratively adjust both the geometric and the elastic degrees of freedom of the model in response to forces that are computed from the discrepancy between the model and the data. by augmenting the state equations of an extended kalman filter to incorporate these additional variables, we are able to significantly improve the quality of the shape estimation. therefore, the model's elastic parameters are always initialized to the same value and they are subsequently modified depending on the data and the noise distribution. we present results demonstrating the effectiveness of our method for both two-dimensional and three-dimensional data","['elastically adaptive deformable models', 'automatic adaptation', 'elastic parameters', 'kalman filter framework', 'shape estimation', 'physics-based modeling techniques', 'elastic degrees of freedom', 'state equations', 'extended kalman filter', 'geometric degrees of freedom']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['elastically adaptive deformable model', 'automatic adaptation', 'elastic parameter', 'kalman filter framework', 'shape estimation', 'physics - base modeling technique', 'elastic degree of freedom', 'state equation', 'extend kalman filter', 'geometric degree of freedom']","['shape estimation', 'deformable model', 'extend kalman filter', 'kalman filter framework', 'elastic parameter depend', 'elastic parameter', 'base modeling technique', 'automatic adaptation', 'elastic', 'model']"
491,869,An exactly solvable random satisfiability problem,"we introduce a new model for the generation of random satisfiability problems. it is an extension of the hyper-sat model of ricci-tersenghi, weigt and zecchina (2001), which is a variant of the famous k-sat model: it is extended to q-state variables and relates to a different choice of the statistical ensemble. the model has an exactly solvable statistic: the critical exponents and scaling functions of the sat/unsat transition are calculable at zero temperature, with no need of replicas, also with exact finite-size corrections. we also introduce an exact duality of the model, and show an analogy of thermodynamic properties with the random energy model of disordered spin system theory. relations with error correcting codes are also discussed","['exactly solvable random satisfiability problem', 'hyper-sat model', 'q-state variables', 'statistical ensemble', 'exact finite-size corrections', 'exact duality', 'thermodynamic properties', 'random energy model', 'disordered spin system theory', 'error correcting codes']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['exactly solvable random satisfiability problem', 'hyper - sit model', 'q - state variable', 'statistical ensemble', 'exact finite - size correction', 'exact duality', 'thermodynamic property', 'random energy model', 'disorder spin system theory', 'error correct code']","['random satisfiability problem', 'disorder spin system theory', 'sit model', 'random energy model', 'thermodynamic property', 'statistical ensemble', 'sit', 'solvable statistic', 'critical exponent', 'unsat transition']"
492,65,The use of subtypes and stereotypes in the UML model,"based on users' experiences of version 1.3 of the unified modeling language (uml) of the object management group (omg), a request for information in 1999 elicited several responses which were asked to identify ""problems"" but not to offer any solutions. one of these responses is examined for ""problems"" relating to the uml metamodel and here some solutions to the problems identified there are proposed. specifically, we evaluate the metamodel relating to stereotypes versus subtypes; the various kinds of classifier (particularly types, interfaces and classes); the introduction of a new subtype for the whole part relationship; as well as identifying areas in the metamodel where the uml seems to have been used inappropriately in the very definition of the uml's metamodel","['subtypes', 'stereotypes', 'uml model', 'unified modeling language', 'object management group', 'request for information', 'classifier', 'whole part relationship']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['subtype', 'stereotype', 'uml model', 'unify modeling language', 'object management group', 'request for information', 'classifier', 'whole part relationship']","['uml metamodel', 'unify modeling language', 'object management group', 'metamodel relate', 'metamodel', 'new subtype', 'uml seem', 'various kind', 'subtype', 'stereotype']"
493,931,Active vibration control of composite sandwich beams with piezoelectric extension-bending and shear actuators,"we have used quasi-static equations of piezoelectricity to derive a finite element formulation capable of modelling two different kinds of piezoelastically induced actuation in an adaptive composite sandwich beam. this formulation is made to couple certain piezoelectric constants to a transverse electric field to develop extension-bending actuation and shear-induced actuation. as an illustration, we present a sandwich model of three sublaminates: face/core/face. we develop a control scheme based on the linear quadratic regulator/independent modal space control (lqr/imsc) method and use this to estimate the active stiffness and the active damping introduced by shear and extension-bending actuators. to assess the performance of each type of actuator, a dynamic response study is carried out in the modal domain. we observe that the shear actuator is more efficient in actively controlling the vibration than the extension-bending actuator for the same control effort","['piezoelectricity', 'shear actuators', 'quasi-static equations', 'finite element formulation', 'piezoelastically', 'adaptive composite sandwich beam', 'piezoelectric constants', 'transverse electric field', 'extension-bending actuation', 'extension-bending actuation', 'shear-induced actuation', 'sandwich model', 'sublaminates', 'linear quadratic regulator', 'modal space control', 'active stiffness', 'active damping', 'dynamic response', 'modal domain', 'finite element procedure', 'extension-bending actuators']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'P']","['piezoelectricity', 'shear actuator', 'quasi - static equation', 'finite element formulation', 'piezoelastically', 'adaptive composite sandwich beam', 'piezoelectric constant', 'transverse electric field', 'extension - bend actuation', 'extension - bend actuation', 'shear - induce actuation', 'sandwich model', 'sublaminate', 'linear quadratic regulator', 'modal space control', 'active stiffness', 'active damp', 'dynamic response', 'modal domain', 'finite element procedure', 'extension - bend actuator']","['adaptive composite sandwich beam', 'piezoelectric constant', 'bend actuator', 'piezoelectricity', 'bend actuator', 'shear actuator', 'bend actuation', 'active damp introduce', 'active stiffness', 'actuator']"
494,974,Extrapolation in Lie groups with approximated BCH-formula,we present an extrapolation algorithm for the integration of differential equations in lie groups which is a suitable generalization of the well-known gbs-algorithm for odes. sufficiently accurate approximations to the bch-formula are required to reach a given order. we give such approximations with a minimized number of commutators,"['lie groups', 'approximated bch-formula', 'differential equations', 'gbs-algorithm', 'geometric integration', 'extrapolation methods']","['P', 'P', 'P', 'P', 'M', 'M']","['lie group', 'approximate bch - formula', 'differential equation', 'gbs - algorithm', 'geometric integration', 'extrapolation method']","['differential equation', 'extrapolation algorithm', 'ode', 'lie group', 'know gbs', 'approximation', 'bch', 'suitable generalization', 'integration', 'algorithm']"
495,137,An efficient DIPIE algorithm for CAD of electrostatically actuated MEMS devices,"pull-in parameters are important properties of electrostatic actuators. efficient and accurate analysis tools that can capture these parameters for different design geometries, are therefore essential. current simulation tools approach the pull-in state by iteratively adjusting the voltage applied across the actuator electrodes. the convergence rate of this scheme gradually deteriorates as the pull-in state is approached. moreover, the convergence is inconsistent and requires many mesh and accuracy refinements to assure reliable predictions. as a result, the design procedure of electrostatically actuated mems devices can be time-consuming. in this paper a novel displacement iteration pull-in extraction (dipie) scheme is presented. the dipie scheme is shown to converge consistently and far more rapidly than the voltage iterations (vi) scheme (>100 times faster!). the dipie scheme requires separate mechanical and electrostatic field solvers. therefore, it can be easily implemented in existing moems cad packages. moreover, using the dipie scheme, the pull-in parameters extraction can be performed in a fully automated mode, and no user input for search bounds is required","['dipie algorithm', 'electrostatically actuated mems devices', 'electrostatic actuators', 'pull-in parameters', 'design geometries', 'convergence rate', 'displacement iteration', 'electrostatic field solver', 'moems cad packages', 'displacement iteration pull-in extraction scheme', 'mechanical field solver', 'computer-aided design']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M']","['dipie algorithm', 'electrostatically actuate mem device', 'electrostatic actuator', 'pull - in parameter', 'design geometry', 'convergence rate', 'displacement iteration', 'electrostatic field solver', 'moem cad package', 'displacement iteration pull - in extraction scheme', 'mechanical field solver', 'computer - aid design']","['actuate mem device', 'electrostatic actuator', 'displacement iteration pull', 'actuator electrode', 'electrostatic field solver', 'moem cad', 'current simulation tool', 'parameter extraction', 'voltage iteration', 'pull']"
496,989,A dynamic checkpoint scheduling scheme for fault tolerant distributed computing systems,"the selection of the optimal checkpointing interval has been a very critical issue in implementing checkpointing-recovery schemes for fault tolerant distributed systems. this paper presents a new scheme that allows a process to select the proper checkpointing interval dynamically. a process in the system evaluates the cost of checkpointing and possible rollback for each checkpointing interval and selects the proper time interval for the next checkpointing. unlike the other schemes, the overhead incurred by both the checkpointing and rollback activities are considered for the cost evaluation, and the current communication pattern is reflected in the selection of the checkpointing interval. moreover, the proposed scheme requires no extra message communication for the checkpointing interval selection and can easily be incorporated into the existing checkpointing coordination schemes","['dynamic checkpoint scheduling scheme', 'distributed computing systems', 'optimal checkpointing interval', 'cost evaluation', 'communication pattern', 'fault tolerant computing', 'rollback recovery']","['P', 'P', 'P', 'P', 'P', 'R', 'M']","['dynamic checkpoint scheduling scheme', 'distribute compute system', 'optimal checkpointing interval', 'cost evaluation', 'communication pattern', 'fault tolerant computing', 'rollback recovery']","['optimal checkpointing interval', 'checkpointe interval', 'implement checkpointing', 'fault tolerant distribute system', 'next checkpointing', 'checkpointe', 'time interval', 'possible rollback', 'recovery scheme', 'rollback']"
497,98,Automating the compliance and supervision process,new technology enables large broker/dealers to supervise and ensure compliance across multiple branches and managers,"['compliance', 'supervision', 'brokers', 'risk management']","['P', 'P', 'P', 'M']","['compliance', 'supervision', 'broker', 'risk management']","['new technology enable large broker', 'ensure compliance', 'multiple branch', 'dealer', 'supervise']"
498,898,Influence of advertising expenses on the characteristics of functioning of an insurance company,"the basic characteristics of the functioning of an insurance company, including the average capital, ruin and survival probabilities, and the conditional time before ruin, are examined with allowance for advertising expenses","['average capital', 'survival probabilities', 'conditional time', 'advertising expenses influence', 'insurance company functioning characteristics', 'ruin probabilities']","['P', 'P', 'P', 'R', 'R', 'R']","['average capital', 'survival probability', 'conditional time', 'advertising expense influence', 'insurance company function characteristic', 'ruin probability']","['insurance company', 'survival probability', 'ruin', 'conditional time', 'average capital', 'allowance', 'basic characteristic', 'include', 'function', 'examine']"
499,820,Yet some more complexity results for default logic,"we identify several new tractable subsets and several new intractable simple cases for reasoning in the propositional version of reiter's default logic. the majority of our findings are related to brave reasoning. by making some intuitive observations, most classes that we identify can be derived quite easily from some subsets of default logic already known in the literature. some of the subsets we discuss are subclasses of the so-called ""extended logic programs"". all the tractable subsets presented in this paper can be recognized in linear time","['complexity results', 'default logic', 'tractable subsets', 'reasoning', 'extended logic programs', 'complexity classes', 'nonmonotonic reasoning']","['P', 'P', 'P', 'P', 'P', 'R', 'M']","['complexity result', 'default logic', 'tractable subset', 'reason', 'extend logic program', 'complexity class', 'nonmonotonic reasoning']","['identify several new tractable subset', 'several new intractable simple case', 'extend logic program', 'default logic', 'brave reasoning', 'tractable subset present', 'propositional version', 'reason', 'intuitive observation', 'most class']"
500,865,Setup cost and lead time reductions on stochastic inventory models with a service level constraint,"the stochastic inventory models analyzed in this paper explore the problem of lead time associated with setup cost reductions for the continuous review and periodic review inventory models. for these two models with a mixture of backorders and lost sales, we respectively assume that their mean and variance of the lead time demand and protection interval (i.e., lead time plus review period) demand are known, but their probability distributions are unknown. we develop a minimax distribution free procedure to find the optimal solution-for each case","['lead time reductions', 'stochastic inventory models', 'service level constraint', 'setup cost reductions', 'periodic review inventory models', 'backorders', 'lost sales', 'lead time demand', 'protection interval', 'probability distributions', 'minimax distribution free procedure', 'continuous review inventory models']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['lead time reduction', 'stochastic inventory model', 'service level constraint', 'setup cost reduction', 'periodic review inventory model', 'backorder', 'lose sale', 'lead time demand', 'protection interval', 'probability distribution', 'minimax distribution free procedure', 'continuous review inventory model']","['stochastic inventory model', 'periodic review inventory model', 'lead time demand', 'minimax distribution free procedure', 'setup cost reduction', 'lead time', 'lose sale', 'review period', 'probability distribution', 'optimal solution']"
501,1436,Modelling tomographic cone-beam projection data from a polyhedral phantom,"analytical phantoms are used to generate projection data for testing reconstruction accuracy in computed axial tomography. a circular source locus (equivalent to rotating specimen with a fixed source) provides insufficient data for 'exact' reconstruction in cone-beam transmission tomography, thus phantom data are useful for studying the consequent errors and also for investigating alternative scanning loci and reconstruction techniques. we present an algorithm that can compute phantom cone-beam projection data from a phantom comprising geometrically defined polyhedra. each polyhedron is defined as a set of polygons enclosing a volume of fixed linear attenuation coefficient. the algorithm works by projecting each polygon in turn onto the modelled detector array, which accumulates the product of source to polygon intersection distance (for the rays intersecting each detector element), linear attenuation coefficient and sign of projected polygon area (indicating whether rays enter or exit the polyhedron at this face). the phantom data are rotated according to the projection angle, whilst the source location and detector plane remain fixed. polyhedra can be of simple geometric form, or complex surfaces derived from 3d images of real specimens. this algorithm is illustrated using a phantom comprising 989 238 polygons, representing an iso-surface generated from a microtomographic reconstruction of a piece of walrus tusk","['tomographic cone-beam projection data', 'polyhedral phantom', 'reconstruction accuracy', 'computed axial tomography', 'cone-beam transmission tomography', 'alternative scanning loci', 'geometrically defined polyhedra', 'linear attenuation coefficient', 'microtomographic reconstruction', 'walrus tusk', 'reconstruction software accuracy', 'x-ray attenuation', 'cumulative pixel array', 'interpolation', 'geometry file']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'M', 'U', 'U']","['tomographic cone - beam projection data', 'polyhedral phantom', 'reconstruction accuracy', 'compute axial tomography', 'cone - beam transmission tomography', 'alternative scan loci', 'geometrically define polyhedra', 'linear attenuation coefficient', 'microtomographic reconstruction', 'walrus tusk', 'reconstruction software accuracy', 'x - ray attenuation', 'cumulative pixel array', 'interpolation', 'geometry file']","['compute axial tomography', 'compute phantom cone', 'beam projection datum', 'project polygon area', 'microtomographic reconstruction', 'polygon intersection distance', 'projection angle', 'polyhedron', 'generate projection datum', 'test reconstruction accuracy']"
502,978,On Implicit Euler for high-order high-index DAEs,"the implicit euler method is seldom used to solve differential-algebraic equations (daes) of differential index r >or= 3, since the method in general fails to converge in the first r - 2 steps after a change of stepsize. however, if the differential equation is of order d = r - 1 >or= 1, an alternative variable-step version of the euler method can be shown uniformly convergent. for d = r - 1, this variable-step method is equivalent to the implicit euler except for the first r - 2 steps after a change of stepsize. generalization to daes with differential equations of order d > r - 1 >or= 1, and to variable-order formulas is discussed","['implicit euler method', 'differential-algebraic equations', 'differential index', 'convergence', 'variable-step method', 'variable-order formulas', 'stepsize change', 'linear multistep method', 'backward differentiation formula', 'initial value problem']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M', 'U']","['implicit euler method', 'differential - algebraic equation', 'differential index', 'convergence', 'variable - step method', 'variable - order formula', 'stepsize change', 'linear multistep method', 'backward differentiation formula', 'initial value problem']","['implicit euler method', 'implicit euler', 'euler method', 'differential equation', 'differential equation', 'solve differential', 'differential index', 'algebraic equation', 'step method', 'order formula']"
503,616,An overview of modems,"this paper describes cursory glance of different types of modems classified for application, range, line type, operating mode, synchronizing mode, modulation, etc., highly useful for all engineering students of communication, electrical, computer science and information technology students. this paper also describes the standards and protocols used and the future trend","['modems', 'line type', 'operating mode', 'synchronizing mode', 'modulation', 'engineering students', 'information technology students', 'standards', 'protocols', 'communication students', 'electrical students', 'computer science students']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['modem', 'line type', 'operate mode', 'synchronizing mode', 'modulation', 'engineering student', 'information technology student', 'standard', 'protocol', 'communication student', 'electrical student', 'computer science student']","['modem classify', 'synchronizing mode', 'operate mode', 'information technology student', 'modulation', 'protocol use', 'different type', 'line type', 'engineering student', 'paper describe cursory glance']"
504,69,Sensitivity calibration of ultrasonic detectors based using ADD diagrams,the paper considers basic problems related to utilization of add diagrams in calibrating sensitivity of ultrasonic detectors. we suggest that a convenient tool for solving such problems can be the software package add universal. version 2.1 designed for plotting individual add diagrams for normal and slanted transducers. the software is compatible with the contemporary operational system windows-95(98). reference signals for calibration are generated in a sample with cylindrical holes,"['sensitivity calibration', 'calibration', 'ultrasonic detectors', 'add diagrams', 'software package', 'slanted transducers', 'contemporary operational system windows-95(98', 'reference signals', 'cylindrical holes', 'normal transducers', 'ultrasonic testing']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['sensitivity calibration', 'calibration', 'ultrasonic detector', 'add diagram', 'software package', 'slant transducer', 'contemporary operational system windows-95(98', 'reference signal', 'cylindrical hole', 'normal transducer', 'ultrasonic testing']","['ultrasonic detector', 'calibrate sensitivity', 'slant transducer', 'calibration', 'add diagram', 'software package add universal', 'signal', 'software', 'basic problem', 'tool']"
505,653,Indexing-neglected and poorly understood,"the growth of the internet has highlighted the use of machine indexing. the difficulties in using the internet as a searching device can be frustrating. the use of the term ""python"" is given as an example. machine indexing is noted as ""rotten"" and human indexing as ""capricious."" the problem seems to be a lack of a theoretical foundation for the art of indexing. what librarians have learned over the last hundred years has yet to yield a consistent approach to what really works best in preparing index terms and in the ability of our customers to search the various indexes. an attempt is made to consider the elements of indexing, their pros and cons. the argument is made that machine indexing is far too prolific in its production of index terms. neither librarians nor computer programmers have made much progress to improve internet indexing. human indexing has had the same problems for over fifty years","['internet', 'machine indexing', 'searching', 'human indexing', 'index terms']","['P', 'P', 'P', 'P', 'P']","['internet', 'machine indexing', 'search', 'human indexing', 'index term']","['improve internet indexing', 'machine indexing', 'prepare index term', 'human indexing', 'various index', 'index term', 'indexing', 'search device', 'computer programmer', 'librarian']"
506,1206,"The MAGNeT toolkit: design, implementation and evaluation","the current trend in constructing high-performance computing systems is to connect a large number of machines via a fast interconnect or a large-scale network such as the internet. this approach relies on the performance of the interconnect (or internet) to enable fast, large-scale distributed computing. a detailed understanding of the communication traffic is required in order to optimize the operation of the entire system. network researchers traditionally monitor traffic in the network to gain the insight necessary to optimize network operations. recent work suggests additional insight can be obtained by also monitoring traffic at the application level. the monitor for application-generated network traffic toolkit (magnet) we describe here monitors application traffic patterns in production systems, thus enabling more highly optimized networks and interconnects for the next generation of high-performance computing systems","['magnet', 'high-performance computing systems', 'high-performance computing', 'interconnects', 'internet', 'optimized networks', 'monitor for application-generated network traffic toolkit', 'network protocol', 'traffic characterization', 'virtual supercomputing', 'computational grids']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'U', 'M']","['magnet', 'high - performance computing system', 'high - performance computing', 'interconnect', 'internet', 'optimize network', 'monitor for application - generate network traffic toolkit', 'network protocol', 'traffic characterization', 'virtual supercomputing', 'computational grid']","['generate network traffic toolkit', 'monitor application traffic pattern', 'monitor traffic', 'optimize network operation', 'monitor traffic', 'communication traffic', 'performance computing system', 'scale distribute computing', 'fast interconnect', 'optimize network']"
507,1243,HPF/JA: extensions of High Performance Fortran for accelerating real-world applications,"this paper presents a set of extensions on high performance fortran (hpf) to make it more usable for parallelizing real-world production codes. hpf has been effective for programs that a compiler can automatically optimize efficiently. however, once the compiler cannot, there have been no ways for the users to explicitly parallelize or optimize their programs. in order to resolve the situation, we have developed a set of hpf extensions (hpf/ja) to give the users more control over sophisticated parallelization and communication optimizations. they include parallelization of loops with complicated reductions, asynchronous communication, user-controllable shadow, and communication pattern reuse for irregular remote data accesses. preliminary experiments have proved that the extensions are effective at increasing hpf's usability","['hpf', 'high performance fortran', 'compiler', 'parallelization of loops', 'parallel processing', 'data parallel language', 'supercomputer', 'parallel programming']","['P', 'P', 'P', 'P', 'M', 'M', 'U', 'R']","['hpf', 'high performance fortran', 'compiler', 'parallelization of loop', 'parallel processing', 'datum parallel language', 'supercomputer', 'parallel programming']","['high performance fortran', 'sophisticated parallelization', 'parallelize real', 'include parallelization', 'irregular remote datum access', 'compiler', 'hpf extension', 'parallelize', 'world production code', 'asynchronous communication']"
508,94,Gearing up for CLS bank,"continuous-linked settlement, a dream of the foreign-exchange community for years, may finally become a reality by the end of 2002","['continuous-linked settlement', 'foreign-exchange']","['P', 'P']","['continuous - link settlement', 'foreign - exchange']","['link settlement', 'exchange community', 'year', 'foreign', 'dream', 'continuous', 'end', 'reality', 'become']"
509,985,Local activity criteria for discrete-map CNN,"discrete-time cnn systems are studied in this paper by the application of chua's local activity principle. these systems are locally active everywhere except for one isolated parameter value. as a result, nonhomogeneous spatiotemporal patterns may be induced by any initial setting of the cnn system when the strength of the system diffusion coupling exceeds a critical threshold. the critical coupling coefficient can be derived from the loaded cell impedance of the cnn system. three well-known 1d map cnn's (namely, the logistic map cnn, the magnetic vortex pinning map cnn, and the spiral wave reproducing map cnn) are introduced to illustrate the applications of the local activity principle. in addition, we use the cell impedance to demonstrate the period-doubling scenario in the logistic and the magnetic vortex pinning maps","['local activity criteria', 'discrete-map cnn', 'discrete-time cnn systems', ""chua's local activity principle"", 'nonhomogeneous spatiotemporal patterns', 'critical coupling coefficient', 'loaded cell impedance', 'logistic map cnn', 'magnetic vortex pinning map cnn', 'spiral wave reproducing map cnn', 'period-doubling', 'difference equation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U']","['local activity criterion', 'discrete - map cnn', 'discrete - time cnn system', ""chua 's local activity principle"", 'nonhomogeneous spatiotemporal pattern', 'critical coupling coefficient', 'load cell impedance', 'logistic map cnn', 'magnetic vortex pin map cnn', 'spiral wave reproducing map cnn', 'period - double', 'difference equation']","['magnetic vortex pin map cnn', 'logistic map cnn', '1d map cnn', 'system diffusion coupling', 'nonhomogeneous spatiotemporal pattern', 'time cnn system', 'load cell impedance', 'spiral wave', 'local activity principle', 'cnn system']"
510,552,Anatomy of the coupling query in a Web warehouse,"to populate a data warehouse specifically designed for web data, i.e. web warehouse, it is imperative to harness relevant documents from the web. in this paper, we describe a query mechanism called coupling query to glean relevant web data in the context of our web warehousing system called warehouse of web data (whoweda). a coupling query may be used for querying both html and xml documents. important features of our query mechanism are the ability to query metadata, content, internal and external (hyperlink) structure of web documents based on partial knowledge, ability to express constraints on tag attributes and tagless segment of data, ability to express conjunctive as well as disjunctive query conditions compactly, ability to control execution of a web query and preservation of the topological structure of hyperlinked documents in the query results. we also discuss how to formulate a query graphically and in textual form using a coupling graph and coupling text, respectively","['coupling query', 'web warehouse', 'data warehouse', 'warehouse of web data', 'xml documents', 'metadata', 'content', 'web documents', 'partial knowledge', 'tag attributes', 'tagless segment', 'disjunctive query conditions', 'topological structure', 'hyperlinked documents', 'coupling text', 'html documents', 'internal structure', 'external structure', 'conjunctive query conditions', 'execution control', 'graphical query formulation', 'textual query formulation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'R', 'R', 'R']","['couple query', 'web warehouse', 'datum warehouse', 'warehouse of web datum', 'xml document', 'metadata', 'content', 'web document', 'partial knowledge', 'tag attribute', 'tagless segment', 'disjunctive query condition', 'topological structure', 'hyperlinke document', 'couple text', 'html document', 'internal structure', 'external structure', 'conjunctive query condition', 'execution control', 'graphical query formulation', 'textual query formulation']","['glean relevant web datum', 'web warehouse', 'web warehousing system', 'web document base', 'query metadata', 'xml document', 'datum warehouse', 'web query', 'web datum', 'hyperlinke document']"
511,1107,A knowledge-navigation system for dimensional metrology,"geometric dimensioning and tolerancing (gd&t) is a method to specify the dimensions and form of a part so that it will meet its design intent. gd&t is difficult to master for two main reasons. first, it is based on complex 3d geometric entities and relationships. second, the geometry is associated with a large, diverse knowledge base of dimensional metrology with many interconnections. this paper describes an approach to create a dimensional metrology knowledge base that is organized around a set of key concepts and to represent those concepts as virtual objects that can be navigated with interactive, computer visualization techniques to access the associated knowledge. the approach can enable several applications. first is the application to convey the definition and meaning of gd&t over a broad range of tolerance types. second is the application to provide a visualization of dimensional metrology knowledge within a control hierarchy of the inspection process. third is the application to show the coverage of interoperability standards to enable industry to make decisions on standards development and harmonization efforts. a prototype system has been implemented to demonstrate the principles involved in the approach","['dimensional metrology', 'geometric dimensioning', 'tolerancing', 'visualization', 'inspection', 'interoperability standards', 'knowledge navigation', 'manufacturing training', 'vrml', 'web']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'U', 'U']","['dimensional metrology', 'geometric dimensioning', 'tolerance', 'visualization', 'inspection', 'interoperability standard', 'knowledge navigation', 'manufacture training', 'vrml', 'web']","['complex 3d geometric entity', 'dimensional metrology knowledge base', 'dimensional metrology knowledge', 'geometric dimensioning', 'dimensional metrology', 'computer visualization technique', 'interoperability standard', 'geometry', 'visualization', 'inspection process']"
512,1142,Fast and accurate leaf verification for dynamic multileaf collimation using an electronic portal imaging device,"a prerequisite for accurate dose delivery of imrt profiles produced with dynamic multileaf collimation (dmlc) is highly accurate leaf positioning. in our institution, leaf verification for dmlc was initially done with film and ionization chamber. to overcome the limitations of these methods, a fast, accurate and two-dimensional method for daily leaf verification, using our ccd-camera based electronic portal imaging device (epid), has been developed. this method is based on a flat field produced with a 0.5 cm wide sliding gap for each leaf pair. deviations in gap widths are detected as deviations in gray scale value profiles derived from the epid images, and not by directly assessing leaf positions in the images. dedicated software was developed to reduce the noise level in the low signal images produced with the narrow gaps. the accuracy of this quality assurance procedure was tested by introducing known leaf position errors. it was shown that errors in leaf gap as small as 0.01-0.02 cm could be detected, which is certainly adequate to guarantee accurate dose delivery of dmlc treatments, even for strongly modulated beam profiles. using this method, it was demonstrated that both short and long term reproducibility in leaf positioning were within 0.01 cm (1 sigma ) for all gantry angles, and that the effect of gravity was negligible","['accurate leaf verification', 'dynamic multileaf collimation', 'electronic portal imaging device', 'accurate dose delivery', 'leaf positioning', 'ionization chamber', 'two-dimensional method', 'ccd-camera based electronic portal imaging device', 'sliding gap', 'leaf pair', 'gap widths', 'gray scale value profiles', 'noise level', 'signal images', 'leaf position errors', 'modulated beam profiles', 'gantry angles', 'intensity modulated radiation therapy profiles', 'electronic portal imaging device images']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R']","['accurate leaf verification', 'dynamic multileaf collimation', 'electronic portal imaging device', 'accurate dose delivery', 'leaf positioning', 'ionization chamber', 'two - dimensional method', 'ccd - camera base electronic portal imaging device', 'slide gap', 'leaf pair', 'gap width', 'gray scale value profile', 'noise level', 'signal image', 'leaf position error', 'modulate beam profile', 'gantry angle', 'intensity modulate radiation therapy profile', 'electronic portal imaging device image']","['electronic portal imaging device', 'assess leaf position', 'accurate leaf positioning', 'leaf positioning', 'leaf position error', 'leaf verification', 'leaf gap', 'epid image', 'leaf', 'multileaf collimation']"
513,1283,UPSILON: universal programming system with incomplete lazy object notation,"this paper presents a new model of computation that differs from prior models in that it emphasizes data over flow control, has no named variables and has an object-oriented flavor. we prove that this model is a complete and confluent acceptable programming system and has a usable type theory. a new data synchronization primitive is introduced in order to achieve the above properties. subtle variations of the model are shown to fall short of having all these necessary properties","['upsilon', 'universal programming system', 'programming system', 'incomplete lazy object notation', 'object-oriented flavor', 'usable type theory', 'data synchronization primitive']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['upsilon', 'universal programming system', 'programming system', 'incomplete lazy object notation', 'object - orient flavor', 'usable type theory', 'data synchronization primitive']","['new data synchronization primitive', 'confluent acceptable programming system', 'flow control', 'prior model', 'usable type theory', 'computation', 'name variable', 'orient flavor', 'datum', 'new model']"
514,693,Lifting factorization of discrete W transform,"a general method is proposed to factor the type-iv discrete w transform (dwt-iv) into lifting steps and additions. then, based on the relationships among various types of dwts, four types of dwts are factored into lifting steps and additions. after approximating the lifting matrices, we get four types of new integer dwts (intdwt-i, intdwt-ii, intdwt-iii, and intdwt-iv) which are floating-point multiplication free. integer-to-integer transforms (ii-dwt), which approximate to dwt, are also proposed. fast algorithms are given for the new transforms and their computational complexities are analyzed","['lifting factorization', 'dwt', 'lifting matrices', 'computational complexity', 'discrete wavelet transform', 'integer transforms', 'data compression', 'feature extraction', 'multiframe detection', 'filter bank', 'lossless coding schemes', 'mobile devices', 'integer arithmetic', 'mobile computing']","['P', 'P', 'P', 'P', 'M', 'R', 'U', 'U', 'U', 'U', 'U', 'U', 'M', 'M']","['lift factorization', 'dwt', 'lift matrix', 'computational complexity', 'discrete wavelet transform', 'integer transform', 'datum compression', 'feature extraction', 'multiframe detection', 'filter bank', 'lossless code scheme', 'mobile device', 'integer arithmetic', 'mobile computing']","['integer transform', 'new transform', 'lift step', 'lift matrix', 'new integer dwts', 'point multiplication free', 'intdwt', 'fast algorithm', 'dwt', 'integer']"
515,1182,Optimization of the memory weighting function in stochastic functional self-organized sorting performed by a team of autonomous mobile agents,"the activity of a team of autonomous mobile agents formed by identical ""robot-like-ant"" individuals capable of performing a random walk through an environment that are able to recognize and move different ""objects"" is modeled. the emergent desired behavior is a distributed sorting and clustering based only on local information and a memory register that records the past objects encountered. an optimum weighting function for the memory registers is theoretically derived. the optimum time-dependent weighting function allows sorting and clustering of the randomly distributed objects in the shortest time. by maximizing the average speed of a texture feature (the contrast) we check the central assumption, the intermediate steady-states hypothesis, of our theoretical result. it is proved that the algorithm optimization based on maximum speed variation of the contrast feature gives relationships similar to the theoretically derived annealing law","['memory weighting function', 'sorting', 'autonomous mobile agents', 'random walk', 'clustering', 'algorithm optimization']","['P', 'P', 'P', 'P', 'P', 'P']","['memory weighting function', 'sort', 'autonomous mobile agent', 'random walk', 'cluster', 'algorithm optimization']","['autonomous mobile agent form', 'algorithm optimization base', 'distribute object', 'distribute sort', 'texture feature', 'cluster base', 'maximum speed variation', 'weighting function allow sort', 'random walk', 'robot']"
516,106,Quantum Zeno subspaces,the quantum zeno effect is recast in terms of an adiabatic theorem when the measurement is described as the dynamical coupling to another quantum system that plays the role of apparatus. a few significant examples are proposed and their practical relevance discussed. we also focus on decoherence-free subspaces,"['quantum zeno subspaces', 'adiabatic theorem', 'measurement', 'dynamical coupling', 'decoherence-free subspaces']","['P', 'P', 'P', 'P', 'P']","['quantum zeno subspace', 'adiabatic theorem', 'measurement', 'dynamical coupling', 'decoherence - free subspace']","['quantum zeno effect', 'quantum system', 'decoherence', 'dynamical coupling', 'adiabatic theorem', 'apparatus', 'measurement', 'relevance discuss', 'describe', 'role']"
517,945,Testing statistical bounds on entanglement using quantum chaos,"previous results indicate that while chaos can lead to substantial entropy production, thereby maximizing dynamical entanglement, this still falls short of maximality. random matrix theory modeling of composite quantum systems, investigated recently, entails a universal distribution of the eigenvalues of the reduced density matrices. we demonstrate that these distributions are realized in quantized chaotic systems by using a model of two coupled and kicked tops. we derive an explicit statistical universal bound on entanglement, which is also valid for the case of unequal dimensionality of the hilbert spaces involved, and show that this describes well the bounds observed using composite quantized chaotic systems such as coupled tops","['statistical bounds', 'entanglement', 'quantum chaos', 'entropy production', 'maximality', 'random matrix theory', 'composite quantum systems', 'universal distribution', 'reduced density matrices', 'quantized chaotic systems', 'kicked tops', 'hilbert spaces']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['statistical bound', 'entanglement', 'quantum chaos', 'entropy production', 'maximality', 'random matrix theory', 'composite quantum system', 'universal distribution', 'reduce density matrix', 'quantize chaotic system', 'kick top', 'hilbert space']","['composite quantize chaotic system such', 'quantize chaotic system', 'maximize dynamical entanglement', 'composite quantum system', 'random matrix theory model', 'entanglement', 'density matrix', 'substantial entropy', 'chaos', 'hilbert space involve']"
518,143,An automated irradiation device for use in cyclotrons,"two cyclotrons are being operated at ipen-cnen/sp: one model cv-28, capable of accelerating protons with energies up to 24 mev and beam currents up to 30 mu a, and three other particles; the other one, model cyclone 30, accelerates protons with energy of 30 mev and currents up to 350 mu a. both have the objective of irradiating targets both for radioisotope production for use in nuclear medicine and general research. the development of irradiating systems completely automatized was the objective of this work, always aiming to reduce the radiation exposition dose to the workers and to increase the reliability of use of these systems","['automated irradiation device', 'cyclotrons', 'cv-28', 'protons', 'cyclone 30', 'radioisotope production', 'nuclear medicine', 'general research', 'radiation exposition dose']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['automate irradiation device', 'cyclotron', 'cv-28', 'proton', 'cyclone 30', 'radioisotope production', 'nuclear medicine', 'general research', 'radiation exposition dose']","['radiation exposition dose', 'irradiate target', 'irradiate system', 'cyclotron', 'radioisotope production', 'nuclear medicine', 'accelerate proton', 'accelerate proton', 'beam current', 'cnen']"
519,900,Mathematical models of functioning of an insurance company with allowance for the rate of return,"models of the functioning of insurance companies are suggested, when the free capital increases from interest at a certain rate. the basic characteristics of the capital of a company are studied in the stationary regime","['mathematical models', 'free capital increase', 'interest', 'stationary regime', 'insurance company functioning', 'return rate allowance']","['P', 'P', 'P', 'P', 'R', 'R']","['mathematical model', 'free capital increase', 'interest', 'stationary regime', 'insurance company function', 'return rate allowance']","['insurance company', 'free capital increase', 'capital', 'basic characteristic', 'model', 'company', 'interest', 'rate', 'study', 'suggest']"
520,592,Approximation theory of fuzzy systems based upon genuine many-valued implications - SISO cases,"it is proved that the single input and single output (siso) fuzzy systems based upon genuine many-valued implications are universal approximators. it is shown theoretically that fuzzy control systems based upon genuine many-valued implications are equivalent to those based upon t-norm implications, the general approach to construct fuzzy systems is given. it is also shown that defuzzifier based upon center of areas is not appropriate to the fuzzy systems based upon genuine many-valued implications","['fuzzy systems', 'many-valued implications', 'siso', 'universal approximator', 'single input and single output fuzzy systems', 'boolean implication']","['P', 'P', 'P', 'P', 'R', 'M']","['fuzzy system', 'many - value implication', 'siso', 'universal approximator', 'single input and single output fuzzy system', 'boolean implication']","['fuzzy control system base', 'fuzzy system base', 'construct fuzzy system', 'universal approximator', 'defuzzifier base', 'value implication', 'norm implication', 'single input', 'single output', 'siso']"
521,11,Does social capital determine innovation? To what extent?,"this paper deals with two questions: does social capital determine innovation in manufacturing firms? if it is the case, to what extent? to deal with these questions, we review the literature on innovation in order to see how social capital came to be added to the other forms of capital as an explanatory variable of innovation. in doing so, we have been led to follow the dominating view of the literature on social capital and innovation which claims that social capital cannot be captured through a single indicator, but that it actually takes many different forms that must be accounted for. therefore, to the traditional explanatory variables of innovation, we have added five forms of structural social capital (business network assets, information network assets, research network assets, participation assets, and relational assets) and one form of cognitive social capital (reciprocal trust). in a context where empirical investigations regarding the relations between social capital and innovation are still scanty, this paper makes contributions to the advancement of knowledge in providing new evidence regarding the impact and the extent of social capital on innovation at the two decisionmaking stages considered in this study","['innovation', 'manufacturing firms', 'structural social capital', 'business network assets', 'information network assets', 'research network assets', 'participation assets', 'relational assets', 'cognitive social capital', 'reciprocal trust', 'two-stage decision-making process', 'degree of radicalness']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'M']","['innovation', 'manufacture firm', 'structural social capital', 'business network asset', 'information network asset', 'research network asset', 'participation asset', 'relational asset', 'cognitive social capital', 'reciprocal trust', 'two - stage decision - make process', 'degree of radicalness']","['social capital determine innovation', 'structural social capital', 'cognitive social capital', 'social capital come', 'social capital', 'business network asset', 'research network asset', 'manufacture firm', 'innovation', 'information network asset']"
522,54,Controls help harmonic spray do OK removing residues,looks at how innovative wafer-cleaning equipment hit the market in a timely fashion thanks in part to controls maker rockwell automation,"['harmonic spray', 'wafer-cleaning equipment', 'rockwell automation', 'residues removal', 'psi machine', 'allen-bradley controllogix automation control platform', 'motion control', 'allen-bradley 1336 plus ii variable frequency ac drives']","['P', 'P', 'P', 'R', 'U', 'M', 'M', 'U']","['harmonic spray', 'wafer - clean equipment', 'rockwell automation', 'residue removal', 'psi machine', 'allen - bradley controllogix automation control platform', 'motion control', 'allen - bradley 1336 plus ii variable frequency ac drive']","['innovative wafer', 'clean equipment hit', 'timely fashion thank', 'market', 'part', 'look']"
523,858,Recruiting and retaining women in undergraduate computing majors,"this paper recommends methods for increasing female participation in undergraduate computer science. the recommendations are based on recent and on-going research into the gender gap in computer science and related disciplines. they are intended to work in tandem with the computing research association's recommendations for graduate programs to promote a general increase in women's participation in computing professions. most of the suggestions offered could improve the educational environment for both male and female students. however, general improvements are likely to be of particular benefit to women because women in our society do not generally receive the same level of support that men receive for entering and persisting in this field","['undergraduate computing majors', 'female participation', 'computer science', 'gender gap', 'women retention', 'women recruitment']","['P', 'P', 'P', 'P', 'M', 'R']","['undergraduate compute major', 'female participation', 'computer science', 'gender gap', 'woman retention', 'woman recruitment']","['increase female participation', 'undergraduate computer science', 'female student', 'compute research association', 'compute profession', 'graduate program', 'gender gap', 'computer science', 'woman', 'educational environment']"
524,1363,Heuristics for single-pass welding task sequencing,"welding task sequencing is a prerequisite in the offline programming of robot arc welding. single-pass welding task sequencing can be modelled as a modified travelling salesman problem. owing to the difficulty of the resulting arc-routing problems, effective local search heuristics are developed. computational speed becomes important because robot arc welding is often part of an automated process-planning procedure. generating a reasonable solution in an acceptable time is necessary for effective automated process planning. several different heuristics are proposed for solving the welding task-sequencing problem considering both productivity and the potential for welding distortion. constructive heuristics based on the nearest neighbour concept and tabu search heuristics are developed and enhanced using improvement procedures. the effectiveness of the heuristics developed is tested and verified on actual welded structure problems and random problems","['single-pass welding task sequencing', 'offline programming', 'robot arc welding', 'modified travelling salesman problem', 'local search heuristics', 'computational speed', 'automated process-planning procedure', 'productivity', 'welding distortion', 'constructive heuristics', 'nearest neighbour concept', 'tabu search heuristics', 'welded structure problems', 'random problems']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['single - pass welding task sequence', 'offline programming', 'robot arc weld', 'modify travel salesman problem', 'local search heuristic', 'computational speed', 'automate process - planning procedure', 'productivity', 'welding distortion', 'constructive heuristic', 'near neighbour concept', 'tabu search heuristic', 'weld structure problem', 'random problem']","['robot arc weld', 'pass welding task sequence', 'weld task sequence', 'weld task', 'tabu search heuristic', 'automate process plan', 'local search heuristic', 'weld', 'weld structure problem', 'planning procedure']"
525,1326,Verona Lastre: consolidation provides opening for a new plate vendor,"fewer companies than ever are manufacturing ctp plates. the market has become globalized, with just four big firms dominating the picture. to the samor group, however, globalization looked like an opportunity; it reasoned that many a national and local distributor would welcome a small, competitive, regional manufacturer. a couple of years ago it formed a company, verona lastre, to exploit that opportunity. now vela, as it's familiarly called, has launched its line of high-quality thermal plates and is busily lining up dealers in europe and the americas","['verona lastre', 'ctp plates', 'vela']","['P', 'P', 'P']","['verona lastre', 'ctp plate', 'vela']","['manufacture ctp plate', 'quality thermal plate', 'regional manufacturer', 'verona lastre', 'vela', 'samor group', 'few company', 'big firm dominate', 'local distributor', 'dealer']"
526,773,Topology-reducing surface simplification using a discrete solid representation,"this paper presents a new approach for generating coarse-level approximations of topologically complex models. dramatic topology reduction is achieved by converting a 3d model to and from a volumetric representation. our approach produces valid, error-bounded models and supports the creation of approximations that do not interpenetrate the original model, either being completely contained in the input solid or bounding it. several simple to implement versions of our approach are presented and discussed. we show that these methods perform significantly better than other surface-based approaches when simplifying topologically-rich models such as scene parts and complex mechanical assemblies","['topology-reducing surface simplification', 'discrete solid representation', 'coarse-level approximations', 'topologically complex models', '3d model', 'volumetric representation', 'error-bounded models', 'scene parts', 'complex mechanical assemblies']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['topology - reduce surface simplification', 'discrete solid representation', 'coarse - level approximation', 'topologically complex model', '3d model', 'volumetric representation', 'error - bound model', 'scene part', 'complex mechanical assembly']","['3d model', 'complex model', 'dramatic topology reduction', 'model such', 'bound model', 'level approximation', 'volumetric representation', 'model', 'surface', 'scene part']"
527,736,The year of the racehorse [China Telecom],does china really offer the telecoms industry a route out of the telecoms slump? according to the chinese government it has yet to receive a single application from foreign companies looking to invest in the country's domestic telecoms sector since the country joined the world trade organisation,"['china', 'china telecom', 'telecoms industry', 'foreign investment', 'china netcom', 'china unicorn']","['P', 'P', 'P', 'R', 'M', 'M']","['china', 'china telecom', 'telecom industry', 'foreign investment', 'china netcom', 'china unicorn']","['domestic telecom sector', 'telecom industry', 'telecom slump', 'foreign company look', 'chinese government', 'china', 'invest', 'application', 'accord', 'country join']"
528,1062,Fidelity of quantum teleportation through noisy channels,"we investigate quantum teleportation through noisy quantum channels by solving analytically and numerically a master equation in the lindblad form. we calculate the fidelity as a function of decoherence rates and angles of a state to be teleported. it is found that the average fidelity and the range of states to be accurately teleported depend on types of noises acting on quantum channels. if the quantum channels are subject to isotropic noise, the average fidelity decays to 1/2, which is smaller than the best possible value of 2/3 obtained only by the classical communication. on the other hand, if the noisy quantum channel is modeled by a single lindblad operator, the average fidelity is always greater than 2/3","['fidelity', 'quantum teleportation', 'noisy quantum channels', 'quantum channels', 'isotropic noise', 'classical communication', 'lindblad operator', 'analytical solution', 'numerical solution', 'alice', 'bob', 'sender', 'recipient', 'dual classical channels', 'eigenstate']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'U', 'U', 'U', 'U', 'M', 'U']","['fidelity', 'quantum teleportation', 'noisy quantum channel', 'quantum channel', 'isotropic noise', 'classical communication', 'lindblad operator', 'analytical solution', 'numerical solution', 'alice', 'bob', 'sender', 'recipient', 'dual classical channel', 'eigenstate']","['noisy quantum channel', 'noisy quantum channel', 'quantum teleportation', 'quantum channel', 'average fidelity decay', 'lindblad operator', 'classical communication', 'decoherence rate', 'teleport depend', 'average fidelity']"
529,1027,Extracting straight road structure in urban environments using IKONOS satellite imagery,"we discuss a fully automatic technique for extracting roads in urban environments. the method has its bases in a vegetation mask derived from multispectral ikonos data and in texture derived from panchromatic ikonos data. these two techniques together are used to distinguish road pixels. we then move from individual pixels to an object-based representation that allows reasoning on a higher level. recognition of individual segments and intersections and the relationships among them are used to determine underlying road structure and to then logically hypothesize the existence of additional road network components. we show results on an image of san diego, california. the object-based processing component may be adapted to utilize other basis techniques as well, and could be used to build a road network in any scene having a straight-line structured topology","['straight road structure', 'urban environments', 'ikonos satellite imagery', 'fully automatic technique', 'vegetation mask', 'texture', 'panchromatic ikonos data', 'road pixels', 'object-based representation', 'road network components', 'san diego', 'object-based processing component', 'straight-line structured topology', 'higher level reasoning', 'individual segment recognition', 'high-resolution imagery', 'large-scale feature extraction', 'vectorized road network']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'M', 'M']","['straight road structure', 'urban environment', 'ikonos satellite imagery', 'fully automatic technique', 'vegetation mask', 'texture', 'panchromatic ikonos datum', 'road pixel', 'object - base representation', 'road network component', 'san diego', 'object - base processing component', 'straight - line structured topology', 'high level reasoning', 'individual segment recognition', 'high - resolution imagery', 'large - scale feature extraction', 'vectorize road network']","['distinguish road pixel', 'determine underlying road structure', 'road network component', 'extract road', 'road network', 'multispectral ikonos datum', 'vegetation mask derive', 'panchromatic ikonos datum', 'base processing component', 'recognition']"
530,70,IT security issues: the need for end user oriented research,"considerable attention has been given to the technical and policy issues involved with it security issues in recent years. the growth of e-commerce and the internet, as well as widely publicized hacker attacks, have brought it security into prominent focus and routine corporate attention. yet, much more research is needed from the end user (eu) perspective. this position paper is a call for such research and outlines some possible directions of interest","['it security', 'end user oriented research', 'e-commerce', 'internet', 'hacker attacks', 'information technology research', 'end user computing']","['P', 'P', 'P', 'P', 'P', 'M', 'M']","['it security', 'end user orient research', 'e - commerce', 'internet', 'hacker attack', 'information technology research', 'end user computing']","['publicize hacker attack', 'security issue', 'security', 'policy issue involve', 'eu', 'commerce', 'such research', 'internet', 'more research', 'corporate']"
531,122,A formal framework for viewpoint consistency,"multiple viewpoint models of system development are becoming increasingly important. each viewpoint offers a different perspective on the target system and system development involves parallel refinement of the multiple views. viewpoint related approaches have been considered in a number of different guises by a spectrum of researchers. our work particularly focuses on the use of viewpoints in open distributed processing (odp) which is an iso/itu standardisation framework. the requirements of viewpoint modelling in odp are very broad and, hence, demanding. multiple viewpoints, though, prompt the issue of consistency between viewpoints. this paper describes a very general interpretation of consistency which we argue is broad enough to meet the requirements of consistency in odp. we present a formal framework for this general interpretation; highlight basic properties of the interpretation and locate restricted classes of consistency. strategies for checking consistency are also investigated. throughout we illustrate our theory using the formal description technique lotos. thus, the paper also characterises the nature of and options for consistency checking in lotos","['formal framework', 'viewpoint consistency', 'multiple viewpoint models', 'system development', 'open distributed processing', 'odp', 'iso/itu standardisation framework', 'formal description technique', 'lotos', 'consistency checking', 'development models', 'process algebra']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['formal framework', 'viewpoint consistency', 'multiple viewpoint model', 'system development', 'open distribute processing', 'odp', 'iso / itu standardisation framework', 'formal description technique', 'lotos', 'consistency checking', 'development model', 'process algebra']","['system development involve parallel refinement', 'open distribute processing', 'formal description technique lotos', 'multiple viewpoint model', 'itu standardisation framework', 'check consistency', 'consistency checking', 'viewpoint model', 'viewpoint relate approach', 'formal framework']"
532,961,Modular and visual specification of hybrid systems: an introduction to HyCharts,"visual description techniques are particularly important for the design of hybrid systems, because specifications of such systems usually have to be discussed between engineers from a number of different disciplines. modularity is vital for hybrid systems not only because it allows to handle large systems, but also because it permits to think in terms of components, which is familiar to engineers. based on two different interpretations for hierarchic graphs and on a clear hybrid computation model, we develop hycharts. hycharts consist of two modular visual formalisms, one for the specification of the architecture and one for the specification of the behavior of hybrid systems. the operators on hierarchic graphs enable us to give a surprisingly simple denotational semantics for many concepts known from statechart-like formalisms. due to a very general composition operator, hycharts can easily be composed with description techniques from other engineering disciplines. such heterogeneous system specifications seem to be particularly appropriate for hybrid systems because of their interdisciplinary character","['visual specification', 'hybrid systems', 'hycharts', 'visual description techniques', 'components', 'hierarchic graphs', 'hybrid computation model', 'denotational semantics', 'heterogeneous system specifications', 'modular specification', 'statechart', 'formal specification']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'R']","['visual specification', 'hybrid system', 'hychart', 'visual description technique', 'component', 'hierarchic graph', 'hybrid computation model', 'denotational semantic', 'heterogeneous system specification', 'modular specification', 'statechart', 'formal specification']","['modular visual formalism', 'simple denotational semantic', 'hierarchic graph enable', 'such heterogeneous system specification seem', 'hierarchic graph', 'clear hybrid computation model', 'visual description technique', 'hybrid system', 'other engineering discipline', 'handle large system']"
533,924,Dynamic testing of inflatable structures using smart materials,"in this paper we present experimental investigations of the vibration testing of an inflated, thin-film torus using smart materials. lightweight, inflatable structures are very attractive in satellite applications. however, the lightweight, flexible and highly damped nature of inflated structures poses difficulties in ground vibration testing. in this study, we show that polyvinylidene fluoride (pvdf) patches and recently developed macro-fiber composite actuators may be used as sensors and actuators in identifying modal parameters. both smart materials can be integrated unobtrusively into the skin of a torus or space device forming an attractive testing arrangement. the addition of actuators and pvdf sensors to the torus does not significantly interfere with the suspension modes of a free-free boundary condition, and can be considered an integral part of the inflated structure. the results indicate the potential of using smart materials to measure and control the dynamic response of inflated structures","['inflated structures', 'smart materials', 'thin-film torus', 'satellite applications', 'ground vibration testing', 'macro-fiber composite actuators', 'modal parameters', 'space device', 'pvdf sensors', 'boundary condition', 'dynamic response', 'polyvinylidene fluoride patches', 'kapton torus']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['inflated structure', 'smart material', 'thin - film torus', 'satellite application', 'ground vibration testing', 'macro - fiber composite actuator', 'modal parameter', 'space device', 'pvdf sensor', 'boundary condition', 'dynamic response', 'polyvinylidene fluoride patch', 'kapton torus']","['ground vibration testing', 'fiber composite actuator', 'vibration testing', 'inflatable structure', 'pvdf sensor', 'actuator', 'inflated structure', 'polyvinylidene fluoride', 'flexible', 'inflated structure']"
534,1046,A suggestion of fractional-order controller for flexible spacecraft attitude control,"a controller design method for flexible spacecraft attitude control is proposed. the system is first described by a partial differential equation with internal damping. then the frequency response is analyzed, and the three basic characteristics of the flexible system, namely, average function, lower bound and upper bound are defined. on this basis, a fractional-order controller is proposed, which functions as phase stabilization control for lower frequency and smoothly enters to amplitude stabilization at higher frequency by proper amplitude attenuation. it is shown that the equivalent damping ratio increases in proportion to the square of frequency","['fractional-order controller', 'flexible spacecraft attitude control', 'partial differential equation', 'internal damping', 'frequency response', 'phase stabilization control', 'amplitude stabilization', 'damping ratio']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['fractional - order controller', 'flexible spacecraft attitude control', 'partial differential equation', 'internal damping', 'frequency response', 'phase stabilization control', 'amplitude stabilization', 'damp ratio']","['flexible spacecraft attitude control', 'phase stabilization control', 'amplitude stabilization', 'damp ratio', 'controller', 'flexible system', 'fractional', 'frequency', 'damp', 'amplitude attenuation']"
535,1003,Lob's theorem as a limitation on mechanism,"we argue that lob's theorem implies a limitation on mechanism. specifically, we argue, via an application of a generalized version of lob's theorem, that any particular device known by an observer to be mechanical cannot be used as an epistemic authority (of a particular type) by that observer: either the belief-set of such an authority is not mechanizable or, if it is, there is no identifiable formal system of which the observer can know (or truly believe) it to be the theorem-set. this gives, we believe, an important and hitherto unnoticed connection between mechanism and the use of authorities by human-like epistemic agents","['limitation on mechanism', 'epistemic authority', 'belief-set', 'formal system', 'theorem-set', 'human-like epistemic agents', 'lob theorem']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['limitation on mechanism', 'epistemic authority', 'belief - set', 'formal system', 'theorem - set', 'human - like epistemic agent', 'lob theorem']","['epistemic authority', 'identifiable formal system', 'observer', 'belief', 'particular device know', 'theorem imply', 'mechanism', 'authority', 'hitherto unnoticed connection', 'lob']"
536,881,Is diversity in computing a moral matter?,"we have presented an ethical argument that takes into consideration the subtleties of the issue surrounding under-representation in computing. we should emphasize that there is nothing subtle about overt, unfair discrimination. where such injustice occurs, we condemn it. our concern is that discrimination need not be explicit or overt. it need not be individual-to-individual. rather, it can be subtly built into social practices and social institutions. our analysis raises ethical questions about aspects of computing that drive women away, aspects that can be changed in ways that improve the profession and access to the profession. we hope that computing will move towards these improvements","['ethical argument', 'unfair discrimination', 'social practices', 'social institutions', 'women', 'computing under-representation']","['P', 'P', 'P', 'P', 'P', 'R']","['ethical argument', 'unfair discrimination', 'social practice', 'social institution', 'woman', 'compute under - representation']","['analysis raise ethical question', 'unfair discrimination', 'ethical argument', 'issue surround under', 'discrimination', 'such injustice occur', 'drive woman', 'social practice', 'social institution', 'compute']"
537,1347,A maximum-likelihood surface estimator for dense range data,"describes how to estimate 3d surface models from dense sets of noisy range data taken from different points of view, i.e., multiple range maps. the proposed method uses a sensor model to develop an expression for the likelihood of a 3d surface, conditional on a set of noisy range measurements. optimizing this likelihood with respect to the model parameters provides an unbiased and efficient estimator. the proposed numerical algorithms make this estimation computationally practical for a wide variety of circumstances. the results from this method compare favorably with state-of-the-art approaches that rely on the closest-point or perpendicular distance metric, a convenient heuristic that produces biased solutions and fails completely when surfaces are not sufficiently smooth, as in the case of complex scenes or noisy range measurements. empirical results on both simulated and real ladar data demonstrate the effectiveness of the proposed method for several different types of problems. furthermore, the proposed method offers a general framework that can accommodate extensions to include surface priors, more sophisticated noise models, and other sensing modalities, such as sonar or synthetic aperture radar","['maximum-likelihood surface estimator', 'dense range data', '3d surface models', 'noisy range data', 'sensor model', 'noisy range measurements', 'heuristic', 'biased solutions', 'complex scenes', 'real ladar data', 'sonar', 'synthetic aperture radar', 'unbiased estimator', 'simulated ladar data', 'surface reconstruction', 'surface fitting', 'optimal estimation', 'parameter estimation', 'bayesian estimation', 'registration', 'calibration']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'M', 'R', 'R', 'M', 'U', 'U']","['maximum - likelihood surface estimator', 'dense range datum', '3d surface model', 'noisy range datum', 'sensor model', 'noisy range measurement', 'heuristic', 'bias solution', 'complex scene', 'real ladar datum', 'sonar', 'synthetic aperture radar', 'unbiased estimator', 'simulate ladar datum', 'surface reconstruction', 'surface fitting', 'optimal estimation', 'parameter estimation', 'bayesian estimation', 'registration', 'calibration']","['estimate 3d surface model', 'multiple range map', '3d surface', 'noisy range datum', 'noisy range measurement', 'perpendicular distance metric', 'surface prior', 'sensor model', 'sense modality', 'surface']"
538,1302,Dynamics of the firing probability of noisy integrate-and-fire neurons,"cortical neurons in vivo undergo a continuous bombardment due to synaptic activity, which acts as a major source of noise. we investigate the effects of the noise filtering by synapses with various levels of realism on integrate-and-fire neuron dynamics. the noise input is modeled by white (for instantaneous synapses) or colored (for synapses with a finite relaxation time) noise. analytical results for the modulation of firing probability in response to an oscillatory input current are obtained by expanding a fokker-planck equation for small parameters of the problem-when both the amplitude of the modulation is small compared to the background firing rate and the synaptic time constant is small compared to the membrane time constant. we report the detailed calculations showing that if a synaptic decay time constant is included in the synaptic current model, the firing-rate modulation of the neuron due to an oscillatory input remains finite in the high-frequency limit with no phase lag. in addition, we characterize the low-frequency behavior and the behavior of the high-frequency limit for intermediate decay times. we also characterize the effects of introducing a rise time to the synaptic currents and the presence of several synaptic receptors with different kinetics. in both cases, we determine, using numerical simulations, an effective decay time constant that describes the neuronal response completely","['firing probability', 'noisy integrate-and-fire neurons', 'cortical neurons', 'synaptic activity', 'noise filtering', 'fokker-planck equation', 'synaptic time constant', 'membrane time constant', 'phase lag', 'synaptic receptors', 'numerical simulation', 'white noise', 'colored noise']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['fire probability', 'noisy integrate - and - fire neuron', 'cortical neuron', 'synaptic activity', 'noise filtering', 'fokker - planck equation', 'synaptic time constant', 'membrane time constant', 'phase lag', 'synaptic receptor', 'numerical simulation', 'white noise', 'color noise']","['synaptic decay time constant', 'fire neuron dynamic', 'synaptic time constant', 'cortical neuron', 'instantaneous synapsis', 'synaptic receptor', 'synaptic current', 'synaptic current model', 'decay time constant', 'oscillatory input current']"
539,757,Ultrafast compound imaging for 2-D motion vector estimation: application to transient elastography,"this paper describes a new technique for two-dimensional (2-d) imaging of the motion vector at a very high frame rate with ultrasound. its potential is experimentally demonstrated for transient elastography. but, beyond this application, it also could be promising for color flow and reflectivity imaging. to date, only axial displacements induced in human tissues by low-frequency vibrators were measured during transient elastography. the proposed technique allows us to follow both axial and lateral displacements during the shear wave propagation and thus should improve young's modulus image reconstruction. the process is a combination of several ideas well-known in ultrasonic imaging: ultra-fast imaging, multisynthetic aperture beamforming, 1-d speckle tracking, and compound imaging. classical beamforming in the transmit mode is replaced here by a single plane wave insonification increasing the frame rate by at least a factor of 128. the beamforming is achieved only in the receive mode on two independent subapertures. comparison of successive frames by a classical 1-d speckle tracking algorithm allows estimation of displacements along two different directions linked to the subapertures beams. the variance of the estimates is finally improved by tilting the emitting plane wave at each insonification, thus allowing reception of successive decorrelated speckle patterns","['ultrafast compound imaging', 'transient elastography', 'high frame rate', 'ultrasound', 'reflectivity imaging', 'axial displacements', 'human tissues', 'lateral displacements', 'shear wave propagation', ""young's modulus image reconstruction"", 'ultrasonic imaging', 'multisynthetic aperture beamforming', 'single plane wave insonification', 'decorrelated speckle patterns', '2d motion vector estimation', 'two-dimensional imaging', '2d imaging', 'colour flow imaging', '1d speckle tracking algorithm']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'M', 'M', 'M']","['ultrafast compound imaging', 'transient elastography', 'high frame rate', 'ultrasound', 'reflectivity imaging', 'axial displacement', 'human tissue', 'lateral displacement', 'shear wave propagation', ""young 's modulus image reconstruction"", 'ultrasonic imaging', 'multisynthetic aperture beamforme', 'single plane wave insonification', 'decorrelate speckle pattern', '2d motion vector estimation', 'two - dimensional imaging', '2d imaging', 'colour flow imaging', '1d speckle track algorithm']","['ultrasonic imaging', 'shear wave propagation', 'transient elastography', 'speckle tracking algorithm allow estimation', 'reflectivity imaging', 'ultrasound', 'subaperture beam', 'axial displacement', 'multisynthetic aperture beamforme', 'speckle tracking']"
540,712,Waiting-time distribution of a discrete-time multiserver queue with correlated arrivals and deterministic service times: D-MAP/D/k system,we derive the waiting-time distribution of a discrete-time multiserver queue with correlated arrivals and deterministic (or constant) service times. we show that the procedure for obtaining the waiting-time distribution of a multiserver queue is reduced to that of a single-server queue. we present a complete solution to the waiting-time distribution of d-map/d/k queue together with some computational results,"['waiting-time distribution', 'discrete-time multiserver queue', 'correlated arrivals', 'deterministic service times', 'd-map/d/k system', 'markovian arrival process']","['P', 'P', 'P', 'P', 'P', 'M']","['wait - time distribution', 'discrete - time multiserver queue', 'correlate arrival', 'deterministic service time', 'd - map / d / k system', 'markovian arrival process']","['time multiserver queue', 'multiserver queue', 'server queue', 'correlate arrival', 'queue', 'time distribution', 'service time', 'wait', 'deterministic', 'discrete']"
541,839,"Women in computing: what brings them to it, what keeps them in it?","career stereotyping and misperceptions about the nature of computing are substantive reasons for the under representation of women in professional computing careers. in this study, 15 women who have work experience in several aspects of computing were asked about their reasons for entering computing, what they liked about working in computing, and what they disliked. while there are many common threads, there are also individual differences. common reasons for choosing computing as a career included: exposure to computing in a setting which enabled them to see the versatility of computers; the influence of someone close to them; personal abilities which they perceived to be appropriate for a career in computing; and characteristics of such careers which appealed to them. generally, women working in the field enjoy the work they are doing. dislikes arising from their work experiences are more likely to be associated with people and politics than with the work they do-and they would like to have more female colleagues","['women', 'career stereotyping', 'misperceptions', 'professional computing careers', 'personal abilities', 'politics']","['P', 'P', 'P', 'P', 'P', 'P']","['woman', 'career stereotype', 'misperception', 'professional computing career', 'personal ability', 'politic']","['professional computing career', 'career stereotype', 'woman work', 'choose computing', 'have work experience', 'work experience', 'such career', 'career include', 'enter computing', 'be many common thread']"
542,804,Voltage control methods with grid connected wind turbines: a tutorial review,"within electricity grid networks it is conventional for large-scale central generators to both provide power and control grid node voltage. therefore when wind turbines replace conventional power stations on a substantial scale, they must not only generate power, but also control grid node voltages. this paper reviews the basic principles of voltage control for tutorial benefit and then considers application of grid-connected wind turbines for voltage control. the most widely used contemporary wind turbine types are considered and further detail is given for determining the range of variables that allow control","['voltage control', 'grid connected wind turbines', 'electricity grid networks', 'large-scale central generators', 'grid node voltages control', 'reactive power', 'direct drive', 'variable speed', 'offshore wind park', 'squirrel cage induction generator', 'doubly fed induction generator', 'direct drive synchronous generator', 'weak grid', 'converter rating']","['P', 'P', 'P', 'P', 'R', 'M', 'U', 'M', 'M', 'M', 'M', 'M', 'M', 'U']","['voltage control', 'grid connect wind turbine', 'electricity grid network', 'large - scale central generator', 'grid node voltage control', 'reactive power', 'direct drive', 'variable speed', 'offshore wind park', 'squirrel cage induction generator', 'doubly feed induction generator', 'direct drive synchronous generator', 'weak grid', 'converter rating']","['control grid node voltage', 'control grid node voltage', 'voltage control', 'wind turbine', 'wind turbine type', 'electricity grid network', 'scale central generator', 'grid', 'generate power', 'variable']"
543,841,Becoming a computer scientist,"the focus of this report is pipeline shrinkage for women in computer science. we describe the situation for women at all stages of training in computer science, from the precollege level through graduate school. because many of the problems discussed are related to the lack of role models for women who are in the process of becoming computer scientists, we also concern ourselves with the status of women faculty members. we not only describe the problems, but also make specific recommendations for change and encourage further study of those problems whose solutions are not yet well understood","['pipeline shrinkage', 'women', 'computer science', 'role models', 'women faculty members']","['P', 'P', 'P', 'P', 'P']","['pipeline shrinkage', 'woman', 'computer science', 'role model', 'woman faculty member']","['woman faculty member', 'become computer scientist', 'pipeline shrinkage', 'encourage further study', 'role model', 'computer science', 'graduate school', 'woman', 'precollege level', 'problem discuss']"
544,1086,Some recent advances in validated methods for IVPs for ODEs,"compared to standard numerical methods for initial value problems (ivps) for ordinary differential equations (odes), validated methods (often called interval methods) for ivps for odes have two important advantages: if they return a solution to a problem, then (1) the problem is guaranteed to have a unique solution, and (2) an enclosure of the true solution is produced. we present a brief overview of interval taylor series (its) methods for ivps for odes and discuss some recent advances in the theory of validated methods for ivps for odes. in particular, we discuss an interval hermite-obreschkoff (iho) scheme for computing rigorous bounds on the solution of an ivp for an ode, the stability of its and iho methods, and a new perspective on the wrapping effect, where we interpret the problem of reducing the wrapping effect as one of finding a more stable scheme for advancing the solution","['validated methods', 'initial value problems', 'ordinary differential equations', 'interval methods', 'interval taylor series', 'wrapping effect', 'interval hermite-obreschkoff scheme', 'qr algorithm']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'U']","['validate method', 'initial value problem', 'ordinary differential equation', 'interval method', 'interval taylor series', 'wrap effect', 'interval hermite - obreschkoff scheme', 'qr algorithm']","['call interval method', 'interval taylor series', 'numerical method', 'interval hermite', 'ode have', 'compute rigorous bound', 'iho method', 'ode', 'ode', 'ivp']"
545,1457,A discontinuous Galerkin method for transient analysis of wave propagation in unbounded domains,"a technique based on the discontinuous galerkin finite element method is developed and applied to the derivation of an absorbing boundary condition for the analysis of transient wave propagation. the condition is exact in that only discretization error is involved. furthermore, the computational cost associated with use of the condition is an order of magnitude lower than for conditions based on green functions. the time-stepping scheme resulting from an implicit method in conjunction with this boundary condition appears to be unconditionally stable","['transient analysis', 'unbounded domains', 'discontinuous galerkin finite element method', 'absorbing boundary condition', 'transient wave propagation', 'discretization error', 'computational cost', 'time-stepping scheme', 'implicit method', 'unconditional stability']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['transient analysis', 'unbounded domain', 'discontinuous galerkin finite element method', 'absorb boundary condition', 'transient wave propagation', 'discretization error', 'computational cost', 'time - step scheme', 'implicit method', 'unconditional stability']","['discontinuous galerkin finite element method', 'transient wave propagation', 'absorb boundary', 'discretization error', 'boundary', 'implicit method', 'derivation', 'computational', 'green', 'technique']"
546,1412,Arbortext: enabler of multichannel publishing,"a company has a document-say, dosage instructions for a prescription drug or a troubleshooting sheet for a dvd drive. that document starts its life in a predictable format, probably microsoft word or wordperfect, but then-to meet the needs of readers who nowadays demand access via multiple devices-the material has to be translated into many more formats: html, pagemaker, or quark, possibly rtf, almost certainly pdf, and nowadays, next-generation devices (cell phones, handheld computers) also impose their own requirements. and what if, suddenly, the dosage levels change or new workarounds emerge to handle dvd problems? that's when a company should put in a call to arbortext, a 20-year-old ann arbor, michigan-based company that exists to solve a single problem: helping clients automate multichannel publishing","['arbortext', 'multichannel publishing', 'next-generation devices', 'document format', 'content assets']","['P', 'P', 'P', 'R', 'U']","['arbortext', 'multichannel publish', 'next - generation device', 'document format', 'content asset']","['handle dvd problem', 'microsoft word', 'handheld computer', 'many more format', 'dvd drive', 'multiple device', 'generation device', 'new workaround emerge', 'dosage level change', 'prescription drug']"
547,797,Adaptive wavelet methods. II. Beyond the elliptic case,"this paper is concerned with the design and analysis of adaptive wavelet methods for systems of operator equations. its main accomplishment is to extend the range of applicability of the adaptive wavelet-based method developed previously for symmetric positive definite problems to indefinite or unsymmetric systems of operator equations. this is accomplished by first introducing techniques (such as the least squares formulation developed previously) that transform the original (continuous) problem into an equivalent infinite system of equations which is now well-posed in the euclidean metric. it is then shown how to utilize adaptive techniques to solve the resulting infinite system of equations. it is shown that for a wide range of problems, this new adaptive method performs with asymptotically optimal complexity, i.e., it recovers an approximate solution with desired accuracy at a computational expense that stays proportional to the number of terms in a corresponding wavelet-best n-term approximation. an important advantage of this adaptive approach is that it automatically stabilizes the numerical procedure so that, for instance, compatibility constraints on the choice of trial spaces, like the lbb condition, no longer arise","['adaptive wavelet methods', 'elliptic case', 'operator equations', 'least squares formulation', 'euclidean metric', 'asymptotically optimal complexity', 'n-term approximation']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['adaptive wavelet method', 'elliptic case', 'operator equation', 'least square formulation', 'euclidean metric', 'asymptotically optimal complexity', 'n - term approximation']","['adaptive wavelet method', 'adaptive wavelet', 'asymptotically optimal complexity', 'new adaptive method', 'wavelet', 'operator equation', 'adaptive technique', 'adaptive approach', 'least square formulation', 'term approximation']"
548,576,Application of Sugeno fuzzy-logic controller to the stator field-oriented doubly-fed asynchronous motor drive,"this study deals with the application of the fuzzy-control theory to wound-rotor asynchronous motor with both its stator and rotor fed by two pwm voltage-source inverters, in which the system operates in stator field-oriented control. thus, after determining the model of the machine, we present two types of fuzzy controller: mamdani and sugeno controllers. the training of the last one is carried out starting from the first. simulation study is conducted to show the effectiveness of the proposed method","['sugeno fuzzy-logic controller', 'stator field-oriented doubly-fed asynchronous motor drive', 'fuzzy-control', 'wound-rotor asynchronous motor', 'pwm voltage-source inverters', 'stator field-oriented control', 'training', 'machine modelling', 'mamdani controller', 'speed regulation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U']","['sugeno fuzzy - logic controller', 'stator field - orient doubly - feed asynchronous motor drive', 'fuzzy - control', 'wound - rotor asynchronous motor', 'pwm voltage - source inverter', 'stator field - orient control', 'train', 'machine modelling', 'mamdani controller', 'speed regulation']","['rotor asynchronous motor', 'fuzzy controller', 'pwm voltage', 'rotor', 'fuzzy', 'inverter', 'stator field', 'sugeno controller', 'stator', 'machine']"
549,1123,A transactional asynchronous replication scheme for mobile database systems,"in mobile database systems, mobility of users has a significant impact on data replication. as a result, the various replica control protocols that exist today in traditional distributed and multidatabase environments are no longer suitable. to solve this problem, a new mobile database replication scheme, the transaction-level result-set propagation (tlrsp) model, is put forward in this paper. the conflict detection and resolution strategy based on tlrsp is discussed in detail, and the implementation algorithm is proposed. in order to compare the performance of the tlrsp model with that of other mobile replication schemes, we have developed a detailed simulation model. experimental results show that the tlrsp model provides an efficient support for replicated mobile database systems by reducing reprocessing overhead and maintaining database consistency","['transaction', 'mobile database', 'data replication', 'multidatabase', 'mobile database replication', 'transaction-level result-set propagation', 'distributed database', 'mobile computing', 'conflict reconciliation']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M']","['transaction', 'mobile database', 'datum replication', 'multidatabase', 'mobile database replication', 'transaction - level result - set propagation', 'distribute database', 'mobile computing', 'conflict reconciliation']","['new mobile database replication scheme', 'replicate mobile database system', 'mobile replication scheme', 'replica control protocol', 'datum replication', 'mobile database system', 'traditional distribute', 'detail simulation model', 'multidatabase environment', 'tlrsp model']"
550,1166,Embedding the outer automorphism group Out(F/sub n/) of a free group of rank n in the group Out(F/sub m/) for m > n,"it is proved that for every n >or= 1, the group out(f/sub n/) is embedded in the group out(f/sub m/) with m = 1 + (n - 1)k/sup n/, where k is an arbitrary natural number coprime to n - 1","['free group', 'arbitrary natural number coprime', 'outer automorphism group embedding']","['P', 'P', 'R']","['free group', 'arbitrary natural number coprime', 'outer automorphism group embed']","['arbitrary natural number', 'group', 'sub', 'prove', 'embed', 'sup']"
551,632,Modelling dependencies in paired comparison data a log-linear approach,"in many bradley-terry models a more or less explicit assumption is that all decisions of the judges are independent. an assumption which might be questionable at least for the decisions of a given judge. in paired comparison studies, a judge chooses among objects several times, and in such cases, judgements made by the same judge are likely to be dependent. a log-linear representation for the bradley-terry model is developed, which takes into account dependencies between judgements. the modelling of the dependencies is embedded in the analysis of multiple binomial responses, which has the advantage of interpretability in terms of conditional odds ratios. furthermore, the modelling is done in the framework of generalized linear models, thus parameter estimation and the assessment of goodness of fit can be obtained in the standard way by using e.g. glim or another standard software","['log-linear approach', 'bradley-terry model', 'multiple binomial responses', 'conditional odds ratios', 'generalized linear models', 'parameter estimation', 'goodness of fit', 'glim', 'paired comparison data dependency modelling', 'judge decisions']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['log - linear approach', 'bradley - terry model', 'multiple binomial response', 'conditional odd ratio', 'generalize linear model', 'parameter estimation', 'goodness of fit', 'glim', 'pair comparison datum dependency modelling', 'judge decision']","['generalize linear model', 'conditional odd ratio', 'terry model', 'terry model', 'multiple binomial response', 'pair comparison study', 'judge choose', 'judgement make', 'many bradley', 'give judge']"
552,677,Acts to facts catalogue,the paper shows a way to satisfy users' changing and specific information needs by providing the modified format-author-collaborators-title-series-subject (facts). catalogue instead of the traditional author-collaborator-title-series-subjects (acts) catalogue,"['information needs', 'format-author-collaborators-title-series-subject catalogue', 'author-collaborator-title-series-subjects catalogue']","['P', 'R', 'R']","['information need', 'format - author - collaborator - title - series - subject catalogue', 'author - collaborator - title - series - subject catalogue']","['modify format', 'specific information need', 'traditional author', 'paper show', 'catalogue', 'change', 'collaborator', 'author', 'satisfy user', 'subject']"
553,1222,Mining the optimal class association rule set,"we define an optimal class association rule set to be the minimum rule set with the same predictive power of the complete class association rule set. using this rule set instead of the complete class association rule set we can avoid redundant computation that would otherwise be required for mining predictive association rules and hence improve the efficiency of the mining process significantly. we present an efficient algorithm for mining the optimal class association rule set using an upward closure property of pruning weak rules before they are actually generated. we have implemented the algorithm and our experimental results show that our algorithm generates the optimal class association rule set, whose size is smaller than 1/17 of the complete class association rule set on average, in significantly less time than generating the complete class association rule set. our proposed criterion has been shown very effective for pruning weak rules in dense databases","['minimum rule set', 'predictive power', 'redundant computation', 'predictive association rules', 'upward closure property', 'experimental results', 'dense databases', 'optimal class association rule set mining', 'relational database', 'data mining', 'weak rule pruning']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M', 'R']","['minimum rule set', 'predictive power', 'redundant computation', 'predictive association rule', 'upward closure property', 'experimental result', 'dense database', 'optimal class association rule set mining', 'relational database', 'datum mining', 'weak rule pruning']","['mining predictive association rule', 'optimal class association rule set', 'complete class association rule set', 'prune weak rule', 'efficient algorithm', 'minimum rule set', 'algorithm generate', 'avoid redundant computation', 'rule set', 'mining process']"
554,1267,3D reconstruction from uncalibrated-camera optical flow and its reliability evaluation,"we present a scheme for reconstructing a 3d structure from optical flow observed by a camera with an unknown focal length in a statistically optimal way as well as evaluating the reliability of the computed shape. first, the flow fundamental matrices are optimally computed from the observed flow. they are then decomposed into the focal length, its rate of change, and the motion parameters. next, the flow is optimally corrected so that it satisfies the epipolar equation exactly. finally, the 3d positions are computed, and their covariance matrices are evaluated. by simulations and real-image experiments, we test the performance of our system and observe how the normalization (gauge) for removing indeterminacy affects the description of uncertainty","['3d reconstruction', 'uncalibrated-camera optical flow', 'reliability evaluation', 'flow fundamental matrices', 'motion parameters', 'epipolar equation', 'covariance matrices', 'real-image experiments', 'normalization']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['3d reconstruction', 'uncalibrate - camera optical flow', 'reliability evaluation', 'flow fundamental matrix', 'motion parameter', 'epipolar equation', 'covariance matrix', 'real - image experiment', 'normalization']","['optical flow observe', 'flow fundamental matrix', 'observe flow', '3d structure', '3d position', 'reconstruct', 'motion parameter', 'flow', 'covariance matrix', 'focal length']"
555,919,Agents in e-commerce: state of the art,"this paper surveys the state of the art of agent-mediated electronic commerce (e-commerce), especially in business-to-consumer (b2c) e-commerce and business-to-business (b2b) e-commerce. from the consumer buying behaviour perspective, the roles of agents in b2c e-commerce are: product brokering, merchant brokering, and negotiation. the applications of agents in b2b e-commerce are mainly in supply chain management. mobile agents, evolutionary agents, and data-mining agents are some special techniques which can be applied in agent-mediated e-commerce. in addition, some technologies for implementation are briefly reviewed. finally, we conclude this paper by discussions on the future directions of agent-mediated e-commerce","['state of the art', 'agent-mediated electronic commerce', 'consumer buying behaviour', 'product brokering', 'merchant brokering', 'negotiation', 'supply chain management', 'mobile agents', 'evolutionary agents', 'data-mining agents', 'business-to-consumer e-commerce', 'multi-agent systems', 'business-to-business e-commerce']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'R']","['state of the art', 'agent - mediate electronic commerce', 'consumer buying behaviour', 'product brokering', 'merchant brokering', 'negotiation', 'supply chain management', 'mobile agent', 'evolutionary agent', 'data - mining agent', 'business - to - consumer e - commerce', 'multi - agent system', 'business - to - business e - commerce']","['mediate electronic commerce', 'consumer buying behaviour perspective', 'merchant brokering', 'mobile agent', 'evolutionary agent', 'mining agent', 'product brokering', 'commerce', 'agent', 'agent']"
556,795,Approximation and complexity. II. Iterated integration,"for pt. i. see ibid., no. 1, p. 289-95 (2001). we introduce two classes of real analytic functions w contained in/implied by u on an interval. starting with rational functions to construct functions in w we allow the application of three types of operations: addition, integration, and multiplication by a polynomial with rational coefficients. in a similar way, to construct functions in u we allow integration, addition, and multiplication of functions already constructed in u and multiplication by rational numbers. thus, u is a subring of the ring of pfaffian functions. two lower bounds on the l/sub infinity /-norm are proved on a function f from w (or from u, respectively) in terms of the complexity of constructing f","['integration', 'real analytic functions', 'rational functions', 'addition', 'multiplication', 'polynomial', 'pfaffian functions', 'lower bounds', 'l/sub infinity /-norm']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['integration', 'real analytic function', 'rational function', 'addition', 'multiplication', 'polynomial', 'pfaffian function', 'low bound', 'l / sub infinity /-norm']","['real analytic function', 'rational function', 'pfaffian function', 'construct function', 'rational coefficient', 'function', 'rational number', 'complexity', 'sub infinity', 'function']"
557,1385,Cache invalidation and replacement strategies for location-dependent data in mobile environments,"mobile location-dependent information services (ldiss) have become increasingly popular in recent years. however, data caching strategies for ldiss have thus far received little attention. in this paper, we study the issues of cache invalidation and cache replacement for location-dependent data under a geometric location model. we introduce a new performance criterion, called caching efficiency, and propose a generic method for location-dependent cache invalidation strategies. in addition, two cache replacement policies, pa and paid, are proposed. unlike the conventional replacement policies, pa and paid take into consideration the valid scope area of a data value. we conduct a series of simulation experiments to study the performance of the proposed caching schemes. the experimental results show that the proposed location-dependent invalidation scheme is very effective and the pa and paid policies significantly outperform the conventional replacement policies","['cache invalidation', 'mobile location-dependent information services', 'location-dependent information', 'data caching', 'cache replacement', 'mobile computing', 'semantic caching', 'performance evaluation']","['P', 'P', 'P', 'P', 'P', 'M', 'M', 'M']","['cache invalidation', 'mobile location - dependent information service', 'location - dependent information', 'datum cache', 'cache replacement', 'mobile computing', 'semantic caching', 'performance evaluation']","['datum cache strategy', 'dependent cache invalidation strategy', 'cache replacement policy', 'propose cache scheme', 'cache efficiency', 'cache invalidation', 'cache replacement', 'mobile location', 'dependent information service', 'valid scope area']"
558,1079,A novel robot hand with embedded shape memory alloy actuators,"describes the development of an active robot hand, which allows smooth and lifelike motions for anthropomorphic grasping and fine manipulations. an active robot finger 10 mm in outer diameter with a shape memory alloy (sma) wire actuator embedded in the finger with a constant distance from the geometric centre of the finger was designed and fabricated. the practical specifications of the sma wire and the flexible rod were determined on the basis of a series of formulae. the active finger consists of two bending parts, the sma actuators and a connecting part. the mechanical properties of the bending part are investigated. the control system on the basis of resistance feedback is also presented. finally, a robot hand with three fingers was designed and the grasping experiment was carried out to demonstrate its performance","['embedded shape memory alloy actuators', 'active robot hand', 'lifelike motions', 'anthropomorphic grasping', 'fine manipulations', 'flexible rod', 'active finger', 'resistance feedback']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['embed shape memory alloy actuator', 'active robot hand', 'lifelike motion', 'anthropomorphic grasping', 'fine manipulation', 'flexible rod', 'active finger', 'resistance feedback']","['active robot finger', 'active robot hand', 'robot hand', 'anthropomorphic grasping', 'wire actuator embed', 'grasp experiment', 'active finger consist', 'sma actuator', 'shape memory alloy', 'flexible rod']"
559,806,Flow measurement - future directions,"interest in the flow of liquids and its measurement can be traced back to early studies by the egyptians, the chinese and the romans. since these early times the science of flow measurement has undergone a massive change but during the last 25 years or so (1977-2002) it has matured enormously. one of the principal reasons for this is that higher accuracies and reliabilities have been demanded by industry in the measurement of fiscal transfers and today there is vigorous interest in the subject from both the flowmeter manufacturer and user viewpoints. this interest is coupled with the development of advanced computer techniques in fluid mechanics together with the application of increasingly sophisticated electronics","['flow measurement', 'egyptians', 'chinese', 'romans', 'fiscal transfers', 'flowmeter manufacturer', 'advanced computer techniques', 'fluid mechanics', 'flow metering', 'signal processing', 'liquid flow', 'electronics application']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U', 'R', 'R']","['flow measurement', 'egyptians', 'chinese', 'roman', 'fiscal transfer', 'flowmeter manufacturer', 'advanced computer technique', 'fluid mechanic', 'flow metering', 'signal processing', 'liquid flow', 'electronic application']","['flow measurement', 'flowmeter manufacturer', 'fluid mechanic', 'flow', 'fiscal transfer', 'liquid', 'measurement', 'advanced computer technique', 'egyptians', 'trace']"
560,843,An ACM-W literature review on women in computing,"the pipeline shrinkage problem for women in computer science is a well-known and documented phenomenon where the ratio of women to men involved in computing shrinks dramatically from early student years to working years. during the last decade, considerable research ensued to understand the reasons behind the existence of the shrinking pipeline and in some cases to take action to increase the numbers of women in computing. through the work of a national science foundation funded project, acm's committee on women in computing (acm-w) has taken a first step towards pulling this research together. a large number of articles was gathered and processed on the topic of women in computing and the shrinking pipeline. the committee created a publicly available online database to organize the references of this body of work by topic, author, and reference information. the database, constantly being updated, is accessible through acm-w's website <http://www.acm.org/women>. a final report is also available via the acm-w web site which covers current statistics on women in computing, summaries of the literature in the database, and a set of recommendations. the article is a brief synopsis of a subset of the literature review as of august 2001","['acm-w literature review', 'pipeline shrinkage problem', 'acm committee on women in computing']","['P', 'P', 'R']","['acm - w literature review', 'pipeline shrinkage problem', 'acm committee on woman in compute']","['national science foundation fund project', 'pipeline shrinkage problem', 'compute shrink', 'shrink pipeline', 'considerable research ensue', 'computer science', 'web site', 'cover current statistic', 'reference information', 'student year']"
561,1084,"On quasi-linear PDAEs with convection: applications, indices, numerical solution","for a class of partial differential algebraic equations (pdaes) of quasi-linear type which include nonlinear terms of convection type, a possibility to determine a time and spatial index is considered. as a typical example we investigate an application from plasma physics. especially we discuss the numerical solution of initial boundary value problems by means of a corresponding finite difference splitting procedure which is a modification of a well-known fractional step method coupled with a matrix factorization. the convergence of the numerical solution towards the exact solution of the corresponding initial boundary value problem is investigated. some results of a numerical solution of the plasma pdae are given","['convection', 'indices', 'numerical solution', 'spatial index', 'plasma physics', 'initial boundary value problems', 'finite difference splitting procedure', 'fractional step method', 'matrix factorization', 'quasi-linear partial differential algebraic equations']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['convection', 'index', 'numerical solution', 'spatial index', 'plasma physic', 'initial boundary value problem', 'finite difference splitting procedure', 'fractional step method', 'matrix factorization', 'quasi - linear partial differential algebraic equation']","['partial differential algebraic equation', 'fractional step method couple', 'numerical solution', 'include nonlinear term', 'plasma pdae', 'convection', 'finite difference splitting procedure', 'matrix factorization', 'plasma physic', 'initial boundary']"
562,1455,A wizard idea [Internet in finance],new technology is set to become an ever-more important area of work for brokers. lawrie holmes looks at how the internet is driving change and opportunity,"['internet', 'finance', 'brokers']","['P', 'P', 'P']","['internet', 'finance', 'broker']","['lawrie holmes look', 'new technology', 'broker', 'internet', 'drive change', 'become', 'important area', 'work', 'set']"
563,1410,WAM!Net: private pipes for electronic media,"""we are the digital version of fedex. we offer storage and intelligent workflow."" the united states military - especially during war time - is pretty careful about the way it handles its workflow and communications. before a company is awarded a government contract, the company and its technology are screened and verified. if the technology or its creators aren't trustworthy and secure, chances are they aren't getting by uncle sam. record companies and publishing houses tend to feel the same way. after all, security is just as important to a record executive as it is to a navy commander. wam!net, a wide-area media network (hence, the name) passes muster with both. the company, which employs about 320 employees around the world, has 15000 customers including the us navy and a host of record labels, publishing companies, healthcare providers, and advertising agencies, all of whom use its network as a way to transport, store, and receive data. ""we are the digital version of fedex. we offer storage and intelligent workflow,"" says murad velani, executive vice president of sales and marketing for wam!net. ""we started out as purely transport and we've become a digital platform.""","['wam!net', 'electronic media', 'intelligent workflow', 'united states military', 'wide-area media network', 'record labels', 'publishing companies', 'healthcare providers', 'advertising agencies', 'digital platform', 'u.s. navy', 'content creators', 'high-speed private network', 'atm technology', 'content information', 'publishing information', 'client-server format', 'asp format']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'M', 'M', 'U', 'M', 'U', 'U']","['wam!net', 'electronic medium', 'intelligent workflow', 'united states military', 'wide - area medium network', 'record label', 'publish company', 'healthcare provider', 'advertising agency', 'digital platform', 'u.s . navy', 'content creator', 'high - speed private network', 'atm technology', 'content information', 'publish information', 'client - server format', 'asp format']","['area medium network', 'publish company', 'digital platform', 'advertising agency', 'us navy', 'united states military', 'navy commander', 'executive vice president', 'government contract', 'record executive']"
564,1378,Development of an Internet-based intelligent design support system for rolling element bearings,"this paper presents a novel approach to developing an intelligent agile design system for rolling bearings based on artificial intelligence (ai), internet and web technologies and expertise. the underlying philosophy of the approach is to use ai technology and web-based design support systems as smart tools from which design customers can rapidly and responsively access the systems' built-in design expertise. the approach is described in detail with a novel ai model and system implementation issues. the major issues in implementing the approach are discussed with particular reference to using ai technologies, network programming, client-server technology and open computing of bearing design and manufacturing requirements","['internet-based intelligent design support system', 'rolling element bearings', 'intelligent agile design system', 'artificial intelligence', 'web technologies', 'smart tools', 'network programming', 'client-server technology', 'bearing design', 'manufacturing requirements', 'internet technologies']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['internet - base intelligent design support system', 'roll element bearing', 'intelligent agile design system', 'artificial intelligence', 'web technology', 'smart tool', 'network programming', 'client - server technology', 'bear design', 'manufacture requirement', 'internet technology']","['intelligent agile design system', 'rolling bearing base', 'bear design', 'base design support system', 'design expertise', 'use ai technology', 'novel ai model', 'artificial intelligence', 'design customer', 'smart tool']"
565,768,Critical lines identification on voltage collapse analysis,"this paper deals with critical lines identification on voltage collapse analysis. it is known, from the literature, that voltage collapse is a local phenomenon that spreads around an initial neighborhood therefore, identifying the system critical bus plays an important role on voltage collapse prevention. for this purpose, the system critical transmission lines should also be identified in this paper, these issues are addressed, yielding reliable results in a short computational time. tests are done with the help of the ieee-118 bus and the southeastern brazilian systems","['local phenomenon', 'ieee-118 bus', 'power system voltage collapse analysis', 'critical transmission lines identification', 'system critical bus identification', 'computer simulation', 'brazil']","['P', 'P', 'M', 'R', 'R', 'M', 'U']","['local phenomenon', 'ieee-118 bus', 'power system voltage collapse analysis', 'critical transmission line identification', 'system critical bus identification', 'computer simulation', 'brazil']","['system critical transmission line', 'critical line identification', 'system critical bus', 'voltage collapse prevention', 'voltage collapse analysis', 'voltage collapse', 'bus', 'initial neighborhood', 'phenomenon', 'short computational']"
566,1199,Quasi stage order conditions for SDIRK methods,"the stage order condition is a simplifying assumption that reduces the number of order conditions to be fulfilled when designing a runge-kutta (rk) method. because a dirk (diagonally implicit rk) method cannot have stage order greater than 1, we introduce quasi stage order conditions and derive some of their properties for dirks. we use these conditions to derive a low-order dirk method with embedded error estimator. numerical tests with stiff odes and daes of index 1 and 2 indicate that the method is competitive with other rk methods for low accuracy tolerances","['quasi stage order conditions', 'sdirk methods', 'embedded error estimator', 'numerical tests', 'diagonally implicit runge-kutta method', 'differential-algebraic systems']","['P', 'P', 'P', 'P', 'R', 'U']","['quasi stage order condition', 'sdirk method', 'embed error estimator', 'numerical test', 'diagonally implicit runge - kutta method', 'differential - algebraic system']","['order dirk method', 'introduce quasi stage order condition', 'kutta', 'have stage order', 'numerical test', 'rk method', 'stage order', 'stiff ode', 'method', 'implicit rk']"
567,589,Hierarchical neuro-fuzzy quadtree models,"hybrid neuro-fuzzy systems have been in evidence during the past few years, due to its attractive combination of the learning capacity of artificial neural networks with the interpretability of the fuzzy systems. this article proposes a new hybrid neuro-fuzzy model, named hierarchical neuro-fuzzy quadtree (hnfq), which is based on a recursive partitioning method of the input space named quadtree. the article describes the architecture of this new model, presenting its basic cell and its learning algorithm. the hnfq system is evaluated in three well known benchmark applications: the sinc(x, y) function approximation, the mackey glass chaotic series forecast and the two spirals problem. when compared to other neuro-fuzzy systems, the hnfq exhibits competing results, with two major advantages it automatically creates its own structure and it is not limited to few input variables","['hierarchical neuro-fuzzy quadtree', 'quadtree', 'neuro-fuzzy systems', 'fuzzy systems', 'recursive partitioning', 'learning algorithm', 'mackey glass chaotic series']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['hierarchical neuro - fuzzy quadtree', 'quadtree', 'neuro - fuzzy system', 'fuzzy system', 'recursive partitioning', 'learn algorithm', 'mackey glass chaotic series']","['mackey glass chaotic series forecast', 'fuzzy quadtree', 'fuzzy model', 'fuzzy system', 'artificial neural network', 'name hierarchical neuro', 'input space name quadtree', 'recursive partitioning method', 'hybrid neuro', 'hnfq system']"
568,630,Score tests for zero-inflated Poisson models,"in many situations count data have a large proportion of zeros and the zero-inflated poisson regression (zip) model may be appropriate. a simple score test for zero-inflation, comparing the zip model with a constant proportion of excess zeros to a standard poisson regression model, was given by van den broek (1995). we extend this test to the more general situation where the zero probability is allowed to depend on covariates. the performance of this test is evaluated using a simulation study. to identify potentially important covariates in the zero-inflation model a composite test is proposed. the use of the general score test and the composite procedure is illustrated on two examples from the literature. the composite score test is found to suggest appropriate models","['score tests', 'count data', 'excess zeros', 'zero probability', 'covariates', 'simulation', 'composite test', 'zero-inflated poisson regression model']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['score test', 'count datum', 'excess zero', 'zero probability', 'covariate', 'simulation', 'composite test', 'zero - inflate poisson regression model']","['inflate poisson regression', 'standard poisson regression model', 'many situation count datum have', 'composite score test', 'inflation model', 'simple score test', 'general score test', 'excess zero', 'inflation', 'composite test']"
569,675,Application foundations [application servers],the changing role of application servers means choosing the right platform has become a complex challenge,"['application servers', 'microsoft .net', 'transaction processing', 'security', 'availability', 'load balancing', 'java 2 enterprise edition']","['P', 'U', 'U', 'U', 'U', 'U', 'U']","['application server', 'microsoft .net', 'transaction processing', 'security', 'availability', 'load balance', 'java 2 enterprise edition']","['application server mean choose', 'right platform', 'change role', 'become']"
570,1220,Modeling discourse in collaborative work support systems: a knowledge representation and configuration perspective,"collaborative work processes usually raise a lot of intricate debates and negotiations among participants, whereas conflicts of interest are inevitable and support for achieving consensus and compromise is required. individual contributions, brought up by parties with different backgrounds and interests, need to be appropriately structured and maintained. this paper presents a model of discourse acts that participants use to communicate their attitudes to each other, or affect the attitudes of others, in such environments. the first part deals with the knowledge representation and communication aspects of the problem, while the second one, in the context of an already implemented system, namely hermes, with issues related to the configuration of the contributions asserted at each discourse instance. the overall work focuses on the machinery needed in a computer-assisted collaborative work environment, the aim being to further enhance the human-computer interaction","['collaborative work support systems', 'knowledge representation', 'conflicts of interest', 'consensus', 'compromise', 'hermes', 'human-computer interaction', 'discourse modeling', 'knowledge communication']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['collaborative work support system', 'knowledge representation', 'conflict of interest', 'consensus', 'compromise', 'hermes', 'human - computer interaction', 'discourse modeling', 'knowledge communication']","['assist collaborative work environment', 'collaborative work process', 'discourse act', 'discourse instance', 'communication aspect', 'participant use', 'knowledge representation', 'intricate debate', 'implement system', 'achieve consensus']"
571,1265,Optimization of requantization parameter for MPEG transcoding,"this paper considers transcoding in which an mpeg stream is converted to a low-bit-rate mpeg stream, and proposes a method in which the transcoding error can be reduced by optimally selecting the quantization parameter for each macroblock. in transcoding with a low compression ratio, it is crucial to prohibit transcoding with a requantization parameter which is 1 to 2 times the quantization parameter of the input stream. consequently, as the first step, an optimization method for the requantization parameter is proposed which cares for the error propagation effect by interframe prediction. then, the proposed optimization method is extended so that the method can also be applied to the case of a high compression ratio in which the rate-distortion curve is approximated for each macroblock in the range of requantization parameters larger than 2 times the quantization parameter. it is verified by a simulation experiment that the psnr is improved by 0.5 to 0.8 db compared to the case in which a 6 mbit/s mpeg stream is not optimized by twofold recompression","['low-bit-rate mpeg stream', 'transcoding error', 'macroblock', 'compression ratio', 'error propagation effect', 'interframe prediction', 'rate-distortion curve', 'simulation', 'psnr', '6 mbit/s', 'twofold recompression', 'requantization parameter optimization', 'rate conversion', 'rate control']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'U']","['low - bit - rate mpeg stream', 'transcode error', 'macroblock', 'compression ratio', 'error propagation effect', 'interframe prediction', 'rate - distortion curve', 'simulation', 'psnr', '6 mbit / s', 'twofold recompression', 'requantization parameter optimization', 'rate conversion', 'rate control']","['rate mpeg stream', 'mpeg stream', 'compression ratio', 'transcode', 'requantization parameter large', 'input stream', 'quantization parameter', 'requantization parameter', 'distortion curve', 'optimize']"
572,1298,An analytical model for a composite adaptive rectangular structure using the Heaviside function,"the objective of this article is to describe a mathematical model, based on the heaviside function and on the delta -dirac distribution, for a composite adaptive rectangular structure with embedded and/or bonded piezoelectric actuators and sensors. in the adopted structure model, the laminae are made up a configuration of rectangular nonpiezoelectric and piezoelectric patches. the laminae do not all have the same area nor do they present the same configuration, such that there are points where there is no material. the equations of motion and the boundary conditions, which describe the electromechanical coupling, are based on the mindlin displacement field, on the linear theory of piezoelectricity, and on the hamilton principle","['composite adaptive rectangular structure', 'heaviside function', 'mathematical model', 'piezoelectric actuators', 'piezoelectric patches', 'equations of motion', 'boundary conditions', 'electromechanical coupling', 'mindlin displacement field', 'hamilton principle', 'delta-dirac distribution', 'embedded actuators', 'embedded sensors', 'bonded actuators', 'bonded sensors', 'piezoelectric sensors', 'nonpiezoelectric patches', 'closed-form solution', 'lagrangian functions', 'linear piezoelectricity', 'constitutive relations', 'virtual kinetic energy', 'rectangular composite plate', 'finite-element method']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'R', 'R', 'R', 'R', 'R', 'U', 'M', 'R', 'U', 'U', 'M', 'U']","['composite adaptive rectangular structure', 'heaviside function', 'mathematical model', 'piezoelectric actuator', 'piezoelectric patch', 'equation of motion', 'boundary condition', 'electromechanical coupling', 'mindlin displacement field', 'hamilton principle', 'delta - dirac distribution', 'embed actuator', 'embed sensor', 'bond actuator', 'bond sensor', 'piezoelectric sensor', 'nonpiezoelectric patch', 'close - form solution', 'lagrangian function', 'linear piezoelectricity', 'constitutive relation', 'virtual kinetic energy', 'rectangular composite plate', 'finite - element method']","['bond piezoelectric actuator', 'composite adaptive rectangular structure', 'piezoelectricity', 'rectangular nonpiezoelectric', 'piezoelectric', 'electromechanical coupling', 'mindlin displacement', 'adopt structure model', 'laminae', 'boundary condition']"
573,688,Active vibration control of piezolaminated smart beams,"this paper deals with the active vibration control of beam like structures with distributed piezoelectric sensor and actuator layers bonded on top and bottom surfaces of the beam. a finite element model based on euler-bernoulli beam theory has been developed. the contribution of the piezoelectric sensor and actuator layers on the mass and stiffness of the beam is considered. three types of classical control strategies, namely direct proportional feedback, constant-gain negative velocity feedback and lyapunov feedback and an optimal control strategy, linear quadratic regulator (lqr) scheme are applied to study their control effectiveness. also, the control performance with different types of loading, such as impulse loading, step loading, harmonic and random loading is studied","['active vibration control', 'piezolaminated smart beams', 'beam like structures', 'bottom surfaces', 'finite element model', 'euler-bernoulli beam theory', 'mass', 'stiffness', 'direct proportional feedback', 'constant-gain negative velocity feedback', 'lyapunov feedback', 'optimal control strategy', 'linear quadratic regulator', 'control effectiveness', 'impulse loading', 'step loading', 'random loading', 'distributed piezoelectric sensor layers', 'distributed piezoelectric actuator layers', 'top surfaces', 'harmonic loading']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R']","['active vibration control', 'piezolaminate smart beam', 'beam like structure', 'bottom surface', 'finite element model', 'euler - bernoulli beam theory', 'mass', 'stiffness', 'direct proportional feedback', 'constant - gain negative velocity feedback', 'lyapunov feedback', 'optimal control strategy', 'linear quadratic regulator', 'control effectiveness', 'impulse loading', 'step load', 'random loading', 'distribute piezoelectric sensor layer', 'distribute piezoelectric actuator layer', 'top surface', 'harmonic loading']","['active vibration control', 'distribute piezoelectric sensor', 'piezoelectric sensor', 'bernoulli beam', 'actuator layer bond', 'beam', 'actuator layer', 'lyapunov feedback', 'finite element model', 'optimal control']"
574,574,A novel approach for the detection of pathlines in X-ray angiograms: the wavefront propagation algorithm,"presents a new pathline approach, based on the wavefront propagation principle, and developed in order to reduce the variability in the outcomes of the quantitative coronary artery analysis. this novel approach, called wavepath, reduces the influence of the user-defined start- and endpoints of the vessel segment and is therefore more robust and improves the reproducibility of the lesion quantification substantially. the validation study shows that the wavepath method is totally constant in the middle part of the pathline, even when using the method for constructing a bifurcation or sidebranch pathline. furthermore, the number of corrections needed to guide the wavepath through the correct vessel is decreased from an average of 0.44 corrections per pathline to an average of 0.12 per pathline. therefore, it can be concluded that the wavepath algorithm improves the overall analysis substantially","['x-ray angiograms', 'wavefront propagation algorithm', 'wavefront propagation principle', 'quantitative coronary artery analysis', 'vessel segment', 'lesion quantification', 'wavepath method', 'bifurcation', 'sidebranch pathline', 'corrections', 'correct vessel', 'user-defined startpoints', 'user-defined endpoints']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R']","['x - ray angiogram', 'wavefront propagation algorithm', 'wavefront propagation principle', 'quantitative coronary artery analysis', 'vessel segment', 'lesion quantification', 'wavepath method', 'bifurcation', 'sidebranch pathline', 'correction', 'correct vessel', 'user - define startpoint', 'user - define endpoint']","['quantitative coronary artery analysis', 'wavepath algorithm improve', 'wavepath method', 'sidebranch pathline', 'wavefront propagation', 'wavepath', 'pathline approach', 'vessel segment', 'pathline', 'vessel']"
575,1121,Optimal bandwidth utilization of all-optical ring with a converter of degree 4,"in many models of all-optical routing, a set of communication paths in a network is given, and a wavelength is to be assigned to each path so that paths sharing an edge receive different wavelengths. the goal is to assign as few wavelengths as possible, in order to use the optical bandwidth efficiently. if a node of a network contains a wavelength converter, any path that passes through this node may change its wavelength. having converters at some of the nodes can reduce the number of wavelengths required for routing. this paper presents a wavelength converter with degree 4 and gives a routing algorithm which shows that any routing with load l can be realized with l wavelengths when a node of an all-optical ring hosts such a wavelength converter. it is also proved that 4 is the minimum degree of the converter to reach the full utilization of the available wavelengths if only one node of an all-optical ring hosts a converter","['all-optical ring', 'all-optical routing', 'communication paths', 'wavelength converter', 'all-optical network', 'wavelength assignment', 'wavelength translation']","['P', 'P', 'P', 'P', 'R', 'R', 'M']","['all - optical ring', 'all - optical routing', 'communication path', 'wavelength converter', 'all - optical network', 'wavelength assignment', 'wavelength translation']","['optical routing', 'optical ring host', 'optical bandwidth', 'wavelength converter', 'route algorithm', 'wavelength', 'few wavelength', 'route', 'wavelength', 'communication path']"
576,1164,Friedberg numberings of families of n-computably enumerable sets,"we establish a number of results on numberings, in particular, on friedberg numberings, of families of d.c.e. sets. first, it is proved that there exists a friedberg numbering of the family of all d.c.e. sets. we also show that this result, patterned on friedberg's famous theorem for the family of all c.e. sets, holds for the family of all n-c.e. sets for any n > 2. second, it is stated that there exists an infinite family of d.c.e. sets without a friedberg numbering. third, it is shown that there exists an infinite family of c.e. sets (treated as a family of d.c.e. sets) with a numbering which is unique up to equivalence. fourth, it is proved that there exists a family of d.c.e. sets with a least numbering (under reducibility) which is friedberg but is not the only numbering (modulo reducibility)","['friedberg numberings', 'families of n-computably enumerable sets', 'infinite family', 'computability theory']","['P', 'P', 'P', 'U']","['friedberg numbering', 'family of n - computably enumerable set', 'infinite family', 'computability theory']","['friedberg numbering', 'friedberg numbering', 'least numbering', 'numbering', 'modulo reducibility', 'set', 'number', 'reducibility', 'friedberg', 'famous theorem']"
577,549,Taking it to the max [ventilation systems],raising the volumetric air supply rate is one way of increasing the cooling capacity of displacement ventilation systems. david butler and michael swainson explore how different types of diffusers can help make this work,"['volumetric air supply rate', 'cooling capacity', 'displacement ventilation systems', 'diffusers']","['P', 'P', 'P', 'P']","['volumetric air supply rate', 'cool capacity', 'displacement ventilation system', 'diffuser']","['volumetric air supply rate', 'displacement ventilation system', 'cool capacity', 'diffuser', 'increase', 'raise', 'butler', 'different type', 'help']"
578,1159,Sigma -admissible families over linear orders,"admissible sets of the form hyp(m), where m is a recursively saturated system, are treated. we provide descriptions of subsets m, which are sigma /sub */-sets in hyp(m), and of families of subsets m, which form sigma -regular families in hyp(m), in terms of the concept of being fundamental couched in the article. fundamental subsets and families are characterized for models of dense linear orderings","['sigma -admissible families', 'linear orders', 'hyp(m)', 'recursively saturated system', 'fundamental subsets', 'dense linear orderings']","['P', 'P', 'P', 'P', 'P', 'P']","['sigma -admissible family', 'linear order', 'hyp(m )', 'recursively saturate system', 'fundamental subset', 'dense linear ordering']","['admissible set', 'saturate system', 'fundamental subset', 'subset', 'form sigma', 'family', 'model', 'provide description', 'sigma', 'characterize']"
579,120,Self-organized critical traffic in parallel computer networks,"in a recent paper, we analysed the dynamics of traffic flow in a simple, square lattice architecture. it was shown that a phase transition takes place between a free and a congested phase. the transition point was shown to exhibit optimal information transfer and wide fluctuations in time, with scale-free properties. in this paper, we further extend our analysis by considering a generalization of the previous model in which the rate of packet emission is regulated by the local congestion perceived by each node. as a result of the feedback between traffic congestion and packet release, the system is poised at criticality. many well-known statistical features displayed by internet traffic are recovered from our model in a natural way","['self-organized critical traffic', 'parallel computer networks', 'square lattice architecture', 'phase transition', 'congested phase', 'transition point', 'optimal information transfer', 'wide fluctuations', 'scale-free properties', 'generalization', 'packet emission', 'packet release', 'statistical features', 'internet traffic', 'traffic flow dynamics', 'free phase']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['self - organize critical traffic', 'parallel computer network', 'square lattice architecture', 'phase transition', 'congested phase', 'transition point', 'optimal information transfer', 'wide fluctuation', 'scale - free property', 'generalization', 'packet emission', 'packet release', 'statistical feature', 'internet traffic', 'traffic flow dynamic', 'free phase']","['traffic congestion', 'internet traffic', 'square lattice architecture', 'traffic flow', 'local congestion perceive', 'packet emission', 'optimal information transfer', 'phase transition take place', 'packet release', 'congested phase']"
580,963,A computational model of learned avoidance behavior in a one-way avoidance experiment,"we present a computational model of learned avoidance behavior in a one-way avoidance experiment. our model employs the reinforcement learning paradigm and a temporal-difference algorithm to implement both classically conditioned and instrumentally conditioned components. the role of the classically conditioned component is to develop an expectation of future benefit that is a function of the learning system's state and action. competition among the instrumentally conditioned components determines the overt behavior generated by the learning system. our model displays, in simulation, the reduced latency of the avoidance behavior during learning with continuing trials and the resistance to extinction of the avoidance response. these results are consistent with experimentally observed animal behavior. our model extends the traditional two-process learning mechanism of mowrer (1947) by explicitly defining the mechanisms of proprioceptive feedback, an internal clock, and generalization over the action space","['computational model', 'learned avoidance behavior', 'one-way avoidance experiment', 'reinforcement learning', 'temporal-difference algorithm', 'instrumentally conditioned components', 'classically conditioned components', 'reduced latency', 'animal behavior', 'traditional two-process learning mechanism', 'proprioceptive feedback', 'internal clock']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['computational model', 'learn avoidance behavior', 'one - way avoidance experiment', 'reinforcement learning', 'temporal - difference algorithm', 'instrumentally condition component', 'classically condition component', 'reduce latency', 'animal behavior', 'traditional two - process learning mechanism', 'proprioceptive feedback', 'internal clock']","['learn avoidance behavior', 'reinforcement learning paradigm', 'avoidance behavior', 'process learn mechanism', 'way avoidance experiment', 'observe animal behavior', 'condition component determine', 'avoidance response', 'condition component', 'learn system']"
581,926,Experimental investigation of active vibration control using neural networks and piezoelectric actuators,"the use of neural networks for identification and control of smart structures is investigated experimentally. piezoelectric actuators are employed to suppress the vibrations of a cantilevered plate subject to impulse, sine wave and band-limited white noise disturbances. the neural networks used are multilayer perceptrons trained with error backpropagation. validation studies show that the identifier predicts the system dynamics accurately. the controller is trained adaptively with the help of the neural identifier. experimental results demonstrate excellent closed-loop performance and robustness of the neurocontroller","['active vibration control', 'control', 'neural networks', 'piezoelectric actuators', 'identification', 'smart structures', 'cantilevered plate', 'white noise disturbances', 'multilayer perceptrons', 'error backpropagation', 'closed-loop performance', 'robustness', 'neurocontroller', 'vibration suppression']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['active vibration control', 'control', 'neural network', 'piezoelectric actuator', 'identification', 'smart structure', 'cantilever plate', 'white noise disturbance', 'multilayer perceptron', 'error backpropagation', 'close - loop performance', 'robustness', 'neurocontroller', 'vibration suppression']","['piezoelectric actuator', 'multilayer perceptron train', 'neural network', 'vibration', 'error backpropagation', 'neural identifier', 'cantilever plate', 'white noise disturbance', 'smart structure', 'controller']"
582,648,Study of ambiguities inherent to the spectral analysis of Voigt profiles-a modified Simplex approach,"in pulsed spectrometries, temporal transients are often analyzed directly in the temporal domain, assuming they consist only of purely exponentially decaying sinusoids. when experimental spectra actually consist of gaussian or voigt profiles (gauss-lorentz profiles), we show that the direct methods may erroneously interpret such lines as the sum of two or more lorentzian profiles. using a nelder and mead simplex method, modified by introducing new means to avoid degeneracies and quenchings in secondary minima, we demonstrate that a large number of different solutions can be obtained with equivalent accuracy over the limited acquisition time interval, with final peak parameters devoid of physical or chemical meaning","['spectral analysis', 'voigt profiles', 'pulsed spectrometries', 'temporal transients', 'gauss-lorentz profiles', 'nelder and mead simplex method', 'accuracy', 'limited acquisition time interval', 'final peak parameters', 'gaussian profiles']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['spectral analysis', 'voigt profile', 'pulse spectrometry', 'temporal transient', 'gauss - lorentz profile', 'nelder and mead simplex method', 'accuracy', 'limit acquisition time interval', 'final peak parameter', 'gaussian profile']","['pulse spectrometry', 'temporal transient', 'experimental spectra', 'decay sinusoid', 'final peak parameter', 'secondary minima', 'mead simplex method', 'lorentz profile', 'lorentzian profile', 'time interval']"
583,72,A three-tier technology training strategy in a dynamic business environment,"as end-user training becomes increasingly important in today's technology-intensive business environment, progressive companies remain alert to find ways to provide their end users with timely training and resources. this paper describes an innovative training strategy adopted by one midsize organization to provide its end users with adequate, flexible, and responsive training. the paper then compares the three-tier strategy with other models described in technology training literature. managers who supervise technology end users in organizations comparable to the one in the study may find the three-tier strategy workable and may want to use it in their own training programs to facilitate training and improve end-user skills. researchers and scholars may find that the idea of three-tier training generates new opportunities for research","['three-tier technology training strategy', 'dynamic business environment', 'end-user training', 'technology-intensive business environment', 'companies', 'innovative training strategy', 'midsize organization', 'organizations']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['three - tier technology training strategy', 'dynamic business environment', 'end - user training', 'technology - intensive business environment', 'company', 'innovative training strategy', 'midsize organization', 'organization']","['tier training generate new opportunity', 'innovative training strategy', 'supervise technology end user', 'technology training literature', 'facilitate training', 'responsive training', 'user training become', 'own training program', 'tier strategy workable', 'timely training']"
584,1258,Implementation and performance evaluation of a FIFO queue class library for time warp,"the authors describe the implementation, use, and performance evaluation of a fifo queue class library by means of a high-performance, easy-to-use interface employed for queuing simulations in parallel discrete simulations based on the time warp method. various general-purpose simulation libraries and languages have been proposed, and among these some have the advantage of not requiring users to define anything other than the state vector, and not needing awareness of rollback under a platform which performs state control based on copies. however, because the state vectors must be defined as simple data structures without pointers, dynamic data structures such as a fifo queue cannot be handled directly. under the proposed class library, both the platform and the user can handle such structures in the same fashion that embedded data structures are handled. in addition, instead of all stored data, just the operational history can be stored and recovered efficiently at an effectively minimal cost by taking advantage of the first-in-first-out characteristics of the above data structures. when the kernel deletes past state histories during a simulation, garbage collection is also performed transparently using the corresponding method","['performance evaluation', 'fifo queue', 'class library', 'easy-to-use interface', 'queuing simulations', 'parallel discrete simulations', 'general-purpose simulation libraries', 'state vectors', 'dynamic data structures', 'embedded data structures', 'operational history', 'first-in-first-out characteristics', 'garbage collection', 'time warp simulation', 'simulation languages', 'object oriented method', 'state management']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'M']","['performance evaluation', 'fifo queue', 'class library', 'easy - to - use interface', 'queue simulation', 'parallel discrete simulation', 'general - purpose simulation librarie', 'state vector', 'dynamic datum structure', 'embed datum structure', 'operational history', 'first - in - first - out characteristic', 'garbage collection', 'time warp simulation', 'simulation language', 'object orient method', 'state management']","['fifo queue class library', 'fifo queue', 'queue simulation', 'parallel discrete simulation', 'embed datum structure', 'purpose simulation librarie', 'dynamic datum structure such', 'garbage collection', 'store datum', 'kernel delete']"
585,1345,Infrared-image classification using hidden Markov trees,"an image of a three-dimensional target is generally characterized by the visible target subcomponents, with these dictated by the target-sensor orientation (target pose). an image often changes quickly with variable pose. we define a class as a set of contiguous target-sensor orientations over which the associated target image is relatively stationary with aspect. each target is in general characterized by multiple classes. a distinct set of wiener filters are employed for each class of images, to identify the presence of target subcomponents. a karhunen-loeve representation is used to minimize the number of filters (templates) associated with a given subcomponent. the statistical relationships between the different target subcomponents are modeled via a hidden markov tree (hmt). the hmt classifier is discussed and example results are presented for forward-looking-infrared (flir) imagery of several vehicles","['infrared-image classification', 'hidden markov trees', 'target-sensor orientation', 'target pose', 'contiguous target-sensor orientations', 'wiener filters', 'karhunen-loeve representation', 'minimization', 'hmt', 'vehicles', 'ir image classification', '3d target image', 'forward-looking-infrared imagery', 'flir imagery']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'R', 'R']","['infrare - image classification', 'hide markov tree', 'target - sensor orientation', 'target pose', 'contiguous target - sensor orientation', 'wiener filter', 'karhunen - loeve representation', 'minimization', 'hmt', 'vehicle', 'ir image classification', '3d target image', 'forward - look - infrare imagery', 'flir imagery']","['visible target subcomponent', 'hide markov tree', 'target pose', 'associate target image', 'different target subcomponent', 'sensor orientation', 'sensor orientation', 'target subcomponent', 'hmt classifier', 'wiener filter']"
586,1300,Will CPXe save the photofinishing market?,a consortium of film suppliers and electronics firms has proposed the common picture exchange environment. it will let diverse providers cooperate via the internet to sell digital-photo prints,"['cpxe', 'photofinishing market', 'common picture exchange environment', 'kodak', 'fujifilm', 'hp', 'web-services standards']","['P', 'P', 'P', 'U', 'U', 'U', 'U']","['cpxe', 'photofinishing market', 'common picture exchange environment', 'kodak', 'fujifilm', 'hp', 'web - service standard']","['common picture exchange environment', 'let diverse provider cooperate', 'film supplier', 'sell digital', 'electronic firm', 'consortium', 'internet', 'propose']"
587,755,Hardware and software platform for real-time processing and visualization of echographic radiofrequency signals,"in this paper the architecture of a hardware and software platform, for ultrasonic investigation is presented. the platform, used in conjunction with an analog front-end hardware for driving the ultrasonic transducers of any commercial echograph, having the radiofrequency echo signal access, make it possible to dispose of a powerful echographic system for experimenting any processing technique, also in a clinical environment in which real-time operation mode is an essential prerequisite. the platform transforms any echograph into a test-system for evaluating the diagnostic effectiveness of new investigation techniques. a particular user interface was designed in order to allow a real-time and simultaneous visualization of the results produced in the different stages of the chosen processing procedure. this is aimed at obtaining a better optimization of the processing algorithm. the most important platform aspect, which also constitutes the basic differentiation with respect to similar systems, is the direct processing of the radiofrequency echo signal, which is essential for a complete analysis of the particular ultrasound-media interaction phenomenon. the platform completely integrates the architecture of a personal computer (pc) giving rise to several benefits, such as the quick technological evolution in the pc field and an extreme degree of programmability for different applications. the pc also constitutes the user interface, as a flexible and intuitive visualization support, and performs some software signal processing, by custom algorithms and commercial libraries. the realized close synergy between hardware and software allows the acquisition and real-time processing of the echographic radiofrequency (rf) signal with fast data representation","['software platform', 'real-time processing', 'echographic radiofrequency signal', 'user interface', 'personal computer', 'data visualization', 'hardware platform', 'ultrasonic imaging', 'clinical diagnosis']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'M']","['software platform', 'real - time processing', 'echographic radiofrequency signal', 'user interface', 'personal computer', 'datum visualization', 'hardware platform', 'ultrasonic imaging', 'clinical diagnosis']","['ultrasonic transducer', 'radiofrequency echo signal access', 'software signal processing', 'radiofrequency echo signal', 'ultrasonic investigation', 'echographic radiofrequency', 'echographic system', 'ultrasound', 'software platform', 'commercial echograph']"
588,710,Optimal allocation of runs in a simulation metamodel with several independent variables,cheng and kleijnen (1999) propose a very general regression metamodel for modelling the output of a queuing system. its main limitations are that the regression function is based on a polynomial and that it can use only one independent variable. these limitations are removed here. we derive an explicit formula for the optimal way of assigning simulation runs to the different design points,"['simulation metamodel', 'independent variables', 'general regression metamodel', 'queuing system', 'regression function', 'optimal runs allocation']","['P', 'P', 'P', 'P', 'P', 'R']","['simulation metamodel', 'independent variable', 'general regression metamodel', 'queue system', 'regression function', 'optimal run allocation']","['general regression metamodel', 'queue system', 'assign simulation run', 'model', 'regression function', 'optimal way', 'independent variable', 'explicit formula', 'main limitation', 'cheng']"
589,1044,Analogue realizations of fractional-order controllers,"an approach to the design of analogue circuits, implementing fractional-order controllers, is presented. the suggested approach is based on the use of continued fraction expansions; in the case of negative coefficients in a continued fraction expansion, the use of negative impedance converters is proposed. several possible methods for obtaining suitable rational approximations and continued fraction expansions are discussed. an example of realization of a fractional-order i/sup lambda / controller is presented and illustrated by obtained measurements. the suggested approach can be used for the control of very fast processes, where the use of digital controllers is difficult or impossible","['analogue realizations', 'fractional-order controllers', 'continued fraction expansions', 'fraction expansion', 'negative coefficients', 'negative impedance converters', 'rational approximations', 'fast processes', 'digital controllers', 'fractional differentiation', 'fractional integration']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M']","['analogue realization', 'fractional - order controller', 'continue fraction expansion', 'fraction expansion', 'negative coefficient', 'negative impedance converter', 'rational approximation', 'fast process', 'digital controller', 'fractional differentiation', 'fractional integration']","['continue fraction expansion', 'continue fraction expansion', 'negative impedance converter', 'implement fractional', 'analogue circuit', 'digital controller', 'fractional', 'order controller', 'rational approximation', 'controller']"
590,1001,A conflict between language and atomistic information,"fred dretske and jerry fodor are responsible for popularizing three well-known theses in contemporary philosophy of mind: the thesis of information-based semantics (ibs), the thesis of content atomism (atomism) and the thesis of the language of thought (lot). lot concerns the semantically relevant structure of representations involved in cognitive states such as beliefs and desires. it maintains that all such representations must have syntactic structures mirroring the structure of their contents. ibs is a thesis about the nature of the relations that connect cognitive representations and their parts to their contents (semantic relations). it holds that these relations supervene solely on relations of the kind that support information content, perhaps with some help from logical principles of combination. atomism is a thesis about the nature of the content of simple symbols. it holds that each substantive simple symbol possesses its content independently of all other symbols in the representational system. i argue that dretske's and fodor's theories are false and that their falsehood results from a conflict ibs and atomism, on the one hand, and lot, on the other","['philosophy of mind', 'information-based semantics', 'ibs', 'content atomism', 'language of thought', 'lot', 'cognitive states', 'beliefs', 'desires']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['philosophy of mind', 'information - base semantic', 'ibs', 'content atomism', 'language of thought', 'lot', 'cognitive state', 'belief', 'desire']","['have syntactic structure mirror', 'support information content', 'semantic relation', 'connect cognitive representation', 'substantive simple symbol possesse', 'base semantic', 'content atomism', 'representational system', 'logical principle', 'other symbol']"
591,883,On conflict-free executions of elementary nets,"deals with analysis of elementary petri nets with respect to possibilities of avoiding conflicts during their executions. there are two main aims of the paper. the first is to find a method of checking if a net is conflict-avoidable (i.e., if it possesses a conflict-free fair run). the second is to find a method of rebuilding any net to a totally conflict-avoidable net (i.e., a net possessing a conflict-free fair run in every one process) with the same behaviour. the main results are the following: 1. the proof of decidability, for elementary nets, of the problem of existence of a conflict-avoidable fair process (and an algorithm producing all fair runs). 2. construction, for an arbitrary given elementary net, of a totally conflict-avoidable net with the same behaviour. the net, completed this way, has the same behaviour as the original one. moreover, it is totally conflict-avoidable, and its execution may be supervised (in order to ensure conflict-freeness) by the reduced case graph built by the algorithm of the former section","['conflict-free executions', 'elementary petri nets', 'conflict-free fair run', 'totally conflict-avoidable net', 'decidability', 'reduced case graph']","['P', 'P', 'P', 'P', 'P', 'P']","['conflict - free execution', 'elementary petri net', 'conflict - free fair run', 'totally conflict - avoidable net', 'decidability', 'reduce case graph']","['elementary petri net', 'arbitrary give elementary net', 'avoidable fair process', 'avoidable net', 'avoid conflict', 'elementary net', 'reduce case graph build', 'decidability', 'net possessing', 'ensure conflict']"
592,13,Stability analysis of the characteristic polynomials whose coefficients are polynomials of interval parameters using monotonicity,"we analyze the stability of the characteristic polynomials whose coefficients are polynomials of interval parameters via monotonicity methods. our stability conditions are based on frazer-duncan's theorem and all conditions can be checked using only endpoint values of interval parameters. these stability conditions are necessary and sufficient under the monotonicity assumptions. when the monotonicity conditions do not hold on the whole parameter region, we present an interval division method and a transformation algorithm in order to apply the monotonicity conditions. then, our stability analysis methods can be applied to all characteristic polynomials whose coefficients are polynomials of interval parameters","['stability analysis', 'characteristic polynomials', 'interval parameters', 'monotonicity', 'endpoint values', 'interval division method', 'transformation algorithm', 'frazer-duncan theorem', 'necessary and sufficient conditions']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['stability analysis', 'characteristic polynomial', 'interval parameter', 'monotonicity', 'endpoint value', 'interval division method', 'transformation algorithm', 'frazer - duncan theorem', 'necessary and sufficient condition']","['interval division method', 'stability analysis method', 'interval parameter', 'monotonicity method', 'stability condition', 'monotonicity condition', 'characteristic polynomial', 'monotonicity assumption', 'polynomial', 'stability']"
593,56,New thinking on rendering,looks at how graphics hardware solves a range of rendering problems,"['rendering', 'graphics hardware', 'programmability', 'gourand-shaded image', 'color values']","['P', 'P', 'U', 'U', 'U']","['render', 'graphic hardware', 'programmability', 'gourand - shaded image', 'color value']","['graphic hardware solve', 'look', 'range']"
594,629,Calibrated initials for an EM applied to recursive models of categorical variables,"the estimates from an em, when it is applied to a large causal model of 10 or more categorical variables, are often subject to the initial values for the estimates. this phenomenon becomes more serious as the model structure becomes more complicated involving more variables. as a measure of compensation for this, it has been recommended in literature that ems are implemented several times with different sets of initial values to obtain more appropriate estimates. we propose an improved approach for initial values. the main idea is that we use initials that are calibrated to data. a simulation result strongly indicates that the calibrated initials give rise to the estimates that are far closer to the true values than the initials that are not calibrated","['calibrated initials', 'em', 'recursive models', 'categorical variables', 'large causal model', 'initial values', 'simulation']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['calibrate initial', 'em', 'recursive model', 'categorical variable', 'large causal model', 'initial value', 'simulation']","['large causal model', 'calibrate initial give rise', 'more categorical variable', 'initial value', 'model structure become', 'complicated involve more variable', 'appropriate estimate', 'implement several time', 'true value', 'estimate']"
595,1239,Three-dimensional global MHD simulation code for the Earth's magnetosphere using HPF/JA,"we have translated a three-dimensional magnetohydrodynamic (mhd) simulation code of the earth's magnetosphere from vpp fortran to hpf/ja on the fujitsu vpp5000/56 vector-parallel supercomputer and the mhd code was fully vectorized and fully parallelized in vpp fortran. the entire performance and capability of the hpf mhd code could be shown to be almost comparable to that of vpp fortran. a three-dimensional global mhd simulation of the earth's magnetosphere was performed at a speed of over 400 gflops with an efficiency of 76.5% using 56 processing elements of the fujitsu vpp5000/56 in vector and parallel computation that permitted comparison with catalog values. we have concluded that fluid and mhd codes that are fully vectorized and fully parallelized in vpp fortran can be translated with relative ease to hpf/ja, and a code in hpf/ja may be expected to perform comparably to the same code written in vpp fortran","['mhd simulation', 'fujitsu vpp5000/56', 'vector-parallel supercomputer', 'hpf mhd code', 'parallel computation', 'magnetohydrodynamic simulation']","['P', 'P', 'P', 'P', 'P', 'R']","['mhd simulation', 'fujitsu vpp5000/56', 'vector - parallel supercomputer', 'hpf mhd code', 'parallel computation', 'magnetohydrodynamic simulation']","['dimensional global mhd simulation', 'parallel supercomputer', 'vpp fortran', 'hpf mhd code', 'parallel computation', 'dimensional magnetohydrodynamic', 'mhd code', 'parallelize', 'mhd code', 'simulation code']"
596,1180,Decomposition of additive cellular automata,"finite additive cellular automata with fixed and periodic boundary conditions are considered as endomorphisms over pattern spaces. a characterization of the nilpotent and regular parts of these endomorphisms is given in terms of their minimal polynomials. generalized eigenspace decomposition is determined and relevant cyclic subspaces are described in terms of symmetries. as an application, the lengths and frequencies of limit cycles in the transition diagram of the automaton are calculated","['cellular automata', 'endomorphisms', 'transition diagram', 'finite cellular automaton', 'computational complexity']","['P', 'P', 'P', 'R', 'U']","['cellular automata', 'endomorphism', 'transition diagram', 'finite cellular automaton', 'computational complexity']","['finite additive cellular automata', 'generalize eigenspace decomposition', 'periodic boundary condition', 'pattern space', 'endomorphism', 'cyclic subspace', 'minimal polynomial', 'automaton', 'limit cycle', 'frequency']"
597,947,The fully entangled fraction as an inclusive measure of entanglement applications,"characterizing entanglement in all but the simplest case of a two qubit pure state is a hard problem, even understanding the relevant experimental quantities that are related to entanglement is difficult. it may not be necessary, however, to quantify the entanglement of a state in order to quantify the quantum information processing significance of a state. it is known that the fully entangled fraction has a direct relationship to the fidelity of teleportation maximized under the actions of local unitary operations. in the case of two qubits we point out that the fully entangled fraction can also be related to the fidelities, maximized under the actions of local unitary operations, of other important quantum information tasks such as dense coding, entanglement swapping and quantum cryptography in such a way as to provide an inclusive measure of these entanglement applications. for two qubit systems the fully entangled fraction has a simple known closed-form expression and we establish lower and upper bounds of this quantity with the concurrence. this approach is readily extendable to more complicated systems","['fully entangled fraction', 'entanglement', 'two qubit pure state', 'quantum information processing', 'fidelity', 'teleportation', 'entanglement swapping', 'quantum cryptography']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['fully entangle fraction', 'entanglement', 'two qubit pure state', 'quantum information processing', 'fidelity', 'teleportation', 'entanglement swap', 'quantum cryptography']","['other important quantum information task such', 'quantum information processing significance', 'qubit pure state', 'quantum cryptography', 'entangle fraction', 'characterize entanglement', 'entanglement application', 'qubit system', 'entanglement swap', 'entanglement']"
598,141,"A high-resolution high-frequency monolithic top-shooting microinjector free of satellite drops - part I: concept, design, and model","introduces an innovative microinjector design, featuring a bubble valve, which entails superior droplet ejection characteristics and monolithic fabrication, which allows handling of a wide range of liquids. this new microinjector uses asymmetric bubbles to reduce crosstalk, increase frequency response and eliminate satellite droplets. during a firing, i.e., droplet ejection, the ""virtual valve"" closes, by growing a thermal bubble in the microchannel, to isolate the microchamber from the liquid supply and neighboring chambers. between firings, however, the virtual valve opens, by collapsing the bubble, to reduce flow restriction for fast refilling of the microchamber. the use of bubble valves brings about fast and reliable device operation without imposing the significant complication fabrication of physical microvalves would call for. in addition, through a special heater configuration and chamber designs, bubbles surrounding the nozzle cut off the tail of the droplets being ejected and completely eliminate satellite droplets. a simple one-dimensional model of the operation of the microinjector is used to estimate the bubble formation and liquid refilling","['monolithic top-shooting microinjector', 'bubble valve', 'droplet ejection characteristics', 'asymmetric bubbles', 'crosstalk', 'frequency response', 'satellite droplets', 'virtual valve', 'flow restriction', 'chamber designs', 'liquid refilling', 'inkjet printing', 'thermal bubble jet']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'M']","['monolithic top - shooting microinjector', 'bubble valve', 'droplet ejection characteristic', 'asymmetric bubble', 'crosstalk', 'frequency response', 'satellite droplet', 'virtual valve', 'flow restriction', 'chamber design', 'liquid refill', 'inkjet printing', 'thermal bubble jet']","['new microinjector use asymmetric bubble', 'bubble valve', 'innovative microinjector design', 'bubble valve', 'entail superior droplet ejection characteristic', 'microinjector', 'thermal bubble', 'microchannel', 'virtual valve open', 'physical microvalve']"
599,902,TCP explicit congestion notification over ATM-UBR: a simulation study,"the enhancement of transmission control protocol's (tcp's) congestion control mechanisms using explicit congestion notification (ecn) over asynchronous transfer mode (atm) networks is overviewed. tcp's congestion control is enhanced so that congestion is indicated by not only packet losses as is currently the case but an agent implemented at the atm network's edge as well. the novel idea uses efci (explicit forward congestion indication) bits (available in every atm cell header) to generalize the ecn response to the ubr (unspecified bit rate) service, notify congestion, and adjust the credit-based window size of the tcr. the authors' simulation experiments show that tcp ecn achieves significantly lower cell loss, packet retransmissions, and buffer utilization, and exhibits better throughput than (non-ecn) tcp reno","['tcp explicit congestion notification', 'atm-ubr', 'simulation', 'congestion control mechanisms', 'packet losses', 'agent', 'atm networks', 'credit-based window size', 'cell loss', 'packet retransmissions', 'buffer utilization', 'throughput', 'explicit forward congestion indication bits', 'unspecified bit rate service']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['tcp explicit congestion notification', 'atm - ubr', 'simulation', 'congestion control mechanism', 'packet loss', 'agent', 'atm network', 'credit - base window size', 'cell loss', 'packet retransmission', 'buffer utilization', 'throughput', 'explicit forward congestion indication bit', 'unspecified bit rate service']","['tcp ecn', 'transmission control protocol', 'use explicit congestion notification', 'explicit forward congestion indication', 'congestion control', 'notify congestion', 'packet retransmission', 'packet loss', 'tcp', 'congestion']"
600,590,Universal approximation by hierarchical fuzzy system with constraints on the fuzzy rule,"this paper presents a special hierarchical fuzzy system where the outputs of the previous layer are not used in the if-parts, but used only in the then-parts of the fuzzy rules of the current layer. the proposed scheme can be shown to be a universal approximator to any continuous function on a compact set if complete fuzzy sets are used in the if-parts of the fuzzy rules with singleton fuzzifier and center average defuzzifier. from the simulation of ball and beam control system, it is demonstrated that the proposed scheme approximates with good accuracy the model nonlinear controller with fewer fuzzy rules than the centralized fuzzy system and its control performance is comparable to that of the nonlinear controller","['universal approximator', 'hierarchical fuzzy system', 'fuzzy rules', 'continuous function', 'ball and beam control system', 'hierarchical fuzzy logic', 'stone-weierstrass theorem']","['P', 'P', 'P', 'P', 'P', 'M', 'U']","['universal approximator', 'hierarchical fuzzy system', 'fuzzy rule', 'continuous function', 'ball and beam control system', 'hierarchical fuzzy logic', 'stone - weierstrass theorem']","['hierarchical fuzzy system', 'centralize fuzzy system', 'fuzzy set', 'model nonlinear controller', 'fuzzy rule', 'beam control system', 'center average defuzzifier', 'universal approximator', 'singleton fuzzifier', 'continuous function']"
601,1138,Approximating martingales for variance reduction in Markov process simulation,"""knowledge of either analytical or numerical approximations should enable more efficient simulation estimators to be constructed."" this principle seems intuitively plausible and certainly attractive, yet no completely satisfactory general methodology has been developed to exploit it. the authors present a new approach for obtaining variance reduction in markov process simulation that is applicable to a vast array of different performance measures. the approach relies on the construction of a martingale that is then used as an internal control variate","['martingales', 'variance reduction', 'markov process simulation', 'performance measures', 'internal control variate', 'approximating martingale-process method', 'complex stochastic processes', 'single-server queue']","['P', 'P', 'P', 'P', 'P', 'M', 'M', 'U']","['martingale', 'variance reduction', 'markov process simulation', 'performance measure', 'internal control variate', 'approximate martingale - process method', 'complex stochastic process', 'single - server queue']","['markov process simulation', 'efficient simulation estimator', 'obtain variance reduction', 'martingale', 'performance measure', 'numerical approximation', 'satisfactory general methodology', 'approach rely', 'plausible', 'seem']"
602,1281,A notion of non-interference for timed automata,the non-interference property of concurrent systems is a security property concerning the flow of information among different levels of security of the system. in this paper we introduce a notion of timed non-interference for real-time systems specified by timed automata. the notion is presented using an automata based approach and then it is characterized also by operations and equivalence between timed languages. the definition is applied to an example of a time-critical system modeling a simplified control of an airplane,"['timed automata', 'concurrent systems', 'security property', 'real-time systems', 'time-critical system', 'noninterference notion']","['P', 'P', 'P', 'P', 'P', 'M']","['time automata', 'concurrent system', 'security property', 'real - time system', 'time - critical system', 'noninterference notion']","['time automata', 'concurrent system', 'time system specify', 'automata base approach', 'time language', 'critical system modeling', 'time non', 'security property', 'interference property', 'time']"
603,691,Robust output-feedback control for linear continuous uncertain state delayed systems with unknown time delay,"the state-delayed time often is unknown and independent of other variables in most real physical systems. a new stability criterion for uncertain systems with a state time-varying delay is proposed. then, a robust observer-based control law based on this criterion is constructed via the sequential quadratic programming method. we also develop a separation property so that the state feedback control law and observer can be independently designed and maintain closed-loop system stability. an example illustrates the availability of the proposed design method","['output-feedback control', 'state delayed systems', 'time delay', 'uncertain systems', 'state time-varying delay', 'observer-based control law', 'sequential quadratic programming', 'state feedback control law', 'closed-loop system stability', 'robust control', 'linear continuous systems']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['output - feedback control', 'state delay system', 'time delay', 'uncertain system', 'state time - vary delay', 'observer - base control law', 'sequential quadratic programming', 'state feedback control law', 'close - loop system stability', 'robust control', 'linear continuous system']","['state feedback control law', 'robust observer', 'base control law base', 'loop system stability', 'stability criterion', 'delay time', 'sequential quadratic programming method', 'delay', 'observer', 'uncertain system']"
604,1060,Variety identification of wheat using mass spectrometry with neural networks and the influence of mass spectra processing prior to neural network analysis,"the performance of matrix-assisted laser desorption/ionisation time-of-flight mass spectrometry with neural networks in wheat variety classification is further evaluated. two principal issues were studied: (a) the number of varieties that could be classified correctly; and (b) various means of preprocessing mass spectrometric data. the number of wheat varieties tested was increased from 10 to 30. the main pre-processing method investigated was based on gaussian smoothing of the spectra, but other methods based on normalisation procedures and multiplicative scatter correction of data were also used. with the final method, it was possible to classify 30 wheat varieties with 87% correctly classified mass spectra and a correlation coefficient of 0.90","['variety identification', 'mass spectra processing', 'neural network analysis', 'matrix-assisted laser desorption/ionisation time-of-flight mass spectrometry', 'wheat variety classification', 'mass spectrometric data', 'gaussian smoothing', 'normalisation procedures', 'multiplicative scatter correction', 'correctly classified mass spectra', 'correlation coefficient', 'pre-processing- method']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['variety identification', 'mass spectra processing', 'neural network analysis', 'matrix - assist laser desorption / ionisation time - of - flight mass spectrometry', 'wheat variety classification', 'mass spectrometric datum', 'gaussian smoothing', 'normalisation procedure', 'multiplicative scatter correction', 'correctly classify mass spectra', 'correlation coefficient', 'pre - processing- method']","['preprocesse mass spectrometric datum', 'wheat variety classification', 'mass spectrometry', 'classify mass spectra', 'wheat variety', 'laser desorption', 'spectra', 'normalisation procedure', 'variety', 'ionisation']"
605,1025,Watermarking techniques for electronic delivery of remote sensing images,"earth observation missions have recently attracted a growing interest, mainly due to the large number of possible applications capable of exploiting remotely sensed data and images. along with the increase of market potential, the need arises for the protection of the image products. such a need is a very crucial one, because the internet and other public/private networks have become preferred means of data exchange. a critical issue arising when dealing with digital image distribution is copyright protection. such a problem has been largely addressed by resorting to watermarking technology. a question that obviously arises is whether the requirements imposed by remote sensing imagery are compatible with existing watermarking techniques. on the basis of these motivations, the contribution of this work is twofold: assessment of the requirements imposed by remote sensing applications on watermark-based copyright protection, and modification of two well-established digital watermarking techniques to meet such constraints. more specifically, the concept of near-lossless watermarking is introduced and two possible algorithms matching such a requirement are presented. experimental results are shown to measure the impact of watermark introduction on a typical remote sensing application, i.e., unsupervised image classification","['watermarking techniques', 'electronic delivery', 'remote sensing images', 'earth observation missions', 'digital image distribution', 'copyright protection', 'digital watermarking', 'near-lossless watermarking', 'unsupervised image classification']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['watermarke technique', 'electronic delivery', 'remote sensing image', 'earth observation mission', 'digital image distribution', 'copyright protection', 'digital watermarking', 'near - lossless watermarking', 'unsupervise image classification']","['digital watermarking', 'lossless watermarking', 'watermarke technology', 'exist watermarking', 'watermark', 'base copyright protection', 'remote sense imagery', 'copyright protection', 'digital image distribution', 'remote sensing application']"
606,1361,Adaptive scheduling of batch servers in flow shops,"batch servicing is a common way of benefiting from economies of scale in manufacturing operations. good examples of production systems that allow for batch processing are ovens found in the aircraft industry and in semiconductor manufacturing. in this paper we study the issue of dynamic scheduling of such systems within the context of multi-stage flow shops. so far, a great deal of research has concentrated on the development of control strategies, which only address the batch stage. this paper proposes an integral scheduling approach that also includes succeeding stages. in this way, we aim for shop optimization, instead of optimizing performance for a single stage. our so-called look-ahead strategy adapts its scheduling decision to shop status, which includes information on a limited number of near-future arrivals. in particular, we study a two-stage flow shop, in which the batch stage is succeeded by a serial stage. the serial stage may be realized by a single machine or by parallel machines. through an extensive simulation study it is demonstrated how shop performance can be improved by the proposed strategy relative to existing strategies","['adaptive scheduling', 'batch servers', 'flow shops', 'batch servicing', 'manufacturing operations', 'production systems', 'ovens', 'aircraft industry', 'semiconductor manufacturing', 'dynamic scheduling', 'multi-stage flow shops', 'control strategies', 'integral scheduling approach', 'shop optimization', 'look-ahead strategy', 'near-future arrivals', 'two-stage flow shop', 'single machine', 'parallel machines', 'simulation study']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['adaptive scheduling', 'batch server', 'flow shop', 'batch servicing', 'manufacture operation', 'production system', 'oven', 'aircraft industry', 'semiconductor manufacturing', 'dynamic scheduling', 'multi - stage flow shop', 'control strategy', 'integral scheduling approach', 'shop optimization', 'look - ahead strategy', 'near - future arrival', 'two - stage flow shop', 'single machine', 'parallel machine', 'simulation study']","['stage flow shop', 'stage flow shop', 'batch processing', 'batch stage', 'dynamic scheduling', 'batch servicing', 'integral scheduling approach', 'shop optimization', 'scheduling decision', 'shop performance']"
607,1324,A look at MonacoProfiler 4,"the newest profiling program from monaco software adds some valuable features: support for up to 8-color printing, profiling for digital cameras, fine-tuning of black generation and tweaking of profile transforms. we tested its ease of use and a few of the advanced functions. in all, it's pretty good","['monacoprofiler 4', 'color-correction', 'pantone hexachrome', 'commercial printers']","['P', 'U', 'U', 'U']","['monacoprofil 4', 'color - correction', 'pantone hexachrome', 'commercial printer']","['new profiling program', 'monaco software add', 'profile', 'profile transform', 'digital camera', 'color printing', 'valuable feature', 'advanced function', 'black generation', 'tweak']"
608,771,Pareto-optimal formulations for cost versus colorimetric accuracy trade-offs in printer color management,"color management for the printing of digital images is a challenging task, due primarily to nonlinear ink-mixing behavior and the presence of redundant solutions for print devices with more than three inks. algorithms for the conversion of image data to printer-specific format are typically designed to achieve a single predetermined rendering intent, such as colorimetric accuracy. we present two cielab to cmyk color conversion schemes based on a general pareto-optimal formulation for printer color management. the schemes operate using a 149-color characterization data set selected to efficiently capture the entire cmyk gamut. the first scheme uses artificial neural networks as transfer functions between the cielab and cmyk spaces. the second scheme is based on a reformulation of tetrahedral interpolation as an optimization problem. characterization data are divided into tetrahedra for the interpolation-based approach using the program qhull, which removes the common restriction that characterization data be well organized. both schemes offer user control over trade-off problems such as cost versus reproduction accuracy, allowing for user-specified print objectives and the use of constraints such as maximum allowable ink and maximum allowable ae*/sub ab/. a formulation for minimization of ink is shown to be particularly favorable, integrating both a clipping and gamut compression features into a single methodology","['pareto-optimal formulations', 'optimization', 'cost versus colorimetric accuracy trade-offs', 'printer color management', 'nonlinear ink-mixing behavior', 'redundant solutions', 'rendering intent', 'cielab to cmyk color conversion schemes', 'artificial neural networks', 'transfer functions', 'tetrahedral interpolation', 'tetrahedra', 'interpolation-based approach', 'user control', 'cost versus reproduction accuracy', 'user-specified print objectives', 'constraints', 'maximum allowable ink', 'clipping', 'gamut compression features', 'digital image printing', 'image data conversion', 'color characterization data set', 'qhull program', 'macbeth colorchecker chart', 'grey component replacement']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'U', 'U']","['pareto - optimal formulation', 'optimization', 'cost versus colorimetric accuracy trade - off', 'printer color management', 'nonlinear ink - mix behavior', 'redundant solution', 'render intent', 'cielab to cmyk color conversion scheme', 'artificial neural network', 'transfer function', 'tetrahedral interpolation', 'tetrahedron', 'interpolation - base approach', 'user control', 'cost versus reproduction accuracy', 'user - specify print objective', 'constraint', 'maximum allowable ink', 'clip', 'gamut compression feature', 'digital image printing', 'image datum conversion', 'color characterization datum set', 'qhull program', 'macbeth colorchecker chart', 'grey component replacement']","['cmyk color conversion scheme base', 'printer color management', 'cmyk gamut', 'specify print objective', 'color characterization datum set', 'nonlinear ink', 'maximum allowable ink', 'first scheme use artificial neural network', 'tetrahedral interpolation', 'print device']"
609,734,Web services boost integration,microsoft and ibm have announced products to help their database software co-exist with competitors' offerings. the products use web services technology allowing users to improve integration between databases and application software from rival vendors,"['microsoft', 'ibm', 'database software', 'web services technology']","['P', 'P', 'P', 'P']","['microsoft', 'ibm', 'database software', 'web service technology']","['product use web service technology allow user', 'database software co', 'application software', 'ibm', 'database', 'announce product', 'microsoft', 'competitor', 'improve integration', 'offering']"
610,1409,North American carrier survey: simply the best,"network magazine carried out a north american carrier survey. thousands of network engineers gave information on providers' strengths and weaknesses across seven services: private lines, frame relay, atm, vpns, dedicated internet access, ethernet services, and web hosting. respondents also ranked providers on their ability to perform in up to eight categories including customer service, reliability, and price. users rated more than a dozen providers for each survey. carriers needed to receive at least 30 votes for inclusion in the survey. readers were asked to rate carriers on up to nine categories using a scale of 1 (unacceptable) to 5 (excellent). not all categories are equally important. to try and get at these differences, network magazine asked readers to assign a weight to each category. the big winners were vpns","['north american carrier survey', 'private lines', 'frame relay', 'atm', 'vpns', 'dedicated internet access', 'ethernet services', 'web hosting', 'customer service', 'reliability', 'price', 'service providers']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['north american carrier survey', 'private line', 'frame relay', 'atm', 'vpns', 'dedicated internet access', 'ethernet service', 'web hosting', 'customer service', 'reliability', 'price', 'service provider']","['network magazine ask reader', 'north american carrier survey', 'category include customer service', 'network engineer give information', 'rate carrier', 'network magazine carry', 'rank provider', 'dozen provider', 'ethernet service', 'carrier need']"
611,1319,Routing security in wireless ad hoc networks,"a mobile ad hoc network consists of a collection of wireless mobile nodes that are capable of communicating with each other without the use of a network infrastructure or any centralized administration. manet is an emerging research area with practical applications. however, wireless manet is particularly vulnerable due to its fundamental characteristics, such as open medium, dynamic topology, distributed cooperation, and constrained capability. routing plays an important role in the security of the entire network. in general, routing security in wireless manets appears to be a problem that is not trivial to solve. in this article we study the routing security issues of manets, and analyze in detail one type of attack-the ""black hole"" problem-that can easily be employed against the manets. we also propose a solution for the black hole problem for ad hoc on-demand distance vector routing protocol","['routing security', 'wireless ad hoc networks', 'mobile ad hoc network', 'wireless mobile nodes', 'wireless manet', 'open medium', 'dynamic topology', 'distributed cooperation', 'on-demand distance vector routing protocol', 'satellite transmission', 'home wireless personal area networks']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'M']","['route security', 'wireless ad hoc network', 'mobile ad hoc network', 'wireless mobile node', 'wireless manet', 'open medium', 'dynamic topology', 'distribute cooperation', 'on - demand distance vector route protocol', 'satellite transmission', 'home wireless personal area network']","['route security issue', 'wireless manet appear', 'wireless manet', 'route security', 'wireless mobile node', 'manet', 'manet', 'route', 'network infrastructure', 'attack']"
612,709,Cooperative mutation based evolutionary programming for continuous function optimization,"an evolutionary programming (ep) algorithm adapting a new mutation operator is presented. unlike most previous eps, in which each individual is mutated on its own, each individual in the proposed algorithm is mutated in cooperation with the other individuals. this not only enhances convergence speed but also gives more chance to escape from local minima","['cooperative mutation based evolutionary programming', 'continuous function optimization', 'convergence speed', 'local minima']","['P', 'P', 'P', 'P']","['cooperative mutation base evolutionary programming', 'continuous function optimization', 'convergence speed', 'local minima']","['algorithm adapt', 'new mutation operator', 'evolutionary programming', 'propose algorithm', 'mutate', 'enhance convergence speed', 'other individual', 'cooperation', 'individual', 'previous ep']"
613,822,Reinventing broadband,"many believe that broadband providers need to change their whole approach. the future, then, is in reinventing broadband. that means tiered pricing to make broadband more competitive with dial-up access and livelier, more distinct content: video on demand, mp3, and other features exclusive to the fat-pipe superhighway","['broadband', 'tiered pricing', 'video on demand', 'mp3', 'business plans']","['P', 'P', 'P', 'P', 'U']","['broadband', 'tiere pricing', 'video on demand', 'mp3', 'business plan']","['broadband provider need', 'reinvent broadband', 'mean tiered pricing', 'broadband', 'other feature exclusive', 'demand', 'mp3', 'dial', 'whole approach', 'distinct content']"
614,867,Tracking control of the flexible slider-crank mechanism system under impact,"the variable structure control (vsc) and the stabilizer design by using the pole placement technique are applied to the tracking control of the flexible slider-crank mechanism under impact. the vsc strategy is employed to track the crank angular position and speed, while the stabilizer design is involved to suppress the flexible vibrations simultaneously. from the theoretical impact consideration, three approaches including the generalized momentum balance (gmb), the continuous force model (cfm), and the cfm associated with the effective mass compensation emc are adopted, and are derived on the basis of the energy and impulse-momentum conservations. simulation results are provided to demonstrate the performance of the motor-controller flexible slider-crank mechanism not only accomplishing good tracking trajectory of the crank angle, but also eliminating vibrations of the flexible connecting rod","['tracking control', 'flexible slider-crank mechanism system', 'impact', 'variable structure control', 'stabilizer design', 'pole placement technique', 'crank angular position', 'flexible vibrations', 'generalized momentum balance', 'continuous force model', 'effective mass compensation', 'tracking trajectory', 'flexible connecting rod', 'conservation laws', 'multibody dynamics']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U']","['track control', 'flexible slider - crank mechanism system', 'impact', 'variable structure control', 'stabilizer design', 'pole placement technique', 'crank angular position', 'flexible vibration', 'generalize momentum balance', 'continuous force model', 'effective mass compensation', 'track trajectory', 'flexible connect rod', 'conservation law', 'multibody dynamic']","['controller flexible slider', 'crank angular position', 'flexible slider', 'flexible vibration', 'crank mechanism', 'crank angle', 'track trajectory', 'generalize momentum balance', 'track control', 'stabilizer']"
615,1434,A simple etalon-stabilized visible laser diode,"visible laser diodes (lds) are inexpensively available with single-transverse-mode, single-longitudinal-mode operation with a coherence length in the metre range. with constant current bias and constant operating temperature, the optical output power and operating wavelength are stable. a simple and inexpensive way is developed to maintain a constant ld temperature as the temperature of the local environment varies, by monitoring the initially changing wavelength with an external etalon and using this information to apply a heating correction to the monitor photodiode commonly integral to the ld package. the fractional wavelength stability achieved is limited by the solid etalon to 7*10/sup -6/ degrees c/sup -1/","['visible laser diode', 'single-transverse-mode', 'single-longitudinal-mode', 'constant current bias', 'constant operating temperature', 'heating correction', 'monitor photodiode', 'fractional wavelength stability', 'etalon-stabilized laser diode', 'index-guided multi-quantum-well', 'closed-loop operation', 'feedback loop']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'M', 'U']","['visible laser diode', 'single - transverse - mode', 'single - longitudinal - mode', 'constant current bias', 'constant operating temperature', 'heating correction', 'monitor photodiode', 'fractional wavelength stability', 'etalon - stabilize laser diode', 'index - guide multi - quantum - well', 'close - loop operation', 'feedback loop']","['visible laser diode', 'fractional wavelength stability', 'monitor photodiode', 'constant ld temperature', 'wavelength', 'optical output', 'temperature', 'ld package', 'metre range', 'heating correction']"
616,1018,Fabrication of polymeric microlens of hemispherical shape using micromolding,"polymeric microlenses play an important role in reducing the size, weight, and cost of optical data storage and optical communication systems. we fabricate polymeric microlenses using the microcompression molding process. the design and fabrication procedures for mold insertion is simplified using silicon instead of metal. pmma powder is used as the molding material. governed by process parameters such as temperature and pressure histories, the micromolding process is controlled to minimize various defects that develop during the molding process. the radius of curvature and magnification ratio of fabricated microlens are measured as 150 mu m and over 3.0, respectively","['micromolding', 'polymeric microlenses', 'size', 'weight', 'cost', 'optical data storage', 'optical communication systems', 'microcompression molding process', 'fabrication procedures', 'mold insertion', 'silicon', 'pmma powder', 'molding material', 'process parameters', 'temperature', 'pressure', 'micromolding process', 'magnification ratio', 'polymeric microlens fabrication', 'hemispherical shape microlens', 'design procedures', '300 micron']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'U']","['micromolde', 'polymeric microlense', 'size', 'weight', 'cost', 'optical datum storage', 'optical communication system', 'microcompression molding process', 'fabrication procedure', 'mold insertion', 'silicon', 'pmma powder', 'mold material', 'process parameter', 'temperature', 'pressure', 'micromolde process', 'magnification ratio', 'polymeric microlen fabrication', 'hemispherical shape microlen', 'design procedure', '300 micron']","['fabricate polymeric microlense use', 'polymeric microlense', 'microcompression molding process', 'fabricate microlen', 'micromolde process', 'mold material', 'fabrication procedure', 'use silicon', 'molding process', 'mold insertion']"
617,987,Proof that the election problem belongs to NF-completeness problems in asynchronous distributed systems,"this paper is about the hardness of the election problem in asynchronous distributed systems in which processes can crash but links are reliable. the hardness of the problem is defined with respect to the difficulty to solve it despite failures. it is shown that problems encountered in the system are classified as three classes of problems: f (fault-tolerant), nf (not fault-tolerant) and nfc (nf-completeness). among those, the class nfc are the hardest problems to solve. in this paper, we prove that the election problem is the most difficult problem which belongs to the class nfc","['election problem', 'nf-completeness problems', 'asynchronous distributed systems', 'distributed computing', 'leader election', 'failure detectors', 'fault-tolerant problems', 'not-fault-tolerant problems']","['P', 'P', 'P', 'M', 'M', 'M', 'R', 'M']","['election problem', 'nf - completeness problem', 'asynchronous distribute system', 'distribute computing', 'leader election', 'failure detector', 'fault - tolerant problem', 'not - fault - tolerant problem']","['asynchronous distribute system', 'election problem', 'hard problem', 'problem encounter', 'difficult problem', 'class nfc', 'failure', 'fault', 'reliable', 'problem']"
618,550,Market watch - air conditioning,"after a boom period in the late nineties, the air conditioning market finds itself in something of a lull at present, but manufacturers aren't panicking","['market', 'air conditioning']","['P', 'P']","['market', 'air conditioning']","['air conditioning market find', 'manufacturer', 'boom period', 'late ninety', 'lull', 'present']"
619,1105,Fuzzy business [Halden Reactor Project],"the halden reactor project has developed two systems to investigate how signal validation and thermal performance monitoring techniques can be improved. peano is an online calibration monitoring system that makes use of artificial intelligence techniques. the system has been tested in cooperation with epri and edan engineering, using real data from a us pwr plant. these tests showed that peano could reliably assess the performance of the process instrumentation at different plant conditions. real cases of zero and span drifts were successfully detected by the system. tempo is a system for thermal performance monitoring and optimisation, which relies on plant-wide first principle models. the system has been installed on a swedish bwr plant. results obtained show an overall rms deviation from measured values of a few tenths of a percent, and giving goodness-of-fits in the order of 95%. the high accuracy demonstrated is a good basis for detecting possible faults and efficiency losses in steam turbine cycles","['halden reactor project', 'thermal performance monitoring', 'peano', 'calibration', 'artificial intelligence', 'pwr', 'tempo', 'bwr', 'steam turbine cycles', 'fuzzy logic', 'steam generators', 'feedwater flow']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'U']","['halden reactor project', 'thermal performance monitoring', 'peano', 'calibration', 'artificial intelligence', 'pwr', 'tempo', 'bwr', 'steam turbine cycle', 'fuzzy logic', 'steam generator', 'feedwater flow']","['online calibration monitoring system', 'thermal performance monitor technique', 'thermal performance monitoring', 'halden reactor project', 'detect possible fault', 'swedish bwr plant', 'us pwr plant', 'process instrumentation', 'accuracy', 'rm deviation']"
620,1140,Computer aided classification of masses in ultrasonic mammography,"frequency compounding was recently investigated for computer aided classification of masses in ultrasonic b-mode images as benign or malignant. the classification was performed using the normalized parameters of the nakagami distribution at a single region of interest at the site of the mass. a combination of normalized nakagami parameters from two different images of a mass was undertaken to improve the performance of classification. receiver operating characteristic (roc) analysis showed that such an approach resulted in an area of 0.83 under the roc curve. the aim of the work described in this paper is to see whether a feature describing the characteristic of the boundary can be extracted and combined with the nakagami parameter to further improve the performance of classification. the combination of the features has been performed using a weighted summation. results indicate a 10% improvement in specificity at a sensitivity of 96% after combining the information at the site and at the boundary. moreover, the technique requires minimal clinical intervention and has a performance that reaches that of the trained radiologist. it is hence suggested that this technique may be utilized in practice to characterize breast masses","['computer aided classification', 'ultrasonic mammography', 'frequency compounding', 'ultrasonic b-mode images', 'benign', 'malignant', 'normalized parameters', 'nakagami distribution', 'single region of interest', 'normalized nakagami parameters', 'receiver operating characteristic', 'roc curve', 'weighted summation', 'specificity', 'sensitivity', 'minimal clinical intervention', 'breast masses']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['computer aid classification', 'ultrasonic mammography', 'frequency compounding', 'ultrasonic b - mode image', 'benign', 'malignant', 'normalize parameter', 'nakagami distribution', 'single region of interest', 'normalize nakagami parameter', 'receiver operate characteristic', 'roc curve', 'weight summation', 'specificity', 'sensitivity', 'minimal clinical intervention', 'breast masse']","['normalize nakagami parameter', 'normalize parameter', 'computer aid classification', 'roc curve', 'nakagami parameter', 'frequency compounding', 'nakagami distribution', 'classification', 'ultrasonic', 'mode image']"
621,96,OMS battle heating up as Chicago Equity ousts LongView for Macgregor,chicago equity partners llc has gone into full production with macgregor's financial trading platform. this marks a concentrated effort to achieve straight-through processing,"['longview', 'macgregor', 'chicago equity partners', 'financial trading platform', 'straight-through processing']","['P', 'P', 'P', 'P', 'P']","['longview', 'macgregor', 'chicago equity partner', 'financial trading platform', 'straight - through processing']","['chicago equity partner llc', 'financial trading platform', 'full production', 'macgregor', 'concentrated effort', 'achieve straight', 'go', 'mark']"
622,614,An on-line distributed intelligent fault section estimation system for large-scale power networks,"in this paper, a novel distributed intelligent system is suggested for on-line fault section estimation (fse) of large-scale power networks. as the first step, a multi-way graph partitioning method based on weighted minimum degree reordering is proposed for effectively partitioning the original large-scale power network into the desired number of connected sub-networks with quasi-balanced fse burdens and minimum frontier elements. after partitioning, a distributed intelligent system based on radial basis function neural network (rbf nn) and companion fuzzy system is suggested for fse. the relevant theoretical analysis and procedure are presented in the paper. the proposed distributed intelligent fse method has been implemented with sparse storage technique and tested on the ieee 14, 30 and 118-bus systems, respectively. computer simulation results show that the proposed fse method works successfully for large-scale power networks","['on-line distributed intelligent fault section estimation system', 'large-scale power networks', 'distributed intelligent system', 'on-line fault section estimation', 'multi-way graph partitioning method based', 'weighted minimum degree reordering', 'connected sub-networks', 'quasi-balanced fse burdens', 'minimum frontier elements', 'radial basis function neural network', 'fuzzy system', 'sparse storage technique', 'computer simulation', 'ieee 14-bus systems', 'ieee 30-bus systems', 'ieee 118-bus systems']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'R']","['on - line distribute intelligent fault section estimation system', 'large - scale power network', 'distribute intelligent system', 'on - line fault section estimation', 'multi - way graph partition method base', 'weight minimum degree reorder', 'connect sub - network', 'quasi - balanced fse burden', 'minimum frontier element', 'radial basis function neural network', 'fuzzy system', 'sparse storage technique', 'computer simulation', 'ieee 14 - bus system', 'ieee 30 - bus system', 'ieee 118 - bus system']","['way graph partition method', 'radial basis function neural network', 'propose distribute intelligent fse method', 'line fault section estimation', 'distribute intelligent system', 'propose fse method', 'scale power network', 'partition', 'scale power network', 'balance fse burden']"
623,651,Application-layer multicasting with Delaunay triangulation overlays,"application-layer multicast supports group applications without the need for a network-layer multicast protocol. here, applications arrange themselves in a logical overlay network and transfer data within the overlay. we present an application-layer multicast solution that uses a delaunay triangulation as an overlay network topology. an advantage of using a delaunay triangulation is that it allows each application to locally derive next-hop routing information without requiring a routing protocol in the overlay. a disadvantage of using a delaunay triangulation is that the mapping of the overlay to the network topology at the network and data link layer may be suboptimal. we present a protocol, called delaunay triangulation (dt protocol), which constructs delaunay triangulation overlay networks. we present measurement experiments of the dt protocol for overlay networks with up to 10 000 members, that are running on a local pc cluster with 100 linux pcs. the results show that the protocol stabilizes quickly, e.g., an overlay network with 10 000 nodes can be built in just over 30 s. the traffic measurements indicate that the average overhead of a node is only a few kilobits per second if the overlay network is in a steady state. results of throughput experiments of multicast transmissions (using tcp unicast connections between neighbors in the overlay network) show an achievable throughput of approximately 15 mb/s in an overlay with 100 nodes and 2 mb/s in an overlay with 1000 nodes","['application-layer multicasting', 'delaunay triangulation overlays', 'group applications', 'network-layer multicast protocol', 'logical overlay network', 'overlay networks', 'overlay network topology', 'next-hop routing information', 'data link layer', 'dt protocol', 'measurement experiments', 'local pc cluster', 'linux pc', 'traffic measurements', 'average overhead', 'throughput experiments', 'multicast transmissions', 'tcp unicast connections', 'data transfer', 'delaunay triangulation protocol', 'network nodes', '15 mbit/s', '2 mbit/s']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'M']","['application - layer multicasting', 'delaunay triangulation overlay', 'group application', 'network - layer multicast protocol', 'logical overlay network', 'overlay network', 'overlay network topology', 'next - hop route information', 'datum link layer', 'dt protocol', 'measurement experiment', 'local pc cluster', 'linux pc', 'traffic measurement', 'average overhead', 'throughput experiment', 'multicast transmission', 'tcp unicast connection', 'datum transfer', 'delaunay triangulation protocol', 'network nod', '15 mbit / s', '2 mbit / s']","['layer multicast protocol', 'layer multicast support group application', 'delaunay triangulation overlay network', 'layer multicast', 'overlay network topology', 'multicast transmission', 'route protocol', 'logical overlay network', 'overlay network', 'hop route information']"
624,1204,Design and prototype of a performance tool interface for OpenMP,"this paper proposes a performance tools interface for openmp, similar in spirit to the mpi profiling interface in its intent to define a clear and portable api that makes openmp execution events visible to runtime performance tools. we present our design using a source-level instrumentation approach based on openmp directive rewriting. rules to instrument each directive and their combination are applied to generate calls to the interface consistent with directive semantics and to pass context information (e.g., source code locations) in a portable and efficient way. our proposed openmp performance api further allows user functions and arbitrary code regions to be marked and performance measurement to be controlled using new openmp directives. to prototype the proposed openmp performance interface, we have developed compatible performance libraries for the expert automatic event trace analyzer [17, 18] and the tau performance analysis framework [13]. the directive instrumentation transformations we define are implemented in a source-to-source translation tool called opari. application examples are presented for both expert and tau to show the openmp performance interface and opari instrumentation tool in operation. when used together with the mpi profiling interface (as the examples also demonstrate), our proposed approach provides a portable and robust solution to performance analysis of openmp and mixed-mode (openmp + mpi) applications","['performance tool interface', 'mpi profiling interface', 'api', 'source-level instrumentation approach', 'openmp directive rewriting', 'directive semantics', 'arbitrary code regions', 'performance libraries', 'expert automatic event trace analyzer', 'tau performance analysis framework', 'source-to-source translation tool', 'opari', 'parallel programming']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U']","['performance tool interface', 'mpi profiling interface', 'api', 'source - level instrumentation approach', 'openmp directive rewrite', 'directive semantic', 'arbitrary code region', 'performance librarie', 'expert automatic event trace analyzer', 'tau performance analysis framework', 'source - to - source translation tool', 'opari', 'parallel programming']","['openmp performance api', 'runtime performance tool', 'openmp execution event visible', 'openmp performance interface', 'mpi profiling interface', 'use new openmp directive', 'opari instrumentation tool', 'expert automatic event trace analyzer', 'performance tool interface', 'openmp directive rewrite']"
625,1241,Code generator for the HPF Library and Fortran 95 transformational functions,"one of the language features of the core language of hpf 2.0 (high performance fortran) is the hpf library. the hpf library consists of 55 generic functions. the implementation of this library presents the challenge that all data types, data kinds, array ranks and input distributions need to be supported. for instance, more than 2 billion separate functions are required to support copy-scatter fully. the efficient support of these billions of specific functions is one of the outstanding problems of hpf. we have solved this problem by developing a library generator which utilizes the mechanism of parameterized templates. this mechanism allows the procedures to be instantiated at compile time for arguments with a specific type, kind, rank and distribution over a specific processor array. we describe the algorithms used in the different library functions. the implementation gives the ease of generating a large number of library routines from a single template. the templates can be extended with special code for specific combinations of the input arguments. we describe in detail the implementation and performance of the matrix multiplication template for the fujitsu vpp5000 platform","['code generation', 'hpf', 'hpf library', 'high performance fortran', 'generic functions', 'data types', 'library generator', 'parameterized templates', 'library functions', 'matrix multiplication', 'parallel computing', 'parallel languages']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'M']","['code generation', 'hpf', 'hpf library', 'high performance fortran', 'generic function', 'datum type', 'library generator', 'parameterized template', 'library function', 'matrix multiplication', 'parallel computing', 'parallel language']","['high performance fortran', 'matrix multiplication template', 'hpf library consist', 'parameterized template', 'hpf library', 'different library function', 'specific processor array', 'library generator', 'compile time', 'array rank']"
626,139,"Equilibrium swelling and kinetics of pH-responsive hydrogels: models, experiments, and simulations","the widespread application of ionic hydrogels in a number of applications like control of microfluidic flow, development of muscle-like actuators, filtration/separation and drug delivery makes it important to properly understand these materials. understanding hydrogel properties is also important from the standpoint of their similarity to many biological tissues. typically, gel size is sensitive to outer solution ph and salt concentration. in this paper, we develop models to predict the swelling/deswelling of hydrogels in buffered ph solutions. an equilibrium model has been developed to predict the degree of swelling of the hydrogel at a given ph and salt concentration in the solution. a kinetic model has been developed to predict the rate of swelling of the hydrogel when the solution ph is changed. experiments are performed to characterize the mechanical properties of the hydrogel in different ph solutions. the degree of swelling as well as the rate of swelling of the hydrogel are also studied through experiments. the simulations are compared with experimental results and the models are found to predict the swelling/deswelling processes accurately","['ph-responsive hydrogels', 'ionic hydrogels', 'microfluidic flow', 'muscle-like actuators', 'filtration/separation', 'drug delivery', 'gel size', 'swelling/deswelling', 'buffered ph solutions', 'equilibrium model', 'mechanical properties']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['ph - responsive hydrogel', 'ionic hydrogel', 'microfluidic flow', 'muscle - like actuator', 'filtration / separation', 'drug delivery', 'gel size', 'swell / deswelle', 'buffer ph solution', 'equilibrium model', 'mechanical property']","['ionic hydrogel', 'hydrogel property', 'hydrogel', 'hydrogel', 'microfluidic flow', 'ph solution', 'kinetic model', 'solution ph', 'gel', 'salt concentration']"
627,1365,Deadlock-free scheduling in flexible manufacturing systems using Petri nets,"this paper addresses the deadlock-free scheduling problem in flexible manufacturing systems. an efficient deadlock-free scheduling algorithm was developed, using timed petri nets, for a class of fmss called systems of sequential systems with shared resources (s/sup 4/ r). the algorithm generates a partial reachability graph to find the optimal or near-optimal deadlock-free schedule in terms of the firing sequence of the transitions of the petri net model. the objective is to minimize the mean flow time (mft). an efficient truncation technique, based on the siphon concept, has been developed and used to generate the minimum necessary portion of the reachability graph to be searched. it has been shown experimentally that the developed siphon truncation technique enhances the ability to develop deadlock-free schedules of systems with a high number of deadlocks, which cannot be achieved using standard petri net scheduling approaches. it may be necessary, in some cases, to relax the optimality condition for large fmss in order to make the search effort reasonable. hence, a user control factor (ucf) was defined and used in the scheduling algorithm. the objective of using the ucf is to achieve an acceptable trade-off between the solution quality and the search effort. its effect on the mft and the cpu time has been investigated. randomly generated examples are used for illustration and comparison. although the effect of ucf did not affect the mean flow time, it was shown that increasing it reduces the search effort (cpu time) significantly","['deadlock-free scheduling', 'flexible manufacturing systems', 'petri nets', 'systems of sequential systems with shared resources', 'partial reachability graph', 'near-optimal deadlock-free schedule', 'siphon truncation technique', 'user control factor', 'cpu time', 'randomly generated examples', 'optimal deadlock-free schedule', 'petri net model transitions firing sequence', 'mean flow time minimization', 'optimality condition relaxation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R']","['deadlock - free scheduling', 'flexible manufacturing system', 'petri net', 'system of sequential system with share resource', 'partial reachability graph', 'near - optimal deadlock - free schedule', 'siphon truncation technique', 'user control factor', 'cpu time', 'randomly generate example', 'optimal deadlock - free schedule', 'petri net model transition firing sequence', 'mean flow time minimization', 'optimality condition relaxation']","['use standard petri net scheduling approach', 'use time petri net', 'petri net model', 'free scheduling algorithm', 'scheduling algorithm', 'free scheduling problem', 'efficient deadlock', 'optimal deadlock', 'flexible manufacturing system', 'free schedule']"
628,1320,Securing the Internet routing infrastructure,"the unprecedented growth of the internet over the last years, and the expectation of an even faster increase in the numbers of users and networked systems, resulted in the internet assuming its position as a mass communication medium. at the same time, the emergence of an increasingly large number of application areas and the evolution of the networking technology suggest that in the near future the internet may become the single integrated communication infrastructure. however, as the dependence on the networking infrastructure grows, its security becomes a major concern, in light of the increased attempt to compromise the infrastructure. in particular, the routing operation is a highly visible target that must be shielded against a wide range of attacks. the injection of false routing information can easily degrade network performance, or even cause denial of service for a large number of hosts and networks over a long period of time. different approaches have been proposed to secure the routing protocols, with a variety of countermeasures, which, nonetheless, have not eradicated the vulnerability of the routing infrastructure. in this article, we survey the up-to-date secure routing schemes. that appeared over the last few years. our critical point of view and thorough review of the literature are an attempt to identify directions for future research on an indeed difficult and still largely open problem","['routing infrastructure', 'networked systems', 'networking technology', 'integrated communication infrastructure', 'networking infrastructure', 'false routing information', 'network performance', 'routing protocols', 'countermeasures', 'secure routing schemes', 'research', 'internet routing infrastructure security', 'preventive security mechanisms', 'link state protocols']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M']","['route infrastructure', 'networked system', 'network technology', 'integrate communication infrastructure', 'network infrastructure', 'false routing information', 'network performance', 'route protocol', 'countermeasure', 'secure routing scheme', 'research', 'internet route infrastructure security', 'preventive security mechanism', 'link state protocol']","['date secure routing scheme', 'route protocol', 'route infrastructure', 'false routing information', 'network infrastructure', 'route operation', 'network technology suggest', 'single integrate communication infrastructure', 'security become', 'attack']"
629,775,Disability-related special libraries,"one of the ways that the federal government works to improve services to people with disabilities is to fund disability-related information centers and clearinghouses that provide information resources and referrals to disabled individuals, their family members, service providers, and the general public. the teaching research division of western oregon university operates two federally funded information centers for people with disabilities: obirn (the oregon brain injury resource network) and db-link (the national information clearinghouse on children who are deaf-blind). both have developed in-depth library collections and services in addition to typical clearinghouse services. the authors describe how obirn and db-link were designed and developed, and how they are currently structured and maintained. both information centers use many of the same strategies and tools in day-to-day operations, but differ in a number of ways, including materials and clientele","['disability-related special libraries', 'federal government', 'disability-related information centers', 'information resources', 'western oregon university', 'obirn', 'oregon brain injury resource network', 'db-link', 'national information clearinghouse on children who are deaf-blind', 'library collections', 'disability-related clearinghouses', 'information referrals']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['disability - relate special library', 'federal government', 'disability - relate information center', 'information resource', 'western oregon university', 'obirn', 'oregon brain injury resource network', 'db - link', 'national information clearinghouse on child who be deaf - blind', 'library collection', 'disability - relate clearinghouse', 'information referral']","['oregon brain injury resource network', 'fund disability', 'western oregon university operate', 'provide information resource', 'service provider', 'depth library collection', 'typical clearinghouse service', 'fund information center', 'information center use many', 'relate information center']"
630,730,Multi-hour design of survivable classical IP networks,"most of internet intra-domain routing protocols (ospf, rip, and is-is) are based on shortest path routing. the path length is defined as the sum of metrics associated with the path links. these metrics are often managed by the network administrator. in this context, the design of an internet backbone network consists in dimensioning the network (routers and transmission links) and establishing the metric. many requirements have to be satisfied. first, internet traffic is not static as significant variations can be observed during the day. second, many failures can occur (cable cuts, hardware failures, software failures, etc.). we present algorithms (meta-heuristics and greedy heuristic) to design internet backbone networks, taking into account the multi-hour behaviour of traffic and some survivability requirements. many multi-hour and protection strategies are studied and numerically compared. our algorithms can be extended to integrate other quality of service constraints","['multi-hour design', 'survivable classical ip networks', 'internet intra-domain routing protocols', 'ospf', 'rip', 'is-is', 'shortest path routing', 'path length', 'path links', 'network administrator', 'internet backbone network', 'transmission links', 'internet traffic', 'survivability requirements', 'quality of service constraints', 'network dimensioning', 'network routers', 'network failures', 'meta-heuristics algorithm', 'greedy heuristic algorithm', 'network protection', 'qos constraints']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'R', 'R', 'M']","['multi - hour design', 'survivable classical ip network', 'internet intra - domain routing protocol', 'ospf', 'rip', 'be - be', 'short path route', 'path length', 'path link', 'network administrator', 'internet backbone network', 'transmission link', 'internet traffic', 'survivability requirement', 'quality of service constraint', 'network dimension', 'network router', 'network failure', 'meta - heuristic algorithm', 'greedy heuristic algorithm', 'network protection', 'qos constraint']","['design internet backbone network', 'internet backbone network consist', 'short path route', 'domain route protocol', 'internet traffic', 'path length', 'survivability requirement', 'path link', 'greedy heuristic', 'cable cut']"
631,1448,Implementing equals for mixed-type comparison,"the idea of comparing objects of different types is not entirely off base, in particular for classes from the same class hierarchy. after all, objects from the same class hierarchy (and by class hierarchy we mean all classes derived from a common superclass other than object) have something in common, namely at least the superclass part. as we demonstrated in a previous paper (2002), providing a correct implementation of a mixed-type comparison is a non-trivial task. in this article, we will show one way of implementing a mixed-type comparison of objects from the same class hierarchy that meets the requirements of the equals contract","['mixed-type comparison', 'superclass', 'equals contract', 'java', 'transitivity requirement']","['P', 'P', 'P', 'U', 'M']","['mixed - type comparison', 'superclass', 'equal contract', 'java', 'transitivity requirement']","['type comparison', 'compare object', 'class hierarchy', 'common superclass other', 'different type', 'class derive', 'superclass part', 'correct implementation', 'class', 'object']"
632,1099,WebCAD: A computer aided design tool constrained with explicit 'design for manufacturability' rules for computer numerical control milling,"a key element in the overall efficiency of a manufacturing enterprise is the compatibility between the features that have been created in a newly designed part, and the capabilities of the downstream manufacturing processes. with this in mind, a process-aware computer aided design (cad) system called webcad has been developed. the system restricts the freedom of the designer in such a way that the designed parts can be manufactured on a three-axis computer numerical control milling machine. this paper discusses the vision of webcad and explains the rationale for its development in comparison with commercial cad/cam (computer aided design/manufacture) systems. the paper then goes on to describe the implementation issues that enforce the manufacturability rules. finally, certain design tools are described that aid a user during the design process. some examples are given of the parts designed and manufactured with webcad","['webcad', 'computer aided design tool', 'design tools', 'computer numerical control milling', 'manufacturability rules', 'design for manufacturability rules', 'manufacturing enterprise efficiency', 'process-aware cad system', 'three-axis cnc milling machine', 'cad/cam systems', 'internet-based cad/cam']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'R', 'M']","['webcad', 'computer aid design tool', 'design tool', 'computer numerical control milling', 'manufacturability rule', 'design for manufacturability rule', 'manufacture enterprise efficiency', 'process - aware cad system', 'three - axis cnc milling machine', 'cad / cam system', 'internet - base cad / cam']","['axis computer numerical control milling machine', 'aware computer aid design', 'design tool', 'computer aid design', 'manufacture process', 'design process', 'webcad', 'commercial cad', 'manufacture enterprise', 'cad']"
633,1064,Quantum-controlled measurement device for quantum-state discrimination,"we propose a ""programmable"" quantum device that is able to perform a specific generalized measurement from a certain set of measurements depending on a quantum state of a ""program register."" in particular, we study a situation when the programmable measurement device serves for the unambiguous discrimination between nonorthogonal states. the particular pair of states that can be unambiguously discriminated is specified by the state of a program qubit. the probability of successful discrimination is not optimal for all admissible pairs. however, for some subsets it can be very close to the optimal value","['quantum-controlled measurement device', 'quantum-state discrimination', 'quantum state', 'program register', 'nonorthogonal states', 'program qubit', 'programmable quantum device']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['quantum - control measurement device', 'quantum - state discrimination', 'quantum state', 'program register', 'nonorthogonal state', 'program qubit', 'programmable quantum device']","['programmable measurement device serve', 'quantum state', 'quantum device', 'program qubit', 'specific generalized measurement', 'unambiguous discrimination', 'nonorthogonal state', 'programmable', 'discrimination', 'program register']"
634,1021,Error-probability analysis of MIL-STD-1773 optical fiber data buses,"we have analyzed the error probabilities of mil-std-1773 optical fiber data buses with three modulation schemes, namely, original manchester ii bi-phase coding, ptmbc, and embc-bsf. using these derived expressions of error probabilities, we can also compare the receiver sensitivities of such optical fiber data buses","['optical fiber data buses', 'error probabilities', 'modulation schemes', 'receiver sensitivities', 'manchester bi-phase coding']","['P', 'P', 'P', 'P', 'R']","['optical fiber datum bus', 'error probability', 'modulation scheme', 'receiver sensitivity', 'manchester bi - phase coding']","['optical fiber datum bus', 'modulation scheme', 'error probability', 'receiver sensitivity', 'embc', 'ptmbc', 'manchester ii', 'bsf', 'mil', 'expression']"
635,788,Rise of the supercompany [CRM],"all the thoughts, conversations and notes of employees help the firm create a wider picture of business. customer relationship management (crm) feeds on data, and it is hungry","['customer relationship management', 'central data repository', 'database', 'staff trained']","['P', 'M', 'U', 'U']","['customer relationship management', 'central datum repository', 'database', 'staff train']","['customer relationship management', 'crm', 'employee help', 'firm create', 'conversation', 'business', 'note', 'datum', 'feed', 'wide picture']"
636,1398,Swamped by data [storage],"while the cost of storage has plummeted, the demand continued to climb and there are plenty of players out there offering solutions to a company's burgeoning storage needs","['cost of storage', 'it personnel', 'resource management', 'disk capacity management', 'disk optimisation', 'file system automation', 'storage virtualisation', 'storage area networks', 'network attached storage']","['P', 'U', 'U', 'U', 'U', 'U', 'M', 'M', 'M']","['cost of storage', 'it personnel', 'resource management', 'disk capacity management', 'disk optimisation', 'file system automation', 'storage virtualisation', 'storage area network', 'network attach storage']","['demand continue', 'storage', 'offer solution', 'cost', 'player', 'be plenty', 'company', 'plummet', 'climb']"
637,9,Achieving competitive capabilities in e-services,"what implications does the internet have for service operations strategy? how can business performance of e-service companies be improved in today's knowledge-based economy? these research questions are the subject of the paper. we propose a model that links the e-service company's knowledge-based competencies with their competitive capabilities. drawing from the current literature, our analysis suggests that services that strategically build a portfolio of knowledge-based competencies, namely human capital, structural capital, and absorptive capacity have more operations-based options, than their counterparts who are less apt to invest. we assume that the combinative capabilities of service quality, delivery, flexibility, and cost are determined by the investment in intellectual capital. arguably, with the advent of the internet, different operating models (e.g., bricks-and-mortar, clicks-and-mortar, or pure dot-com) have different strategic imperatives in terms of knowledge-based competencies. thus, the new e-operations paradigm can be viewed as a configuration of knowledge-based competencies and capabilities","['competitive capabilities', 'e-services', 'internet', 'service operations strategy', 'business performance', 'knowledge-based economy', 'knowledge-based competencies', 'human capital', 'structural capital', 'absorptive capacity', 'operations-based options', 'investment', 'combinative capabilities', 'service quality', 'delivery', 'flexibility', 'cost', 'intellectual capital', 'bricks-and-mortar', 'clicks-and-mortar', 'dot-com', 'strategic imperatives']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['competitive capability', 'e - service', 'internet', 'service operation strategy', 'business performance', 'knowledge - base economy', 'knowledge - base competency', 'human capital', 'structural capital', 'absorptive capacity', 'operation - base option', 'investment', 'combinative capability', 'service quality', 'delivery', 'flexibility', 'cost', 'intellectual capital', 'brick - and - mortar', 'click - and - mortar', 'dot - com', 'strategic imperative']","['absorptive capacity have more operation', 'competitive capability', 'service operation strategy', 'service company', 'have different strategic imperative', 'service company', 'business performance', 'combinative capability', 'base competency', 'service quality']"
638,569,Application of an internally consistent material model to determine the effect of tool edge geometry in orthogonal machining,"it is well known that the edge geometry of a cutting tool affects the forces measured in metal cutting. two experimental methods have been suggested in the past to extract the ploughing (non-cutting) component from the total measured force: (1) the extrapolation approach, and (2) the dwell force technique. this study reports the behavior of zinc during orthogonal machining using tools of controlled edge radius. applications of both the extrapolation and dwell approaches show that neither produces an analysis that yields a material response consistent with the known behavior of zinc. further analysis shows that the edge geometry modifies the shear zone of the material and thereby modifies the forces. when analyzed this way, the measured force data yield the expected material response without requiring recourse to an additional ploughing component","['tool edge geometry', 'edge geometry', 'orthogonal machining', 'cutting tool', 'metal cutting', 'extrapolation', 'dwell force', 'zinc', 'ploughing component']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['tool edge geometry', 'edge geometry', 'orthogonal machining', 'cut tool', 'metal cutting', 'extrapolation', 'dwell force', 'zinc', 'plough component']","['cut tool affect', 'orthogonal machining', 'metal cutting', 'measure force', 'force measure', 'edge geometry', 'force technique', 'cut', 'edge radius', 'plough']"
639,1179,Evolution complexity of the elementary cellular automaton rule 18,"cellular automata are classes of mathematical systems characterized by discreteness (in space, time, and state values), determinism, and local interaction. using symbolic dynamical theory, we coarse-grain the temporal evolution orbits of cellular automata. by means of formal languages and automata theory, we study the evolution complexity of the elementary cellular automaton with local rule number 18 and prove that its width 1-evolution language is regular, but for every n >or= 2 its width n-evolution language is not context free but context sensitive","['evolution complexity', 'complexity', 'elementary cellular automaton', 'cellular automata', 'symbolic dynamical theory', 'formal languages']","['P', 'P', 'P', 'P', 'P', 'P']","['evolution complexity', 'complexity', 'elementary cellular automaton', 'cellular automata', 'symbolic dynamical theory', 'formal language']","['cellular automata', 'elementary cellular automaton', 'symbolic dynamical theory', 'automata theory', 'temporal evolution orbit', 'evolution complexity', 'mathematical system characterize', 'evolution language', 'formal language', 'local rule number']"
640,1285,On fractal dimension in information systems. Toward exact sets in infinite information systems,"the notions of an exact as well as a rough set are well-grounded as basic notions in rough set theory. they are however defined in the setting of a finite information system i.e. an information system having finite numbers of objects as well as attributes. in theoretical studies e.g. of topological properties of rough sets, one has to trespass this limitation and to consider information systems with potentially unbound number of attributes. in such setting, the notions of rough and exact sets may be defined in terms of topological operators of interior and closure with respect to an appropriate topology following the ideas from the finite case, where it is noticed that in the finite case rough-set-theoretic operators of lower and upper approximation are identical with the interior, respectively, closure operators in topology induced by equivalence classes of the indiscernibility relation. extensions of finite information systems are also desirable from application point of view in the area of knowledge discovery and data mining, when demands of e.g. mass collaboration and/or huge experimental data call for need of working with large data tables so the sound theoretical generalization of these cases is an information system with the number of attributes not bound in advance by a fixed integer i.e. an information system with countably but infinitely many attributes, in large information systems, a need arises for qualitative measures of complexity of concepts involved free of parameters, cf. e.g. applications for the vapnik-czervonenkis dimension. we study here in the theoretical setting of infinite information system a proposal to apply fractal dimensions suitably modified as measures of concept complexity","['fractal dimension', 'information systems', 'exact sets', 'infinite information systems', 'rough set', 'topological properties', 'closure operators', 'equivalence classes', 'knowledge discovery', 'data mining', 'qualitative measures', 'complexity']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['fractal dimension', 'information system', 'exact set', 'infinite information system', 'rough set', 'topological property', 'closure operator', 'equivalence class', 'knowledge discovery', 'datum mining', 'qualitative measure', 'complexity']","['finite information system', 'rough set theory', 'rough set', 'consider information system', 'finite information system', 'large information system', 'topological property', 'finite case rough', 'basic notion', 'topological operator']"
641,695,Design of high-performance wavelets for image coding using a perceptual time domain criterion,"this paper presents a new biorthogonal linear-phase wavelet design for image compression. instead of calculating the prototype filters as spectral factors of a half-band filter, the design is based on the direct optimization of the low pass analysis filter using an objective function directly related to a perceptual criterion for image compression. this function is defined as the product of the theoretical coding gain and an index called the peak-to-peak ratio, which was shown to have high correlation with perceptual quality. a distinctive feature of the proposed technique is a procedure by which, given a ""good"" starting filter, ""good"" filters of longer lengths are generated. the results are excellent, showing a clear improvement in perceptual image quality. also, we devised a criterion for constraining the coefficients of the filters in order to design wavelets with minimum ringing","['high-performance wavelets', 'image coding', 'perceptual time domain criterion', 'biorthogonal linear-phase wavelet design', 'image compression', 'prototype filters', 'half-band filter', 'analysis filter', 'objective function', 'coding gain', 'peak-to-peak ratio', 'perceptual image quality', 'low pass filter', 'filter banks']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['high - performance wavelet', 'image code', 'perceptual time domain criterion', 'biorthogonal linear - phase wavelet design', 'image compression', 'prototype filter', 'half - band filter', 'analysis filter', 'objective function', 'code gain', 'peak - to - peak ratio', 'perceptual image quality', 'low pass filter', 'filter bank']","['phase wavelet design', 'design wavelet', 'perceptual image quality', 'low pass analysis filter', 'image compression', 'perceptual quality', 'band filter', 'filter', 'filter', 'perceptual criterion']"
642,1278,Verification of timed automata based on similarity,"the paper presents a modification of the standard partitioning technique to generate abstract state spaces preserving similarity for timed automata. since this relation is weaker than bisimilarity, most of the obtained models (state spaces) are smaller than bisimilar ones, but still preserve the universal fragments of branching time temporal logics. the theoretical results are exemplified for strong, delay, and observational simulation relations","['partitioning technique', 'abstract state spaces', 'bisimilarity', 'universal fragments', 'branching time temporal logics', 'observational simulation relations', 'timed automata verification']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['partition technique', 'abstract state space', 'bisimilarity', 'universal fragment', 'branch time temporal logic', 'observational simulation relation', 'time automata verification']","['branch time temporal logic', 'generate abstract state space preserve similarity', 'time automata', 'state space', 'universal fragment', 'bisimilar one', 'standard partitioning', 'model', 'bisimilarity', 'delay']"
643,1184,Measuring return: revealing ROI,"the most critical part of the return-on-investment odyssey is to develop metrics that matter to the business and to measure systems in terms of their ability to help achieve those business goals. everything must flow from those key metrics. and don't forget to revisit those every now and then, too. since all systems wind down over time, it's important to keep tabs on how well your automation investment is meeting the metrics established by your company. manufacturers are clamoring for a tool to help quantify returns and analyze the results","['roi', 'return-on-investment', 'key metrics', 'automation investment', 'technology purchases']","['P', 'P', 'P', 'P', 'U']","['roi', 'return - on - investment', 'key metric', 'automation investment', 'technology purchase']","['automation investment', 'develop metric', 'investment odyssey', 'quantify return', 'metric establish', 'key metric', 'measure system', 'business goal', 'manufacturer', 'system']"
644,100,Separate accounts go mainstream [investment],new entrants are shaking up the separate-account industry by supplying web-based platforms that give advisers the tools to pick independent money managers,"['investment', 'separate-account industry', 'web-based platforms', 'independent money managers', 'financial advisors']","['P', 'P', 'P', 'P', 'U']","['investment', 'separate - account industry', 'web - base platform', 'independent money manager', 'financial advisor']","['account industry', 'base platform', 'supply web', 'give adviser', 'new entrant', 'separate', 'tool', 'shake']"
645,943,Implementation of universal quantum gates based on nonadiabatic geometric phases,"we propose an experimentally feasible scheme to achieve quantum computation based on nonadiabatic geometric phase shifts, in which a cyclic geometric phase is used to realize a set of universal quantum gates. physical implementation of this set of gates is designed for josephson junctions and for nmr systems. interestingly, we find that the nonadiabatic phase shift may be independent of the operation time under appropriate controllable conditions. a remarkable feature of the present nonadiabatic geometric gates is that there is no intrinsic limitation on the operation time","['universal quantum gates', 'quantum computation', 'nonadiabatic geometric phase shifts', 'cyclic geometric phase', 'josephson junctions', 'nmr systems', 'nonadiabatic phase shift', 'operation time', 'nonadiabatic geometric gates']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['universal quantum gate', 'quantum computation', 'nonadiabatic geometric phase shift', 'cyclic geometric phase', 'josephson junction', 'nmr system', 'nonadiabatic phase shift', 'operation time', 'nonadiabatic geometric gate']","['universal quantum gate', 'achieve quantum computation', 'present nonadiabatic geometric gate', 'nonadiabatic geometric phase shift', 'josephson junction', 'cyclic geometric phase', 'nonadiabatic phase shift', 'gate', 'nmr system', 'operation time']"
646,145,If the RedBoot fits [open-source ROM monitor],"many embedded developers today use a rom- or flash-resident software program that provides functionality such as loading and running application software, scripting, read/write access to processor registers, and memory dumps. a rom monitor, as it is often called, can be a useful and far less expensive debugging tool than an in-circuit emulator. this article describes the redboot rom monitor. it takes a look at the features offered by the redboot rom monitor and sees how it can be configured. it also walks through the steps of rebuilding and installing a new redboot image on a target platform. finally, it looks at future enhancements that are coming in new releases and how to get support and additional information when using redboot. although redboot uses software modules from the ecos real-time operating system (rtos) and is often used in systems running embedded linux, it is completely independent of both operating systems. redboot can be used with any operating system or rtos, or even without one","['redboot', 'open-source rom monitor', 'flash-resident software program', 'scripting', 'memory dumps', 'debugging tool', 'ecos', 'real-time operating system', 'embedded linux', 'embedded systems', 'processor register access', 'bootstrapping']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U']","['redboot', 'open - source rom monitor', 'flash - resident software program', 'script', 'memory dump', 'debug tool', 'ecos', 'real - time operating system', 'embed linux', 'embed system', 'processor register access', 'bootstrappe']","['redboot rom monitor', 'redboot use software module', 'system run embed linux', 'new redboot image', 'use redboot', 'rom monitor', 'redboot', 'many embed developer', 'expensive debugging tool', 'run application software']"
647,906,High-performance servo systems based on multirate sampling control,"in this paper, novel multirate two-degree-of-freedom controllers are proposed for digital control systems, in which the sampling period of plant output is restricted to be relatively longer than the control period of plant input. the proposed feedforward controller assures perfect tracking at m inter-sampling points. on the other hand, the proposed feedback controller assures perfect disturbance rejection at m inter-sample points in the steady state. illustrative examples of position control for hard disk drive are presented, and advantages of these approaches are demonstrated","['servo system', 'multirate sampling control', 'digital control systems', 'feedforward', 'tracking', 'feedback', 'disturbance rejection', 'position control', 'hard disk drive']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['servo system', 'multirate sampling control', 'digital control system', 'feedforward', 'track', 'feedback', 'disturbance rejection', 'position control', 'hard disk drive']","['digital control system', 'feedback controller', 'feedforward controller', 'freedom controller', 'position control', 'control period', 'disk drive', 'multirate', 'sample period', 'plant output']"
648,594,Improved analysis for the nonlinear performance of CMOS current mirrors with device mismatch,the nonlinear performance of the simple and complementary mosfet current mirrors are analyzed. closed-form expressions are obtained for the harmonic and intermodulation components resulting from a multisinusoidal input current. these expressions can be used for predicting the limiting values of the input current under prespecified conditions of threshold-voltage mismatches and/or transconductance mismatches. the case of a single input sinusoid is discussed in detail and the results are compared with spice simulations,"['nonlinear performance', 'cmos current mirrors', 'device mismatch', 'complementary mosfet current mirrors', 'closed-form expressions', 'intermodulation components', 'multisinusoidal input current', 'input current', 'threshold-voltage mismatch', 'transconductance mismatch', 'spice simulations', 'harmonic components', 'simulation results']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['nonlinear performance', 'cmos current mirror', 'device mismatch', 'complementary mosfet current mirror', 'close - form expression', 'intermodulation component', 'multisinusoidal input current', 'input current', 'threshold - voltage mismatch', 'transconductance mismatch', 'spice simulation', 'harmonic component', 'simulation result']","['complementary mosfet current mirror', 'transconductance mismatch', 'voltage mismatch', 'multisinusoidal', 'nonlinear performance', 'current', 'sinusoid', 'harmonic', 'intermodulation component', 'form']"
649,610,AGC for autonomous power system using combined intelligent techniques,"in the present work two intelligent load frequency controllers have been developed to regulate the power output and system frequency by controlling the speed of the generator with the help of fuel rack position control. the first controller is obtained using fuzzy logic (fl) only, whereas the second one by using a combination of fl, genetic algorithms and neural networks. the aim of the proposed controller(s) is to restore in a very smooth way the frequency to its nominal value in the shortest time possible whenever there is any change in the load demand etc. the action of these controller(s) provides a satisfactory balance between frequency overshoot and transient oscillations with zero steady-state error. the design and performance evaluation of the proposed controller(s) structure are illustrated with the help of case studies applied (without loss of generality) to a typical single-area power system. it is found that the proposed controllers exhibit satisfactory overall dynamic performance and overcome the possible drawbacks associated with other competing techniques","['autonomous power system', 'combined intelligent techniques', 'frequency control', 'fuel rack position control', 'fuzzy logic', 'genetic algorithms', 'neural networks', 'load demand', 'frequency overshoot', 'transient oscillations', 'zero steady-state error', 'performance evaluation', 'single-area power system', 'overall dynamic performance', 'competing techniques', 'power output regulation', 'generator speed control', 'controller design']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['autonomous power system', 'combine intelligent technique', 'frequency control', 'fuel rack position control', 'fuzzy logic', 'genetic algorithm', 'neural network', 'load demand', 'frequency overshoot', 'transient oscillation', 'zero steady - state error', 'performance evaluation', 'single - area power system', 'overall dynamic performance', 'compete technique', 'power output regulation', 'generator speed control', 'controller design']","['intelligent load frequency controller', 'fuel rack position control', 'frequency overshoot', 'controller', 'system frequency', 'use fuzzy logic', 'generator', 'frequency', 'transient oscillation', 'power output']"
650,655,Mapping CCF to MARC21: an experimental approach,"the purpose of this article is to raise and address a number of issues pertaining to the conversion of common communication format (ccf) into marc21. in this era of global resource sharing, exchange of bibliographic records from one system to another is imperative in today's library communities. instead of using a single standard to create machine-readable catalogue records, more than 20 standards have emerged and are being used by different institutions. because of these variations in standards, sharing of resources and transfer of data from one system to another among the institutions locally and globally has become a significant problem. addressing this problem requires keeping in mind that countries such as india and others in southeast asia are using the ccf as a standard for creating bibliographic cataloguing records. this paper describes a way to map the bibliographic catalogue records from ccf to marc21, although 100% mapping is not possible. in addition, the paper describes an experimental approach that enumerates problems that may occur during the mapping of records/exchanging of records and how these problems can be overcome","['marc21', 'global resource sharing', 'library communities', 'standards', 'machine-readable catalogue records', 'india', 'southeast asia', 'common communication format conversion', 'bibliographic records exchange', 'data transfer', 'ccf to marc21 mapping']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R']","['marc21', 'global resource sharing', 'library community', 'standard', 'machine - readable catalogue record', 'india', 'southeast asia', 'common communication format conversion', 'bibliographic record exchange', 'datum transfer', 'ccf to marc21 mapping']","['create bibliographic catalogue record', 'bibliographic catalogue record', 'readable catalogue record', 'bibliographic record', 'global resource sharing', 'common communication format', 'library community', 'address', 'standard', 'different institution']"
651,1200,From continuous recovery to discrete filtering in numerical approximations of conservation laws,"modern numerical approximations of conservation laws rely on numerical dissipation as a means of stabilization. the older, alternative approach is the use of central differencing with a dose of artificial dissipation. in this paper we review the successful class of weighted essentially non-oscillatory finite volume schemes which comprise sophisticated methods of the first kind. new developments in image processing have made new devices possible which can serve as highly nonlinear artificial dissipation terms. we view artificial dissipation as discrete filter operation and introduce several new algorithms inspired by image processing","['continuous recovery', 'discrete filtering', 'numerical approximations', 'conservation laws', 'numerical dissipation', 'central differencing', 'artificial dissipation', 'finite volume schemes', 'image processing', 'highly nonlinear artificial dissipation terms', 'discrete filter operation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['continuous recovery', 'discrete filtering', 'numerical approximation', 'conservation law', 'numerical dissipation', 'central differencing', 'artificial dissipation', 'finite volume scheme', 'image processing', 'highly nonlinear artificial dissipation term', 'discrete filter operation']","['nonlinear artificial dissipation term', 'numerical dissipation', 'modern numerical approximation', 'oscillatory finite volume scheme', 'view artificial dissipation', 'artificial dissipation', 'discrete filter operation', 'several new algorithm inspire', 'conservation law rely', 'stabilization']"
652,1245,A brief guide to competitive intelligence: how to gather and use information on competitors,"the author outlines the processes involved in competitive intelligence, and discusses what it is, how to do it and gives examples of what happens when companies fail to monitor their competitive environment effectively. the author presents a case study, showing how the company that produced the pre-cursor to the barbie doll failed to look at their business environment and how this led to the firm's failure. the author discusses what competitive intelligence is, and what it is not, and why it is important for businesses, and presents three models used to describe the competitive intelligence process, going through the various steps involved in defining intelligence requirements and collecting, analyzing, communicating and utilizing competitive intelligence","['competitive intelligence', 'barbie doll', 'business environment', 'competitor information', 'intelligence collection', 'intelligence analysis', 'intelligence communication', 'intelligence utilization']","['P', 'P', 'P', 'R', 'R', 'M', 'R', 'R']","['competitive intelligence', 'barbie doll', 'business environment', 'competitor information', 'intelligence collection', 'intelligence analysis', 'intelligence communication', 'intelligence utilization']","['competitive intelligence process', 'competitive intelligence', 'define intelligence requirement', 'competitive environment', 'business environment', 'company fail', 'barbie doll fail', 'process involve', 'business', 'analyze']"
653,983,Limitations of delayed state feedback: a numerical study,"stabilization of a class of linear time-delay systems can be achieved by a numerical procedure, called the continuous pole placement method [michiels et al., 2000]. this method can be seen as an extension of the classical pole placement algorithm for ordinary differential equations to a class of delay differential equations. in [michiels et al., 2000] it was applied to the stabilization of a linear time-invariant system with an input delay using static state feedback. in this paper we study the limitations of such delayed state feedback laws. more precisely we completely characterize the class of stabilizable plants in the 2d-case. for that purpose we make use of numerical continuation techniques. the use of delayed state feedback in various control applications and the effect of its limitations are briefly discussed","['delayed state feedback', 'linear time-delay systems', 'continuous pole placement method', 'delay differential equations', 'static state feedback', 'numerical continuation']","['P', 'P', 'P', 'P', 'P', 'P']","['delay state feedback', 'linear time - delay system', 'continuous pole placement method', 'delay differential equation', 'static state feedback', 'numerical continuation']","['continuous pole placement method', 'classical pole placement algorithm', 'delay state feedback', 'delay system', 'stabilization', 'delay differential equation', 'stabilizable plant', 'numerical continuation technique', 'static state feedback', 'control application']"
654,554,A scalable and lightweight QoS monitoring technique combining passive and active approaches: on the mathematical formulation of CoMPACT monitor,"to make a scalable and lightweight qos monitoring system, we (2002) have proposed a new qos monitoring technique, called the change-of-measure based passive/active monitoring (compact monitor), which is based on the change-of-measure framework and is an active measurement transformed by using passively monitored data. this technique enables us to measure detailed qos information for individual users, applications and organizations, in a scalable and lightweight manner. in this paper, we present the mathematical foundation of compact monitor. in addition, we show its characteristics through simulations in terms of typical implementation issues for inferring the delay distributions. the results show that compact monitor gives accurate qos estimations with only a small amount of extra traffic for active measurement","['qos monitoring', 'compact monitor', 'change-of-measure', 'active monitoring', 'passive monitoring', 'delay distributions', 'quality of service', 'internet', 'network performance']","['P', 'P', 'P', 'P', 'P', 'P', 'M', 'U', 'U']","['qos monitoring', 'compact monitor', 'change - of - measure', 'active monitoring', 'passive monitoring', 'delay distribution', 'quality of service', 'internet', 'network performance']","['lightweight qos monitoring system', 'new qos monitoring', 'measure detail qos information', 'accurate qos estimation', 'active monitoring', 'measure base passive', 'monitor datum', 'compact monitor', 'active measurement', 'measure framework']"
655,1101,Evaluation of existing and new feature recognition algorithms. 1. Theory and implementation,"this is the first of two papers evaluating the performance of general-purpose feature detection techniques for geometric models. in this paper, six different methods are described to identify sets of faces that bound depression and protrusion faces. each algorithm has been implemented and tested on eight components from the national design repository. the algorithms studied include previously published general-purpose feature detection algorithms such as the single-face inner-loop and concavity techniques. others are improvements to existing algorithms such as extensions of the two-dimensional convex hull method to handle curved faces as well as protrusions. lastly, new algorithms based on the three-dimensional convex hull, minimum concave, visible and multiple-face inner-loop face sets are described","['feature recognition algorithms', 'general-purpose feature detection techniques', 'geometric models', 'sets of faces', 'protrusion faces', 'national design repository', 'concavity technique', 'two-dimensional convex hull method', 'curved faces', 'three-dimensional convex hull', 'minimum concave', 'multiple-face inner-loop face sets', 'depression faces', 'single-face inner-loop technique', 'cad/cam software', 'geometric reasoning algorithms', 'visible inner-loop face sets']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U', 'M', 'R']","['feature recognition algorithm', 'general - purpose feature detection technique', 'geometric model', 'set of face', 'protrusion face', 'national design repository', 'concavity technique', 'two - dimensional convex hull method', 'curve face', 'three - dimensional convex hull', 'minimum concave', 'multiple - face inner - loop face set', 'depression face', 'single - face inner - loop technique', 'cad / cam software', 'geometric reasoning algorithm', 'visible inner - loop face set']","['purpose feature detection algorithm such', 'purpose feature detection technique', 'handle curve face', 'dimensional convex hull method', 'protrusion face', 'dimensional convex hull', 'loop face set', 'geometric model', 'face', 'minimum concave']"
656,1144,Simultaneous iterative reconstruction of emission and attenuation images in positron emission tomography from emission data only,"for quantitative image reconstruction in positron emission tomography attenuation correction is mandatory. in case that no data are available for the calculation of the attenuation correction factors one can try to determine them from the emission data alone. however, it is not clear if the information content is sufficient to yield an adequate attenuation correction together with a satisfactory activity distribution. therefore, we determined the log likelihood distribution for a thorax phantom depending on the choice of attenuation and activity pixel values to measure the crosstalk between both. in addition an iterative image reconstruction (one-dimensional newton-type algorithm with a maximum likelihood estimator), which simultaneously reconstructs the images of the activity distribution and the attenuation coefficients is used to demonstrate the problems and possibilities of such a reconstruction. as result we show that for a change of the log likelihood in the range of statistical noise, the associated change in the activity value of a structure is between 6% and 263%. in addition, we show that it is not possible to choose the best maximum on the basis of the log likelihood when a regularization is used, because the coupling between different structures mediated by the (smoothing) regularization prevents an adequate solution due to crosstalk. we conclude that taking into account the attenuation information in the emission data improves the performance of image reconstruction with respect to the bias of the activities, however, the reconstruction still is not quantitative","['image reconstruction', 'positron emission tomography attenuation correction', 'attenuation correction factors', 'activity distribution', 'log likelihood distribution', 'thorax phantom', 'activity pixel values', 'crosstalk', 'iterative image reconstruction', 'one-dimensional newton-type algorithm', 'maximum likelihood estimator', 'attenuation coefficients', 'statistical noise', 'smoothing', 'attenuation information']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['image reconstruction', 'positron emission tomography attenuation correction', 'attenuation correction factor', 'activity distribution', 'log likelihood distribution', 'thorax phantom', 'activity pixel value', 'crosstalk', 'iterative image reconstruction', 'one - dimensional newton - type algorithm', 'maximum likelihood estimator', 'attenuation coefficient', 'statistical noise', 'smooth', 'attenuation information']","['positron emission tomography attenuation', 'iterative image reconstruction', 'quantitative image reconstruction', 'log likelihood distribution', 'maximum likelihood estimator', 'thorax phantom depend', 'image reconstruction', 'log likelihood', 'regularization', 'activity pixel value']"
657,92,Wireless-retail financial services: adoption can't justify the cost,"slow adoption by retail investors, costly services and bankrupt vendors has prompted banks and brokerage firms to turn off their wireless applications","['banks', 'brokerage firms', 'wireless applications']","['P', 'P', 'P']","['bank', 'brokerage firm', 'wireless application']","['retail investor', 'brokerage firm', 'bankrupt vendor', 'prompt bank', 'slow adoption', 'costly service', 'turn']"
658,1059,Mustering motivation to enact decisions: how decision process characteristics influence goal realization,"decision scientists tend to focus mainly on decision antecedents, studying how people make decisions. action psychologists, in contrast, study post-decision issues, investigating how decisions, once formed, are maintained, protected, and enacted. through the research presented here, we seek to bridge these two disciplines, proposing that the process by which decisions are reached motivates subsequent pursuit and benefits eventual realization. we identify three characteristics of the decision process (dp) as having motivation-mustering potential: dp effort investment, dp importance, and dp confidence. through two field studies tracking participants' decision processes, pursuit and realization, we find that after controlling for the influence of the motivational mechanisms of goal intention and implementation intention, the three decision process characteristics significantly influence the successful enactment of the chosen decision directly. the theoretical and practical implications of these findings are considered and future research opportunities are identified","['motivation', 'decision process characteristics', 'goal realization', 'decision scientists', 'action psychologists', 'post-decision issues', 'motivation-mustering potential', 'goal intention', 'research opportunities', 'decision enactment', 'decision process investment', 'decision process importance', 'decision process confidence']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R']","['motivation', 'decision process characteristic', 'goal realization', 'decision scientist', 'action psychologist', 'post - decision issue', 'motivation - muster potential', 'goal intention', 'research opportunity', 'decision enactment', 'decision process investment', 'decision process importance', 'decision process confidence']","['reach motivate subsequent pursuit', 'decision process characteristic', 'decision antecedent', 'goal intention', 'people make decision', 'dp effort investment', 'decision process', 'choose decision', 'benefit eventual realization', 'motivational mechanism']"
659,1358,Analysis of the surface roughness and dimensional accuracy capability of fused deposition modelling processes,"building up materials in layers poses significant challenges from the viewpoint of material science, heat transfer and applied mechanics. however, numerous aspects of the use of these technologies have yet to be studied. one of these aspects is the characterization of the surface roughness and dimensional precision obtainable in layered manufacturing processes. in this paper, a study of roughness parameters obtained through the use of these manufacturing processes was made. prototype parts were manufactured using fdm techniques and an experimental analysis of the resulting roughness average (r/sub a/) and rms roughness (r/sub q/) obtained through the use of these manufacturing processes was carried out. dimensional parameters were also studied in order to determine the capability of the fused deposition modelling process for manufacturing parts","['surface roughness', 'dimensional accuracy capability', 'fused deposition modelling processes', 'dimensional precision', 'layered manufacturing processes', 'prototype parts', 'roughness average', 'rms roughness', 'rapid prototyping', 'three-dimensional solid objects', 'cad model', 'cnc-controlled robot', 'extrusion head']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U', 'M', 'U', 'U']","['surface roughness', 'dimensional accuracy capability', 'fuse deposition modelling process', 'dimensional precision', 'layer manufacturing process', 'prototype part', 'roughness average', 'rm roughness', 'rapid prototyping', 'three - dimensional solid object', 'cad model', 'cnc - control robot', 'extrusion head']","['surface roughness', 'roughness average', 'layer manufacturing process', 'fuse deposition modelling process', 'rm roughness', 'roughness parameter', 'manufacture process', 'dimensional precision', 'dimensional parameter', 'prototype part']"
660,748,Simulation study of the cardiovascular functional status in hypertensive situation,"an extended cardiovascular model was established based on our previous work to study the consequences of physiological or pathological changes to the homeostatic functions of the cardiovascular system. to study hemodynamic changes in hypertensive situations, the impacts of cardiovascular parameter variations (peripheral vascular resistance, arterial vessel wall stiffness and baroreflex gain) upon hemodynamics and the short-term regulation of the cardiovascular system were investigated. for the purpose of analyzing baroregulation function, the short-term regulation of arterial pressure in response to moderate dynamic exercise for normotensive and hypertensive cases was studied through computer simulation and clinical experiments. the simulation results agree well with clinical data. the results of this work suggest that the model presented in this paper provides a useful tool to investigate the functional status of the cardiovascular system in normal or pathological conditions","['cardiovascular functional status', 'hypertensive situation', 'extended cardiovascular model', 'pathological changes', 'homeostatic functions', 'hemodynamics', 'cardiovascular parameter variations', 'peripheral vascular resistance', 'arterial vessel wall stiffness', 'baroreflex gain', 'short-term regulation', 'arterial pressure', 'moderate dynamic exercise', 'computer simulation', 'clinical experiments', 'physiological changes', 'normotensive cases']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['cardiovascular functional status', 'hypertensive situation', 'extend cardiovascular model', 'pathological change', 'homeostatic function', 'hemodynamic', 'cardiovascular parameter variation', 'peripheral vascular resistance', 'arterial vessel wall stiffness', 'baroreflex gain', 'short - term regulation', 'arterial pressure', 'moderate dynamic exercise', 'computer simulation', 'clinical experiment', 'physiological change', 'normotensive case']","['cardiovascular parameter variation', 'arterial vessel wall stiffness', 'extend cardiovascular model', 'arterial pressure', 'cardiovascular system', 'moderate dynamic exercise', 'peripheral vascular resistance', 'hypertensive situation', 'hemodynamic change', 'hypertensive']"
661,826,"A round of cash, a pound of flesh [telecom]","despite the upheaval across telecom, venture capital firms are still investing in start-ups. but while a promising idea and a catchy name were enough to guarantee millions in funding at the peak of the dotcom frenzy, now start-ups must prove-their long-term viability, and be willing to concede control of their business to their vc suitors","['telecom', 'venture capital firms', 'viability']","['P', 'P', 'P']","['telecom', 'venture capital firm', 'viability']","['venture capital firm', 'dotcom frenzy', 'promising idea', 'guarantee million', 'start', 'funding', 'invest', 'term viability', 'business', 'telecom']"
662,863,A scanline-based algorithm for the 2D free-form bin packing problem,"this paper describes a heuristic algorithm for the 2d free-form bin packing (2d-fbp) problem. given a set of 2d free-form bins and a set of 2d free-form items, the 2d-fbp problem is to lay out items inside one or more bins in such a way that the number of bins used is minimized, and for each bin, the yield is maximized. the proposed algorithm handles the problem as a variant of the 1d problem; i.e., items and bins are approximated as sets of scanlines, and scanlines are packed. the details of the algorithm are given, and its application to a nesting problem in a shipbuilding company is reported. the proposed algorithm consists of the basic and the group placement algorithms. the basic placement algorithm is a variant of the first-fit decreasing algorithm which is simply extended from the 1d case to the 2d case by a novel scanline approximation. a numerical study with real instances shows that the basic placement algorithm has sufficient performance for most of the instances, however, the group placement algorithm is required when items must be aligned in columns. the qualities of the resulting layouts are good enough for practical use, and the processing times are good","['scanline-based algorithm', '2d free-form bin packing problem', 'heuristic algorithm', '2d-fbp problem', 'minimization', 'nesting problem', 'shipbuilding company', 'group placement algorithm', 'first-fit decreasing algorithm', 'irregular cutting', 'irregular packing', 'yield maximization']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'M', 'R']","['scanline - base algorithm', '2d free - form bin packing problem', 'heuristic algorithm', '2d - fbp problem', 'minimization', 'nesting problem', 'shipbuilde company', 'group placement algorithm', 'first - fit decreasing algorithm', 'irregular cutting', 'irregular packing', 'yield maximization']","['form bin packing', 'group placement algorithm', 'basic placement algorithm have sufficient performance', 'group placement algorithm', 'heuristic algorithm', 'basic placement algorithm', 'form bin', 'propose algorithm consist', 'propose algorithm', 'bin']"
663,1430,The free lunch is over: online content subscriptions on the rise,"high need, rather than high use, may be what really determines a user's willingness to pay. retooling and targeting content may be a sharper strategy than trying to re-educate users that it is time to pay up for material that has been free. waiting for a paradigm shift in general user attitudes about paying for online content could be a fool's errand","['online content subscriptions', 'content retooling', 'content targeting', 'pay-to-play business models']","['P', 'R', 'R', 'U']","['online content subscription', 'content retooling', 'content target', 'pay - to - play business model']","['target content', 'pay', 'online content', 'pay', 'educate user', 'willingness', 'free', 'high use', 'general user attitude', 'sharp strategy']"
664,570,Prediction and compensation of dynamic errors for coordinate measuring machines,"coordinate measuring machines (cmms) are already widely utilized as measuring tools in the modem manufacturing industry. rapidly approaching now is the trend for next-generation cmms. however, the increases in measuring velocity of cmm applications are limited by dynamic errors that occur in cmms. in this paper a systematic approach for modeling the dynamic errors of a touch-trigger probe cmm is developed through theoretical analysis and experimental study. an overall analysis of the dynamic errors of cmms is conducted, with weak components of the cmm identified by a laser interferometer. the probing process, as conducted with a touch-trigger probe, is analyzed. the dynamic errors are measured, modeled, and predicted using neural networks. the results indicate that, using this mode, it is possible to compensate for the dynamic errors of cmms","['compensation', 'dynamic errors', 'coordinate measuring machines', 'manufacturing industry', 'touch-trigger probe', 'laser interferometer', 'neural networks', 'inertial forces']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'U']","['compensation', 'dynamic error', 'coordinate measure machine', 'manufacture industry', 'touch - trigger probe', 'laser interferometer', 'neural network', 'inertial force']","['trigger probe cmm', 'coordinate measure machine', 'laser interferometer', 'modem manufacture industry', 'trigger probe', 'measure tool', 'predict use neural network', 'measure velocity', 'cmms', 'dynamic error']"
665,1125,Structure of weakly invertible semi-input-memory finite automata with delay 1,"semi-input-memory finite automata, a kind of finite automata introduced by the first author of this paper for studying error propagation, are a generalization of input memory finite automata by appending an autonomous finite automaton component. in this paper, we give a characterization of the structure of weakly invertible semi-input-memory finite automata with delay 1, in which the state graph of each autonomous finite automaton is a cycle. from a result on mutual invertibility of finite automata obtained by the authors recently, it leads to a characterization of the structure of feedforward inverse finite automata with delay 1","['weakly invertible', 'invertibility', 'semi-input-memory', 'semi-input-memory finite automata', 'finite automata', 'delay 1', 'state graph', 'feedforward inverse finite automata']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['weakly invertible', 'invertibility', 'semi - input - memory', 'semi - input - memory finite automata', 'finite automata', 'delay 1', 'state graph', 'feedforward inverse finite automata']","['feedforward inverse finite automata', 'input memory finite automata', 'autonomous finite automaton component', 'memory finite automata', 'autonomous finite automaton', 'finite automata obtain', 'finite automata introduce', 'weakly invertible semi', 'mutual invertibility', 'state graph']"
666,1160,Monoids all polygons over which are omega -stable: proof of the Mustafin-Poizat conjecture,"a monoid s is called an omega -stabilizer (superstabilizer, or stabilizer) if every s-polygon has an omega -stable (superstable, or stable) theory. it is proved that every omega -stabilizer is a regular monoid. this confirms the mustafin-poizat conjecture and allows us to end up the description of omega -stabilizers","['monoids all polygons', 'mustafin-poizat conjecture', 'omega -stabilizer', 's-polygon', 'regular monoid']","['P', 'P', 'P', 'P', 'P']","['monoid all polygon', 'mustafin - poizat conjecture', 'omega -stabilizer', 's - polygon', 'regular monoid']","['regular monoid', 'monoid', 'poizat conjecture', 'stabilizer', 'superstabilizer', 'polygon have', 'stable', 'omega', 'superstable', 'theory']"
667,119,JPEG2000: standard for interactive imaging,"jpeg2000 is the latest image compression standard to emerge from the joint photographic experts group (jpeg) working under the auspices of the international standards organization. although the new standard does offer superior compression performance to jpeg, jpeg2000 provides a whole new way of interacting with compressed imagery in a scalable and interoperable fashion. this paper provides a tutorial-style review of the new standard, explaining the technology on which it is based and drawing comparisons with jpeg and other compression standards. the paper also describes new work, exploiting the capabilities of jpeg2000 in client-server systems for efficient interactive browsing of images over the internet","['jpeg2000', 'interactive imaging', 'image compression', 'joint photographic experts group', 'international standards organization', 'review', 'client-server systems', 'scalable compression', 'interoperable compression']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['jpeg2000', 'interactive imaging', 'image compression', 'joint photographic expert group', 'international standard organization', 'review', 'client - server system', 'scalable compression', 'interoperable compression']","['late image compression standard', 'offer superior compression performance', 'jpeg2000 provide', 'other compression standard', 'compress imagery', 'jpeg2000', 'joint photographic expert group', 'jpeg', 'efficient interactive browsing', 'image']"
668,634,An approximation to the F distribution using the chi-square distribution,"for the cumulative distribution function (c.d.f.) of the f distribution, f(x; k, n), with associated degrees of freedom, k and n, a shrinking factor approximation (sfa), g( lambda kx; k), is proposed for large n and any fixed k, where g(x; k) is the chi-square c.d.f. with degrees of freedom, k, and lambda = lambda (kx; n) is the shrinking factor. numerical analysis indicates that for n/k >or= 3, approximation accuracy of the sfa is to the fourth decimal place for most small values of k. this is a substantial improvement on the accuracy that is achievable using the normal, ordinary chi-square, and scheffe-tukey approximations. in addition, it is shown that the theoretical approximation error of the sfa, |f(x; k,n)-g( lambda kx; k)|, is o(1/n/sup 2/) uniformly over x","['f distribution', 'chi-square distribution', 'cumulative distribution function', 'degrees of freedom', 'shrinking factor approximation', 'numerical analysis']","['P', 'P', 'P', 'P', 'P', 'P']","['f distribution', 'chi - square distribution', 'cumulative distribution function', 'degree of freedom', 'shrink factor approximation', 'numerical analysis']","['shrink factor approximation', 'approximation accuracy', 'cumulative distribution function', 'theoretical approximation error', 'tukey approximation', 'numerical analysis indicate', 'fourth decimal', 'shrink factor', 'accuracy', 'most small value']"
669,671,Expert advice - how can my organisation take advantage of reverse auctions without jeopardising existing supplier relationships?,"in a recent survey, amr research found that companies that use reverse auctions to negotiate prices with suppliers typically achieve savings of between 10% and 15% on direct goods and between 20% and 25% on indirect goods, and can slash sourcing cycle times from months to weeks. suppliers, however, are less enthusiastic. they believe that these savings are achieved only by stripping the human element out of negotiations and evaluating bids on price alone, which drives down their profit margins. as a result, reverse auctions carry the risk of jeopardising long-term and trusted relationships. suppliers that have not been involved in a reverse auction before typically fear the bidding event itself - arguably the most theatrical and, therefore, most hyped-up part of the process. although it may only last one hour, weeks of preparation go into setting up a successful bidding event","['reverse auctions', 'supplier relationships', 'preparation', 'request for quotation']","['P', 'P', 'P', 'U']","['reverse auction', 'supplier relationship', 'preparation', 'request for quotation']","['use reverse auction', 'reverse auction', 'reverse auction', 'bidding event', 'evaluate bid', 'slash source cycle time', 'negotiate price', 'negotiation', 'profit margin', 'amr research find']"
670,1224,Formalization of weighted factors analysis,"weighted factors analysis (wefa) has been proposed as a new approach for elicitation, representation, and manipulation of knowledge about a given problem, generally at a high and strategic level. central to this proposal is that a group of experts in the area of the problem can identify a hierarchy of factors with positive or negative influences on the problem outcome. the tangible output of wefa is a directed weighted graph called a wefa graph. this is a set of nodes denoting factors that can directly or indirectly influence an overall aim of the graph. the aim is also represented by a node. each directed arc is a direct influence of one factor on another. a chain of directed arcs indicates an indirect influence. the influences may be identified as either positive or negative. for example, sales and costs are two factors that influence the aim of profitability in an organization. sales has a positive influence on profitability and costs has a negative influence on profitability. in addition, the relative significance of each influence is represented by a weight. we develop binary wefa which is a variant of wefa where the factors in the graph are restricted to being either true or false. imposing this restriction on a wefa graph allows us to be more precise about the meaning of the graph and of reasoning in it. binary wefa is a new proposal that provides a formal yet sufficiently simple language for logic-based argumentation for use by business people in decision-support and knowledge management. whilst binary wefa is expressively simpler than other logic-based argumentation formalisms, it does incorporate a novel formalization of the notion of significance","['weighted factors analysis', 'directed weighted graph', 'wefa graph', 'directed arc', 'profitability', 'organization', 'significance', 'binary wefa', 'reasoning', 'logic-based argumentation', 'decision-support', 'knowledge management', 'knowledge elicitation', 'knowledge representation', 'knowledge manipulation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['weight factor analysis', 'direct weight graph', 'wefa graph', 'direct arc', 'profitability', 'organization', 'significance', 'binary wefa', 'reason', 'logic - base argumentation', 'decision - support', 'knowledge management', 'knowledge elicitation', 'knowledge representation', 'knowledge manipulation']","['weight factor analysis', 'direct weight graph', 'nod denote factor', 'wefa graph allow', 'wefa graph', 'develop binary wefa', 'direct arc indicate', 'indirect influence', 'base argumentation formalism', 'binary wefa']"
671,1261,Topology-adaptive modeling of objects using surface evolutions based on 3D mathematical morphology,"level set methods were proposed mainly by mathematicians for constructing a model of a 3d object of arbitrary topology. however, those methods are computationally inefficient due to repeated distance transformations and increased dimensions. in the paper, we propose a new method of modeling fast objects of arbitrary topology by using a surface evolution approach based on mathematical morphology. given sensor data covering the whole object surface, the method begins with an initial approximation of the object by evolving a closed surface into a model topologically equivalent to the real object. the refined approximation is then performed using energy minimization. the method has been applied in several experiments using range data, and the results are reported in the paper","['topology-adaptive modeling', 'surface evolutions', '3d mathematical morphology', 'level set methods', '3d object', 'arbitrary topology', 'repeated distance transformations', 'initial approximation', 'refined approximation', 'energy minimization', 'range data', 'pseudo curvature flow']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U']","['topology - adaptive modeling', 'surface evolution', '3d mathematical morphology', 'level set method', '3d object', 'arbitrary topology', 'repeat distance transformation', 'initial approximation', 'refined approximation', 'energy minimization', 'range datum', 'pseudo curvature flow']","['model fast object', 'object surface', '3d object', 'surface evolution approach base', 'arbitrary topology', 'level set method', 'sensor datum cover', 'close surface', 'repeat distance transformation', 'mathematical morphology']"
672,802,A brief history of electronic reserves,"electronic reserves has existed as a library service for barely ten years, yet its history, however brief, is important as an indicator of the direction being taken by the profession of librarianship as a whole. recent improvements in technology and a desire to provide better service to students and faculty have resulted in the implementation of e-reserves by ever greater numbers of academic libraries. yet a great deal of confusion still surrounds the issue of copyright compliance. negotiation, litigation, and legislation in particular have framed the debate over the application of fair use to an e-reserves environment, and the question of whether or not permission fees should be paid to rights holders, but as of yet no definitive answers or standards have emerged","['electronic reserves', 'library service', 'librarianship', 'students', 'faculty', 'academic libraries', 'copyright compliance', 'negotiation', 'litigation', 'legislation', 'e-reserves environment', 'permission fees']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['electronic reserve', 'library service', 'librarianship', 'student', 'faculty', 'academic library', 'copyright compliance', 'negotiation', 'litigation', 'legislation', 'e - reserve environment', 'permission fee']","['copyright compliance', 'electronic reserve', 'permission fee', 'right holder', 'academic library', 'library service', 'reserve environment', 'librarianship', 'reserve', 'legislation']"
673,847,A gendered view of computer professionals: preliminary results of a survey,"the under-representation of women in the computing profession in many parts the western world has received our attention through numerous publications, the noticeable low representation of women at computer science conferences and in the lecture halls. over the past two decades, the situation had become worse. this paper seeks to add to the dialogue by presenting preliminary findings from a research project conducted in four countries. the aim of this research was to gain an insight into the perceptions future computer professionals hold on the category of employment loosely defined under the term of ""a computer professional."" one goal was to get insight into whether or not there is a difference between female and mate students regarding their view of computer professionals. other goals were to determine if there was any difference between female and male students in different parts of the world, as well as who or what most influences the students to undertake their courses in computing","['computing profession', 'employment', 'mate students', 'women under-representation', 'future computer professional perceptions', 'female students', 'computing courses']","['P', 'P', 'P', 'R', 'R', 'R', 'R']","['compute profession', 'employment', 'mate student', 'woman under - representation', 'future computer professional perception', 'female student', 'compute course']","['perception future computer professional hold', 'compute profession', 'computer professional', 'computer science conference', 'computer professional', 'research project conduct', 'male student', 'mate student regard', 'woman', 'present preliminary finding']"
674,1080,Car-caravan snaking. 2 Active caravan braking,"for part 1, see ibid., p.707-22. founded on the review and results of part 1, part 2 contains a description of the virtual design of an active braking system for caravans or other types of trailer, to suppress snaking vibrations, while being simple from a practical viewpoint. the design process and the design itself are explained. the performance is examined by simulations and it is concluded that the system is effective, robust and realizable with modest and available components","['car-caravan snaking', 'active caravan braking', 'virtual design', 'trailer', 'snaking vibrations suppression', 'dynamics']","['P', 'P', 'P', 'P', 'R', 'U']","['car - caravan snaking', 'active caravan braking', 'virtual design', 'trailer', 'snake vibration suppression', 'dynamic']","['active braking system', 'suppress snaking vibration', 'virtual design', 'caravan', 'trailer', 'practical viewpoint', 'design process', 'design', 'robust', 'system']"
675,1451,From information gateway to digital library management system: a case analysis,"this paper discusses the design, implementation and evolution of the cornell university library gateway using the case analysis method. it diagnoses the gateway within the conceptual framework of definitions and best practices associated with information gateways, portals, and emerging digital library management systems, in particular the product encompass","['information gateways', 'digital library management system', 'cornell university library gateway', 'portals', 'encompass', 'metadata']","['P', 'P', 'P', 'P', 'P', 'U']","['information gateway', 'digital library management system', 'cornell university library gateway', 'portal', 'encompass', 'metadata']","['cornell university library gateway use', 'emerge digital library management system', 'case analysis method', 'information gateway', 'gateway', 'conceptual framework', 'good practice associate', 'portal', 'paper discuss', 'design']"
676,1414,Survey says! [online world of polls and surveys],"many content managers miss the fundamental interactivity of the web by not using polls and surveys. using interactive features-like a poll or quiz-offers your readers an opportunity to become more engaged in your content. using a survey to gather feedback about your content provides cost-effective data to help make modifications or plot the appropriate course of action. the web has allowed us to take traditional market research and turn it on its ear. surveys and polls can be conducted faster and cheaper than with telephone and mail. but if you are running a web site, should you care about polls and surveys? do you know the difference between the two in web-speak?","['surveys', 'polls', 'content managers', 'site owners', 'world wide web', 'site feedback']","['P', 'P', 'P', 'M', 'M', 'R']","['survey', 'poll', 'content manager', 'site owner', 'world wide web', 'site feedback']","['use poll', 'survey', 'poll', 'use interactive feature', 'take traditional market research', 'web site', 'many content manager', 'poll', 'survey', 'gather feedback']"
677,1339,Edge-colorings with no large polychromatic stars,"given a graph g and a positive integer r, let f/sub r/(g) denote the largest number of colors that can be used in a coloring of e(g) such that each vertex is incident to at most r colors. for all positive integers n and r, we determine f/sub r/(k/sub n,n/) exactly and f/sub r/(k/sub n/) within 1. in doing so, we disprove a conjecture by y. manoussakis et al. (1996)","['polychromatic stars', 'positive integer', 'positive integer', 'edge colorings', 'positive integers']","['P', 'P', 'P', 'M', 'P']","['polychromatic star', 'positive integer', 'positive integer', 'edge coloring', 'positive integer']","['conjecture', 'color', 'color', 'large number', 'graph', 'positive integer', 'positive integer', 'vertex', 'disprove', 'most']"
678,791,The rise and fall and rise again of customer care,"taking care of customers has never gone out of style, but as the recession fades, interest is picking up in a significant retooling of the crm solutions banks have been using. the goal: usable knowledge to help improve service","['banks', 'usable knowledge', 'customer relationship management']","['P', 'P', 'M']","['bank', 'usable knowledge', 'customer relationship management']","['crm solution bank', 'usable knowledge', 'customer', 'recession fade', 'significant retooling', 'take care', 'interest', 'use', 'goal', 'pick']"
679,1381,An augmented spatial digital tree algorithm for contact detection in computational mechanics,"based on the understanding of existing spatial digital tree-based contact detection approaches, and the alternating digital tree (adt) algorithm in particular, a more efficient algorithm, termed the augmented spatial digital tree (asdt) algorithm, is proposed in the present work. the asdt algorithm adopts a different point representation scheme that uses only the lower comer vertex to represent a (hyper-)rectangle, with the upper comer vertex serving as the augmented information. consequently, the asdt algorithm can keep the working space the same as the original n-dimensional space and, in general, a much better balanced tree can be expected. this, together with the introduction of an additional bounding subregion for the rectangles associated with each tree node, makes it possible to significantly reduce the number of node visits in the region search, although each node visit may be slightly more expensive. three examples arising in computational mechanics are presented to provide an assessment of the performance of the asdt. the numerical results indicate that the asdt is, at least, over 3.9 times faster than the adt","['augmented spatial digital tree algorithm', 'contact detection', 'computational mechanics', 'upper comer vertex', 'alternating digital tree algorithm', 'augmented data structure', 'spatial binary tree-based contact detection approaches']","['P', 'P', 'P', 'P', 'R', 'M', 'M']","['augment spatial digital tree algorithm', 'contact detection', 'computational mechanic', 'upper comer vertex', 'alternate digital tree algorithm', 'augment datum structure', 'spatial binary tree - base contact detection approach']","['augment spatial digital tree', 'exist spatial digital tree', 'alternate digital tree', 'tree node', 'asdt algorithm adopt', 'asdt algorithm', 'contact detection approach', 'efficient algorithm', 'node visit', 'low comer vertex']"
680,1038,The analysis and control of longitudinal vibrations from wave viewpoint,"the analysis and control of longitudinal vibrations in a rod from feedback wave viewpoint are synthesized. both collocated and noncollocated feedback wave control strategies are explored. the control design is based on the local properties of wave transmission and reflection in the vicinity of the control force applied area, hence there is no complex closed form solution involved. the controller is designed to achieve various goals, such as absorbing the incoming vibration energy, creating a vibration free zone and eliminating standing waves in the structure. the findings appear to be very useful in practice due to the simplicity in the implementation of the controllers","['feedback waves', 'noncollocated feedback wave control', 'control design', 'wave transmission', 'control force', 'complex closed form solution', 'vibration energy', 'vibration free zone', 'standing waves', 'longitudinal vibration control', 'collocated feedback wave control', 'wave reflection']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['feedback wave', 'noncollocate feedback wave control', 'control design', 'wave transmission', 'control force', 'complex closed form solution', 'vibration energy', 'vibration free zone', 'stand wave', 'longitudinal vibration control', 'collocate feedback wave control', 'wave reflection']","['noncollocate feedback wave control', 'longitudinal vibration', 'vibration free zone', 'eliminate stand wave', 'feedback wave', 'vibration', 'rod', 'control design', 'controller', 'wave transmission']"
681,1040,CRONE control: principles and extension to time-variant plants with asymptotically constant coefficients,"the principles of crone control, a frequency-domain robust control design methodology based on fractional differentiation, are presented. continuous time-variant plants with asymptotically constant coefficients are analysed in the frequency domain, through their representation using time-variant frequency responses. a stability theorem for feedback systems including time-variant plants with asymptotically constant coefficients is proposed. finally, crone control is extended to robust control of these plants","['crone control', 'time-variant plants', 'asymptotically constant coefficients', 'frequency-domain robust control design', 'robust control', 'fractional differentiation', 'time-variant frequency responses', 'stability theorem', 'feedback systems', 'automatic control']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['crone control', 'time - variant plant', 'asymptotically constant coefficient', 'frequency - domain robust control design', 'robust control', 'fractional differentiation', 'time - variant frequency response', 'stability theorem', 'feedback system', 'automatic control']","['crone control', 'robust control design methodology base', 'robust control', 'fractional differentiation', 'stability theorem', 'variant frequency', 'frequency', 'constant coefficient', 'feedback system', 'variant plant']"
682,1005,The average-case identifiability and controllability of large scale systems,"needs for increased product quality, reduced pollution, and reduced energy and material consumption are driving enhanced process integration. this increases the number of manipulated and measured variables required by the control system to achieve its objectives. this paper addresses the question of whether processes tend to become increasingly more difficult to identify and control as the process dimension increases. tools and results of multivariable statistics are used to show that, under a variety of assumed distributions on the elements, square processes of higher dimension tend to be more difficult to identify and control, whereas the expected controllability and identifiability of nonsquare processes depends on the relative numbers of measured and manipulated variables. these results suggest that the procedure of simplifying the control problem so that only a square process is considered is a poor practice for large scale systems","['average-case identifiability', 'large scale systems', 'enhanced process integration', 'measured variables', 'multivariable statistics', 'nonsquare processes', 'manipulated variables', 'average-case controllability', 'process control', 'high dimension square processes', 'process identification', 'monte carlo simulations', 'chemical engineering']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'M', 'U', 'U']","['average - case identifiability', 'large scale system', 'enhance process integration', 'measure variable', 'multivariable statistic', 'nonsquare process', 'manipulate variable', 'average - case controllability', 'process control', 'high dimension square process', 'process identification', 'monte carlo simulation', 'chemical engineering']","['process dimension increase', 'square process', 'nonsquare process depend', 'drive enhanced process integration', 'expect controllability', 'control system', 'measure variable require', 'reduce pollution', 'square process', 'manipulate variable']"
683,887,Towards strong stability of concurrent repetitive processes sharing resources,"the paper presents a method for design of stability conditions of concurrent, repetitive processes sharing common resources. steady-state behaviour of the system with m cyclic processes utilising a resource with the mutual exclusion is considered. based on a recurrent equations framework necessary and sufficient conditions for the existence of maximal performance steady-state are presented. it was shown that if the conditions hold then the m-process system is marginally stable, i.e., a steady-state of the system depends on the perturbations. the problem of finding the relative positions of the processes leading to waiting-free (maximal efficiency) steady-states of the system is formulated as a constraint logic programming problem. an example illustrating the solving of the problem for a 3-process system using object-oriented, constraint logic programming language oz is presented. a condition sufficient for strong stability of the m-process system is given. when the condition holds then for any initial phases of the processes a waiting-free steady-state will be reached","['strong stability', 'concurrent repetitive processes', 'common resources', 'steady-state behaviour', 'cyclic processes', 'mutual exclusion', 'recurrent equations framework', 'necessary and sufficient conditions', 'maximal performance steady-state', 'constraint logic programming', '3-process system', 'waiting-free steady-states', 'oz language']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['strong stability', 'concurrent repetitive process', 'common resource', 'steady - state behaviour', 'cyclic process', 'mutual exclusion', 'recurrent equation framework', 'necessary and sufficient condition', 'maximal performance steady - state', 'constraint logic programming', '3 - process system', 'wait - free steady - state', 'oz language']","['constraint logic programming language', 'constraint logic programming problem', 'repetitive process share common resource', 'cyclic process utilise', 'stability condition', 'process system', 'concurrent', 'recurrent equation framework', 'condition hold', 'condition hold']"
684,1429,Online coverage of the Olympic Games,"in 1956 a new medium was evolving which helped shape not only the presentation of the games to a worldwide audience, but created entirely new avenues for marketing and sponsorship which changed the entire economic relevance of the games. the medium in 1956 was television, and the medium now, of course, is the internet. not since 1956 has olympic coverage been so impacted by the onset of new technology as the current olympiad has been. but now the ioc finds itself in another set of circumstances not altogether different from 1956","['online coverage', 'olympic games', 'marketing', 'sponsorship', 'economic relevance', 'olympiad', 'ioc', 'online rights', 'e-broadcast']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U']","['online coverage', 'olympic game', 'marketing', 'sponsorship', 'economic relevance', 'olympiad', 'ioc', 'online right', 'e - broadcast']","['olympic coverage', 'worldwide audience', 'new technology', 'entire economic relevance', 'current olympiad', 'ioc find', 'new medium', 'television', 'internet', 'game']"
685,1341,STEM: Secure Telephony Enabled Middlebox,"dynamic applications, including ip telephony, have not seen wide acceptance within enterprises because of problems caused by the existing network infrastructure. static elements, including firewalls and network address translation devices, are not capable of allowing dynamic applications to operate properly. the secure telephony enabled middlebox (stem) architecture is an enhancement of the existing network design to remove the issues surrounding static devices. the architecture incorporates an improved firewall that can interpret and utilize information in the application layer of packets to ensure proper functionality. in addition to allowing dynamic applications to function normally, the stem architecture also incorporates several detection and response mechanisms for well-known network-based vulnerabilities. this article describes the key components of the architecture with respect to the sip protocol","['stem', 'secure telephony enabled middlebox', 'dynamic applications', 'ip telephony', 'network infrastructure', 'firewalls', 'network address translation devices', 'network design', 'static devices', 'application layer', 'stem architecture', 'response mechanisms', 'network-based vulnerabilities', 'sip protocol', 'detection mechanisms']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['stem', 'secure telephony enable middlebox', 'dynamic application', 'ip telephony', 'network infrastructure', 'firewall', 'network address translation device', 'network design', 'static device', 'application layer', 'stem architecture', 'response mechanism', 'network - base vulnerability', 'sip protocol', 'detection mechanism']","['secure telephony enable middlebox', 'include ip telephony', 'exist network infrastructure', 'network address translation device', 'include firewall', 'exist network design', 'issue surround static device', 'improve firewall', 'allow dynamic application', 'application layer']"
686,1304,Center-crossing recurrent neural networks for the evolution of rhythmic behavior,"a center-crossing recurrent neural network is one in which the null(hyper)surfaces of each neuron intersect at their exact centers of symmetry, ensuring that each neuron's activation function is centered over the range of net inputs that it receives. we demonstrate that relative to a random initial population, seeding the initial population of an evolutionary search with center-crossing networks significantly improves both the frequency and the speed with which high-fitness oscillatory circuits evolve on a simple walking task. the improvement is especially striking at low mutation variances. our results suggest that seeding with center-crossing networks may often be beneficial, since a wider range of dynamics is more likely to be easily accessible from a population of center-crossing networks than from a population of random networks","['center-crossing recurrent neural networks', 'symmetry', 'activation function', 'random initial population', 'evolutionary search', 'high-fitness oscillatory circuits', 'low mutation variance', 'random networks', 'rhythmic behavior evolution', 'null surfaces', 'evolutionary algorithm', 'learning']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'M', 'U']","['center - cross recurrent neural network', 'symmetry', 'activation function', 'random initial population', 'evolutionary search', 'high - fitness oscillatory circuit', 'low mutation variance', 'random network', 'rhythmic behavior evolution', 'null surface', 'evolutionary algorithm', 'learn']","['cross recurrent neural network', 'fitness oscillatory circuit evolve', 'cross network', 'evolutionary search', 'neuron intersect', 'random initial population', 'neuron', 'mutation variance', 'simple walk task', 'net input']"
687,751,A new method of regression on latent variables. Application to spectral data,"several applications are based on the assessment of a linear model linking a set of variables y to a set of predictors x. in the presence of strong colinearity among predictors, as in the case with spectral data, several alternative procedures to ordinary least squares (ols) are proposed, we discuss a new alternative approach which we refer to as regression models through constrained principal components analysis (rm-cpca). this method basically shares certain common characteristics with pls regression as the dependent variables play a central role in determining the latent variables to be used as predictors. unlike pls, however, the approach discussed leads to straightforward models. this method also bears some similarity to latent root regression analysis (lrr) that was discussed by several authors. moreover, a tuning parameter that ranges between 0 and 1 is introduced and the family of models thus formed includes several other methods as particular cases","['latent variables', 'spectral data', 'linear model', 'predictors', 'strong colinearity', 'regression models through constrained principal components analysis', 'dependent variables', 'latent root regression analysis', 'tuning parameter', 'near-ir spectroscopy']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U']","['latent variable', 'spectral datum', 'linear model', 'predictor', 'strong colinearity', 'regression model through constrain principal component analysis', 'dependent variable', 'latent root regression analysis', 'tune parameter', 'near - ir spectroscopy']","['latent root regression analysis', 'constrain principal component analysis', 'regression model', 'pls regression', 'linear model link', 'latent variable', 'include several other method', 'predictor', 'straightforward model', 'spectral datum']"
688,714,Embeddings of planar graphs that minimize the number of long-face cycles,"we consider the problem of finding embeddings of planar graphs that minimize the number of long-face cycles. we prove that for any k >or= 4, it is np-complete to find an embedding that minimizes the number of face cycles of length at least k","['embeddings', 'planar graphs', 'long-face cycles', 'np-complete problem', 'graph drawing']","['P', 'P', 'P', 'R', 'M']","['embedding', 'planar graph', 'long - face cycle', 'np - complete problem', 'graph draw']","['planar graph', 'find embedding', 'face cycle', 'embed', 'minimize', 'minimize', 'length', 'long', 'find', 'complete']"
689,124,High-speed CMOS circuits with parallel dynamic logic and speed-enhanced skewed static logic,"in this paper, we describe parallel dynamic logic (pdl) which exhibits high speed without charge sharing problem. pdl uses only parallel-connected transistors for fast logic evaluation and is a good candidate for high-speed low-voltage operation. it has less back-bias effect compared to other logic styles, which use stacked transistors. furthermore, pdl needs no signal ordering or tapering. pdl with speed-enhanced skewed static logic renders straightforward logic synthesis without the usual area penalty due to logic duplication. our experimental results on two 32-bit carry lookahead adders using 0.25- mu m cmos technology show that pdl with speed-enhanced skewed static (sss) look reduces the delay over clock-delayed(cd)-domino by 15%-27% and the power-delay product by 20%-37%","['high-speed cmos circuits', 'parallel dynamic logic', 'speed-enhanced skewed static logic', 'parallel-connected transistors', 'low-voltage operation', 'back-bias effect', 'stacked transistors', 'logic synthesis', 'carry lookahead adders', 'delay', 'power-delay product', '32 bit', '0.25 micron']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'U']","['high - speed cmos circuit', 'parallel dynamic logic', 'speed - enhance skewed static logic', 'parallel - connect transistor', 'low - voltage operation', 'back - bias effect', 'stack transistor', 'logic synthesis', 'carry lookahead adder', 'delay', 'power - delay product', '32 bit', '0.25 micron']","['enhance skewed static logic render straightforward logic synthesis', 'bit carry lookahead adder use', 'parallel dynamic logic', 'cmos technology show', 'enhance skewed static', 'stack transistor', 'fast logic', 'other logic style', 'logic duplication', 'speed low']"
690,967,On the relationship between parametric variation and state feedback in chaos control,"in this letter, we study the popular parametric variation chaos control and state-feedback methodologies in chaos control, and point out for the first time that they are actually equivalent in the sense that there exist diffeomorphisms that can convert one to the other for most smooth chaotic systems. detailed conversions are worked out for typical discrete chaotic maps (logistic, henon) and continuous flows (rossler, lorenz) for illustration. this unifies the two seemingly different approaches from the physics and the engineering communities on chaos control. this new perspective reveals some new potential applications such as chaos synchronization and normal form analysis from a unified mathematical point of view","['parametric variation', 'chaos control', 'state-feedback', 'diffeomorphisms', 'logistic', 'continuous flows', 'henon map', 'rossler system', 'lorenz system']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['parametric variation', 'chaos control', 'state - feedback', 'diffeomorphism', 'logistic', 'continuous flow', 'henon map', 'rossler system', 'lorenz system']","['parametric variation chaos control', 'chaos synchronization', 'smooth chaotic system', 'chaos control', 'discrete chaotic map', 'diffeomorphism', 'continuous flow', 'lorenz', 'unify mathematical point', 'normal form analysis']"
691,922,Smart collision information processing sensors for fast moving objects,"in this technical note we survey the area of smart collision information processing sensors. we review the existing technologies to detect collision or overlap between fast moving physical objects or objects in virtual environments, physical environments or a combination of physical and virtual objects. we report developments in the collision detection of fast moving objects at discrete time steps such as two consecutive time frames, as well as continuous time intervals such as in an interframe collision detection system. our discussion of computational techniques in this paper is limited to convex objects. techniques exist however to efficiently decompose non-convex objects into convex objects. we also discuss the tracking technologies for objects from the standpoint of collision detection or avoidance","['collision information processing', 'fast moving objects', 'virtual environments', 'physical environments', 'collision detection', 'discrete time steps', 'consecutive time frames', 'continuous time intervals', 'interframe collision detection', 'convex objects', 'tracking', 'nonconvex objects', 'air traffic control', 'smart sensors', 'military training', 'high speed machining']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U', 'R', 'U', 'U']","['collision information processing', 'fast move object', 'virtual environment', 'physical environment', 'collision detection', 'discrete time step', 'consecutive time frame', 'continuous time interval', 'interframe collision detection', 'convex object', 'track', 'nonconvex object', 'air traffic control', 'smart sensor', 'military training', 'high speed machining']","['interframe collision detection system', 'smart collision information processing sensor', 'collision detection', 'detect collision', 'fast move object', 'move physical object', 'convex object', 'track technology', 'consecutive time frame', 'virtual object']"
692,76,Reaching strong consensus in a general network,"the strong consensus (sc) problem is a variant of the conventional distributed consensus problem (also known as the byzantine agreement problem). the sc problem requires that the agreed value among fault-free processors be one of the fault-free processor's initial values. originally, the problem was studied in a fully connected network with malicious faulty processors. in this paper, the sc problem is re-examined in a general network, in which the components (processors and communication links) may be subjected to different faulty types simultaneously (also called the hybrid fault model or mixed faulty types) and the network topology does not have to be fully connected. the proposed protocol can tolerate the maximum number of tolerable faulty components such that each fault-free processor obtains a common value for the sc problem in a general network","['strong consensus', 'distributed consensus problem', 'byzantine agreement', 'fault-free processors', 'fully connected network', 'hybrid fault model', 'strong consensus problem', 'fault-tolerant distributed system']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['strong consensus', 'distribute consensus problem', 'byzantine agreement', 'fault - free processor', 'fully connect network', 'hybrid fault model', 'strong consensus problem', 'fault - tolerant distribute system']","['conventional distribute consensus problem', 'byzantine agreement problem', 'malicious faulty processor', 'tolerable faulty component such', 'strong consensus', 'hybrid fault model', 'propose protocol', 'mixed faulty type', 'different faulty type', 'connect network']"
693,609,Chemical production in the superlative [formaldehyde plant process control system and remote I/O system],"basf commissioned the largest formaldehyde production plant in the world, in december 2000, with an annual capacity of 180000 t. the new plant, built to meet the growing demand for formaldehyde, sets new standards. its size, technology and above all its cost-effectiveness give it a leading position internationally. to maintain such high standards by the automation technology, in addition to the trail-blazing simatic pcs 7 process control system from siemens, basf selected the innovative remote i/o system i.s.1 from r. stahl schaltgerate gmbh to record and to output field signals in hazardous areas zone 1 and 2. this combination completely satisfied all technical requirements and also had the best price-performance ratio of all the solutions. 25 remote i/o field stations were designed and matched to the needs of the formaldehyde plant","['chemical production', 'superlative', 'process control system', 'basf', 'automation technology', 'trail-blazing simatic pcs 7', 'siemens', 'remote i/o system i.s.1', 'r. stahl schaltgerate gmbh', 'price-performance ratio', 'formaldehyde production plant construction', 'cost-effective plant', 'signal recording', 'zone 1 hazardous area', 'zone 2 hazardous area', 'remote i/o field station design']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'R', 'R', 'R', 'R']","['chemical production', 'superlative', 'process control system', 'basf', 'automation technology', 'trail - blaze simatic pc 7', 'siemens', 'remote i / o system i.s.1', 'r. stahl schaltgerate gmbh', 'price - performance ratio', 'formaldehyde production plant construction', 'cost - effective plant', 'signal recording', 'zone 1 hazardous area', 'zone 2 hazardous area', 'remote i / o field station design']","['large formaldehyde production plant', 'process control system', 'automation technology', 'basf commission', 'maintain such high standard', 'technical requirement', 'stahl schaltgerate gmbh', 'blaze simatic pc', 'basf', 'siemens']"
694,1219,Knowledge organisation of product design blackboard systems via graph decomposition,"knowledge organisation plays an important role in building a knowledge-based product design blackboard system. well-organised knowledge sources will facilitate the effectiveness and efficiency of communication and data exchange in a blackboard system. in a previous investigation, an approach for constructing blackboard systems for product design using a non-directed graph decomposition algorithm was proposed. in this paper, the relationship between graph decomposition and the resultant blackboard system is further studied. a case study of a number of hypothetical blackboard systems that comprise different knowledge organisations is provided","['knowledge organisation', 'product design blackboard systems', 'graph decomposition', 'knowledge-based product design', 'data exchange', 'case study']","['P', 'P', 'P', 'P', 'P', 'P']","['knowledge organisation', 'product design blackboard system', 'graph decomposition', 'knowledge - base product design', 'datum exchange', 'case study']","['base product design blackboard system', 'construct blackboard system', 'direct graph decomposition algorithm', 'comprise different knowledge organisation', 'hypothetical blackboard system', 'resultant blackboard system', 'organise knowledge source', 'knowledge organisation', 'blackboard system', 'product design use']"
695,1118,Run-time data-flow analysis,"parallelizing compilers have made great progress in recent years. however, there still remains a gap between the current ability of parallelizing compilers and their final goals. in order to achieve the maximum parallelism, run-time techniques were used in parallelizing compilers during last few years. first, this paper presents a basic run-time privatization method. the definition of run-time dead code is given and its side effect is discussed. to eliminate the imprecision caused by the run-time dead code, backward data-flow information must be used. proteus test, which can use backward information in run-time, is then presented to exploit more dynamic parallelism. also, a variation of proteus test, the advanced proteus test, is offered to achieve partial parallelism. proteus test was implemented on the parallelizing compiler aft. in the end of this paper the program fpppp.f of spec95fp benchmark is taken as an example, to show the effectiveness of proteus test","['parallelizing compilers', 'run-time privatization method', 'run-time dead code', 'backward data-flow information', 'proteus test', 'dynamic parallelism', 'run-time data flow analysis']","['P', 'P', 'P', 'P', 'P', 'P', 'M']","['parallelize compiler', 'run - time privatization method', 'run - time dead code', 'backward data - flow information', 'proteus test', 'dynamic parallelism', 'run - time datum flow analysis']","['parallelize compiler aft', 'parallelize compiler', 'spec95fp benchmark', 'achieve partial parallelism', 'dynamic parallelism', 'advanced proteus test', 'maximum parallelism', 'time privatization method', 'proteus test', 'basic run']"
696,1343,Estimating the intrinsic dimension of data with a fractal-based method,"in this paper, the problem of estimating the intrinsic dimension of a data set is investigated. a fractal-based approach using the grassberger-procaccia algorithm is proposed. since the grassberger-procaccia algorithm (1983) performs badly on sets of high dimensionality, an empirical procedure that improves the original algorithm has been developed. the procedure has been tested on data sets of known dimensionality and on time series of santa fe competition","['fractal-based method', 'time series', 'santa fe competition', 'data intrinsic dimension estimation', 'pattern recognition']","['P', 'P', 'P', 'R', 'U']","['fractal - base method', 'time series', 'santa fe competition', 'datum intrinsic dimension estimation', 'pattern recognition']","['intrinsic dimension', 'know dimensionality', 'high dimensionality', 'procaccia algorithm', 'datum set', 'fractal', 'datum set', 'algorithm', 'empirical procedure', 'estimate']"
697,1306,Scalable hybrid computation with spikes,"we outline a hybrid analog-digital scheme for computing with three important features that enable it to scale to systems of large complexity: first, like digital computation, which uses several one-bit precise logical units to collectively compute a precise answer to a computation, the hybrid scheme uses several moderate-precision analog units to collectively compute a precise answer to a computation. second, frequent discrete signal restoration of the analog information prevents analog noise and offset from degrading the computation. third, a state machine enables complex computations to be created using a sequence of elementary computations. a natural choice for implementing this hybrid scheme is one based on spikes because spike-count codes are digital, while spike-time codes are analog. we illustrate how spikes afford easy ways to implement all three components of scalable hybrid computation. first, as an important example of distributed analog computation, we show how spikes can create a distributed modular representation of an analog number by implementing digital carry interactions between spiking analog neurons. second, we show how signal restoration may be performed by recursive spike-count quantization of spike-time codes. third, we use spikes from an analog dynamical system to trigger state transitions in a digital dynamical system, which reconfigures the analog dynamical system using a binary control vector; such feedback interactions between analog and digital dynamical systems create a hybrid state machine (hsm). the hsm extends and expands the concept of a digital finite-state-machine to the hybrid domain. we present experimental data from a two-neuron hsm on a chip that implements error-correcting analog-to-digital conversion with the concurrent use of spike-time and spike-count codes. we also present experimental data from silicon circuits that implement hsm-based pattern recognition using spike-time synchrony. we outline how hsms may be used to perform learning, vector quantization, spike pattern recognition and generation, and how they may be reconfigured","['scalable hybrid computation', 'spikes', 'hybrid analog-digital scheme', 'moderate-precision analog units', 'frequent discrete signal restoration', 'analog noise', 'spike-count codes', 'spike-time codes', 'distributed analog computation', 'digital carry interactions', 'binary control vector', 'feedback interactions', 'finite-state-machine', 'error-correcting analog-to-digital conversion', 'silicon circuits', 'pattern recognition', 'learning', 'vector quantization', 'two neuron hybrid state machine']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['scalable hybrid computation', 'spike', 'hybrid analog - digital scheme', 'moderate - precision analog unit', 'frequent discrete signal restoration', 'analog noise', 'spike - count code', 'spike - time code', 'distribute analog computation', 'digital carry interaction', 'binary control vector', 'feedback interaction', 'finite - state - machine', 'error - correct analog - to - digital conversion', 'silicon circuit', 'pattern recognition', 'learn', 'vector quantization', 'two neuron hybrid state machine']","['spike analog neuron', 'distribute analog computation', 'analog dynamical system use', 'digital dynamical system create', 'scalable hybrid computation', 'analog dynamical system', 'precision analog unit', 'pattern recognition use spike', 'digital computation', 'spike afford easy way']"
698,753,In medias res [DVD formats],"four years in the making, the dvd format war rages on, no winner insight. meanwhile, the spoils of war abound, and dvd media manufacturers stand poised to profit","['dvd format war', 'dvd media manufacturers', 'dvd-ram', 'dvd+rw', 'dvd+r', 'dvd-rw', 'dvd-r', 'compatibility', 'writable dvd']","['P', 'P', 'U', 'U', 'U', 'U', 'U', 'U', 'M']","['dvd format war', 'dvd medium manufacturer', 'dvd - ram', 'dvd+rw', 'dvd+r', 'dvd - rw', 'dvd - r', 'compatibility', 'writable dvd']","['dvd medium manufacturer stand poise', 'dvd format war rage', 'war abound', 'spoil', 'year', 'winner insight', 'make']"
699,716,Algorithmic results for ordered median problems,"in a series of papers a new type of objective function in location theory, called ordered median function, has been introduced and analyzed. this objective function unifies and generalizes most common objective functions used in location theory. in this paper we identify finite dominating sets for these models and develop polynomial time algorithms together with a detailed complexity analysis","['algorithmic results', 'ordered median problems', 'objective function', 'location theory', 'ordered median function', 'finite dominating sets', 'polynomial time algorithms', 'detailed complexity analysis']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['algorithmic result', 'order median problem', 'objective function', 'location theory', 'order median function', 'finite dominate set', 'polynomial time algorithm', 'detailed complexity analysis']","['call ordered median function', 'polynomial time algorithm', 'finite dominate set', 'common objective function', 'objective function unifie', 'objective function', 'location theory', 'model', 'generalize', 'analyze']"
700,878,"Girls, boys, and computers","today north american girls, boys, teachers, and parents frequently regard computer science and programming as something boys are better at. the author considers how many of the factors that contribute to the low participation of women in computing occur first, and perhaps most forcefully, in childhood. she presents four recommendations to address the situation","['girls', 'boys', 'teachers', 'computer science', 'programming', 'women', 'childhood', 'gender issues']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'U']","['girl', 'boy', 'teacher', 'computer science', 'programming', 'woman', 'childhood', 'gender issue']","['regard computer science', 'computing occur', 'today north american girl', 'programming', 'low participation', 'teacher', 'parent', 'woman', 'boy', 'childhood']"
701,1042,Chaotic phenomena and fractional-order dynamics in the trajectory control of redundant manipulators,"redundant manipulators have some advantages when compared with classical arms because they allow the trajectory optimization, both on the free space and on the presence of obstacles, and the resolution of singularities. for this type of arms the proposed kinematic control algorithms adopt generalized inverse matrices but, in general, the corresponding trajectory planning schemes show important limitations. motivated by these problems this paper studies the chaos revealed by the pseudoinverse-based trajectory planning algorithms, using the theory of fractional calculus","['chaotic phenomena', 'fractional-order dynamics', 'trajectory control', 'redundant manipulators', 'classical arms', 'trajectory optimization', 'kinematic control algorithms', 'generalized inverse matrices', 'trajectory planning schemes', 'fractional calculus']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['chaotic phenomenon', 'fractional - order dynamic', 'trajectory control', 'redundant manipulator', 'classical arm', 'trajectory optimization', 'kinematic control algorithm', 'generalize inverse matrix', 'trajectory planning scheme', 'fractional calculus']","['propose kinematic control algorithm adopt generalized inverse matrix', 'trajectory planning algorithm', 'redundant manipulator have', 'trajectory planning scheme', 'trajectory optimization', 'pseudoinverse', 'singularity', 'chaos reveal', 'classical arm', 'obstacle']"
702,1007,Conditions for decentralized integral controllability,"the term decentralized integral controllability (dic) pertains to the existence of stable decentralized controllers with integral action that have closed-loop properties such as stable independent detuning. it is especially useful to select control structures systematically at the early stage of control system design because the only information needed for dic is the steady-state process gain matrix. here, a necessary and sufficient condition conjectured in the literature is proved. the real structured singular value which can exploit realness of the controller gain is used to describe computable conditions for dic. the primary usage of dic is to eliminate unworkable pairings. for this, two other simple necessary conditions are proposed. examples are given to illustrate the effectiveness of the proposed conditions for dic","['decentralized integral controllability', 'stable decentralized controllers', 'integral action', 'closed-loop properties', 'stable independent detuning', 'control system design', 'steady-state process gain matrix', 'real structured singular value', 'necessary sufficient conditions', 'systematic control structure selection', 'controller gain realness', 'unworkable pairing elimination', 'schur complement']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'U']","['decentralize integral controllability', 'stable decentralized controller', 'integral action', 'close - loop property', 'stable independent detuning', 'control system design', 'steady - state process gain matrix', 'real structured singular value', 'necessary sufficient condition', 'systematic control structure selection', 'controller gain realness', 'unworkable pairing elimination', 'schur complement']","['decentralize integral controllability', 'stable decentralized controller', 'stable independent detuning', 'control system design', 'select control structure', 'describe computable condition', 'controller gain', 'real structured singular value', 'eliminate unworkable pairing', 'state process gain matrix']"
703,885,Assignment of periods and priorities of messages and tasks in distributed control systems,"presents a task and message-based scheduling method to guarantee the given end-to-end constraints including precedence constraints, time constraints, and period and priority of task and message. the method is an integrated one considering both tasks executed in each node and messages transmitted via the network and is designed to apply to a general distributed control system that has multiple loops and a single loop has sensor nodes with multiple sensors, actuator nodes with multiple actuators, controller nodes with multiple tasks, and several types of constraints. the assigning method of the optimal period and priority of task and message is proposed, using the presented task and message-based scheduling method","['distributed control systems', 'message-based scheduling method', 'end-to-end constraints', 'precedence constraints', 'time constraints', 'periods assignment', 'priorities assignment', 'task-based scheduling method']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'M']","['distribute control system', 'message - base scheduling method', 'end - to - end constraint', 'precedence constraint', 'time constraint', 'period assignment', 'priority assignment', 'task - base scheduling method']","['precedence constraint', 'scheduling', 'distribute control system', 'sensor nod', 'actuator nod', 'multiple task', 'controller nod', 'time constraint', 'multiple sensor', 'multiple actuator']"
704,998,Discreteness and relevance: a reply to Roman Poznanski,"in reply to poznanski (see ibid., p.435, 2002) on discreteness and relevance, eliasmith claims that all of the concerns voiced by poznanski in his reply fail to offer a serious challenge to the idea that continuity is irrelevant to a good understanding of cognitive systems. eliasmith hopes that it is evident that he does not claim that the process in neural systems is discrete, but rather that a complete characterization of the process can be discrete; these of course are significantly different claims","['discreteness', 'relevance', 'continuity', 'cognitive systems', 'neural systems']","['P', 'P', 'P', 'P', 'P']","['discreteness', 'relevance', 'continuity', 'cognitive system', 'neural system']","['cognitive system', 'neural system', 'discreteness', 'discrete', 'complete characterization', 'eliasmith hope', 'eliasmith claim', 'process', 'poznanski', 'good understanding']"
705,89,A framework for rapid local area modeling for construction automation,"rapid 3d positioning and modeling in construction can be used to more effectively plan, visualize, and communicate operations before execution. it can also help to optimize equipment operations, significantly improve safety, and enhance a remote operator's spatial perception of the workspace. a new framework for rapid local area sensing and 3d modeling for better planning and control of construction equipment operation is described and demonstrated. by combining human-assisted graphical workspace modeling with pre-stored computer-aided design (cad) models and simple sensors (such as single-axis laser rangefinders and remote video cameras), modeling time can be significantly reduced while potentially increasing modeling accuracy","['rapid local area modeling', 'construction automation', 'rapid 3d positioning', 'equipment operations', 'spatial perception', 'rapid local area sensing', '3d modeling', 'human-assisted graphical workspace modeling', 'single-axis laser rangefinders', 'remote video cameras', 'pre-stored computer-aided design models']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['rapid local area model', 'construction automation', 'rapid 3d positioning', 'equipment operation', 'spatial perception', 'rapid local area sense', '3d modeling', 'human - assist graphical workspace model', 'single - axis laser rangefinder', 'remote video camera', 'pre - store computer - aid design model']","['assist graphical workspace model', '3d modeling', 'rapid 3d positioning', 'construction equipment operation', 'rapid local area sense', 'axis laser rangefinder', 'optimize equipment operation', 'remote video camera', 'model time', 'model']"
706,74,End-user perspectives on the uptake of computer supported cooperative working,"researchers in information systems have produced a rich collection of meta-analyses and models to further understanding of factors influencing the uptake of information technologies. in the domain of cscw, however, these models have largely been neglected, and while there are many case studies, no systematic account of uptake has been produced. we use findings from information systems research to structure a meta-analysis of uptake issues as reported in cscw case studies, supplemented by a detailed re-examination of one of our own case studies from this perspective. this shows that while there are some factors which seem to be largely specific to cscw introductions, many of the case study results are very similar to standard is findings. we conclude by suggesting how the two communities of researchers might build on each other's work, and finally propose activity theory as a means of integrating the two perspectives","['end-user perspectives', 'computer supported cooperative work', 'information systems', 'meta-analyses', 'information technology', 'cscw', 'activity theory']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['end - user perspective', 'computer support cooperative work', 'information system', 'meta - analysis', 'information technology', 'cscw', 'activity theory']","['information system research', 'cscw case study', 'be many case study', 'propose activity theory', 'uptake issue', 'information technology', 'own case study', 'case study result', 'factor influence', 'information system']"
707,126,A new architecture for implementing pipelined FIR ADF based on classification of coefficients,"in this paper, we propose a new method for implementing pipelined finite-impulse response (fir) adaptive digital filter (adf), with an aim of reducing the maximum delay of the filtering portion of conventional delayed least mean square (dlms) pipelined adf. we achieve a filtering section with a maximum delay of one by simplifying a pre-upsampled and a post-downsampled fir filter using the concept of classification of coefficients. this reduction is independent of the order of the filter, which is an advantage when the order of the filter is very large, and as a result the method can also be applied to infinite impulse response (iir) filters. furthermore, when the proposed method is compared with the transpose adf, which has a filtering section with zero delay, it is realized that it significantly reduces the maximum delay associated with updating the coefficients of fir adf. the effect of this is that, the proposed method exhibits a higher convergence speed in comparison to the transpose fir adf","['pipelined fir adf', 'adaptive digital filter', 'maximum delay', 'convergence speed', 'coefficient classification', 'delayed least mean square filter', 'pre-upsampled filter', 'post-downsampled filter']","['P', 'P', 'P', 'P', 'R', 'R', 'R', 'R']","['pipeline fir adf', 'adaptive digital filter', 'maximum delay', 'convergence speed', 'coefficient classification', 'delay least mean square filter', 'pre - upsampled filter', 'post - downsample filter']","['adaptive digital filter', 'downsample fir filter', 'fir adf', 'transpose adf', 'conventional delay least mean', 'infinite impulse', 'filter', 'filter', 'filter', 'implement pipelined finite']"
708,965,Sliding mode control of chaos in the cubic Chua's circuit system,"in this paper, a sliding mode controller is applied to control the cubic chua's circuit system. the sliding surface of this paper used is one dimension higher than the traditional surface and guarantees its passage through the initial states of the controlled system. therefore, using the characteristic of this sliding mode we aim to design a controller that can meet the desired specification and use less control energy by comparing with the result in the current existing literature. the results show that the proposed controller can steer chua's circuit system to the desired state without the chattering phenomenon and abrupt state change","['sliding mode control', 'chaos', 'sliding surface', 'chattering', 'state change', 'cubic chua circuit system', 'match disturbance', 'mismatch disturbance']","['P', 'P', 'P', 'P', 'P', 'R', 'U', 'U']","['slide mode control', 'chaos', 'slide surface', 'chatter', 'state change', 'cubic chua circuit system', 'match disturbance', 'mismatch disturbance']","['slide mode controller', 'cubic chua', 'steer chua', 'slide mode', 'circuit system', 'slide surface', 'control system', 'controller', 'control energy', 'control']"
709,920,Three-dimensional periodic Voronoi grain models and micromechanical FE-simulations of a two-phase steel,"a three-dimensional model is proposed for modeling of microstructures. the model is based on the finite element method with periodic boundary conditions. the voronoi algorithm is used to generate the geometrical model, which has a periodic grain structure that follows the original boundaries of the voronoi cells. as an application, the model is used to model a two-phase ferrite/pearlite steel. it is shown that periodic cells with only five grains generate representative stress-strain curves","['periodic voronoi grain models', 'two-phase steel', 'three-dimensional model', 'periodic boundary conditions', 'voronoi algorithm', 'geometrical model', 'stress-strain curves', 'micromechanical fem simulations', 'microstructures modeling', 'ferrite-pearlite steel', 'voronoi tessellation', 'adaptive mesh generator', 'quadtree/octree-based algorithm', 'kinematic constraints', 'computational time']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'M', 'M', 'M', 'M', 'U', 'U']","['periodic voronoi grain model', 'two - phase steel', 'three - dimensional model', 'periodic boundary condition', 'voronoi algorithm', 'geometrical model', 'stress - strain curve', 'micromechanical fem simulation', 'microstructure model', 'ferrite - pearlite steel', 'voronoi tessellation', 'adaptive mesh generator', 'quadtree / octree - base algorithm', 'kinematic constraint', 'computational time']","['periodic grain structure', 'periodic boundary condition', 'microstructure', 'pearlite steel', 'periodic cell', 'voronoi algorithm', 'voronoi cell', 'phase ferrite', 'model', 'geometrical model']"
710,636,FLID-DL: congestion control for layered multicast,"we describe fair layered increase/decrease with dynamic layering (flid-dl): a new multirate congestion control algorithm for layered multicast sessions. flid-dl generalizes the receiver-driven layered congestion control protocol (rlc) introduced by vicisano et al. (proc. ieee infocom, san francisco, ca, , p.996-1003, mar. 1998)ameliorating the problems associated with large internet group management protocol (igmp) leave latencies and abrupt rate increases. like rlc, flid-dl, is a scalable, receiver-driven congestion control mechanism in which receivers add layers at sender-initiated synchronization points and leave layers when they experience congestion. flid-dl congestion control coexists with transmission control protocol (tcp) flows as well as other flid-dl sessions and supports general rates on the different multicast layers. we demonstrate via simulations that our congestion control scheme exhibits better fairness properties and provides better throughput than previous methods. a key contribution that enables flid-dl and may be useful elsewhere is dynamic layering (dl), which mitigates the negative impact of long igmp leave latencies and eliminates the need for probe intervals present in rlc. we use dl to respond to congestion much faster than igmp leave operations, which have proven to be a bottleneck in practice for prior work","['flid-dl', 'congestion control', 'fair layered increase/decrease with dynamic layering', 'dynamic layering', 'multirate congestion control algorithm', 'layered multicast sessions', 'receiver-driven layered congestion control protocol', 'internet group management protocol', 'igmp', 'sender-initiated synchronization', 'transmission control protocol', 'multicast layers', 'simulations', 'throughput', 'scalable congestion control', 'internet protocol multicast', 'tcp fairness']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['flid - dl', 'congestion control', 'fair layered increase / decrease with dynamic layering', 'dynamic layering', 'multirate congestion control algorithm', 'layer multicast session', 'receiver - drive layered congestion control protocol', 'internet group management protocol', 'igmp', 'sender - initiate synchronization', 'transmission control protocol', 'multicast layer', 'simulation', 'throughput', 'scalable congestion control', 'internet protocol multicast', 'tcp fairness']","['layer congestion control protocol', 'layer multicast session', 'new multirate congestion control algorithm', 'different multicast layer', 'large internet group management protocol', 'dl congestion control', 'congestion control scheme', 'transmission control protocol', 'congestion control', 'experience congestion']"
711,673,The Information Age interview - Capital One,credit card company capital one attributes its rapid customer growth to the innovative use of cutting-edge technology. european cio catherine doran talks about the systems that have fuelled that runaway success,"['capital one', 'credit card company', 'customer growth', 'cutting-edge technology']","['P', 'P', 'P', 'P']","['capital one', 'credit card company', 'customer growth', 'cut - edge technology']","['credit card company capital', 'rapid customer growth', 'european cio catherine doran talk', 'innovative use', 'edge technology', 'system', 'attribute', 'fuel', 'cut']"
712,1226,Temp IT chief rallies troops [Mori],the appointment of a highly qualified interim it manager enabled market research company mori to rapidly restructure its it department. now the resulting improvements are allowing it to support an increasing role for technology in the assimilation and analysis of market research,"['mori', 'interim it manager', 'market research company']","['P', 'P', 'P']","['mori', 'interim it manager', 'market research company']","['manager enable market research company mori', 'qualified interim', 'it department', 'increase role', 'technology', 'result improvement', 'analysis', 'appointment', 'assimilation', 'restructure']"
713,1263,Super high definition image (WHD: Wide/Double HD) transmission system,"this paper describes a whd image transmission system constructed from a display projector, codecs, and a camera system imaging a super high definition image (whd: wide/double hd) corresponding to two screen portions of common high-vision images. this system was developed as a transmission system to communicate with or transmit information giving a reality-enhanced feeling to a remote location by using images of super high definition. in addition, the correction processing for the distortions of images occurring due to the structure of the camera system, an outline of the transmission experiments using the proposed system, and subjective evaluation experiments using whd images are presented","['whd image transmission system', 'codecs', 'camera system imaging', 'reality-enhanced feeling', 'super high definition image transmission system']","['P', 'P', 'P', 'P', 'R']","['whd image transmission system', 'codec', 'camera system image', 'reality - enhance feeling', 'super high definition image transmission system']","['whd image transmission system construct', 'subjective evaluation experiment use whd image', 'camera system image', 'super high definition image', 'display projector', 'vision image', 'camera system', 'super high definition', 'double hd', 'screen portion']"
714,958,Efficient combinational verification using overlapping local BDDs and a hash table,we propose a novel methodology that combines local bdds (binary decision diagrams) with a hash table for very efficient verification of combinational circuits. the main purpose of this technique is to remove the considerable overhead associated with case-by-case verification of internal node pairs in typical internal correspondence based verification methods. two heuristics based on the number of structural levels of circuitry looked at and the total number of nodes in the bdd manager are used to control the bdd sizes and introduce new cutsets based on already found equivalent nodes. we verify the iscas85 benchmark circuits and demonstrate significant speedup over existing methods. we also verify several hard industrial circuits and show our superiority in extracting internal equivalences,"['combinational verification', 'overlapping local bdds', 'hash table', 'binary decision diagrams', 'case-by-case verification', 'internal node pairs', 'internal correspondence based verification', 'heuristics', 'structural levels', 'bdd manager', 'bdd sizes', 'cutsets', 'iscas85 benchmark circuits', 'hard industrial circuits', 'internal equivalences', 'combinational circuit verification', 'formal verification', 'internal correspondence-based verification']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M']","['combinational verification', 'overlap local bdd', 'hash table', 'binary decision diagram', 'case - by - case verification', 'internal node pair', 'internal correspondence base verification', 'heuristic', 'structural level', 'bdd manager', 'bdd size', 'cutset', 'iscas85 benchmark circuit', 'hard industrial circuit', 'internal equivalence', 'combinational circuit verification', 'formal verification', 'internal correspondence - base verification']","['iscas85 benchmark circuit', 'verify several hard industrial circuit', 'binary decision diagram', 'combine local bdd', 'combinational circuit', 'case verification', 'efficient verification', 'internal node pair', 'bdd size', 'bdd']"
715,572,Characterization of sheet buckling subjected to controlled boundary constraints,"a wedge strip test is designed to study the onset and post-buckling behavior of a sheet under various boundary constraints. the device can be easily incorporated into a conventional tensile test machine, and material resistance to buckling is measured as the buckling height versus the in-plane strain state. the design yields different but consistent buckling modes with easy changes of boundary conditions (either clamped or freed) and sample geometry. experimental results are then used to verify a hybrid approach to buckling prediction, i.e., the combination of the fem analysis and an energy-based analytical wrinkling criterion. the fem analysis is used to obtain the stress field and deformed geometry in a complex forming condition, while the analytical solution is to provide the predictions less sensitive to artificial numerical parameters. a good agreement between experimental data and numerical predictions is obtained","['sheet buckling', 'boundary constraints', 'wedge strip test', 'tensile test machine', 'strain state', 'energy-based analytical wrinkling criterion', 'stress field', 'deformed geometry', 'forming processes', 'finite element analysis']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M']","['sheet buckle', 'boundary constraint', 'wedge strip test', 'tensile test machine', 'strain state', 'energy - base analytical wrinkling criterion', 'stress field', 'deform geometry', 'form process', 'finite element analysis']","['wedge strip test', 'conventional tensile test machine', 'buckle prediction', 'buckle mode', 'artificial numerical parameter', 'buckle height', 'buckle behavior', 'buckle', 'form condition', 'numerical prediction']"
716,1127,Repeated games with lack of information on one side: the dual differential approach,"we introduce the dual differential game of a repeated game with lack of information on one side as the natural continuous time version of the dual game introduced by de meyer (1996). a traditional way to study the value of differential games is through discrete time approximations. here, we follow the opposite approach: we identify the limit value of a repeated game in discrete time as the value of a differential game. namely, we use the recursive structure for the finitely repeated version of the dual game to construct a differential game for which the upper values of the uniform discretization satisfy precisely the same property. the value of the dual differential game exists and is the unique viscosity solution of a first-order derivative equation with a limit condition. we identify the solution by translating viscosity properties in the primal","['repeated games', 'repeated games', 'dual differential game', 'discrete time approximations', 'discrete time', 'limit value', 'viscosity solution', 'limit condition', 'repeated game']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['repeat game', 'repeat game', 'dual differential game', 'discrete time approximation', 'discrete time', 'limit value', 'viscosity solution', 'limit condition', 'repeat game']","['dual differential game', 'unique viscosity solution', 'differential game', 'discrete time approximation', 'dual game introduce', 'translate viscosity property', 'differential game', 'dual game', 'uniform discretization satisfy', 'natural continuous time version']"
717,1162,Recognition of finite simple groups S/sub 4/(q) by their element orders,"it is proved that among simple groups s/sub 4/(q) in the class of finite-groups, only the groups s/sub 4/(3/sup n/), where n is an odd number greater than unity, are recognizable by a set of their element orders. it is also shown that simple groups u/sub 3/(9), /sup 3/d/sub 4/(2), g/sub 2/(4), s/sub 6/(3), f/sub 4/(2), and /sup 2/e/sub 6/(2) are recognizable, but l/sub 3/(3) is not","['element orders', 'finite simple groups recognition', 'divisibility relation']","['P', 'R', 'U']","['element order', 'finite simple group recognition', 'divisibility relation']","['simple group', 'group', 'element order', 'odd number great', 'recognizable', 'finite', 'class', 'show', 'sub', 'unity']"
718,793,Advancements during the past quarter century in on-line monitoring of motor and generator winding insulation,"electrical insulation plays a critical role in the operation of motor and generator rotor and stator windings. premature failure of the insulation can cost millions of dollars per day. with advancements in electronics, sensors, computers and software, tremendous progress has been made in the past 25 yr which has transformed on-line insulation monitoring from a rarely used and expensive tool, to the point where 50% of large utility generators in north america are now equipped for such monitoring. this review paper outlines the motivation for online monitoring, discusses the transition to today's technology, and describes the variety of methods now in use for rotor winding and stator winding monitoring","['generator winding insulation', 'electrical insulation', 'stator windings', 'electronics', 'sensors', 'computers', 'software', 'rotor windings', 'motor generator winding insulation', 'winding insulation on-line monitoring', 'premature insulation failure', 'temperature monitoring', 'condition monitors', 'tagging compounds', 'ozone monitoring', 'pd monitoring', 'magnetic flux monitoring', 'partial discharge monitoring', 'endwinding vibration monitoring']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'M', 'U', 'M', 'M', 'M', 'M', 'M']","['generator wind insulation', 'electrical insulation', 'stator winding', 'electronic', 'sensor', 'computer', 'software', 'rotor winding', 'motor generator wind insulation', 'wind insulation on - line monitoring', 'premature insulation failure', 'temperature monitoring', 'condition monitor', 'tag compound', 'ozone monitoring', 'pd monitoring', 'magnetic flux monitor', 'partial discharge monitoring', 'endwinde vibration monitoring']","['line insulation monitoring', 'stator winding', 'rotor winding', 'online monitoring', 'electrical insulation', 'generator rotor', 'monitor', 'utility generator', 'sensor', 'insulation']"
719,1383,Semantic data broadcast for a mobile environment based on dynamic and adaptive chunking,"database broadcast is an effective and scalable approach to disseminate information of high affinity to a large collection of mobile clients. a common problem of existing broadcast approaches is the lack of knowledge for a client to determine if all data items satisfying its query could be obtained from the broadcast. we therefore propose a semantic-based broadcast approach. a semantic descriptor is attached to each broadcast unit, called a data chunk. this semantic descriptor allows a client to determine if a query can be answered entirely based on broadcast items and, if needed, identify the precise definition of the remaining items in the form of a ""supplementary"" query. data chunks can be of static or dynamic sizes and organized hierarchically. their boundary can be determined on-the-fly, adaptive to the nature of client queries. we investigate different ways of organizing the data chunks over a broadcast channel to improve access performance. we introduce the data affinity index metric, which more accurately reflects client-perceived performance. a simulation model is built to evaluate our semantic-based broadcast schemes","['semantic data broadcast', 'adaptive chunking', 'mobile clients', 'semantic descriptor', 'data chunking', 'answerability', 'data affinity index', 'mobile databases', 'mobile computing', 'query processing']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M']","['semantic datum broadcast', 'adaptive chunking', 'mobile client', 'semantic descriptor', 'datum chunk', 'answerability', 'data affinity index', 'mobile database', 'mobile computing', 'query process']","['data affinity index metric', 'database broadcast', 'client query', 'broadcast channel', 'data chunk', 'datum chunk', 'datum item satisfy', 'broadcast item', 'semantic descriptor', 'mobile client']"
720,800,A model for choosing an electronic reserves system: a pre-implementation study at the library of Long Island University's Brooklyn campus,this study explores the nature of electronic reserves (e-reserves) and investigates the possibilities of implementing the e-reserves at the long island university/brooklyn campus library (liu/bcl),"['electronic reserves system', 'long island university brooklyn campus library']","['P', 'R']","['electronic reserve system', 'long island university brooklyn campus library']","['electronic reserve', 'brooklyn campus library', 'reserve', 'long island university', 'study explore', 'implement', 'investigate', 'bcl', 'possibility', 'nature']"
721,845,"Gender, software design, and occupational equity","after reviewing the work on gender bias in software design, a model of gender-role influenced achievement choice taken from eccles (1994) is presented. the paper concludes that (1) though laudable, reduction of gender bias in software design is not the most straightforward way to reduce gender inequity in the choice of computing as a career, (2) the model itself makes more clear some of the ethical issues involved in attempting to achieve gender equity on computing, and (3) efforts to reduce gender inequity in the choice of computing as a career need to be evaluated in the light of this model","['software design', 'occupational equity', 'gender bias', 'ethical issues', 'gender-role influenced achievement choice model', 'computing career']","['P', 'P', 'P', 'P', 'R', 'R']","['software design', 'occupational equity', 'gender bias', 'ethical issue', 'gender - role influence achievement choice model', 'compute career']","['role influence achievement choice take', 'achieve gender equity', 'gender bias', 'reduce gender inequity', 'software design', 'ethical issue involve', 'gender', 'career need', 'career', 'compute']"
722,1082,Numerical approximation of nonlinear BVPs by means of BVMs,"boundary value methods (bvms) would seem to be suitable candidates for the solution of nonlinear boundary value problems (bvps). they have been successfully used for solving linear bvps together with a mesh selection strategy based on the conditioning of the linear systems. our aim is to extend this approach so as to use them for the numerical approximation of nonlinear problems. for this reason, we consider the quasi-linearization technique that is an application of the newton method to the nonlinear differential equation. consequently, each iteration requires the solution of a linear bvp. in order to guarantee the convergence to the solution of the continuous nonlinear problem, it is necessary to determine how accurately the linear bvps must be solved. for this goal, suitable stopping criteria on the residual and on the error for each linear bvp are given. numerical experiments on stiff problems give rather satisfactory results, showing that the experimental code, called tom, that uses a class of bvms and the quasi-linearization technique, may be competitive with well known solvers for bvps","['numerical approximation', 'bvms', 'boundary value methods', 'nonlinear boundary value problems', 'mesh selection strategy', 'quasi-linearization technique', 'newton method', 'nonlinear differential equation', 'stopping criteria', 'stiff problems']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['numerical approximation', 'bvm', 'boundary value method', 'nonlinear boundary value problem', 'mesh selection strategy', 'quasi - linearization technique', 'newton method', 'nonlinear differential equation', 'stop criterion', 'stiff problem']","['nonlinear boundary value problem', 'solve linear bvps', 'numerical approximation', 'boundary value method', 'nonlinear differential equation', 'linear bvp', 'linearization technique', 'linear bvps', 'newton method', 'continuous nonlinear problem']"
723,1453,Mobile banking's tough sell,"banks are having to put their mobile-commerce projects on hold because the essential technology to make the services usable, in particular gprs (general packet radio service) hasn't become widely available. it is estimated that by the end of 2002, only 5 per cent of adults will have gprs phones. this will have a knock-on effect for other technologies such as clickable icons and multimedia messaging. in fact banking via wap (wireless application protocol) has proved to be a frustrating and time-consuming process for the customer. financial firms' hopes for higher mobile usage are stymied by the fact that improvements to the systems won't happen as fast as they want and the inadequacies of the system go beyond immature technology. financial services institutions should not wait for customers to become au fait with their wap. instead they should be the ones ""driving the traffic""","['banking', 'mobile-commerce', 'gprs', 'wireless application protocol']","['P', 'P', 'P', 'P']","['banking', 'mobile - commerce', 'gprs', 'wireless application protocol']","['wireless application protocol', 'financial service institution', 'gprs phone', 'general packet radio service', 'high mobile usage', 'multimedia message', 'fact banking', 'financial firm', 'other technology such', 'mobile']"
724,1416,Look into the future of content management,"predictions of consolidation in the content management (cm) vendor arena have appeared in nearly every major industry prognosis over the past two years. gartner group, for example, recently reiterated its prediction that half the cm vendors in existence in mid-2001 would leave the marketplace by the end of 2002. analysts consistently advise prospective cm buyers to tread carefully because their vendor may not stick around. but fortunately, the story goes, fewer vendor choices will finally bring greater clarity and sharper differentiators to this otherwise very messy product landscape. in fact, the number of cm vendors continues to rise. industry growth has come through greater demand among cm buyers, but also expanding product functionality as well as successful partnerships. the marketplace certainly cannot sustain its current breadth of vendors in the long run, yet it remains unclear when and how any serious industry consolidation will occur. in the meantime, evolving business models and feature sets have created just the kind of clearer segmentation and transparent product differences that were supposed to emerge following an industry contraction","['content management', 'product functionality', 'partnerships', 'industry consolidation', 'enterprise systems']","['P', 'P', 'P', 'P', 'U']","['content management', 'product functionality', 'partnership', 'industry consolidation', 'enterprise system']","['cm vendor continue', 'serious industry consolidation', 'advise prospective cm buyer', 'few vendor choice', 'cm vendor', 'expand product functionality', 'evolve business model', 'major industry prognosis', 'cm buyer', 'vendor arena']"
725,90,LAN-based building maintenance and surveillance robot,"the building and construction industry is the major industry of hong kong as in many developed countries around the world. after the commissioning of a high-rise building or a large estate, substantial manpower, both inside the management centre under a standby manner, as well as surveillance for security purposes around the whole building, is required for daily operation to ensure a quality environment for the occupants. if the surveillance job can be done by robots, the efficiency can be highly enhanced, resulting in a great saving of manpower and the improved safety of the management staff as a by-product. furthermore, if the robot can retrieve commands from the building management system via a local area network (lan), further savings in manpower can be achieved in terms of first-line fault attendance by human management staff. this paper describes the development of a robot prototype here in hong kong, which can handle some daily routine maintenance works and surveillance responsibilities. the hardware structure of the robot and its on-board devices are described. real-time images captured by a camera on the robot with pan/tilt/zoom functions can be transmitted back to the central management office via a local area network. the interface between the robot and the building automation system (bas) of the building is discussed. this is the first key achievement of this project with a strong implication on reducing the number of human staff to manage a modem building. teleoperation of the robot via the internet or intranet is also possible, which is the second achievement of this project. finally, the robot can identify its physical position inside the building by a landmark recognition method based on standard cad drawings, which is the third achievement of this project. the main goal of this paper is not the description of some groundbreaking technology in robotic development. it is mainly intended to convince building designers and managers to incorporate robotic systems when they are managing modem buildings to save manpower and improve efficiency","['lan-based building maintenance and surveillance robot', 'high-rise building', 'security purposes', 'building management system', 'local area network', 'first-line fault attendance', 'hardware structure', 'pan/tilt/zoom functions', 'teleoperation', 'landmark recognition method']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['lan - base building maintenance and surveillance robot', 'high - rise building', 'security purpose', 'build management system', 'local area network', 'first - line fault attendance', 'hardware structure', 'pan / tilt / zoom function', 'teleoperation', 'landmark recognition method']","['build automation system', 'manage modem building', 'robot prototype', 'build management system', 'human management staff', 'robotic system', 'central management office', 'robotic development', 'hong kong', 'surveillance responsibility']"
726,981,Basin configuration of a six-dimensional model of an electric power system,"as part of an ongoing project on the stability of massively complex electrical power systems, we discuss the global geometric structure of contacts among the basins of attraction of a six-dimensional dynamical system. this system represents a simple model of an electrical power system involving three machines and an infinite bus. apart from the possible occurrence of attractors representing pathological states, the contacts between the basins have a practical importance, from the point of view of the operation of a real electrical power system. with the aid of a global map of basins, one could hope to design an intervention strategy to boot the power system back into its normal state. our method involves taking two-dimensional sections of the six-dimensional state space, and then determining the basins directly by numerical simulation from a dense grid of initial conditions. the relations among all the basins are given for a specific numerical example, that is, choosing particular values for the parameters in our model","['basin configuration', 'six-dimensional model', 'electric power system', 'massively complex electrical power systems', 'global geometric structure', 'infinite bus', 'attractors', 'pathological states', 'global map', 'state space', 'power system stability']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['basin configuration', 'six - dimensional model', 'electric power system', 'massively complex electrical power system', 'global geometric structure', 'infinite bus', 'attractor', 'pathological state', 'global map', 'state space', 'power system stability']","['complex electrical power system', 'dimensional dynamical system', 'real electrical power system', 'electrical power system involve', 'attractor represent pathological state', 'numerical simulation', 'dimensional state space', 'basin have', 'power system', 'basin']"
727,556,Coarse-grained reduction and analysis of a network model of cortical response: I. Drifting grating stimuli,"we present a reduction of a large-scale network model of visual cortex developed by mclaughlin, shapley, shelley, and wielaard. the reduction is from many integrate-and-fire neurons to a spatially coarse-grained system for firing rates of neuronal subpopulations. it accounts explicitly for spatially varying architecture, ordered cortical maps (such as orientation preference) that vary regularly across the cortical layer, and disordered cortical maps (such as spatial phase preference or stochastic input conductances) that may vary widely from cortical neuron to cortical neuron. the result of the reduction is a set of nonlinear spatiotemporal integral equations for ""phase-averaged"" firing rates of neuronal subpopulations across the model cortex, derived asymptotically from the full model without the addition of any extra phenomological constants. this reduced system is used to study the response of the model to drifting grating stimuli - where it is shown to be useful for numerical investigations that reproduce, at far less computational cost, the salient features of the point-neuron network and for analytical investigations that unveil cortical mechanisms behind the responses observed in the simulations of the large-scale computational model. for example, the reduced equations clearly show (1) phase averaging as the source of the time-invariance of cortico-cortical conductances, (2) the mechanisms in the model for higher firing rates and better orientation selectivity of simple cells which are near pinwheel centers, (3) the effects of the length-scales of cortico-cortical coupling, and (4) the role of noise in improving the contrast invariance of orientation selectivity","['coarse-graining', 'large-scale network model', 'visual cortex', 'nonlinear spatiotemporal integral equations', 'point-neuron network', 'orientation selectivity', 'neuronal networks', 'phase-averaged firing rates', 'dynamics']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U']","['coarse - graining', 'large - scale network model', 'visual cortex', 'nonlinear spatiotemporal integral equation', 'point - neuron network', 'orientation selectivity', 'neuronal network', 'phase - average firing rate', 'dynamic']","['cortical neuron', 'disorder cortical map', 'cortical conductance', 'visual cortex', 'drift grate stimulus', 'cortical map', 'unveil cortical mechanism', 'cortical layer', 'model cortex', 'neuron network']"
728,1103,New age computing [autonomic computing],"autonomic computing (ac), sometimes called self-managed computing, is the name chosen by ibm to describe the company's new initiative aimed at making computing more reliable and problem-free. it is a response to a growing realization that the problem today with computers is not that they need more speed or have too little memory, but that they crash all too often. this article reviews current initiatives being carried out in the ac field by the it industry, followed by key challenges which require to be addressed in its development and implementation","['new age computing', 'autonomic computing', 'ac', 'self-managed computing', 'ibm initiative', 'computing reliability', 'problem-free computing', 'computer speed', 'computer memory', 'computer crash', 'it industry initiatives', 'ac requirements', 'ac development', 'ac implementation', 'open standards', 'self-healing computing', 'adaptive algorithms']","['P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'U', 'M', 'U']","['new age computing', 'autonomic computing', 'ac', 'self - manage computing', 'ibm initiative', 'compute reliability', 'problem - free computing', 'computer speed', 'computer memory', 'computer crash', 'it industry initiative', 'ac requirement', 'ac development', 'ac implementation', 'open standard', 'self - heal computing', 'adaptive algorithm']","['autonomic computing', 'manage computing', 'make compute', 'article review current initiative', 'ibm', 'ac field', 'computer', 'little memory', 'new initiative', 'it industry']"
729,1146,Mammogram synthesis using a 3D simulation. I. Breast tissue model and image acquisition simulation,a method is proposed for generating synthetic mammograms based upon simulations of breast tissue and the mammographic imaging process. a computer breast model has been designed with a realistic distribution of large and medium scale tissue structures. parameters controlling the size and placement of simulated structures (adipose compartments and ducts) provide a method for consistently modeling images of the same simulated breast with modified position or acquisition parameters. the mammographic imaging process is simulated using a compression model and a model of the x-ray image acquisition process. the compression model estimates breast deformation using tissue elasticity parameters found in the literature and clinical force values. the synthetic mammograms were generated by a mammogram acquisition model using a monoenergetic parallel beam approximation applied to the synthetically compressed breast phantom,"['mammogram synthesis', '3d simulation', 'breast tissue model', 'image acquisition simulation', 'computer breast model', 'adipose compartments', 'ducts', 'x-ray image acquisition', 'tissue elasticity parameters', 'force values', 'monoenergetic parallel beam approximation', 'mammographic compression', 'breast lesions', 'rectangular slice approximation', 'composite beam model', ""linear young's moduli""]","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M', 'M', 'U']","['mammogram synthesis', '3d simulation', 'breast tissue model', 'image acquisition simulation', 'computer breast model', 'adipose compartment', 'duct', 'x - ray image acquisition', 'tissue elasticity parameter', 'force value', 'monoenergetic parallel beam approximation', 'mammographic compression', 'breast lesion', 'rectangular slice approximation', 'composite beam model', ""linear young 's modulus""]","['compression model estimate breast deformation use tissue elasticity parameter', 'mammogram acquisition model use', 'generate synthetic mammogram', 'mammographic imaging process', 'synthetic mammogram', 'simulate breast', 'computer breast model', 'breast tissue', 'medium scale tissue structure', 'modeling image']"
730,939,Image reconstruction from fan-beam projections on less than a short scan,this work is concerned with 2d image reconstruction from fan-beam projections. it is shown that exact and stable reconstruction of a given region-of-interest in the object does not require all lines passing through the object to be measured. complete (non-truncated) fan-beam projections provide sufficient information for reconstruction when 'every line passing through the region-of-interest intersects the vertex path in a non-tangential way'. the practical implications of this condition are discussed and a new filtered-backprojection algorithm is derived for reconstruction. experiments with computer-simulated data are performed to support the mathematical results,"['fan-beam projections', '2d image reconstruction', 'region-of-interest', 'vertex path', 'filtered-backprojection algorithm', 'exact stable reconstruction', 'x-ray computed tomography', 'short-scan condition', 'hilbert transform', 'radon transform', 'rebinning formula', 'convolution', 'linear interpolation', '3d head phantom']","['P', 'P', 'P', 'P', 'P', 'R', 'U', 'M', 'U', 'U', 'U', 'U', 'U', 'U']","['fan - beam projection', '2d image reconstruction', 'region - of - interest', 'vertex path', 'filter - backprojection algorithm', 'exact stable reconstruction', 'x - ray compute tomography', 'short - scan condition', 'hilbert transform', 'radon transform', 'rebinne formula', 'convolution', 'linear interpolation', '3d head phantom']","['beam projection', 'backprojection algorithm', 'image reconstruction', 'reconstruction', 'vertex path', 'fan', 'line pass', 'simulate datum', 'intersect', 'line pass']"
731,612,Analysis and operation of hybrid active filter for harmonic elimination,"this paper presents a hybrid active filter topology and its control to suppress the harmonic currents from entering the power source. the adopted hybrid active filter consists of one active filter and one passive filter connected in series. by controlling the equivalent output voltage of active filter, the harmonic currents generated by the nonlinear load are blocked and flowed into the passive filter. the power rating of the converter is reduced compared with the pure active filters to filter the harmonic currents. the harmonic current detecting approach and dc-link voltage regulation are proposed to obtain equivalent voltage of active filter. the effectiveness of the adopted topology and control scheme has been verified by the computer simulation and experimental results in a scaled-down laboratory prototype","['hybrid active filter', 'active filter', 'harmonic elimination', 'harmonic currents', 'passive filter', 'equivalent output voltage', 'nonlinear load', 'dc-link voltage regulation', 'computer simulation', 'scaled-down laboratory prototype', 'harmonic currents suppression', 'converter power rating reduction', 'active filter equivalent voltage', 'voltage source inverter']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'R', 'M']","['hybrid active filter', 'active filter', 'harmonic elimination', 'harmonic current', 'passive filter', 'equivalent output voltage', 'nonlinear load', 'dc - link voltage regulation', 'computer simulation', 'scale - down laboratory prototype', 'harmonic current suppression', 'converter power rating reduction', 'active filter equivalent voltage', 'voltage source inverter']","['adopt hybrid active filter consist', 'hybrid active filter topology', 'passive filter', 'active filter', 'active filter', 'harmonic current detecting', 'harmonic current', 'filter', 'link voltage regulation', 'converter']"
732,657,The web services agenda,even the most battle-scarred of cios have become excited at the prospect of what web services can do for their businesses. but there are still some shortcomings to be addressed,"['web services', 'transaction support', 'security']","['P', 'U', 'U']","['web service', 'transaction support', 'security']","['web service', 'cio', 'business', 'shortcoming', 'prospect', 'be', 'scar', 'become', 'battle']"
733,1202,More than the money [software project],"experiences creating budgets for large software projects have taught manufacturers that it is not about the money - it is about what one really needs. before a company can begin to build a budget for a software. project, it has to have a good understanding of what business issues need to be addressed and what the business objectives are. this step is critical because it defines the business goals, outlines the metrics for success, sets the scope for the project, and defines the criteria for selecting the right software","['software projects', 'budgeting', 'manufacturing industry', 'management', 'software requirements']","['P', 'P', 'M', 'U', 'M']","['software project', 'budget', 'manufacture industry', 'management', 'software requirement']","['large software project', 'experience create budget', 'business objective', 'business goal', 'business issue need', 'budget', 'software', 'build', 'teach manufacturer', 'project']"
734,1247,The changing landscape for multi access portals,"discusses the factors that have made life difficult for consumer portal operators in recent years causing them, like others in the telecommunications, media and technology sector, to take a close look at their business models following the dot.com crash and the consequent reassessment of internet-related project financing by the venture capital community. while the pressure is on to generate income from existing customers and users, portal operators must reach new markets and find realistic revenue streams. this search for real revenues has led to a move towards charging for content, a strategy being pursued by a large number of horizontal portal players, including msn and terra lycos. this trend is particularly noticeable in china, where chinadotcom operates a mainland portal and plans a range of fee-based services, including electronic mail. the nature of advertising itself is changing, with portals seeking blue-chip sponsorship and marketing deals that span a number of years. players are struggling to redefine and reinvent themselves as a result of the changing environment and even the term ""portal"" is believed to be obsolete, partly due to its dot.com crash associations. multi-access portals are expected to dominate the consumer sector, becoming bigger and better overall than their predecessors and playing a more powerful role in the consumer environment","['consumer portal operators', 'revenue streams', 'fee-based services', 'advertising', 'blue-chip sponsorship', 'multi-access portals']","['P', 'P', 'P', 'P', 'P', 'P']","['consumer portal operator', 'revenue stream', 'fee - base service', 'advertise', 'blue - chip sponsorship', 'multi - access portal']","['consumer portal', 'chinadotcom operate', 'mainland portal', 'consumer sector', 'reach new market', 'venture capital community', 'exist customer', 'marketing deal', 'business model follow', 'access portal']"
735,824,"The Internet, knowledge and the academy","as knowledge is released from the bounds of libraries, as research becomes no longer confined to the academy, and education/certification is available, any time/any place, the university and the faculty must redefine themselves. liberal studies, once the core, and currently eschewed in favor of science and technology, will be reborn in those institutions that can rise above the mundane and embrace an emerging ""third culture""","['internet', 'knowledge', 'academy', 'education', 'certification', 'university', 'faculty', 'liberal studies']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['internet', 'knowledge', 'academy', 'education', 'certification', 'university', 'faculty', 'liberal study']","['liberal study', 'education', 'university', 'faculty', 'institution', 'third culture', 'technology', 'science', 'librarie', 'academy']"
736,861,The decision procedure for profitability of investment projects using the internal rate of return of single-period projects,"the internal rate of return (irr) criterion is often used to evaluate profitability of investment projects. in this paper, we focus on a single-period project which consists of two types of cash flows; an investment at one period and a return at a succeeding period, and a financing at one period and a repayment at a succeeding period. we decompose the given investment project into a series of the single-period projects. from the viewpoint of the single-period project, we point out the applicability issue of the irr criterion, namely the irr criterion cannot be applied in which a project is composed of both investment type and financing type. investigating the properties of a series of the single-period projects, we resolve the applicability issue of the irr criterion and propose the decision procedure for profitability judgment toward any type of investment project based on the comparison between the irr and the capital cost. we develop a new algorithm to obtain the value of the project investment rate (pir) for the given project, which is a function of the capital cost, only using the standard irr computing routine. this outcome is a theoretical breakthrough to widen the utilization of irr in practical applications","['decision procedure', 'profitability', 'internal rate of return', 'single-period projects', 'cash flows', 'irr criterion', 'project investment rate', 'pir', 'investment project profitability', 'investment project decomposition']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['decision procedure', 'profitability', 'internal rate of return', 'single - period project', 'cash flow', 'irr criterion', 'project investment rate', 'pir', 'investment project profitability', 'investment project decomposition']","['project investment rate', 'investment project', 'irr criterion', 'investment project base', 'give investment project', 'evaluate profitability', 'standard irr computing', 'profitability judgment', 'investment type', 'investment']"
737,1432,"To classify or not to classify, that is the question?","in addressing classification issues, the librarian needs to decide what best suits the purpose and requirements of the user group and the organisation they work in. the author has used the well-established moys classification scheme. this gives the level of detail required for current stock and allows for the incorporation of new material as the firm's specialisations develop. the scheme is widely used in other firms as well as in the local law society library, so it will be familiar to many users","['moys classification scheme', 'law society library']","['P', 'P']","['moy classification scheme', 'law society library']","['establish moys classification scheme', 'local law society library', 'address classification issue', 'specialisation develop', 'librarian need', 'other firm', 'organisation', 'user group', 'current stock', 'new material']"
738,1066,Application of artificial intelligence to search ground-state geometry of clusters,"we introduce a global optimization procedure, the neural-assisted genetic algorithm (naga). it combines the power of an artificial neural network (ann) with the versatility of the genetic algorithm. this method is suitable to solve optimization problems that depend on some kind of heuristics to limit the search space. if a reasonable amount of data is available, the ann can ""understand"" the problem and provide the genetic algorithm with a selected population of elements that will speed up the search for the optimum solution. we tested the method in a search for the ground-state geometry of silicon clusters. we trained the ann with information about the geometry and energetics of small silicon clusters. next, the ann learned how to restrict the configurational space for larger silicon clusters. for si/sub 10/ and si/sub 20/, we noticed that the naga is at least three times faster than the ""pure"" genetic algorithm. as the size of the cluster increases, it is expected that the gain in terms of time will increase as well","['artificial intelligence', 'ground-state geometry', 'global optimization procedure', 'neural-assisted genetic algorithm', 'artificial neural network', 'population', 'optimum solution', 'silicon clusters', 'si/sub 10/', 'si/sub 20/', 'atomic clusters', 'cluster size']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R']","['artificial intelligence', 'ground - state geometry', 'global optimization procedure', 'neural - assist genetic algorithm', 'artificial neural network', 'population', 'optimum solution', 'silicon cluster', 'si / sub 10/', 'si / sub 20/', 'atomic cluster', 'cluster size']","['small silicon cluster', 'large silicon cluster', 'silicon cluster', 'artificial neural network', 'global optimization procedure', 'assist genetic algorithm', 'genetic algorithm', 'search space', 'cluster increase', 'ann learn']"
739,1023,Simple nonlinear dual-window operator for edge detection,"we propose a nonlinear edge detection technique based on a two-concentric-circular-window operator. we perform a preliminary selection of edge candidates using a standard gradient and use the dual-window operator to reveal edges as zero-crossing points of a simple difference function depending only on the minimum and maximum values in the two windows. comparisons with other well-established techniques are reported in terms of visual appearance and computational efficiency. they show that detected edges are surely comparable with canny's and laplacian of gaussian algorithms, with a noteworthy reduction in terms of computational load","['nonlinear dual-window operator', 'edge detection', 'nonlinear edge detection technique', 'two-concentric-circular-window operator', 'standard gradient', 'zero-crossing points', 'difference function', 'maximum values', 'computational efficiency', 'detected edges', 'gaussian algorithms', 'computational load', 'dual window operator', 'minimum values', 'laplacian algorithms', ""canny's algorithms"", 'nonlinear processing']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'R', 'R', 'M']","['nonlinear dual - window operator', 'edge detection', 'nonlinear edge detection technique', 'two - concentric - circular - window operator', 'standard gradient', 'zero - cross point', 'difference function', 'maximum value', 'computational efficiency', 'detect edge', 'gaussian algorithm', 'computational load', 'dual window operator', 'minimum value', 'laplacian algorithm', ""canny 's algorithm"", 'nonlinear processing']","['nonlinear edge detection technique', 'detect edge', 'gaussian algorithm', 'reveal edge', 'window operator', 'edge candidate', 'concentric', 'circular', 'simple difference function depend', 'gradient']"
740,819,Local search with constraint propagation and conflict-based heuristics,"search algorithms for solving csp (constraint satisfaction problems) usually fall into one of two main families: local search algorithms and systematic algorithms. both families have their advantages. designing hybrid approaches seems promising since those advantages may be combined into a single approach. in this paper, we present a new hybrid technique. it performs a local search over partial assignments instead of complete assignments, and uses filtering techniques and conflict-based techniques to efficiently guide the search. this new technique benefits from both classical approaches: a priori pruning of the search space from filtering-based search and possible repair of early mistakes from local search. we focus on a specific version of this technique: tabu decision-repair. experiments done on open-shop scheduling problems show that our approach competes well with the best highly specialized algorithms","['search algorithms', 'csp', 'constraint satisfaction problems', 'local search algorithms', 'systematic algorithms', 'partial assignments', 'filtering techniques', 'tabu decision-repair']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['search algorithm', 'csp', 'constraint satisfaction problem', 'local search algorithm', 'systematic algorithm', 'partial assignment', 'filter technique', 'tabu decision - repair']","['shop scheduling problem', 'local search algorithm', 'search algorithm', 'constraint satisfaction problem', 'local search', 'solve csp', 'complete assignment', 'systematic algorithm', 'partial assignment', 'tabu decision']"
741,1367,The set of just-in-time management strategies: an assessment of their impact on plant-level productivity and input-factor substitutability using variable cost function estimates,"many manufacturers in the automobile industry around the world have adopted the just-in-time (jit) set of management strategies in an effort to improve productivity, efficiency and product quality. the paper provides empirical evidence that supports the idea that jit manufacturing environments are, in fact, more productive than their non-jit counterparts. plant-level cross-sectional data from auto-parts manufacturing firms are used to estimate variable cost functions for a jit group as well as for a non-jit group of plants. differences in cost function characteristics between the two groups are examined and discussed","['just-in-time management strategies', 'plant-level productivity', 'input-factor substitutability', 'variable cost function estimates', 'automobile industry', 'jit', 'efficiency', 'product quality', 'auto-parts manufacturing firms']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['just - in - time management strategy', 'plant - level productivity', 'input - factor substitutability', 'variable cost function estimate', 'automobile industry', 'jit', 'efficiency', 'product quality', 'auto - part manufacturing firm']","['part manufacturing firm', 'jit manufacture environment', 'automobile industry', 'estimate variable cost function', 'improve productivity', 'many manufacturer', 'management strategy', 'jit group', 'jit counterpart', 'efficiency']"
742,777,Access to information for blind and visually impaired clients,"this article guides i&r providers in establishing effective communication techniques for working with visually impaired consumers. the authors discuss common causes of vision impairment and the functional implications of each and offer information on disability etiquette and effective voice, accessible media and in-person communication. there is an overview of assistive technologies used by people who are visually impaired-to facilitate written and electronic communications as well as low-tech solutions for producing large-print and braille materials in-house. providers who implement these communication techniques will be well equipped to serve visually-impaired consumers, and consumers will be more likely to avail themselves of these services when providers make them easily accessible","['visually impaired clients', 'communication techniques', 'disability etiquette', 'effective voice', 'accessible media', 'in-person communication', 'assistive technologies', 'electronic communications', 'braille materials', 'information access', 'blind clients', 'information and referral systems', 'written communications', 'large-print materials']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'R', 'R']","['visually impair client', 'communication technique', 'disability etiquette', 'effective voice', 'accessible medium', 'in - person communication', 'assistive technology', 'electronic communication', 'braille material', 'information access', 'blind client', 'information and referral system', 'write communication', 'large - print material']","['vision impairment', 'impair consumer', 'disability etiquette', 'establish effective communication technique', 'assistive technology use', 'braille material', 'accessible medium', 'impair', 'electronic communication', 'communication technique']"
743,732,A unifying co-operative Web caching architecture,"network caching of objects has become a standard way of reducing network traffic and latency in the web. however, web caches exhibit poor performance with a hit rate of about 30%. a solution to improve this hit rate is to have a group of proxies form co-operation where objects can be cached for later retrieval. a cooperative cache system includes protocols for hierarchical and transversal caching. the drawback of such a system lies in the resulting network load due to the number of messages that need to be exchanged to locate an object. this paper proposes a new co-operative web caching architecture, which unifies previous methods of web caching. performance results shows that the architecture achieve up to 70% co-operative hit rate and accesses the cached object in at most two hops. moreover, the architecture is scalable with low traffic and database overhead","['co-operative web caching architecture', 'network caching', 'cooperative cache system', 'protocols', 'transversal caching', 'network load', 'co-operative hit rate', 'network traffic reduction', 'network latency reduction', 'hierarchical caching', 'scalable architecture', 'low traffic overhead', 'low database overhead', 'web browser', 'world wide web']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'R', 'R', 'R', 'R', 'M', 'M']","['co - operative web cache architecture', 'network cache', 'cooperative cache system', 'protocol', 'transversal cache', 'network load', 'co - operative hit rate', 'network traffic reduction', 'network latency reduction', 'hierarchical caching', 'scalable architecture', 'low traffic overhead', 'low database overhead', 'web browser', 'world wide web']","['cooperative cache system include protocol', 'operative web cache architecture', 'web cache', 'network cache', 'web cache exhibit', 'transversal cache', 'cache object', 'later retrieval', 'cache', 'reduce network traffic']"
744,1186,Implementing: it's all about processes,looks at how the key to successful technology deployment can be found in a set of four basic disciplines,"['implementation', 'technology deployment', 'incremental targets', 'third-party integration', 'vendor-supplied hardware integration services', 'vendor-supplied software integration services', 'manufacturers']","['P', 'P', 'U', 'U', 'U', 'U', 'U']","['implementation', 'technology deployment', 'incremental target', 'third - party integration', 'vendor - supply hardware integration service', 'vendor - supply software integration service', 'manufacturer']","['successful technology deployment', 'look', 'key', 'set']"
745,102,Harmless delays in Cohen-Grossberg neural networks,"without assuming monotonicity and differentiability of the activation functions and any symmetry of interconnections, we establish some sufficient conditions for the globally asymptotic stability of a unique equilibrium for the cohen-grossberg (1983) neural network with multiple delays. lyapunov functionals and functions combined with the razumikhin technique are employed. the criteria are all independent of the magnitudes of the delays, and thus the delays under these conditions are harmless","['harmless delays', 'cohen-grossberg neural networks', 'monotonicity', 'differentiability', 'activation functions', 'interconnections', 'globally asymptotic stability', 'multiple delays', 'lyapunov functionals', 'razumikhin technique']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['harmless delay', 'cohen - grossberg neural network', 'monotonicity', 'differentiability', 'activation function', 'interconnection', 'globally asymptotic stability', 'multiple delay', 'lyapunov functional', 'razumikhin technique']","['lyapunov functional', 'asymptotic stability', 'neural network', 'multiple delay', 'unique equilibrium', 'cohen', 'delay', 'activation function', 'differentiability', 'grossberg']"
746,941,Option pricing formulas based on a non-Gaussian stock price model,"options are financial instruments that depend on the underlying stock. we explain their non-gaussian fluctuations using the nonextensive thermodynamics parameter q. a generalized form of the black-scholes (bs) partial differential equation (1973) and some closed-form solutions are obtained. the standard bs equation (q = 1) which is used by economists to calculate option prices requires multiple values of the stock volatility (known as the volatility smile). using q = 1.5 which well models the empirical distribution of returns, we get a good description of option prices using a single volatility","['option pricing formulas', 'financial instruments', 'nonextensive thermodynamics parameter', 'closed-form solutions', 'stock volatility', 'volatility smile', 'empirical distribution', 'nongaussian stock price model', 'black-scholes partial differential equation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R']","['option pricing formula', 'financial instrument', 'nonextensive thermodynamic parameter', 'close - form solution', 'stock volatility', 'volatility smile', 'empirical distribution', 'nongaussian stock price model', 'black - schole partial differential equation']","['stock volatility', 'nonextensive thermodynamic parameter', 'gaussian fluctuation', 'volatility smile', 'option price', 'empirical distribution', 'standard bs equation', 'underlie stock', 'partial differential equation', 'schole']"
747,904,Modeling and simulation of adaptive available bit rate voice over asynchronous transfer mode networks,"this article presents a modeling and simulation methodology to analyze the performance of voice quality when sent over the available bit rate service in asynchronous transfer mode networks. sources can modify the rate at which they send traffic to the network based on the feedback carried in the resource management cells. this is achieved by changing the encoding level. as the contention increases to network resources-bandwidth in this case-sources start reducing the rate at which they generate and send traffic. the efficiency of the scheme under different scheduling/drop policies and other operating conditions and environments is evaluated using simulation modeling. furthermore, sensitivity analysis is applied to different parameters, such as queue size and averaging interval length, to investigate their impact on the performance metrics. results show that limiting the load to 41% of the link capacity results in an acceptable quality","['modeling', 'simulation', 'adaptive available bit rate voice', 'voice quality', 'traffic', 'feedback', 'resource management cells', 'encoding level', 'scheduling/drop policies', 'queue size', 'averaging interval length', 'performance metrics', 'link capacity', 'performance analysis', 'bandwidth contention', 'atm networks']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M']","['model', 'simulation', 'adaptive available bit rate voice', 'voice quality', 'traffic', 'feedback', 'resource management cell', 'encode level', 'scheduling / drop policy', 'queue size', 'average interval length', 'performance metric', 'link capacity', 'performance analysis', 'bandwidth contention', 'atm network']","['asynchronous transfer mode network', 'voice quality', 'available bit rate service', 'bandwidth', 'network resource', 'queue size', 'contention increase', 'send traffic', 'link capacity', 'performance metric']"
748,596,Copyright management in the digital age,"listening to and buying music online is becoming increasingly popular with consumers. so much so that merrill lynch forecasts the value of the online music market will explode from $8 million in 2001 to $1,409 million in 2005. but online delivery is not without problems; the issue of copyright management in particular has become a serious thorn in the side for digital content creators. martin brass, ex- music producer and senior industry consultant at syntegra, explains","['digital age', 'digital content creators', 'online music delivery', 'music industry', 'internet', 'napster']","['P', 'P', 'R', 'R', 'U', 'U']","['digital age', 'digital content creator', 'online music delivery', 'music industry', 'internet', 'napster']","['online music market', 'digital content creator', 'buy music', 'music producer', 'copyright management', 'merrill lynch forecast', 'martin brass', 'industry consultant', 'online delivery', 'value']"
749,1287,On average depth of decision trees implementing Boolean functions,"the article considers the representation of boolean functions in the form of decision trees. it presents the bounds on average time complexity of decision trees for all classes of boolean functions that are closed over substitution, and the insertion and deletion of unessential variables. the obtained results are compared with the results developed by m.ju. moshkov (1995) that describe the worst case time complexity of decision trees","['average depth', 'decision trees', 'boolean functions', 'average time complexity', 'worst case time complexity']","['P', 'P', 'P', 'P', 'P']","['average depth', 'decision tree', 'boolean function', 'average time complexity', 'bad case time complexity']","['bad case time complexity', 'average time complexity', 'boolean function', 'decision tree', 'unessential variable', 'bound', 'article consider', 'substitution', 'insertion', 'class']"
750,697,Schedulability analysis of real-time traffic in WorldFIP networks: an integrated approach,"the worldfip protocol is one of the profiles that constitute the european fieldbus standard en-50170. it is particularly well suited to be used in distributed computer-controlled systems where a set of process variables must be shared among network devices. to cope with the real-time requirements of such systems, the protocol provides communication services based on the exchange of periodic and aperiodic identified variables. the periodic exchanges have the highest priority and are executed at run time according to a cyclic schedule. therefore, the respective schedulability can be determined at pre-run-time when building the schedule table. concerning the aperiodic exchanges, the situation is different since their priority is lower and they are bandied according to a first-come-first-served policy. in this paper, a response-time-based schedulability analysis for the real-time traffic is presented. such analysis considers both types of traffic in an integrated way, according to their priorities. furthermore, a fixed-priorities-based policy is also used to schedule the periodic traffic. the proposed analysis represents an improvement relative to previous work and it can be evaluated online as part of a traffic online admission control. this feature is of particular importance when a planning scheduler is used, instead of the typical offline static scheduler, to allow online changes to the set of periodic process variables","['worldfip networks', 'distributed computer-controlled systems', 'communication services', 'aperiodic exchanges', 'first-come-first-served policy', 'traffic online admission control', 'periodic process variables', 'en-50170 european fieldbus standard', 'real-time traffic schedulability analysis', 'real-time communication', 'scheduling algorithms', 'response time']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'M']","['worldfip network', 'distribute computer - control system', 'communication service', 'aperiodic exchange', 'first - come - first - serve policy', 'traffic online admission control', 'periodic process variable', 'en-50170 european fieldbus standard', 'real - time traffic schedulability analysis', 'real - time communication', 'scheduling algorithm', 'response time']","['typical offline static scheduler', 'protocol provide communication service base', 'traffic online admission control', 'plan scheduler', 'worldfip protocol', 'respective schedulability', 'base schedulability analysis', 'cyclic schedule', 'schedule table', 'schedule']"
751,1301,Integrate-and-fire neurons driven by correlated stochastic input,"neurons are sensitive to correlations among synaptic inputs. however, analytical models that explicitly include correlations are hard to solve analytically, so their influence on a neuron's response has been difficult to ascertain. to gain some intuition on this problem, we studied the firing times of two simple integrate-and-fire model neurons driven by a correlated binary variable that represents the total input current. analytic expressions were obtained for the average firing rate and coefficient of variation (a measure of spike-train variability) as functions of the mean, variance, and correlation time of the stochastic input. the results of computer simulations were in excellent agreement with these expressions. in these models, an increase in correlation time in general produces an increase in both the average firing rate and the variability of the output spike trains. however, the magnitude of the changes depends differentially on the relative values of the input mean and variance: the increase in firing rate is higher when the variance is large relative to the mean, whereas the increase in variability is higher when the variance is relatively small. in addition, the firing rate always tends to a finite limit value as the correlation time increases toward infinity, whereas the coefficient of variation typically diverges. these results suggest that temporal correlations may play a major role in determining the variability as well as the intensity of neuronal spike trains","['integrate-and-fire neurons', 'correlated stochastic input', 'firing times', 'correlated binary variable', 'coefficient of variation', 'spike-train variability', 'computer simulation', 'output spike trains', 'temporal correlations', 'synaptic input correlations']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['integrate - and - fire neuron', 'correlate stochastic input', 'fire time', 'correlate binary variable', 'coefficient of variation', 'spike - train variability', 'computer simulation', 'output spike train', 'temporal correlation', 'synaptic input correlation']","['fire model neuron drive', 'correlation time increase', 'temporal correlation', 'synaptic input', 'correlate binary variable', 'output spike train', 'correlation time', 'stochastic input', 'train variability', 'fire time']"
752,1344,Restoration of archival documents using a wavelet technique,"this paper addresses a problem of restoring handwritten archival documents by recovering their contents from the interfering handwriting on the reverse side caused by the seeping of ink. we present a novel method that works by first matching both sides of a document such that the interfering strokes are mapped with the corresponding strokes originating from the reverse side. this facilitates the identification of the foreground and interfering strokes. a wavelet reconstruction process then iteratively enhances the foreground strokes and smears the interfering strokes so as to strengthen the discriminating capability of an improved canny edge detector against the interfering strokes. the method has been shown to restore the documents effectively with average precision and recall rates for foreground text extraction at 84 percent and 96 percent, respectively","['wavelet technique', 'handwritten archival documents', 'wavelet reconstruction process', 'canny edge detector', 'archival documents restoration', 'ink seepage', 'iterative stroke enhancement']","['P', 'P', 'P', 'P', 'R', 'M', 'R']","['wavelet technique', 'handwritten archival document', 'wavelet reconstruction process', 'canny edge detector', 'archival document restoration', 'ink seepage', 'iterative stroke enhancement']","['restore handwritten archival document', 'foreground text extraction', 'interfere handwriting', 'improve canny edge detector', 'wavelet reconstruction process', 'foreground stroke', 'interfere stroke', 'ink', 'paper address', 'document such']"
753,711,On bivariate dependence and the convex order,"we investigate the interplay between variability (in the sense of the convex order) and dependence in a bivariate framework, extending some previous results in this area. we exploit the fact that discrete uniform distributions are dense in the space of probability measures in the topology of weak convergence to prove our central result. we also obtain a partial result in the general multivariate case. our findings can be interpreted in terms of the impact of component variability on the mean life of correlated serial and parallel systems","['bivariate dependence', 'convex order', 'discrete uniform distributions', 'probability measures', 'topology', 'weak convergence', 'component variability', 'mean life', 'parallel systems', 'serial systems', 'bivariate probability distributions']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['bivariate dependence', 'convex order', 'discrete uniform distribution', 'probability measure', 'topology', 'weak convergence', 'component variability', 'mean life', 'parallel system', 'serial system', 'bivariate probability distribution']","['correlate serial', 'component variability', 'discrete uniform distribution', 'general multivariate', 'variability', 'bivariate framework', 'weak convergence', 'probability measure', 'dependence', 'convex order']"
754,754,Record makers [UK health records],plans for a massive cradle-to-grave electronic records project have been revealed by the government. is the scheme really viable?,"['uk health records', 'electronic records project', 'integrated care records services', 'health care', 'social care']","['P', 'P', 'M', 'M', 'U']","['uk health record', 'electronic record project', 'integrate care record service', 'health care', 'social care']","['grave electronic record project', 'massive cradle', 'plan', 'viable', 'government', 'scheme', 'reveal']"
755,1000,Does classicism explain universality? Arguments against a pure classical component of mind,"one of the hallmarks of human cognition is the capacity to generalize over arbitrary constituents. marcus (cognition 66, p.153; cognitive psychology 37, p. 243, 1998) argued that this capacity, called ""universal generalization"" (universality), is not supported by connectionist models. instead, universality is best explained by classical symbol systems, with connectionism as its implementation. here it is argued that universality is also a problem for classicism in that the syntax-sensitive rules that are supposed to provide causal explanations of mental processes are either too strict, precluding possible generalizations; or too lax, providing no information as to the appropriate alternative. consequently, universality is not explained by a classical theory","['classicism', 'universality', 'classical component of mind', 'human cognition', 'universal generalization', 'connectionist models', 'classical symbol systems', 'syntax-sensitive rules', 'causal explanations', 'mental processes']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['classicism', 'universality', 'classical component of mind', 'human cognition', 'universal generalization', 'connectionist model', 'classical symbol system', 'syntax - sensitive rule', 'causal explanation', 'mental process']","['universal generalization', 'cognitive psychology', 'classical symbol system', 'preclude possible generalization', 'human cognition', 'universality', 'provide causal explanation', 'cognition', 'connectionist model', 'generalize']"
756,1045,Using fractional order adjustment rules and fractional order reference models in model-reference adaptive control,"this paper investigates the use of fractional order calculus (foc) in conventional model reference adaptive control (mrac) systems. two modifications to the conventional mrac are presented, i.e., the use of fractional order parameter adjustment rule and the employment of fractional order reference model. through examples, benefits from the use of foc are illustrated together with some remarks for further research","['fractional order adjustment rules', 'fractional order reference models', 'model-reference adaptive control', 'foc', 'mrac', 'fractional calculus']","['P', 'P', 'P', 'P', 'P', 'R']","['fractional order adjustment rule', 'fractional order reference model', 'model - reference adaptive control', 'foc', 'mrac', 'fractional calculus']","['conventional model reference adaptive control', 'fractional order parameter adjustment rule', 'fractional order reference model', 'fractional order calculus', 'conventional mrac', 'mrac', 'system', 'foc', 'modification', 'example']"
757,882,On M/D/1 queue with deterministic server vacations,"we study a single server vacation queue with poisson arrivals, deterministic service of constant duration b (> 0) and deterministic vacations of constant duration d (> 0) and designate this model as m/d/d/1. after completion of each service, the server may take a vacation with probability p or may continue working in the system with probability 1 - p. we obtain time-dependent as well as steady state probability generation functions for the number in the system. for the steady state we obtain explicitly the mean number and the mean waiting time for the system and for the queue. all known results of the m/d/1 queue are derived as a special case. finally, a numerical illustration is discussed","['m/d/1 queue', 'deterministic server vacations', 'poisson arrivals', 'deterministic service', 'deterministic vacations', 'steady state probability generation functions', 'mean number', 'mean waiting time', 'm/d/d/1 model', 'time-dependent probability generation functions']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['m / d/1 queue', 'deterministic server vacation', 'poisson arrival', 'deterministic service', 'deterministic vacation', 'steady state probability generation function', 'mean number', 'mean wait time', 'm / d / d/1 model', 'time - dependent probability generation function']","['single server vacation queue', 'poisson arrival', 'steady state probability generation function', 'deterministic vacation', 'queue', 'constant duration', 'deterministic service', 'mean wait time', 'vacation', 'steady state']"
758,548,Cool and green [air conditioning],"in these days of global warming, air conditioning engineers need to specify not just for the needs of the occupants, but also to maximise energy efficiency. julian brunnock outlines the key areas to consider for energy efficient air conditioning systems","['air conditioning', 'energy efficiency']","['P', 'P']","['air conditioning', 'energy efficiency']","['maximise energy efficiency', 'air conditioning engineer', 'global warming', 'occupant', 'key area', 'specify', 'consider', 'julian brunnock', 'need']"
759,1158,From powder to perfect parts,gkn sinter metals has increased productivity and quality by automating the powder metal lines that produce its transmission parts,"['gkn sinter metals', 'automating', 'powder metal lines', 'conveyors', 'gentle transfer units', 'robotic systems']","['P', 'P', 'P', 'U', 'U', 'U']","['gkn sinter metal', 'automate', 'powder metal line', 'conveyor', 'gentle transfer unit', 'robotic system']","['gkn sinter metal', 'powder metal line', 'increase productivity', 'quality', 'produce', 'automate']"
760,927,Autonomous detection of crack initiation using surface-mounted piezotransducers,"in this paper we report on the application of an in situ health monitoring system, comprising an array of piezoceramic wafer elements, to the detection of fatigue degradation in metallic specimens exposed to cyclic loading. lamb waves, transmitted through a beam test coupon, are sensed using small surface-mounted piezotransducer elements, and the signals are then autonomously analysed for indications relating to the onset of structural degradation. the experimental results confirm the efficacy of the approach and provide a demonstration of good robustness under realistic loading conditions, emphasizing the great potential for developing an automated in situ structural health monitoring system for application to fatigue-prone operational structures, such as aircraft","['in situ health monitoring', 'piezoceramic wafer elements', 'fatigue degradation', 'metallic specimens', 'cyclic loading', 'lamb waves', 'surface-mounted piezotransducer elements', 'structural degradation', 'robustness', 'loading conditions', 'automated in situ structural health monitoring', 'aircraft', 'fatigue operational structures']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['in situ health monitoring', 'piezoceramic wafer element', 'fatigue degradation', 'metallic specimen', 'cyclic loading', 'lamb wave', 'surface - mount piezotransducer element', 'structural degradation', 'robustness', 'loading condition', 'automate in situ structural health monitoring', 'aircraft', 'fatigue operational structure']","['situ structural health monitoring system', 'situ health monitoring system', 'fatigue degradation', 'mount piezotransducer element', 'piezoceramic wafer element', 'structural degradation', 'lamb wave', 'fatigue', 'beam test', 'metallic specimen']"
761,962,Optimal control using the transport equation: the Liouville machine,"transport theory describes the scattering behavior of physical particles such as photons. here we show how to connect this theory to optimal control theory and to adaptive behavior of agents embedded in an environment. environments and tasks are defined by physical boundary conditions. given some task, we compute a set of probability densities on continuous state and action and time. from these densities we derive an optimal policy such that for all states the most likely action maximizes the probability of reaching a predefined goal state. liouville's conservation theorem tells us that the conditional density at time t, state s, and action a must equal the density at t + dt, s + ds, a + da. discretization yields a linear system that can be solved directly and whose solution corresponds to an optimal policy. discounted reward schemes are incorporated naturally by taking the laplace transform of the equations. the liouville machine quickly solves rather complex maze problems","['optimal control', 'transport equation', 'liouville machine', 'scattering behavior', 'physical particles', 'adaptive behavior', 'embedded agents']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['optimal control', 'transport equation', 'liouville machine', 'scatter behavior', 'physical particle', 'adaptive behavior', 'embed agent']","['optimal control theory', 'transport theory describe', 'physical boundary condition', 'optimal policy', 'physical particle', 'discount reward scheme', 'scatter behavior', 'action maximize', 'probability density', 'adaptive behavior']"
762,121,Formula-dependent equivalence for compositional CTL model checking,"we present a polytime computable state equivalence that is defined with respect to a given ctl formula. since it does not attempt to preserve all ctl formulas, like bisimulation does, we can expect to compute coarser equivalences. this equivalence can be used to reduce the complexity of model checking a system of interacting fsm. additionally, we show that in some cases our techniques can detect if a formula passes or fails, without forming the entire product machine. the method is exact and fully automatic, and handles full ctl","['formula-dependent equivalence', 'ctl model checking', 'polytime computable state equivalence', 'ctl formula', 'interacting fsm', 'compositional minimization', 'coarse equivalence', 'complexity reduction', 'automatic method', 'formal design verification', 'computation tree logic']","['P', 'P', 'P', 'P', 'P', 'M', 'M', 'M', 'R', 'U', 'M']","['formula - dependent equivalence', 'ctl model check', 'polytime computable state equivalence', 'ctl formula', 'interact fsm', 'compositional minimization', 'coarse equivalence', 'complexity reduction', 'automatic method', 'formal design verification', 'computation tree logic']","['polytime computable state equivalence', 'compute coarser equivalence', 'give ctl formula', 'ctl formula', 'interact fsm', 'model check', 'entire product machine', 'bisimulation', 'complexity', 'detect']"
763,73,How does attitude impact IT implementation: a study of small business owners,"according to previous studies, attitude towards information technology (it) among small business owners appears to be a key factor in achieving high quality it implementations. in an effort to extend this stream of research, we conducted case studies with small business owners and learned that high quality it implementations resulted with owners who had positive or negative attitudes toward it, but not with owners who had uncertain attitudes. owners with apolar attitude, either positive or negative, all took action to temper the uncertainty and risk surrounding the use of new it in their organization. in contrast, owners with uncertain attitudes did not make mitigating attempts to reduce uncertainty and risk. a consistent finding among those with high quality it implementations was an entrepreneurial, or shared, management style. it is proposed, based on case study data, that small business owners with an uncertain attitude towards it might experience higher quality it results in their organizations through practicing a more entrepreneurial, or shared, management style. the study provides insights for both computer specialists and small business owners planning it implementations","['small business owners', 'negative attitudes', 'uncertain attitude', 'risk', 'organization', 'management style', 'computer specialists', 'planning', 'information technology implementation', 'positive attitudes']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['small business owner', 'negative attitude', 'uncertain attitude', 'risk', 'organization', 'management style', 'computer specialist', 'plan', 'information technology implementation', 'positive attitude']","['small business owner plan', 'small business owner appear', 'small business owner', 'uncertain attitude', 'uncertain attitude', 'experience high quality', 'management style', 'entrepreneurial', 'information technology', 'achieve high quality']"
764,649,Methods for outlier detection in prediction,"if a prediction sample is different from the calibration samples, it can be considered as an outlier in prediction. in this work, two techniques, the use of uncertainty estimation and the convex hull method are studied to detect such prediction outliers. classical techniques (mahalanobis distance and x-residuals), potential functions and robust techniques are used for comparison. it is concluded that the combination of the convex hull method and uncertainty estimation offers a practical way for detecting outliers in prediction. by adding the potential function method, inliers can also be detected","['outlier detection', 'prediction sample', 'calibration samples', 'uncertainty estimation', 'convex hull method', 'mahalanobis distance', 'x-residuals', 'potential functions', 'robust techniques', 'inliers']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['outlier detection', 'prediction sample', 'calibration sample', 'uncertainty estimation', 'convex hull method', 'mahalanobis distance', 'x - residual', 'potential function', 'robust technique', 'inlier']","['detect such prediction outlier', 'detect outlier', 'uncertainty estimation', 'convex hull method', 'outlier', 'inlier', 'calibration sample', 'prediction sample', 'robust technique', 'prediction']"
765,1259,A mechanism for inferring approximate solutions under incomplete knowledge based on rule similarity,"this paper proposes an inference method which can obtain an approximate solution even if the knowledge stored in the problem-solving system is incomplete. when a rule needed for solving the problem does not exist, the problem can be solved by using rules similar to the existing rules. in an implementation using the sld procedure, a resolution is executed between a subgoal and a rule if an atom of the subgoal is similar to the consequence atom of the rule. similarities between atoms are calculated using a knowledge base of words with account of the reasoning situation, and the reliability of the derived solution is calculated based on these similarities. if many solutions are obtained, they are grouped into classes of similar solutions and a representative solution is then selected for each class. the proposed method was verified experimentally by solving simple problems","['approximate solution', 'incomplete knowledge', 'rule similarity', 'inference method', 'sld procedure', 'consequence atom', 'reasoning', 'reliability', 'representative solution', 'problem solving', 'subgoal atom', 'word knowledge base', 'common sense knowledge']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M']","['approximate solution', 'incomplete knowledge', 'rule similarity', 'inference method', 'sld procedure', 'consequence atom', 'reason', 'reliability', 'representative solution', 'problem solve', 'subgoal atom', 'word knowledge base', 'common sense knowledge']","['inference method', 'reasoning situation', 'solve system', 'sld procedure', 'knowledge base', 'approximate solution', 'similar solution', 'use rule similar', 'derive solution', 'propose method']"
766,1198,Post-projected Runge-Kutta methods for index-2 differential-algebraic equations,"a new projection technique for runge-kutta methods applied to index-2 differential-algebraic equations is presented in which the numerical approximation is projected only as part of the output process. it is shown that for methods that are strictly stable at infinity, the order of convergence is unaffected compared to standard projected methods. gauss methods, for which this technique is of special interest when some symmetry is to be preserved, are studied in more detail","['post-projected runge-kutta methods', 'index-2 differential-algebraic equations', 'numerical approximation', 'order of convergence', 'projected methods']","['P', 'P', 'P', 'P', 'P']","['post - project runge - kutta method', 'index-2 differential - algebraic equation', 'numerical approximation', 'order of convergence', 'project method']","['kutta method', 'numerical approximation', 'project method', 'gauss method', 'projection technique', 'method', 'algebraic equation', 'differential', 'runge', 'technique']"
767,588,An accurate COG defuzzifier design using Lamarckian co-adaptation of learning and evolution,"this paper proposes a design technique of optimal center of gravity (cog) defuzzifier using the lamarckian co-adaptation of learning and evolution. the proposed cog defuzzifier is specified by various design parameters such as the centers, widths, and modifiers of mfs. the design parameters are adjusted with the lamarckian co-adaptation of learning and evolution, where the learning performs a local search of design parameters in an individual cog defuzzifier, but the evolution performs a global search of design parameters among a population of various cog defuzzifiers. this co-adaptation scheme allows to evolve much faster than the non-learning case and gives a higher possibility of finding an optimal solution due to its wider searching capability. an application to the truck backer-upper control problem of the proposed co-adaptive design method of cog defuzzifier is presented. the approximation ability and control performance are compared with those of the conventionally simplified cog defuzzifier in terms of the fuzzy logic controller's approximation error and the average tracing distance, respectively","['learning', 'evolution', 'local search', 'fuzzy logic controller', 'optimal center of gravity defuzzifier']","['P', 'P', 'P', 'P', 'R']","['learn', 'evolution', 'local search', 'fuzzy logic controller', 'optimal center of gravity defuzzifier']","['adaptive design method', 'propose cog defuzzifier', 'fuzzy logic controller', 'simplify cog defuzzifier', 'optimal center', 'individual cog defuzzifier', 'cog defuzzifier', 'cog defuzzifier', 'truck backer', 'wide search capability']"
768,674,Portal payback,"the benefits of deploying a corporate portal are well-documented: access to applications and content is centralised, so users do not spend hours searching for information; the management of disparate applications is also centralised, and by allowing users to access 'self-service' applications in areas such as human resources and procurement, organisations spend less time on manual processing tasks. but how far can prospective customers rely on the roi figures presented to them by portal technology vendors? in particular, how reliable are the 'roi calculators' these vendors supply on their web sites?","['corporate portal', 'roi calculator', 'web sites', 'return on investment', 'metrics']","['P', 'P', 'P', 'M', 'U']","['corporate portal', 'roi calculator', 'web site', 'return on investment', 'metric']","['portal technology vendor', 'roi calculator', 'roi figure present', 'corporate portal', 'prospective customer rely', 'vendor supply', 'organisation spend less', 'application', 'benefit', 'procurement']"
769,631,A modified Fieller interval for the interval estimation of effective doses for a logistic dose-response curve,"interval estimation of the gamma % effective dose ( mu /sub gamma / say) is often based on the asymptotic variance of the maximum likelihood estimator (delta interval) or fieller's theorem (fieller interval). sitter and wu (1993) compared the delta and fieller intervals for the median effective dose ( mu /sub 50/) assuming a logistic dose-response curve. their results indicated that although fieller intervals are generally superior to delta intervals, they appear to be conservative. here an adjusted form of the fieller interval for mu /sub gamma / termed an adjusted fieller (af) interval is introduced. a comparison of the af interval with the delta and fieller intervals is provided and the properties of these three interval estimation methods are investigated","['modified fieller interval', 'interval estimation', 'effective doses', 'logistic dose-response curve', 'asymptotic variance', 'maximum likelihood estimator', 'delta interval', ""fieller's theorem"", 'median effective dose']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['modify fieller interval', 'interval estimation', 'effective dose', 'logistic dose - response curve', 'asymptotic variance', 'maximum likelihood estimator', 'delta interval', ""fieller 's theorem"", 'median effective dose']","['maximum likelihood estimator', 'interval estimation method', 'interval estimation', 'median effective dose', 'fieller interval', 'fieller interval', 'delta interval', 'effective dose', 'delta interval', 'adjust fieller']"
770,1264,Estimation of the vanishing point for automatic driving system using a cross ratio,"this paper proposes a new method to estimate the vanishing point used as the vehicle heading, which is essential in automatic driving systems. the proposed method uses a cross ratio comprised of a ratio of lengths from four collinear points for extracting the edges that shape the vanishing point. then, lines that intersect at one point are fitted to the edges in a hough space. consequently, the vanishing point is estimated robustly even when the lane markings are occluded by other vehicles. in the presence of lane markings, the road boundaries are also estimated at the same time. experimental results from images of a real road scene show the effectiveness of the proposed method","['automatic driving system', 'automatic driving system', 'cross ratio', 'collinear points', 'hough space', 'lane markings', 'real road scene', 'vanishing point estimation', 'automatic driving systems']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'P']","['automatic driving system', 'automatic driving system', 'cross ratio', 'collinear point', 'hough space', 'lane marking', 'real road scene', 'vanish point estimation', 'automatic driving system']","['lane marking', 'vanish point', 'real road scene show', 'collinear point', 'vehicle heading', 'road boundary', 'automatic driving system', 'intersect', 'cross ratio comprise', 'line']"
771,1221,An approach to developing computational supports for reciprocal tutoring,"this study presents a novel approach to developing computational supports for reciprocal tutoring. reciprocal tutoring is a collaborative learning activity, where two participants take turns to play the role of a tutor and a tutee. the computational supports include scaffolding tools for the tutor and a computer-simulated virtual participant. the approach, including system architecture, implementations of scaffolding tools for the tutor and of a virtual participant is presented herein. furthermore, a system for reciprocal tutoring is implemented as an example of the approach","['collaborative learning', 'scaffolding tools', 'computer-simulated virtual participant', 'system architecture', 'reciprocal tutoring computational support', 'intelligent tutoring system']","['P', 'P', 'P', 'P', 'R', 'M']","['collaborative learning', 'scaffold tool', 'computer - simulate virtual participant', 'system architecture', 'reciprocal tutoring computational support', 'intelligent tutoring system']","['computational support include scaffold tool', 'reciprocal tutoring', 'collaborative learning activity', 'develop computational support', 'simulate virtual participant', 'tutor', 'scaffold tool', 'virtual participant', 'study present', 'participant']"
772,1299,How much should publishers spend on technology?,"a study confirms that spending on publishing-specific information technology (it) resources is growing much faster than it spending for general business activities, at least among leading publishers in the scientific, technical and medical (stm) market. the survey asked about information technology funding and staffing levels-past, present and future-and also inquired about activities in content management, web delivery, computer support and customer relationship management. the results provide a starting point for measuring information technology growth and budget allocations in this publishing segment","['publishing', 'it spending', 'content management', 'web delivery', 'computer support', 'customer relationship management', 'budget']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['publish', 'it spend', 'content management', 'web delivery', 'computer support', 'customer relationship management', 'budget']","['measure information technology growth', 'information technology funding', 'specific information technology', 'lead publisher', 'budget allocation', 'content management', 'web delivery', 'publish', 'business activity', 'customer relationship management']"
773,689,Continuous-time linear systems: folklore and fact,"we consider a family of continuous input-output maps representing linear time-invariant systems that take a set of signals into itself. it is shown that this family contains maps whose impulse response is the zero function, but which take certain inputs into nonzero outputs. it is shown also that this family contains members whose input-output properties are not described by their frequency domain response functions, and that the maps considered need not even commute","['linear systems', 'continuous input-output maps', 'time-invariant systems', 'impulse response', 'zero function', 'frequency domain response', 'commutation', 'continuous-time systems', 'signal processing']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['linear system', 'continuous input - output map', 'time - invariant system', 'impulse response', 'zero function', 'frequency domain response', 'commutation', 'continuous - time system', 'signal processing']","['output map represent linear time', 'frequency domain response function', 'invariant system', 'family contain map', 'nonzero output', 'output property', 'continuous input', 'map', 'signal', 'impulse response']"
774,575,A new voltage-vector selection algorithm in direct torque control of induction motor drives,"ac drives based on direct torque control of induction machines allow high dynamic performance to be obtained with very simple control schemes. the drive behavior, in terms of current, flux and torque ripple, is dependent on the utilised voltage vector selection strategy and the operating conditions. in this paper a new voltage vector selection algorithm, which allows a sensible reduction of the rms value of the stator current ripple without increasing the average value of the inverter switching frequency and without the need of a pwm pulse generator block is presented numerical simulations have been carried out to validate the proposed method","['voltage-vector selection algorithm', 'direct torque control', 'induction motor drives', 'ac drives', 'high dynamic performance', 'torque ripple', 'voltage vector selection strategy', 'operating conditions', 'rms value', 'stator current ripple', 'inverter switching frequency', 'torque variations', 'flux variations', '4-poles induction motor', 'steady-state operation', 'dynamic behavior', 'torque step response', '220 v', '50 hz', '4 kw']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'M', 'M', 'R', 'M', 'U', 'U', 'U']","['voltage - vector selection algorithm', 'direct torque control', 'induction motor drive', 'ac drive', 'high dynamic performance', 'torque ripple', 'voltage vector selection strategy', 'operate condition', 'rm value', 'stator current ripple', 'inverter switch frequency', 'torque variation', 'flux variation', '4 - pole induction motor', 'steady - state operation', 'dynamic behavior', 'torque step response', '220 v', '50 hz', '4 kw']","['new voltage vector selection algorithm', 'voltage vector selection strategy', 'ac drive base', 'inverter switch', 'stator current ripple', 'rm', 'torque control', 'induction machine', 'torque ripple', 'generator block']"
775,1165,Recognizing groups G/sub 2/(3/sup n/) by their element orders,"it is proved that a finite group that is isomorphic to a simple non-abelian group g = g/sub 2/(3/sup n/) is, up to isomorphism, recognized by a set omega (g) of its element orders, that is, h approximately= g if omega (h) = omega (g) for some finite group h","['element orders', 'finite group', 'isomorphism']","['P', 'P', 'P']","['element order', 'finite group', 'isomorphism']","['finite group', 'isomorphic', 'element order', 'isomorphism', 'set omega', 'omega', 'simple non', 'sup', 'sub', 'prove']"
776,1120,An effective feedback control mechanism for DiffServ architecture,"as a scalable qos (quality of service) architecture, diffserv (differentiated service) mainly consists of two components: traffic conditioning at the edge of the diffserv domain and simple packet forwarding inside the diffserv domain. diffserv has many advantages such as flexibility, scalability and simplicity. but when providing af (assured forwarding) services, diffserv has some problems such as unfairness among aggregated flows or among micro-flows belonging to an aggregated flow. in this paper, a feedback mechanism for af aggregated flows is proposed to solve this problem. simulation results show that this mechanism does improve the performance of diffserv. first, it can improve the fairness among aggregated flows and make diffserv more friendly toward tcp (transmission control protocol) flows. second, it can decrease the buffer requirements at the congested router and thus obtain lower delay and packet loss rate. third, it also keeps almost the same link utility as in normal diffserv. finally, it is simple and easy to be implemented","['feedback control', 'diffserv', 'qos', 'traffic conditioning', 'af', 'packet forwarding', 'fairness', 'feedback mechanism', 'tcp', 'qos architecture']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['feedback control', 'diffserv', 'qos', 'traffic conditioning', 'af', 'packet forwarding', 'fairness', 'feedback mechanism', 'tcp', 'qos architecture']","['packet forwarding', 'transmission control protocol', 'scalable qos', 'packet loss rate', 'assure forward', 'aggregate flow', 'aggregate flow', 'tcp', 'traffic conditioning', 'diffserv have']"
777,794,On the discretization of double-bracket flows,"this paper extends the method of magnus series to lie-algebraic equations originating in double-bracket flows. we show that the solution of the isospectral flow y' = [[y,n],y], y(o) = y/sub 0/ in sym(n), can be represented in the form y(t) = e/sup omega (t)/y/sub 0/e/sup - omega (1)/, where the taylor expansion of omega can be constructed explicitly, term-by-term, identifying individual expansion terms with certain rooted trees with bicolor leaves. this approach is extended to other lie-algebraic equations that can be appropriately expressed in terms of a finite ""alphabet""","['magnus series', 'lie-algebraic equations', 'isospectral flow', 'taylor expansion', 'bicolor leaves', 'double-bracket flows discretization']","['P', 'P', 'P', 'P', 'P', 'R']","['magnus series', 'lie - algebraic equation', 'isospectral flow', 'taylor expansion', 'bicolor leave', 'double - bracket flow discretization']","['algebraic equation originate', 'algebraic equation', 'isospectral flow', 'expansion term', 'bracket flow', 'magnus series', 'taylor expansion', 'root tree', 'sup omega', 'term']"
778,1384,Data allocation on wireless broadcast channels for efficient query processing,"data broadcast is an excellent method for efficient data dissemination in the mobile computing environment. the application domain of data broadcast will be widely expanded in the near future, where the client is expected to perform complex queries or transactions on the broadcast data. to reduce the access latency for processing the complex query, it is beneficial to place the data accessed in a query close to each other on the broadcast channel. in this paper, we propose an efficient algorithm to determine the allocation of the data on the broadcast channel such that frequently co-accessed data are not only allocated close to each other, but also in a particular order which optimizes the performance of query processing. our mechanism is based on the well-known problem named optimal linear ordering. experiments are performed to justify the benefit of our approach","['wireless broadcast channels', 'query processing', 'mobile computing', 'access latency', 'database broadcasting', 'access time', 'tuning time', 'broadcast program']","['P', 'P', 'P', 'P', 'M', 'M', 'U', 'M']","['wireless broadcast channel', 'query process', 'mobile computing', 'access latency', 'database broadcast', 'access time', 'tune time', 'broadcast program']","['efficient datum dissemination', 'broadcast channel such', 'broadcast channel', 'optimal linear order', 'datum broadcast', 'broadcast datum', 'efficient algorithm', 'mobile computing', 'query process', 'query close']"
779,1078,Action aggregation and defuzzification in Mamdani-type fuzzy systems,discusses the issues of action aggregation and defuzzification in mamdani-type fuzzy systems. the paper highlights the shortcomings of defuzzification techniques associated with the customary interpretation of the sentence connective 'and' by means of the set union operation. these include loss of smoothness of the output characteristic and inaccurate mapping of the fuzzy response. the most appropriate procedure for aggregating the outputs of different fuzzy rules and converting them into crisp signals is then suggested. the advantages in terms of increased transparency and mapping accuracy of the fuzzy response are demonstrated,"['action aggregation', 'defuzzification', 'mamdani-type fuzzy systems', 'sentence connective', 'set union operation', 'fuzzy response', 'fuzzy rules', 'crisp signals', 'transparency', 'mapping accuracy']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['action aggregation', 'defuzzification', 'mamdani - type fuzzy system', 'sentence connective', 'set union operation', 'fuzzy response', 'fuzzy rule', 'crisp signal', 'transparency', 'mapping accuracy']","['type fuzzy system', 'different fuzzy rule', 'fuzzy response', 'defuzzification technique associate', 'action aggregation', 'set union operation', 'defuzzification', 'crisp signal', 'mapping accuracy', 'mamdani']"
780,842,The incredible shrinking pipeline,"we look at the harsh facts concerning the percentage of degrees awarded in cs to women. we study the trend of degrees awarded in cs since 1980, and compare the trend in cs to other science and engineering disciplines. we consider the relationship between the percentage of degrees awarded to women by a cs department and the college the cs department is within. we find that cs departments in engineering colleges graduate, on average, proportionately fewer women than cs departments in non-engineering colleges. we request that the community respond to the facts and speculations presented in this article","['women', 'science', 'engineering', 'pipeline shrinkage problem', 'computer science degrees']","['P', 'P', 'P', 'M', 'M']","['woman', 'science', 'engineering', 'pipeline shrinkage problem', 'computer science degree']","['engineering college graduate', 'engineering discipline', 'engineering college', 'cs department', 'few woman', 'cs department', 'degree award', 'woman', 'cs', 'college']"
781,807,Integrated optical metrology controls post etch CDs,"control of the transistor gate critical dimension (cd) on the order of a few nanometers is a top priority in many advanced ic fabs. each nanometer deviation from the target gate length translates directly into the operational speed of these devices. however, using in-line process control by linking the lithography and etch tools can improve cd performance beyond what each individual tool can achieve. the integration of optical cd metrology tools to etch mainframes can result in excellent etcher stability and better control of post-etch cds","['integrated optical metrology', 'transistor gate critical dimension', 'ic fabs', 'target gate length', 'operational speed', 'in-line process control', 'cd performance', 'optical cd metrology tools', 'etch mainframes', 'etcher stability', 'post etch cd control', 'lithography tools', 'photolithography']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U']","['integrate optical metrology', 'transistor gate critical dimension', 'ic fab', 'target gate length', 'operational speed', 'in - line process control', 'cd performance', 'optical cd metrology tool', 'etch mainframe', 'etcher stability', 'post etch cd control', 'lithography tool', 'photolithography']","['optical cd metrology tool', 'lithography', 'improve cd performance', 'etch tool', 'transistor gate critical dimension', 'etch mainframe', 'etcher stability', 'cd', 'nanometer', 'nanometer']"
782,1411,Speedera: Web without the wait,"there's no greater testament to the utility of the internet than the fact that hundreds of millions of people worldwide are willing to wait for web pages as they build incrementally on screen. but while users may put up with the ""world wide wait,"" they definitely don't like it. that's where content delivery networks come in. cdns can't turn a footpath into a freeway, but they can help data in transit take advantage of shortcuts and steer clear of traffic jams. and while enhancing the responsiveness of web interaction, cdns also enhance the prospects of their clients, who need engaged visitors to keep their web-based business models afloat. ""our mission is to improve the quality of the internet experience for end-users,"" says gordon smith, vice president of marketing at speedera networks in santa clara, california, ""and to enable web-site operators to provide better delivery quality, performance, scalability, and security through an outsourced service model that slashes it costs.""","['content delivery networks', 'web interaction', 'web-based business models', 'internet experience', 'web-site operators', 'delivery quality', 'scalability', 'security', 'outsourced service model', 'world wide web']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['content delivery network', 'web interaction', 'web - base business model', 'internet experience', 'web - site operator', 'delivery quality', 'scalability', 'security', 'outsource service model', 'world wide web']","['content delivery network come', 'provide well delivery quality', 'cdns', 'web page', 'outsource service model', 'internet experience', 'base business model afloat', 'internet', 'traffic jam', 'enable web']"
783,1085,A variable-stepsize variable-order multistep method for the integration of perturbed linear problems,"g. scheifele (1971) wrote the solution of a perturbed oscillator as an expansion in terms of a new set of functions, which extends the monomials in the taylor series of the solution. recently, p. martin and j.m. ferrandiz (1997) constructed a multistep code based on the scheifele technique, and it was generalized by d.j. lopez and p. martin (1998) for perturbed linear problems. however, the remarked codes are constant steplength methods, and efficient integrators must be able to change the steplength. in this paper we extend the ideas of f.t. krogh (1974) from adams methods to the algorithm proposed by lopez and martin, and we show the advantages of the new code in perturbed problems","['variable-stepsize variable-order multistep method', 'perturbed oscillator', 'monomials', 'taylor series', 'multistep code', 'constant steplength methods', 'adams methods', 'perturbed linear problems integration']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['variable - stepsize variable - order multistep method', 'perturb oscillator', 'monomial', 'taylor series', 'multistep code', 'constant steplength method', 'adam method', 'perturb linear problem integration']","['perturb oscillator', 'perturb linear problem', 'constant steplength method', 'multistep code', 'adam method', 'efficient integrator', 'algorithm propose', 'steplength', 'taylor series', 'scheifele technique']"
784,1379,Web-based intelligent helpdesk-support environment,"with the advent of internet technology, it is now feasible to provide effective and efficient helpdesk service over the global internet to meet customers' requirements and satisfaction. in this research, we have designed and developed a web-based intelligent helpdesk-support environment, webhotline, to support the customer service centre of a large multinational corporation in the electronics industry. the paper describes the basic architecture of the environment that supports the major functions of web-based fault information retrieval, online multilingual translation capability, different operating modes of video-conferencing for enhanced support and direct intelligent fault diagnosis by customers or customer support engineers. as a result, webhotline helps to save cost in eliminating the expensive overseas telephone charges, reduction in machine down time and number of on-site visits by service engineers as in traditional helpdesk environment","['web-based intelligent helpdesk-support environment', 'internet technology', 'webhotline', 'customer service centre', 'web-based fault information retrieval', 'online multilingual translation capability', 'videoconferencing']","['P', 'P', 'P', 'P', 'P', 'P', 'U']","['web - base intelligent helpdesk - support environment', 'internet technology', 'webhotline', 'customer service centre', 'web - base fault information retrieval', 'online multilingual translation capability', 'videoconference']","['helpdesk service', 'customer support engineer', 'customer service centre', 'base fault information retrieval', 'online multilingual translation capability', 'webhotline help', 'base intelligent helpdesk', 'direct intelligent fault diagnosis', 'service engineer', 'webhotline']"
785,769,"Permission grids: practical, error-bounded simplification","we introduce the permission grid, a spatial occupancy grid which can be used to guide almost any standard polygonal surface simplification algorithm into generating an approximation with a guaranteed geometric error bound. in particular, all points on the approximation are guaranteed to be within some user-specified distance from the original surface. such bounds are notably absent from many current simplification methods, and are becoming increasingly important for applications in scientific computing and adaptive level of detail control. conceptually simple, the permission grid defines a volume in which the approximation must lie, and does not permit the underlying simplification algorithm to generate approximations outside the volume. the permission grid makes three important, practical improvements over current error-bounded simplification methods. first, it works on arbitrary triangular models, handling all manners of mesh degeneracies gracefully. further, the error tolerance may be easily expanded as simplification proceeds, allowing the construction of an error-bounded level of detail hierarchy with vertex correspondences among all levels of detail. and finally, the permission grid has a representation complexity independent of the size of the input model, and a small running time overhead, making it more practical and efficient than current methods with similar guarantees","['permission grid', 'error-bounded simplification', 'spatial occupancy grid', 'polygonal surface simplification algorithm', 'approximation', 'guaranteed geometric error bound', 'user-specified distance', 'scientific computing', 'adaptive level of detail control', 'arbitrary triangular models', 'mesh degeneracies', 'error tolerance', 'vertex correspondences', 'representation complexity', 'running time overhead']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['permission grid', 'error - bound simplification', 'spatial occupancy grid', 'polygonal surface simplification algorithm', 'approximation', 'guarantee geometric error bind', 'user - specify distance', 'scientific computing', 'adaptive level of detail control', 'arbitrary triangular model', 'mesh degeneracy', 'error tolerance', 'vertex correspondence', 'representation complexity', 'run time overhead']","['standard polygonal surface simplification algorithm', 'spatial occupancy grid', 'permission grid define', 'permission grid have', 'underlie simplification algorithm', 'arbitrary triangular model', 'permission grid', 'mesh degeneracy', 'generate approximation', 'bound simplification method']"
786,551,Access privilege management in protection systems,"we consider the problem of managing access privileges on protected objects. we associate one or more locks with each object, one lock for each access right defined by the object type. possession of an access right on a given object is certified by possession of a key for this object, if this key matches one of the object locks. we introduce a number of variants to this basic key-lock technique. polymorphic access rights make it possible to decrease the number of keys required to certify possession of complex access privileges that are defined in terms of several access rights. multiple locks on the same access right allow us to exercise forms of selective revocation of access privileges. a lock conversion function can be used to reduce the number of locks associated with any given object to a single lock. the extent of the results obtained is evaluated in relation to alternative methodologies for access privilege management","['access privilege management', 'protection systems', 'protected objects', 'locks', 'key-lock technique', 'polymorphic access rights', 'selective revocation', 'lock conversion function', 'complex access privilege possession certification']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['access privilege management', 'protection system', 'protect object', 'lock', 'key - lock technique', 'polymorphic access right', 'selective revocation', 'lock conversion function', 'complex access privilege possession certification']","['polymorphic access right make', 'manage access privilege', 'complex access privilege', 'access privilege', 'several access right', 'multiple lock', 'lock conversion function', 'object lock', 'lock associate', 'more lock']"
787,986,Wavelet-based level-of-detail representation of 3D objects,"in this paper, we propose a 3d object lod (level of detail) modeling system that constructs a mesh from range images and generates the mesh of various lod using the wavelet transform. in the initial mesh generation, we use the marching cube algorithm. we modify the original algorithm to apply it to construct the mesh from multiple range images efficiently. to get the base mesh we use the decimation algorithm which simplifies a mesh with preserving the topology. finally, when reconstructing new mesh which is similar to initial mesh we calculate the wavelet coefficients by using the wavelet transform. we solve the critical problem of wavelet-based methods - the surface crease problem - by using the mesh simplification as the base mesh generation method","['wavelet-based level-of-detail representation', 'range images', 'wavelet transform', 'marching cube algorithm', 'base mesh', 'decimation algorithm', 'wavelet coefficients', 'critical problem', 'surface crease problem', 'mesh simplification', '3d object level of detail modeling system', 'hierarchy transformation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['wavelet - base level - of - detail representation', 'range image', 'wavelet transform', 'march cube algorithm', 'base mesh', 'decimation algorithm', 'wavelet coefficient', 'critical problem', 'surface crease problem', 'mesh simplification', '3d object level of detail modeling system', 'hierarchy transformation']","['march cube algorithm', 'surface crease', '3d object lod', 'mesh simplification', 'base mesh', 'mesh generation', 'wavelet transform', 'mesh', 'decimation algorithm', 'wavelet coefficient']"
788,1141,Reproducibility of mammary gland structure during repeat setups in a supine position,"purpose: in breast conserving therapy, complete excision of the tumor with an acceptable cosmetic outcome depends on accurate localization in terms of both the position of the lesion and its extent. we hypothesize that preoperative contrast-enhanced magnetic resonance (mr) imaging of the patient in a supine position may be used for accurate tumor localization and marking of its extent immediately prior to surgery. our aims in this study are to assess the reproducibility of mammary gland structure during repeat setups in a supine position, to evaluate the effect of a breast immobilization device, and to derive reproducibility margins that take internal tissue shifts into account occurring between repeat setups. materials methods: the reproducibility of mammary gland structure during repeat setups in a supine position is estimated by quantification of tissue shifts in the breasts of healthy volunteers between repeat mr setups. for each volunteer fiducials are identified and registered with their counter locations in corresponding mr volumes. the difference in position denotes the shift of breast tissue. the dependence on breast volume and the part of the breast, as well as the effect of a breast immobilization cast are studied. results: the tissue shifts are small with a mean standard deviation on the order of 1.5 mm, being slightly larger in large breasts (v>1000 cm/sup 3/), and in the posterior part (toward the pectoral muscle) of both small and large breasts. the application of a breast immobilization cast reduces the tissue shifts in large breasts. a reproducibility margin on the order of 5 mm will take the internal tissue shifts into account that occur between repeat setups. conclusion: the results demonstrate a high reproducibility of mammary gland structure during repeat setups in a supine position","['repeat setups', 'supine position', 'breast conserving therapy', 'accurate tumor localization', 'breast immobilization device', 'reproducibility margins', 'internal tissue shifts', 'mammary gland structure reproducibility', 'contrast-enhanced magnetic resonance imaging', 'localization methods']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['repeat setup', 'supine position', 'breast conserve therapy', 'accurate tumor localization', 'breast immobilization device', 'reproducibility margin', 'internal tissue shift', 'mammary gland structure reproducibility', 'contrast - enhance magnetic resonance imaging', 'localization method']","['breast immobilization device', 'breast immobilization cast reduce', 'breast immobilization cast', 'breast tissue', 'mammary gland structure', 'breast conserve therapy', 'breast volume', 'accurate tumor localization', 'preoperative contrast', 'breast']"
789,1104,A 3-stage pipelined architecture for multi-view images decoder,"in this paper, we proposed the architecture of the decoder which implements the multi-view images decoding algorithm. the study of the hardware structure of the multi-view image processing has not been accomplished. the proposed multi-view images decoder operates in a three stage pipelined manner and extracts the depth of the pixels of the decoded image every clock. the multi-view images decoder consists of three modules, node selector which transfers the value of the nodes repeatedly and depth extractor which extracts the depth of each pixel from the four values of the nodes and affine transformer which generates the projecting position on the image plane from the values of the pixels and the specified viewpoint. the proposed architecture is designed and simulated by the max+plusii design tool and the operating frequency is 30 mhz. the image can be constructed in a real time by the decoder with the proposed architecture","['multi-view images decoder', 'hardware structure', 'node selector', 'depth extractor', 'affine transformer', 'viewpoint', 'max+plusii design tool', 'operating frequency', '30 mhz', 'three-stage pipelined architecture', 'pixel depth']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R']","['multi - view image decoder', 'hardware structure', 'node selector', 'depth extractor', 'affine transformer', 'viewpoint', 'max+plusii design tool', 'operate frequency', '30 mhz', 'three - stage pipeline architecture', 'pixel depth']","['view image decode algorithm', 'view image decoder consist', 'view image decoder', 'view image processing', 'decode image', 'decoder', 'pixel', 'affine transformer', 'pixel', 'depth extractor']"
790,97,Philadelphia stock exchange taps TimesTen for database technology,phlx rolls out equity options autoquote system to traders as the first application to leverage its enhanced data architecture,"['philadelphia stock exchange', 'timesten', 'equity options autoquote system', 'data architecture']","['P', 'P', 'P', 'P']","['philadelphia stock exchange', 'timesten', 'equity option autoquote system', 'datum architecture']","['equity option autoquote system', 'phlx roll', 'trader', 'leverage', 'first application']"
791,650,Molecular descriptor selection combining genetic algorithms and fuzzy logic: application to database mining procedures,"a new algorithm, devoted to molecular descriptor selection in the context of data mining problems, has been developed. this algorithm is based on the concepts of genetic algorithms (ga) for descriptor hyperspace exploration and combined with a stepwise approach to get local convergence. its selection power was evaluated by a fitness function derived from a fuzzy clustering method. different training and test sets were randomly generated at each ga generation. the fitness score was derived by combining the scores of the training and test sets. the ability of the proposed algorithm to select relevant subsets of descriptors was tested on two data sets. the first one, an academic example, corresponded to the artificial problem of bullseye, the second was a real data set including 114 olfactory compounds divided into three odor categories. in both cases, the proposed method allowed to improve the separation between the different data set classes","['molecular descriptor selection', 'genetic algorithms', 'fuzzy logic', 'database mining', 'data mining', 'descriptor hyperspace exploration', 'stepwise approach', 'local convergence', 'fitness function', 'fuzzy clustering method', 'test sets', 'fitness score', 'bullseye', 'olfactory compounds', 'odor categories', 'training sets']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['molecular descriptor selection', 'genetic algorithm', 'fuzzy logic', 'database mining', 'datum mining', 'descriptor hyperspace exploration', 'stepwise approach', 'local convergence', 'fitness function', 'fuzzy clustering method', 'test set', 'fitness score', 'bullseye', 'olfactory compound', 'odor category', 'training set']","['molecular descriptor selection', 'fuzzy clustering method', 'descriptor hyperspace exploration', 'genetic algorithm', 'odor category', 'olfactory compound', 'descriptor', 'select relevant subset', 'datum mining problem', 'fitness function derive']"
792,615,An intelligent tutoring system for a power plant simulator,"in this paper, an intelligent tutoring system (its) is proposed for a power plant simulator. with a well designed its, the need for an instructor is minimized and the operator may readily and efficiently take, in real-time, the control of simulator with appropriate messages he(she) gets from the tutoring system. using simulink and based on object oriented programming (oop) and c programming language, a fossil-fuelled power plant simulator with an its is proposed. promising results are demonstrated for a typical power plant","['intelligent tutoring system', 'simulink', 'object oriented programming', 'c programming language', 'fossil-fuelled power plant simulator', 'control simulation', 'cai']","['P', 'P', 'P', 'P', 'P', 'R', 'U']","['intelligent tutoring system', 'simulink', 'object orient programming', 'c programming language', 'fossil - fuel power plant simulator', 'control simulation', 'cai']","['fuel power plant simulator', 'intelligent tutoring system', 'power plant simulator', 'object orient programming', 'tutoring system', 'programming language', 'simulator', 'use simulink', 'instructor', 'oop']"
793,1240,Implementation and evaluation of HPF/SX V2,"we are developing hpf/sx v2, a high performance fortran (hpf) compiler for vector parallel machines. it provides some unique extensions as well as the features of hpf 2.0 and hpf/ja. in particular, this paper describes four of them: (1) the on directive of hpf 2.0; (2) the reflect and local directives of hpf/ja; (3) vectorization directives; and (4) automatic parallelization. we evaluate these features through some benchmark programs on nec sx-5. the results show that each of them achieved a 5-8 times speedup in 8-cpu parallel execution and the four features are useful for vector parallel execution. we also evaluate the overall performance of hpf/sx v2 by using over 30 well-known benchmark programs from hpfbench, apr benchmarks, genesis benchmarks, and nas parallel benchmarks. about half of the programs showed good performance, while the other half suggest weakness of the compiler, especially on its runtimes. it is necessary to improve them to put the compiler to practical use","['hpf/sx v2', 'compiler', 'vector parallel machines', 'parallelization', 'benchmark', 'high performance fortran compiler']","['P', 'P', 'P', 'P', 'P', 'R']","['hpf / sx v2', 'compiler', 'vector parallel machine', 'parallelization', 'benchmark', 'high performance fortran compiler']","['nas parallel benchmark', 'cpu parallel execution', 'vector parallel execution', 'vector parallel machine', 'high performance fortran', 'know benchmark program', 'benchmark program', 'automatic parallelization', 'program show good performance', 'genesis benchmark']"
794,1205,HPCVIEW: a tool for top-down analysis of node performance,"it is increasingly difficult for complex scientific programs to attain a significant fraction of peak performance on systems that are based on microprocessors with substantial instruction-level parallelism and deep memory hierarchies. despite this trend, performance analysis and tuning tools are still not used regularly by algorithm and application designers. to a large extent, existing performance tools fail to meet many user needs and are cumbersome to use. to address these issues, we developed hpcview - a toolkit for combining multiple sets of program profile data, correlating the data with source code, and generating a database that can be analyzed anywhere with a commodity web browser. we argue that hpcview addresses many of the issues that have limited the usability and the utility of most existing tools. we originally built hpcview to facilitate our own work on data layout and optimizing compilers. now, in addition to daily use within our group, hpcview is being used by several code development teams in dod and doe laboratories as well as at ncsa","['hpcview', 'top-down analysis', 'node performance', 'complex scientific programs', 'peak performance', 'instruction-level parallelism', 'deep memory hierarchies', 'performance analysis', 'source code', 'commodity web browser', 'data layout', 'optimizing compilers', 'software tools', 'binary analysis']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M']","['hpcview', 'top - down analysis', 'node performance', 'complex scientific program', 'peak performance', 'instruction - level parallelism', 'deep memory hierarchy', 'performance analysis', 'source code', 'commodity web browser', 'datum layout', 'optimize compiler', 'software tool', 'binary analysis']","['optimize compiler', 'exist performance tool', 'program profile datum', 'hpcview address many', 'several code development team', 'deep memory hierarchy', 'most exist tool', 'complex scientific program', 'develop hpcview', 'build hpcview']"
795,138,Optical actuation of a bistable MEMS,"this paper presents an optical actuation scheme for mems devices based on the well-established fact that light possesses momentum, and hence, imparts a force equal to 2 w/c when reflected by a surface. here, w is the total power of the reflected light, and c is the speed of light. radiation pressure, as it is known, is nearly insignificant for most macroscale applications, but it can be quite significant for mems devices. in addition, light actuation offers a new paradigm. first, intersecting light beams do not interfere, in contrast to electrical conductors, which short when they come into contact. second, light can operate in high temperature and high radiation environments far outside the capability of solid state electronic components. this actuation method is demonstrated, both in air and in vacuum, by switching the state of a bistable mems device. the associated heat transfer model is also presented","['bistable mems', 'optical actuation scheme', 'mems devices', 'radiation pressure', 'intersecting light beams', 'high radiation environments', 'heat transfer model', 'high temperature environments']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['bistable mem', 'optical actuation scheme', 'mem device', 'radiation pressure', 'intersect light beam', 'high radiation environment', 'heat transfer model', 'high temperature environment']","['light actuation offer', 'optical actuation', 'intersect light beam', 'bistable mem device', 'mem device', 'reflect light', 'light possess momentum', 'solid state electronic component', 'actuation', 'electrical conductor']"
796,1318,Network intrusion and fault detection: a statistical anomaly approach,"with the advent and explosive growth of the global internet and electronic commerce environments, adaptive/automatic network/service intrusion and anomaly detection in wide area data networks and e-commerce infrastructures is fast gaining critical research and practical importance. we present and demonstrate the use of a general-purpose hierarchical multitier multiwindow statistical anomaly detection technology and system that operates automatically, adaptively, and proactively, and can be applied to various networking technologies, including both wired and wireless ad hoc networks. our method uses statistical models and multivariate classifiers to detect anomalous network conditions. some numerical results are also presented that demonstrate that our proposed methodology can reliably detect attacks with traffic anomaly intensity as low as 3-5 percent of the typical background traffic intensity, thus promising to generate an effective early warning","['network intrusion', 'fault detection', 'internet', 'electronic commerce environment', 'adaptive/automatic network/service intrusion', 'wide area data networks', 'e-commerce infrastructure', 'wireless ad hoc networks', 'statistical models', 'multivariate classifiers', 'traffic anomaly intensity', 'background traffic intensity', 'computer network attacks', 'denial of service', 'early warning systems', 'neural network classification', 'ad hoc wireless experiments', 'backpropagation', 'perceptron-back propagation hybrid', 'hierarchical multitier statistical anomaly detection', 'multiwindow anomaly detection', 'wired ad hoc networks']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'R', 'M', 'M', 'U', 'U', 'R', 'R', 'R']","['network intrusion', 'fault detection', 'internet', 'electronic commerce environment', 'adaptive / automatic network / service intrusion', 'wide area datum network', 'e - commerce infrastructure', 'wireless ad hoc network', 'statistical model', 'multivariate classifier', 'traffic anomaly intensity', 'background traffic intensity', 'computer network attack', 'denial of service', 'early warning system', 'neural network classification', 'ad hoc wireless experiment', 'backpropagation', 'perceptron - back propagation hybrid', 'hierarchical multiti statistical anomaly detection', 'multiwindow anomaly detection', 'wire ad hoc network']","['purpose hierarchical multiti multiwindow statistical anomaly detection technology', 'detect anomalous network', 'traffic anomaly intensity', 'anomaly detection', 'detect attack', 'typical background traffic intensity', 'service intrusion', 'multivariate classifier', 'wide area datum network', 'various networking technology']"
797,708,Sufficient conditions on nonemptiness and boundedness of the solution set of the P/sub 0/ function nonlinear complementarity problem,"the p/sub 0/ function nonlinear complementarity, problem (ncp) has attracted a lot of attention among researchers. various assumed conditions, which ensure that the ncp has a solution have been proposed. in this paper, by using the notion of an exceptional family of elements we develop a sufficient condition which ensures that the solution set of the p/sub 0/ function ncp is nonempty and bounded. in particular, we prove that many existing assumed conditions imply this sufficient condition. thus, these conditions imply that the solution set of the p/sub 0/ function ncp is nonempty and bounded. in addition, we also prove directly that a few existence conditions imply that the solution set of the p/sub 0/ function ncp is bounded","['sufficient conditions', 'nonemptiness', 'boundedness', 'solution set', 'p/sub 0/ function nonlinear complementarity problem']","['P', 'P', 'P', 'P', 'P']","['sufficient condition', 'nonemptiness', 'boundedness', 'solution set', 'p / sub 0/ function nonlinear complementarity problem']","['function nonlinear complementarity', 'existence condition imply', 'exist assume condition imply', 'condition imply', 'function ncp', 'sufficient condition', 'assume condition', 'solution set', 'bound', 'ncp']"
798,866,Adjoint-based optimization of steady suction for disturbance control in incompressible flows,"the optimal distribution of steady suction needed to control the growth of single or multiple disturbances in quasi-three-dimensional incompressible boundary layers on a flat plate is investigated. the evolution of disturbances is analysed in the framework of the parabolized stability equations (pse). a gradient-based optimization procedure is used and the gradients are evaluated using the adjoint of the parabolized stability equations (apse) and the adjoint of the boundary layer equations (able). the accuracy of the gradient is increased by introducing a stabilization procedure for the pse. results show that a suction peak appears in the upstream part of the suction region for optimal control of tollmien-schlichting (t-s) waves, steady streamwise streaks in a two-dimensional boundary layer and oblique waves in a quasi-three-dimensional boundary layer subject to an adverse pressure gradient. the mean flow modifications due to suction are shown to have a stabilizing effect similar to that of a favourable pressure gradient. it is also shown that the optimal suction distribution for the disturbance of interest reduces the growth rate of other perturbations. results for control of a steady cross-flow mode in a three-dimensional boundary layer subject to a favourable pressure gradient show that not even large amounts of suction can completely stabilize the disturbance","['adjoint-based optimization', 'steady suction', 'disturbance control', 'incompressible flows', 'flat plate', 'parabolized stability equations', 'gradient-based optimization procedure', 'stabilization procedure', 'steady streamwise streaks', 'oblique waves', 'adverse pressure gradient', 'mean flow', 'steady cross-flow mode', 'quasithree-dimensional incompressible boundary layers', 'tollmien-schlichting waves', 'laminar-turbulent transition']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'U']","['adjoint - base optimization', 'steady suction', 'disturbance control', 'incompressible flow', 'flat plate', 'parabolize stability equation', 'gradient - base optimization procedure', 'stabilization procedure', 'steady streamwise streak', 'oblique wave', 'adverse pressure gradient', 'mean flow', 'steady cross - flow mode', 'quasithree - dimensional incompressible boundary layer', 'tollmien - schlichte wave', 'laminar - turbulent transition']","['incompressible boundary layer', 'boundary layer equation', 'steady streamwise streak', 'parabolize stability equation', 'boundary layer', 'oblique wave', 'steady suction', 'suction peak', 'favourable pressure gradient', 'wave']"
799,823,Estimation of thermal coefficients of magneto-optical media,"previously we described a method for estimating the thermal conductivity of magneto-optic recording media. the method relies on identifying the laser power that brings the maximum temperature of the tbfeco layer to as high as the curie temperature. we extensively use a similar method to estimate the heat capacity of a dielectric layer, a tbfeco layer, and an aluminum alloy layer of magneto-optic recording media. measurements are conducted on static disks with a beam of light focused on a tbfeco layer. the method has the advantage of thermal diffusion depending on a multilayer structure and irradiation time","['thermal coefficients', 'magneto-optical media', 'thermal conductivity', 'magneto-optic recording media', 'laser power', 'maximum temperature', 'tbfeco layer', 'tbfeco', 'curie temperature', 'heat capacity', 'dielectric layer', 'aluminum alloy layer', 'static disks', 'light focusing', 'thermal diffusion', 'multilayer structure', 'irradiation time']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['thermal coefficient', 'magneto - optical medium', 'thermal conductivity', 'magneto - optic recording medium', 'laser power', 'maximum temperature', 'tbfeco layer', 'tbfeco', 'curie temperature', 'heat capacity', 'dielectric layer', 'aluminum alloy layer', 'static disk', 'light focus', 'thermal diffusion', 'multilayer structure', 'irradiation time']","['thermal conductivity', 'thermal diffusion', 'optic recording medium', 'curie temperature', 'maximum temperature', 'tbfeco layer', 'dielectric layer', 'laser', 'heat capacity', 'aluminum alloy layer']"
800,1435,Experimental investigations on monitoring and control of induction heating process for semi-solid alloys using the heating coil as sensor,"a method of monitoring the state of metal alloys during induction heating and control of the heating process utilizing the heating coil itself as a sensor is proposed, and its usefulness and effectiveness were experimentally investigated using aluminium a357 billets for the semi-solid metal (ssm) casting processes. the impedance of the coil containing the billet was continuously measured by the proposed method in the temperature range between room temperature and 700 degrees c. it was found that the reactance component of the impedance varied distinctively according to the billet state and could clearly monitor the deformation of the billet, while the resistance component increased with temperature, reflecting the variation of the resistivity of the billet which has strong correlation to the solid/liquid fraction of the billets. the measured impedance is very sensitive to the billet states such as temperature, deformation and solid/liquid fraction and could be used as a parameter to monitor and control the heating process for ssms","['induction heating process', 'reactance component', 'billet state', 'resistance component', 'solid/liquid fraction', 'process monitoring', 'process control', 'semisolid alloys', 'semisolid metal casting', 'heating coil sensor', 'coil impedance', 'billet deformation', 'resistivity variation', 'solenoid coil', '20 to 700 c']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'M', 'R', 'R', 'R', 'R', 'M', 'M']","['induction heating process', 'reactance component', 'billet state', 'resistance component', 'solid / liquid fraction', 'process monitor', 'process control', 'semisolid alloy', 'semisolid metal casting', 'heating coil sensor', 'coil impedance', 'billet deformation', 'resistivity variation', 'solenoid coil', '20 to 700 c']","['metal alloy', 'aluminium a357 billet', 'heating coil', 'induction heating', 'solid metal', 'heat', 'temperature', 'measure impedance', 'billet state', 'billet state']"
801,1019,Optical setup and analysis of disk-type photopolymer high-density holographic storage,"a relatively simple scheme for disk-type photopolymer high-density holographic storage based on angular and spatial multiplexing is described. the effects of the optical setup on the recording capacity and density are studied. calculations and analysis show that this scheme is more effective than a scheme based on the spatioangular multiplexing for disk-type photopolymer high-density holographic storage, which has a limited medium thickness. also an optimal beam recording angle exists to achieve maximum recording capacity and density","['optical setup', 'disk-type photopolymer high-density holographic storage', 'spatial multiplexing', 'recording capacity', 'limited medium thickness', 'optimal beam recording angle', 'maximum recording capacity', 'angular multiplexing', 'recording density', 'spatio-angular multiplexing', 'maximum density']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'R']","['optical setup', 'disk - type photopolym high - density holographic storage', 'spatial multiplexing', 'recording capacity', 'limit medium thickness', 'optimal beam recording angle', 'maximum recording capacity', 'angular multiplexing', 'record density', 'spatio - angular multiplexing', 'maximum density']","['density holographic storage', 'photopolymer high', 'spatioangular multiplexing', 'spatial multiplexing', 'beam recording angle', 'recording capacity', 'optical setup', 'disk', 'density', 'angular']"
802,1024,"Rational systems exhibit moderate risk aversion with respect to ""gambles"" on variable-resolution compression","in an embedded wavelet scheme for progressive transmission, a tree structure naturally defines the spatial relationship on the hierarchical pyramid. transform coefficients over each tree correspond to a unique local spatial region of the original image, and they can be coded bit-plane by bit-plane through successive-approximation quantization. after receiving the approximate value of some coefficients, the decoder can obtain a reconstructed image. we show a rational system for progressive transmission that, in absence of a priori knowledge about regions of interest, chooses at any truncation time among alternative trees for further transmission in such a way as to avoid certain forms of behavioral inconsistency. we prove that some rational transmission systems might exhibit aversion to risk involving ""gambles"" on tree-dependent quality of encoding while others favor taking such risks. based on an acceptable predictor for visual distinctness from digital imagery, we demonstrate that, without any outside knowledge, risk-prone systems as well as those with strong risk aversion appear in capable of attaining the quality of reconstructions that can be achieved with moderate risk-averse behavior","['rational system', 'moderate risk aversion', 'gambles', 'variable-resolution compression', 'embedded wavelet scheme', 'progressive transmission', 'tree structure', 'transform coefficients', 'local spatial region', 'successive-approximation quantization', 'reconstructed image', 'truncation time', 'acceptable predictor', 'visual distinctness', 'digital imagery', 'hierarchical pyramid spatial relationship', 'behavioral inconsistency avoidance', 'image encoding', 'embedded coding', 'rate control optimization', 'decision problem', 'progressive transmission utility functions', 'information theoretic measure']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'U', 'U', 'M', 'U']","['rational system', 'moderate risk aversion', 'gamble', 'variable - resolution compression', 'embed wavelet scheme', 'progressive transmission', 'tree structure', 'transform coefficient', 'local spatial region', 'successive - approximation quantization', 'reconstruct image', 'truncation time', 'acceptable predictor', 'visual distinctness', 'digital imagery', 'hierarchical pyramid spatial relationship', 'behavioral inconsistency avoidance', 'image encoding', 'embed code', 'rate control optimization', 'decision problem', 'progressive transmission utility function', 'information theoretic measure']","['embed wavelet scheme', 'digital imagery', 'strong risk aversion appear', 'rational transmission system', 'hierarchical pyramid', 'approximation quantization', 'progressive transmission', 'reconstruct image', 'code bit', 'alternative tree']"
803,1061,"Abacus, EFI and anti-virus","the extensible firmware interface (efi) standard emerged as a logical step to provide flexibility and extensibility to boot sequence processes, enabling the complete abstraction of a system's bios interface from the system's hardware. in doing so, this provided the means of standardizing a boot-up sequence, extending device drivers and boot time applications' portability to non pc-at-based architectures, including embedded systems like internet appliances, tv internet set-top boxes and 64-bit itanium platforms","['anti-virus', 'embedded systems', 'extensible firmware interface standard']","['P', 'P', 'R']","['anti - virus', 'embed system', 'extensible firmware interface standard']","['extensible firmware interface', 'bio interface', 'extend device driver', 'include embed system', 'efi', 'boot time application', 'boot sequence process', 'hardware', 'boot', 'portability']"
804,1325,X-Rite: more than a graphic arts company,"although it is well known as a maker of densitometers and spectrophotometers, x-rite is active in measuring light and shape in many industries. among them are automobile finishes, paint and home improvements, scientific instruments, optical semiconductors and even cosmetic dentistry","['x-rite', 'graphic arts', 'colour measurement']","['P', 'P', 'M']","['x - rite', 'graphic art', 'colour measurement']","['optical semiconductor', 'measure light', 'scientific instrument', 'densitometer', 'spectrophotometer', 'automobile finish', 'many industry', 'shape', 'rite', 'home improvement']"
805,1360,Automated post bonding inspection by using machine vision techniques,"inspection plays an important role in the semiconductor industry. in this paper, we focus on the inspection task after wire bonding in packaging. the purpose of wire bonding (w/b) is to connect the bond pads with the lead fingers. two major types of defects are (1) bonding line missing and (2) bonding line breakage. the numbers of bonding lines and bonding balls are used as the features for defect classification. the proposed method consists of image preprocessing, orientation determination, connection detection, bonding line detection, bonding ball detection, and defect classification. the proposed method is simple and fast. the experimental results show that the proposed method can detect the defects effectively","['automated post bonding inspection', 'machine vision', 'semiconductor industry', 'wire bonding', 'packaging', 'lead fingers', 'bonding line missing', 'bonding line breakage', 'bonding balls', 'defect classification', 'image preprocessing', 'orientation determination', 'connection detection', 'bonding line detection', 'bonding ball detection', 'ic manufacturing', 'bond pad connection']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'R']","['automate post bonding inspection', 'machine vision', 'semiconductor industry', 'wire bonding', 'package', 'lead finger', 'bond line miss', 'bond line breakage', 'bonding ball', 'defect classification', 'image preprocesse', 'orientation determination', 'connection detection', 'bond line detection', 'bond ball detection', 'ic manufacture', 'bond pad connection']","['bond line detection', 'bond line breakage', 'bond line', 'wire bonding', 'bond line', 'bonding ball', 'bond pad', 'bond', 'defect classification', 'inspection']"
806,735,IT at the heart of joined-up policing,"police it is to shift from application-focused to component-based technology. the change of strategy, part of the valiant programme, will make information held by individual forces available on a national basis","['police it', 'valiant programme', 'uk']","['P', 'P', 'U']","['police it', 'valiant programme', 'uk']","['valiant programme', 'base technology', 'make information hold', 'strategy', 'application', 'component', 'individual force available', 'police', 'change', 'shift']"
807,770,The 3D visibility complex,"visibility problems are central to many computer graphics applications. the most common examples include hidden-part removal for view computation, shadow boundaries, mutual visibility of objects for lighting simulation. in this paper, we present a theoretical study of 3d visibility properties for scenes of smooth convex objects. we work in the space of light rays, or more precisely, of maximal free segments. we group segments that ""see"" the same object; this defines the 3d visibility complex. the boundaries of these groups of segments correspond to the visual events of the scene (limits of shadows, disappearance of an object when the viewpoint is moved, etc.). we provide a worst case analysis of the complexity of the visibility complex of 3d scenes, as well as a probabilistic study under a simple assumption for ""normal"" scenes. we extend the visibility complex to handle temporal visibility. we give an output-sensitive construction algorithm and present applications of our approach","['3d visibility complex', 'computer graphics', 'hidden-part removal', 'view computation', 'shadow boundaries', 'lighting simulation', 'smooth convex objects', 'light rays', 'maximal free segments', 'visual events', 'probabilistic study', 'temporal visibility', 'output-sensitive construction algorithm', 'mutual object visibility', 'worst case complexity analysis', 'normal scenes']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['3d visibility complex', 'computer graphic', 'hide - part removal', 'view computation', 'shadow boundary', 'light simulation', 'smooth convex object', 'light ray', 'maximal free segment', 'visual event', 'probabilistic study', 'temporal visibility', 'output - sensitive construction algorithm', 'mutual object visibility', 'bad case complexity analysis', 'normal scene']","['3d visibility property', '3d visibility complex', 'smooth convex object', 'handle temporal visibility', '3d scene', 'visibility complex', 'visibility problem', 'mutual visibility', 'view computation', 'light simulation']"
808,1408,PKI: coming to an enterprise near you?,"for many years public key infrastructure (pki) deployments were the provenance of governments and large, security-conscious corporations and financial institutions. these organizations have the financial and human resources necessary to successfully manage the complexities of a public key system. lately however, several forces have converged to encourage a broader base of enterprises to take a closer look at pki. these forces are discussed. pki vendors are now demonstrating to customers how they can make essential business applications faster and more efficient by moving them to the internet-without sacrificing security. those applications usually include secure remote access, secure messaging, electronic document exchange, transaction validation, and network authentication. after a brief discussion of pki basics the author reviews various products available on the market","['pki', 'public key infrastructure', 'security', 'pki vendors', 'secure remote access', 'secure messaging', 'electronic document exchange', 'transaction validation', 'network authentication', 'business-critical applications', 'e-commerce', 'ipsec vpns', 'baltimore technologies', 'entrust', 'geotrust', 'rsa security', 'verisign']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U', 'U', 'U', 'U', 'U', 'M', 'U']","['pki', 'public key infrastructure', 'security', 'pki vendor', 'secure remote access', 'secure messaging', 'electronic document exchange', 'transaction validation', 'network authentication', 'business - critical application', 'e - commerce', 'ipsec vpns', 'baltimore technology', 'entrust', 'geotrust', 'rsa security', 'verisign']","['many year public key infrastructure', 'pki vendor', 'secure remote access', 'pki basic', 'network authentication', 'essential business application', 'public key system', 'electronic document exchange', 'pki', 'secure messaging']"
809,57,Speaker adaptive modeling by vocal tract normalization,"this paper presents methods for speaker adaptive modeling using vocal tract normalization (vtn) along with experimental tests on three databases. we propose a new training method for vtn: by using single-density acoustic models per hmm state for selecting the scale factor of the frequency axis, we avoid the problem that a mixture-density tends to learn the scale factors of the training speakers and thus cannot be used for selecting the scale factor. we show that using single gaussian densities for selecting the scale factor in training results in lower error rates than using mixture densities. for the recognition phase, we propose an improvement of the well-known two-pass strategy: by using a non-normalized acoustic model for the first recognition pass instead of a normalized model, lower error rates are obtained. in recognition tests, this method is compared with a fast variant of vtn. the two-pass strategy is an efficient method, but it is suboptimal because the scale factor and the word sequence are determined sequentially. we found that for telephone digit string recognition this suboptimality reduces the vtn gain in recognition performance by 30% relative. in summary, on the german spontaneous speech task verbmobil, the wsj task and the german telephone digit string corpus sietill, the proposed methods for vtn reduce the error rates significantly","['speaker adaptive modeling', 'vocal tract normalization', 'databases', 'training method', 'single-density acoustic models', 'hmm state', 'training speakers', 'single gaussian densities', 'training results', 'two-pass strategy', 'word sequence', 'telephone digit string recognition', 'german spontaneous speech task', 'wsj task', 'german telephone digit string corpus', 'sietill', 'frequency scale factor', 'error rate reduction', 'nonnormalized acoustic model', 'verlimobil']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M', 'U']","['speaker adaptive modeling', 'vocal tract normalization', 'database', 'training method', 'single - density acoustic model', 'hmm state', 'training speaker', 'single gaussian density', 'training result', 'two - pass strategy', 'word sequence', 'telephone digit string recognition', 'german spontaneous speech task', 'wsj task', 'german telephone digit string corpus', 'sietill', 'frequency scale factor', 'error rate reduction', 'nonnormalize acoustic model', 'verlimobil']","['speaker adaptive modeling use vocal tract normalization', 'normalize acoustic model', 'german telephone digit string corpus', 'telephone digit string recognition', 'german spontaneous speech task verbmobil', 'density acoustic model', 'normalize model', 'first recognition pass', 'recognition performance', 'gaussian density']"
810,628,Rank tests of association for exchangeable paired data,"we describe two rank tests of association for paired exchangeable data motivated by the study of lifespans in twins. the pooled sample is ranked. the nonparametric test of association is based on r/sup +/, the sum of the smaller within-pair ranks. a second measure l/sup +/ is the sum of within-pair rank products. under the null hypothesis of within-pair independence, the two test statistics are approximately normally distributed. expressions for the exact means and variances of r/sup +/ and l/sup +/ are given. we describe the power of these two statistics under a close alternative hypothesis to that of independence. both the r/sup +/ and l/sup +/ tests indicate nonparametric statistical evidence of positive association of longevity in identical twins and a negligible relationship between the lifespans of fraternal twins listed in the danish twin registry. the statistics are also applied to the analysis of a clinical trial studying the time to failure of ventilation tubes in children with bilateral otitis media","['rank tests', 'association', 'paired exchangeable data', 'pooled sample', 'nonparametric test', 'within-pair ranks', 'within-pair rank products', 'null hypothesis', 'within-pair independence', 'test statistics', 'exact means', 'nonparametric statistical evidence', 'longevity', 'identical twins', 'fraternal twins', 'danish twin registry', 'clinical trial', 'bilateral otitis media', 'twin lifespans', 'exact variances', 'ventilation tube failure time']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['rank test', 'association', 'pair exchangeable datum', 'pool sample', 'nonparametric test', 'within - pair rank', 'within - pair rank product', 'null hypothesis', 'within - pair independence', 'test statistic', 'exact mean', 'nonparametric statistical evidence', 'longevity', 'identical twin', 'fraternal twin', 'danish twin registry', 'clinical trial', 'bilateral otitis medium', 'twin lifespan', 'exact variance', 'ventilation tube failure time']","['nonparametric statistical evidence', 'identical twin', 'fraternal twin', 'danish twin registry', 'pair rank product', 'test statistic', 'pair exchangeable datum', 'pair rank', 'twin', 'nonparametric test']"
811,12,National learning systems: a new approach on technological change in late industrializing economies and evidences from the cases of Brazil and South Korea,"the paper has two intertwined parts. the first one is a proposal for a conceptual and theoretical framework to understand technical change in late industrializing economies. the second part develops a kind of empirical test of the usefulness of that new framework by means of a comparative study of the brazilian and south korean cases. all the four types of macroevidences of the technical change processes of brazil and korea corroborate, directly or indirectly, the hypothesis of the existence of actual cases of national learning systems (nlss) of passive and active nature, as it is shown to be the cases of brazil and south korea, respectively. the contrast between the two processes of technical change prove remarkable, despite both processes being essentially confined to learning. the concepts of passive and active nlss show how useful they are to apprehend the diversity of those realities, and, consequently, to avoid, for instance, interpretations that misleadingly suppose (based on conventional economic theory) that those countries have a similar lack of technological dynamism","['national learning systems', 'technological change', 'late industrializing economies', 'brazil', 'south korea', 'national innovation system']","['P', 'P', 'P', 'P', 'P', 'M']","['national learning system', 'technological change', 'late industrialize economy', 'brazil', 'south korea', 'national innovation system']","['late industrialize economy', 'conventional economic theory', 'national learning system', 'technical change process', 'technical change prove remarkable', 'understand technical change', 'comparative study', 'south korean case', 'south korea', 'theoretical framework']"
812,1238,Optimization of element-by-element FEM in HPF 1.1,"in this study, poisson's equation is numerically evaluated by the element-by-element (ebe) finite-element method in a parallel environment using hpf 1.1 (high-performance fortran). in order to achieve high parallel efficiency, the data structures have been altered to node-based data instead of mixtures of node- and element-based data, representing a node-based ebe finite-element scheme (nebe). the parallel machine used in this study was the nec sx-4, and experiments were performed on a single node having 32 processors sharing common memory. the hpf compiler used in the experiments is hpf/sx rev 2.0 released in 1997 (unofficial), which supports hpf 1.1. models containing approximately 200 000 and 1,500,000 degrees of freedom were analyzed in order to evaluate the method. the calculation time, parallel efficiency, and memory used were compared. the performance of hpf in the conjugate gradient solver for the large model, using the nec sx-4 compiler option-noshrunk, was about 85% that of the message passing interface","['element-by-element', 'hpf', 'hpf compiler', 'conjugate gradient solver', 'message passing', 'finite element method', 'parallel programs', 'poisson equation']","['P', 'P', 'P', 'P', 'P', 'M', 'M', 'R']","['element - by - element', 'hpf', 'hpf compiler', 'conjugate gradient solver', 'message pass', 'finite element method', 'parallel program', 'poisson equation']","['hpf compiler', 'parallel efficiency', 'performance fortran', 'parallel machine', 'support hpf', 'processor share', 'use hpf', 'gradient solver', 'hpf', 'poisson']"
813,1181,Dynamic neighborhood structures in parallel evolution strategies,"parallelizing is a straightforward approach to reduce the total computation time of evolutionary algorithms. finding an appropriate communication network within spatially structured populations for improving convergence speed and convergence probability is a difficult task. a new method that uses a dynamic communication scheme in an evolution strategy will be compared with conventional static and dynamic approaches. the communication structure is based on a so-called diffusion model approach. the links between adjacent individuals are dynamically chosen according to deterministic or probabilistic rules. due to self-organization effects, efficient and stable communication structures are established that perform robustly and quickly on a multimodal test function","['parallelizing', 'evolutionary algorithms', 'convergence speed', 'convergence probability', 'multimodal test function', 'parallel evolutionary algorithms']","['P', 'P', 'P', 'P', 'P', 'R']","['parallelize', 'evolutionary algorithm', 'convergence speed', 'convergence probability', 'multimodal test function', 'parallel evolutionary algorithm']","['evolutionary algorithm', 'dynamic communication scheme', 'evolution strategy', 'appropriate communication network', 'stable communication structure', 'parallelize', 'call diffusion model approach', 'structure population', 'communication structure', 'adjacent individual']"
814,903,Modeling and simulation of an ABR flow control algorithm using a virtual source/virtual destination switch,"the available bit rate (abr) service class of asynchronous transfer mode networks uses a feedback control mechanism to adapt to varying link capacities. the virtual source/virtual destination (vs/vd) technique offers the possibility of segmenting the otherwise end-to-end abr control loop into separate loops. the improved feedback delay and control of abr traffic inside closed segments provide a better performance for abr connections. this article presents the use of classical linear control theory to model and develop an abr vs/vd flow control algorithm. discrete event simulations are used to analyze the behavior of the algorithm with respect to transient behavior and correctness of the control model. linear control theory offers the means to derive correct choices of parameters and to assess performance issues, such as stability of the system, during the design phase. the performance goals are high link utilization, fair bandwidth distribution, and robust operation in various environments, which are verified by discrete event simulations. the major contribution of this work is the use of analytic methods (linear control theory) to model and design an abr flow control algorithm tailored for the special layout of a vs/vd switch, and the use of simulation techniques to verify the result","['modeling', 'abr flow control algorithm', 'virtual source/virtual destination switch', 'feedback control mechanism', 'link capacities', 'control loop', 'feedback delay', 'closed segments', 'classical linear control theory', 'discrete event simulations', 'transient behavior', 'control model', 'performance issues', 'stability', 'high link utilization', 'fair bandwidth distribution', 'robust operation', 'atm networks', 'available bit rate service class', 'traffic control']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'R']","['model', 'abr flow control algorithm', 'virtual source / virtual destination switch', 'feedback control mechanism', 'link capacity', 'control loop', 'feedback delay', 'close segment', 'classical linear control theory', 'discrete event simulation', 'transient behavior', 'control model', 'performance issue', 'stability', 'high link utilization', 'fair bandwidth distribution', 'robust operation', 'atm network', 'available bit rate service class', 'traffic control']","['vd flow control algorithm', 'asynchronous transfer mode network', 'abr flow control algorithm', 'vd switch', 'classical linear control', 'linear control', 'abr traffic', 'control loop', 'bandwidth', 'virtual destination']"
815,140,"A high-resolution high-frequency monolithic top-shooting microinjector free of satellite drops - part II: fabrication, implementation, and characterization","for pt. i, see ibid., vol. 11, no. 5, p. 427-36 (2002). describes the fabrication, implementation and characterization of a thermal driven microinjector, featuring a bubble check valve and monolithic fabrication. microfabrication of this microinjector is based on bulk/surface-combined micromachining of the silicon wafer, free of the bonding process that is commonly used in the fabrication of commercial printing head, so that even solvents and fuels can be ejected. droplet ejection sequences of two microinjectors have been studied along with a commercial inkjet printhead for comparison. the droplet ejection of our microinjector with 10 mu m diameter nozzle has been characterized at a frequency over 35 khz, at least 3 times higher than those of commercial counterparts. the droplet volume from this device is smaller than 1 pl, 10 times smaller than those of commercial inkjets employed in the consumer market at the time of testing. visualization results have verified that our design, although far from being optimized, operates in the frequency several times higher than those of commercial products and reduces the crosstalk among neighboring chambers","['monolithic top-shooting microinjector', 'satellite drops', 'thermal driven microinjector', 'bubble check valve', 'bulk/surface-combined micromachining', 'bonding process', 'inkjet printhead', 'nozzle', '35 khz', 'droplet volume', 'consumer market', 'crosstalk', '10 micron']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['monolithic top - shooting microinjector', 'satellite drop', 'thermal drive microinjector', 'bubble check valve', 'bulk / surface - combine micromachining', 'bonding process', 'inkjet printhead', 'nozzle', '35 khz', 'droplet volume', 'consumer market', 'crosstalk', '10 micron']","['commercial inkjet printhead', 'microinjector', 'droplet ejection', 'microinjector', 'diameter nozzle', 'commercial inkjet employ', 'microfabrication', 'bubble check valve', 'combine micromachine', 'silicon wafer']"
816,591,Approximation theory of fuzzy systems based upon genuine many-valued implications - MIMO cases,"it is constructively proved that the multi-input-multi-output fuzzy systems based upon genuine many-valued implications are universal approximators (they are called boolean type fuzzy systems in this paper). the general approach to construct such fuzzy systems is given, that is, through the partition of the output region (by the given accuracy). two examples are provided to demonstrate the way in which fuzzy systems are designed to approximate given functions with a given required approximation accuracy","['fuzzy systems', 'many-valued implication', 'multi-input-multi-output fuzzy systems', 'universal approximator', 'boolean type fuzzy systems']","['P', 'P', 'P', 'P', 'P']","['fuzzy system', 'many - value implication', 'multi - input - multi - output fuzzy system', 'universal approximator', 'boolean type fuzzy system']","['output fuzzy system base', 'boolean type fuzzy system', 'construct such fuzzy system', 'fuzzy system', 'universal approximator', 'output region', 'multi', 'approximate', 'value implication', 'accuracy']"
817,946,Entanglement measures with asymptotic weak-monotonicity as lower (upper) bound for the entanglement of cost (distillation),we propose entanglement measures with asymptotic weak-monotonicity. we show that a normalized form of entanglement measures with the asymptotic weak-monotonicity are lower (upper) bound for the entanglement of cost (distillation),"['entanglement measures', 'asymptotic weak-monotonicity', 'entanglement of cost', 'distillation']","['P', 'P', 'P', 'P']","['entanglement measure', 'asymptotic weak - monotonicity', 'entanglement of cost', 'distillation']","['entanglement measure', 'entanglement', 'asymptotic weak', 'monotonicity', 'distillation', 'bind', 'normalize', 'cost', 'lower', 'upper']"
818,105,Greenberger-Horne-Zeilinger paradoxes for many qubits,"we construct greenberger-horne-zeilinger (ghz) contradictions for three or more parties sharing an entangled state, the dimension of each subsystem being an even integer d. the simplest example that goes beyond the standard ghz paradox (three qubits) involves five ququats (d = 4). we then examine the criteria that a ghz paradox must satisfy in order to be genuinely m partite and d dimensional","['greenberger-horne-zeilinger paradoxes', 'many qubits', 'entangled state', 'ghz paradox', 'ghz contradictions']","['P', 'P', 'P', 'P', 'R']","['greenberger - horne - zeilinger paradox', 'many qubit', 'entangle state', 'ghz paradox', 'ghz contradiction']","['standard ghz paradox', 'ghz paradox', 'entangle state', 'construct greenberger', 'qubit', 'ghz', 'dimension', 'ququat', 'contradiction', 'party share']"
819,1139,Development and evaluation of a case-based reasoning classifier for prediction of breast biopsy outcome with BI-RADS/sup TM/ lexicon,"approximately 70-85% of breast biopsies are performed on benign lesions. to reduce this high number of biopsies performed on benign lesions, a case-based reasoning (cbr) classifier was developed to predict biopsy results from bi-rads/sup tm/ findings. we used 1433 (931 benign) biopsy-proven mammographic cases. cbr similarity was defined using either the hamming or euclidean distance measure over case features. ten features represented each case: calcification distribution, calcification morphology, calcification number, mass margin, mass shape, mass density, mass size, associated findings, special cases, and age. performance was evaluated using round robin sampling, receiver operating characteristic (roc) analysis, and bootstrap. to determine the most influential features for the cbr, an exhaustive feature search was performed over all possible feature combinations (1022) and similarity thresholds. influential features were defined as the most frequently occurring features in the feature subsets with the highest partial roc areas (/sub 0.90/auc). for cbr with hamming distance, the most influential features were found to be mass margin, calcification morphology, age, calcification distribution, calcification number, and mass shape, resulting in an /sub 0.90/auc of 0.33. at 95% sensitivity, the hamming cbr would spare from biopsy 34% of the benign lesions. at 98% sensitivity, the hamming cbr would spare 27% benign lesions. for the cbr with euclidean distance, the most influential feature subset consisted of mass margin, calcification morphology, age, mass density, and associated findings, resulting in /sub 0.90/auc of 0.37. at 95% sensitivity, the euclidean cbr would spare from biopsy 41% benign lesions. at 98% sensitivity, the euclidean cbr would spare 27% benign lesions. the profile of cases spared by both distance measures at 98% sensitivity indicates that the cbr is a potentially useful diagnostic tool for the classification of mammographic lesions, by recommending short-term follow-up for likely benign lesions that is in agreement with final biopsy results and mammographer's intuition","['case-based reasoning classifier', 'breast biopsy outcome', 'benign lesions', 'biopsy-proven mammographic cases', 'cbr similarity', 'euclidean distance measure', 'calcification distribution', 'calcification morphology', 'calcification number', 'mass margin', 'mass shape', 'mass density', 'mass size', 'associated findings', 'special cases', 'age', 'round robin sampling', 'bootstrap', 'influential features', 'feature combinations', 'similarity thresholds', 'feature subsets', 'highest partial roc areas', 'diagnostic tool', 'short-term follow-up', 'bi-rads lexicon', 'hamming distance measure', 'receiver operating characteristic analysis', 'mammographic lesion classification']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R']","['case - base reasoning classifier', 'breast biopsy outcome', 'benign lesion', 'biopsy - prove mammographic case', 'cbr similarity', 'euclidean distance measure', 'calcification distribution', 'calcification morphology', 'calcification number', 'mass margin', 'mass shape', 'mass density', 'mass size', 'associate finding', 'special case', 'age', 'round robin sample', 'bootstrap', 'influential feature', 'feature combination', 'similarity threshold', 'feature subset', 'high partial roc area', 'diagnostic tool', 'short - term follow - up', 'bi - rad lexicon', 'hamming distance measure', 'receiver operate characteristic analysis', 'mammographic lesion classification']","['prove mammographic case', 'predict biopsy result', 'mammographic lesion', 'breast biopsy', 'biopsy result', 'high partial roc area', 'exhaustive feature search', 'cbr similarity', 'case feature', 'likely benign lesion']"
820,1280,Products and polymorphic subtypes,"this paper is devoted to a comprehensive study of polymorphic subtypes with products. we first present a sound and complete hilbert style axiomatization of the relation of being a subtype in presence of to , * type constructors and the for all quantifier, and we show that such axiornatization is not encodable in the system with to , for all only. in order to give a logical semantics to such a subtyping relation, we propose a new form of a sequent which plays a key role in a natural deduction and a gentzen style calculi. interestingly enough, the sequent must have the form e implies t, where e is a non-commutative, non-empty sequence of typing assumptions and t is a finite binary tree of typing judgements, each of them behaving like a pushdown store. we study basic metamathematical properties of the two logical systems, such as subject reduction and cut elimination. some decidability/undecidability issues related to the presented subtyping relation are also explored: as expected, the subtyping over to , *, for all is undecidable, being already undecidable for the to , for all fragment (as proved in [15]), but for the *, for all fragment it turns out to be decidable","['polymorphic subtypes', 'hilbert style axiomatization', 'logical semantics', 'gentzen style calculi', 'finite binary tree', 'pushdown store', 'decidability', 'products subtypes', 'metamathernatical properties']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['polymorphic subtype', 'hilbert style axiomatization', 'logical semantic', 'gentzen style calculi', 'finite binary tree', 'pushdown store', 'decidability', 'product subtype', 'metamathernatical property']","['complete hilbert style axiomatization', 'polymorphic subtype', 'basic metamathematical property', 'logical semantic', 'type constructor', 'undecidability issue relate', 'decidability', 'subtype', 'such axiornatization', 'logical system']"
821,690,Robust Kalman filter design for discrete time-delay systems,the problem of finite- and infinite-horizon robust kalman filtering for uncertain discrete-time systems with state delay is addressed. the system under consideration is subject to time-varying norm-bounded parameter uncertainty in both the state and output matrices. we develop a new methodology for designing a linear filter such that the error variance of the filter is guaranteed to be within a certain upper bound for any allowed uncertainty and time delay. the solution is given in terms of two riccati equations. multiple time-delay systems are also investigated,"['robust kalman filter', 'discrete time-delay systems', 'state delay', 'norm-bounded parameter uncertainty', 'output matrices', 'linear filter', 'riccati equations', 'uncertain systems', 'time-varying parameter uncertainty', 'state matrices', 'robust state estimation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M']","['robust kalman filter', 'discrete time - delay system', 'state delay', 'norm - bound parameter uncertainty', 'output matrix', 'linear filter', 'riccati equation', 'uncertain system', 'time - vary parameter uncertainty', 'state matrix', 'robust state estimation']","['horizon robust kalman filtering', 'linear filter such', 'parameter uncertainty', 'state delay', 'riccati equation', 'allow uncertainty', 'delay system', 'time delay', 'uncertain discrete', 'error variance']"
822,859,Developing a hardware and programming curriculum for middle school girls,"techbridge provides experiences and resources that would teach girls technology skills as well as excite their curiosity and build their confidence. funded by the national science foundation and sponsored by chabot space and science center in oakland, california, techbridge is a three-year program that serves approximately 200 girls annually. techbridge is hosted at 8 middle and high schools in oakland and at the california school for the blind in fremont, california generally as an after-school program meeting once a week. techbridge comes at a critical time in girls' development when girls have many important decisions to make regarding classes and careers, but often lack the confidence and guidance to make the best choices. techbridge helps girls plan for the next steps to high school and college with its role models and guidance. techbridge also provides training and resources for teachers, counselors, and families","['hardware and programming curriculum', 'middle school girls', 'techbridge', 'technology skills teaching']","['P', 'P', 'P', 'R']","['hardware and programming curriculum', 'middle school girl', 'techbridge', 'technology skill teach']","['teach girl technology skill', 'techbridge come', 'techbridge', 'california school', 'school program meeting', 'high school', 'college', 'counselor', 'high school', 'girl plan']"
823,1362,Process planning for reliable high-speed machining of moulds,"a method of generating nc programs for the high-speed milling of moulds is investigated. forging dies and injection moulds, whether plastic or aluminium, have a complex surface geometry. in addition they are made of steels of hardness as much as 30 or even 50 hrc. since 1995, high-speed machining has been much adopted by the die-making industry, which with this technology can reduce its use of sinking electrodischarge machining (sedm). edm, in general, calls for longer machining times. the use of high-speed machining makes it necessary to redefine the preliminary stages of the process. in addition, it affects the methodology employed in the generation of nc programs, which requires the use of high-level cam software. the aim is to generate error-free programs that make use of optimum cutting strategies in the interest of productivity and surface quality. the final result is a more reliable manufacturing process. there are two risks in the use of high-speed milling on hardened steels. one of these is tool breakage, which may be very costly and may furthermore entail marks on the workpiece. the other is collisions between the tool and the workpiece or fixtures, the result of which may be damage to the ceramic bearings in the spindles. in order to minimize these risks it is necessary that new control and optimization steps be included in the cam methodology. there are three things that the firm adopting high-speed methods should do. it should redefine its process engineering, it should systematize access by its cam programmers to high-speed knowhow, and it should take up the use of process simulation tools. in the latter case, it will be very advantageous to use tools for the estimation of cutting forces. the new work methods proposed in this article have made it possible to introduce high speed milling (hsm) into the die industry. examples are given of how the technique has been applied with cam programming re-engineered as here proposed, with an explanation of the novel features and the results","['process planning', 'reliable high-speed machining', 'moulds', 'nc programs', 'high-speed milling', 'forging dies', 'injection moulds', 'complex surface geometry', 'error-free programs', 'optimum cutting strategies', 'cutting strategies', 'productivity', 'surface quality', 'hardened steels', 'tool breakage', 'ceramic bearings', 'cam methodology', 'process simulation tools', 'cam programming re-engineering', 'tool workpiece collisions', 'process engineering redefinition']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['process plan', 'reliable high - speed machining', 'mould', 'nc program', 'high - speed milling', 'forge die', 'injection mould', 'complex surface geometry', 'error - free program', 'optimum cutting strategy', 'cut strategy', 'productivity', 'surface quality', 'harden steel', 'tool breakage', 'ceramic bearing', 'cam methodology', 'process simulation tool', 'cam programming re - engineer', 'tool workpiece collision', 'process engineering redefinition']","['speed machining make', 'speed machining', 'electrodischarge machining', 'long machine time', 'speed milling', 'process simulation tool', 'tool breakage', 'reliable manufacturing process', 'harden steel', 'optimum cutting']"
824,737,What's in a name? [mobile telephony branding],mobile operators are frantically consolidating businesses into single international brands,"['mobile telephony', 'branding', 'consolidating businesses']","['P', 'P', 'P']","['mobile telephony', 'brand', 'consolidate business']","['consolidate business', 'mobile operator']"
825,772,Meshed atlases for real-time procedural solid texturing,"we describe an implementation of procedural solid texturing that uses the texture atlas, a one-to-one mapping from an object's surface into its texture space. the method uses the graphics hardware to rasterize the solid texture coordinates as colors directly into the atlas. a texturing procedure is applied per-pixel to the texture map, replacing each solid texture coordinate with its corresponding procedural solid texture result. the procedural solid texture is then mapped back onto the object surface using standard texture mapping. the implementation renders procedural solid textures in real time, and the user can design them interactively. the quality of this technique depends greatly on the layout of the texture atlas. a broad survey of texture atlas schemes is used to develop a set of general purpose mesh atlases and tools for measuring their effectiveness at distributing as many available texture samples as evenly across the surface as possible. the main contribution of this paper is a new multiresolution texture atlas. it distributes all available texture samples in a nearly uniform distribution. this multiresolution texture atlas also supports mip-mapped minification antialiasing and linear magnification filtering","['meshed atlases', 'real-time procedural solid texturing', 'texture atlas', 'one-to-one mapping', 'texture space', 'graphics hardware', 'rasterization', 'solid texture coordinates', 'colors', 'object surface', 'rendering', 'multiresolution texture atlas', 'mip-mapped minification antialiasing', 'linear magnification filtering']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['mesh atlas', 'real - time procedural solid texturing', 'texture atla', 'one - to - one mapping', 'texture space', 'graphic hardware', 'rasterization', 'solid texture coordinate', 'color', 'object surface', 'render', 'multiresolution texture atla', 'mip - map minification antialiasing', 'linear magnification filtering']","['implementation render procedural solid texture', 'multiresolution texture atla', 'correspond procedural solid texture result', 'procedural solid texturing', 'procedural solid texture', 'texture atlas scheme', 'texture atla', 'general purpose mesh atlas', 'texture map', 'solid texture coordinate']"
826,1026,Use of SPOT images as a tool for coastal zone management and monitoring of environmental impacts in the coastal zone,"modern techniques such as remote sensing have been one of the main factors leading toward the achievement of serious plans regarding coastal management. a multitemporal analysis of land use in certain areas of the colombian caribbean coast is described. it mainly focuses on environmental impacts caused by anthropogenic activities, such as deforestation of mangroves due to shrimp farming. selection of sensitive areas, percentage of destroyed mangroves, possible endangered areas, etc., are some of the results of this analysis. recommendations for a coastal management plan in the area have also resulted from this analysis. some other consequences of the deforestation of mangroves in the coastal zone and the construction of shrimp ponds are also analyzed, such as the increase of erosion problems in these areas and water pollution, among others. the increase of erosion in these areas has also changed part of their morphology, which has been studied by the analysis of spot images in previous years. a serious concern exists about the future of these areas. for this reason new techniques like satellite images (spot) have been applied with good results, leading to more effective control and coastal management in the area. the use of spot images to study changes of the land use of the area is a useful technique to determine patterns of human activities and suggest solutions for severe problems in these areas","['spot images', 'coastal zone management', 'remote sensing', 'multitemporal analysis', 'land use', 'colombian caribbean coast', 'anthropogenic activities', 'shrimp farming', 'endangered areas', 'shrimp ponds', 'erosion problems', 'water pollution', 'satellite images', 'human activities', 'environmental impact monitoring', 'mangrove deforestation', 'supervised classification', 'sedimentation', 'vectorization', 'vector overlay']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U', 'U', 'U', 'U']","['spot image', 'coastal zone management', 'remote sensing', 'multitemporal analysis', 'land use', 'colombian caribbean coast', 'anthropogenic activity', 'shrimp farming', 'endanger area', 'shrimp pond', 'erosion problem', 'water pollution', 'satellite image', 'human activity', 'environmental impact monitor', 'mangrove deforestation', 'supervise classification', 'sedimentation', 'vectorization', 'vector overlay']","['colombian caribbean coast', 'environmental impact cause', 'satellite image', 'destroy mangrove', 'plan regard coastal management', 'mangrove due', 'spot image', 'shrimp farming', 'mangrove', 'shrimp pond']"
827,1063,Operations that do not disturb partially known quantum states,"consider a situation in which a quantum system is secretly prepared in a state chosen from the known set of states. we present a principle that gives a definite distinction between the operations that preserve the states of the system and those that disturb the states. the principle is derived by alternately applying a fundamental property of classical signals and a fundamental property of quantum ones. the principle can be cast into a simple form by using a decomposition of the relevant hilbert space, which is uniquely determined by the set of possible states. the decomposition implies the classification of the degrees of freedom of the system into three parts depending on how they store the information on the initially chosen state: one storing it classically, one storing it nonclassically, and the other one storing no information. then the principle states that the nonclassical part is inaccessible and the classical part is read-only if we are to preserve the state of the system. from this principle, many types of no-cloning, no-broadcasting, and no-imprinting conditions can easily be derived in general forms including mixed states. it also gives a unified view on how various schemes of quantum cryptography work. the principle helps one to derive optimum amount of resources (bits, qubits, and ebits) required in data compression or in quantum teleportation of mixed-state ensembles","['partially known quantum states', 'quantum system', 'classical signals', 'hilbert space', 'degrees of freedom', 'nonclassical part', 'quantum cryptography', 'bits', 'qubits', 'ebits', 'quantum teleportation', 'mixed-state ensembles', 'secretly prepared quantum state']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['partially know quantum state', 'quantum system', 'classical signal', 'hilbert space', 'degree of freedom', 'nonclassical part', 'quantum cryptography', 'bit', 'qubit', 'ebit', 'quantum teleportation', 'mixed - state ensemble', 'secretly prepare quantum state']","['quantum cryptography work', 'quantum teleportation', 'quantum system', 'quantum one', 'form include mixed state', 'classical signal', 'qubit', 'imprinting condition', 'hilbert space', 'decomposition']"
828,1282,Completeness of timed mu CRL,"previously a straightforward extension of the process algebra mu crl was proposed to explicitly deal with time. the process algebra mu crl has been especially designed to deal with data in a process algebraic context. using the features for data, only a minor extension of the language was needed to obtain a very expressive variant of time. previously it contained syntax, operational semantics and axioms characterising timed mu crl. it did not contain an in depth analysis of theory of timed mu crl. this paper fills this gap, by providing soundness and completeness results. the main tool to establish these is a mapping of timed to untimed mu crl and employing the completeness results obtained for untimed mu crl","['completeness', 'timed mu crl', 'process algebra', 'operational semantics']","['P', 'P', 'P', 'P']","['completeness', 'time mu crl', 'process algebra', 'operational semantic']","['axiom characterise time mu crl', 'process algebra mu crl', 'time mu crl', 'untimed mu crl', 'process algebraic context', 'operational semantic', 'completeness result obtain', 'time', 'completeness result', 'contain syntax']"
829,692,A partial converse to Hadamard's theorem on homeomorphisms,"a theorem by hadamard gives a two-part condition under which a map from one banach space to another is a homeomorphism. the theorem, while often very useful, is incomplete in the sense that it does not explicitly specify the family of maps for which the condition is met. here, under a typically weak additional assumption on the map, we show that hadamard's condition is met if, and only if, the map is a homeomorphism with a lipschitz continuous inverse. an application is given concerning the relation between the stability of a nonlinear system and the stability of related linear systems","['partial converse', 'homeomorphisms', 'banach space', 'lipschitz continuous inverse', 'linearization', 'hadamard theorem', 'nonlinear system stability', 'linear system stability', 'nonlinear feedback systems', 'nonlinear networks']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'M']","['partial converse', 'homeomorphism', 'banach space', 'lipschitz continuous inverse', 'linearization', 'hadamard theorem', 'nonlinear system stability', 'linear system stability', 'nonlinear feedback system', 'nonlinear network']","['lipschitz continuous inverse', 'banach space', 'nonlinear system', 'homeomorphism', 'stability', 'hadamard', 'map', 'map', 'theorem', 'weak']"
830,1183,Evolving robust asynchronous cellular automata for the density task,"in this paper the evolution of three kinds of asynchronous cellular automata are studied for the density task. results are compared with those obtained for synchronous automata and the influence of various asynchronous update policies on the computational strategy is described. how synchronous and asynchronous cellular automata behave is investigated when the update policy is gradually changed, showing that asynchronous cellular automata are more adaptable. the behavior of synchronous and asynchronous evolved automata are studied under the presence of random noise of two kinds and it is shown that asynchronous cellular automata implicitly offer superior fault tolerance","['asynchronous cellular automata', 'cellular automata', 'synchronous automata', 'random noise', 'fault tolerance', 'discrete dynamical systems']","['P', 'P', 'P', 'P', 'P', 'U']","['asynchronous cellular automata', 'cellular automata', 'synchronous automata', 'random noise', 'fault tolerance', 'discrete dynamical system']","['asynchronous cellular automata behave', 'asynchronous cellular automata', 'asynchronous evolved automata', 'synchronous automata', 'various asynchronous update policy', 'synchronous', 'random noise', 'computational strategy', 'density task', 'evolution']"
831,901,Estimation of the Poisson stream intensity in a multilinear queue with an exponential job queue decay,times the busy queue periods start are found for a multilinear queue with an exponential job queue decay and uniform resource allocation to individual servers. the stream intensity and the average job are estimated from observations of the times the queue busy periods start,"['poisson stream intensity', 'stream intensity', 'multilinear queue', 'exponential job queue decay', 'busy queue periods start', 'uniform resource allocation', 'individual servers']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['poisson stream intensity', 'stream intensity', 'multilinear queue', 'exponential job queue decay', 'busy queue period start', 'uniform resource allocation', 'individual server']","['exponential job queue decay', 'busy queue period start', 'multilinear queue', 'uniform resource allocation', 'stream intensity', 'individual server', 'average job', 'observation', 'time', 'estimate']"
832,142,Surface micromachined paraffin-actuated microvalve,normally-open microvalves have been fabricated and tested which use a paraffin microactuator as the active element. the entire structure with nominal dimension of phi 600 mu m * 30 mu m is batch-fabricated by surface micromachining the actuator and channel materials on top of a single substrate. gas flow rates in the 0.01-0.1 sccm range have been measured for several devices with actuation powers ranging from 50 to 150 mw on glass substrates. leak rates as low as 500 mu sccm have been measured. the normally-open blocking microvalve structure has been used to fabricate a precision flow control system of microvalves consisting of four blocking valve structures. the control valve is designed to operate over a 0.01-5.0 sccm flow range at a differential pressure of 800 torr. flow rates ranging from 0.02 to 4.996 sccm have been measured. leak rates as low as 3.2 msccm for the four valve system have been measured,"['normally-open microvalves', 'paraffin microactuator', 'active element', 'channel materials', 'gas flow rates', 'flow rates', 'actuation powers', '50 to 150 mw', 'leak rates', 'blocking valve structures', 'differential pressure', '800 torr', 'surface micromachined microvalve', '600 micron', '30 micron']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M']","['normally - open microvalve', 'paraffin microactuator', 'active element', 'channel material', 'gas flow rate', 'flow rate', 'actuation power', '50 to 150 mw', 'leak rate', 'block valve structure', 'differential pressure', '800 torr', 'surface micromachine microvalve', '600 micron', '30 micron']","['surface micromachine', 'microactuator', 'open microvalve', 'open blocking microvalve', 'microvalve', 'sccm flow range', 'mu sccm', 'control valve', 'gas flow rate', 'precision flow control system']"
833,593,Fuzzy systems with overlapping Gaussian concepts: Approximation properties in Sobolev norms,"in this paper the approximating capabilities of fuzzy systems with overlapping gaussian concepts are considered. the target function is assumed to be sampled either on a regular gird or according to a uniform probability density. by exploiting a connection with radial basis functions approximators, a new method for the computation of the system coefficients is provided, showing that it guarantees uniform approximation of the derivatives of the target function","['fuzzy systems', 'overlapping gaussian concepts', 'radial basis functions', 'learning', 'fuzzy system models', 'reproducing kernel hilbert spaces']","['P', 'P', 'P', 'U', 'M', 'U']","['fuzzy system', 'overlap gaussian concept', 'radial basis function', 'learn', 'fuzzy system model', 'reproduce kernel hilbert space']","['radial basis function approximator', 'overlap gaussian concept', 'fuzzy system', 'guarantee uniform approximation', 'approximate', 'target function', 'system coefficient', 'computation', 'uniform probability density', 'regular gird']"
834,944,Conditions for the local manipulation of Gaussian states,we present a general necessary and sufficient criterion for the possibility of a state transformation from one mixed gaussian state to another of a bipartite continuous-variable system with two modes. the class of operations that will be considered is the set of local gaussian completely positive trace-preserving maps,"['local manipulation', 'gaussian states', 'state transformation', 'bipartite continuous-variable system', 'trace-preserving maps', 'quantum information theory']","['P', 'P', 'P', 'P', 'P', 'U']","['local manipulation', 'gaussian state', 'state transformation', 'bipartite continuous - variable system', 'trace - preserve map', 'quantum information theory']","['mix gaussian state', 'bipartite continuous', 'state transformation', 'local gaussian', 'positive trace', 'variable system', 'mode', 'operation', 'general necessary', 'criterion']"
835,107,Deterministic single-photon source for distributed quantum networking,"a sequence of single photons is emitted on demand from a single three-level atom strongly coupled to a high-finesse optical cavity. the photons are generated by an adiabatically driven stimulated raman transition between two atomic ground states, with the vacuum field of the cavity stimulating one branch of the transition, and laser pulses deterministically driving the other branch. this process is unitary and therefore intrinsically reversible, which is essential for quantum communication and networking, and the photons should be appropriate for all-optical quantum information processing","['deterministic single-photon source', 'distributed quantum networking', 'single three-level atom', 'high-finesse optical cavity', 'adiabatically driven stimulated raman transition', 'vacuum field', 'quantum communication', 'all-optical quantum information processing']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['deterministic single - photon source', 'distribute quantum networking', 'single three - level atom', 'high - finesse optical cavity', 'adiabatically drive stimulate raman transition', 'vacuum field', 'quantum communication', 'all - optical quantum information processing']","['drive stimulate raman transition', 'finesse optical cavity', 'laser pulse', 'single photon', 'quantum communication', 'atomic ground state', 'level atom', 'photon', 'cavity stimulate', 'vacuum field']"
836,55,Self-testing chips take a load off ATE,looks at how chipmakers get more life out of automatic test equipment by embedding innovative circuits in silicon,"['self-testing chips', 'ate', 'automatic test equipment', 'innovative circuits', 'design-for-test techniques', 'embedded deterministic testing technique']","['P', 'P', 'P', 'P', 'U', 'M']","['self - testing chip', 'eat', 'automatic test equipment', 'innovative circuit', 'design - for - test technique', 'embed deterministic testing technique']","['embed innovative circuit', 'automatic test equipment', 'chipmaker get more life', 'look']"
837,979,"Design, analysis and testing of some parallel two-step W-methods for stiff systems","parallel two-step w-methods are linearly-implicit integration methods where the s stage values can be computed in parallel. we construct methods of stage order q = s and order p = s with favourable stability properties. generalizations for the concepts of a- and l-stability are proposed and conditions for stiff accuracy are given. numerical comparisons on a shared memory computer show the efficiency of the methods, especially in combination with krylov-techniques for large stiff systems","['parallel two-step w-methods', 'linearly-implicit integration methods', 'stage order', 'stability', 'shared memory computer', 'krylov-techniques', 'large stiff systems', 'differential equations', 'convergence analysis']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'M']","['parallel two - step w - method', 'linearly - implicit integration method', 'stage order', 'stability', 'share memory computer', 'krylov - technique', 'large stiff system', 'differential equation', 'convergence analysis']","['implicit integration method', 'stiff accuracy', 'numerical comparison', 'parallel', 'stability', 'stage order', 'krylov', 'method', 'share memory computer', 'step']"
838,652,A case for end system multicast,"the conventional wisdom has been that internet protocol (ip) is the natural protocol layer for implementing multicast related functionality. however, more than a decade after its initial proposal, ip multicast is still plagued with concerns pertaining to scalability, network management, deployment, and support for higher layer functionality such as error, flow, and congestion control. we explore an alternative architecture that we term end system multicast, where end systems implement all multicast related functionality including membership management and packet replication. this shifting of multicast support from routers to end systems has the potential to address most problems associated with ip multicast. however, the key concern is the performance penalty associated with such a model. in particular, end system multicast introduces duplicate packets on physical links and incurs larger end-to-end delays than ip multicast. we study these performance concerns in the context of the narada protocol. in narada, end systems self-organize into an overlay structure using a fully distributed protocol. further, end systems attempt to optimize the efficiency of the overlay by adapting to network dynamics and by considering application level performance. we present details of narada and evaluate it using both simulation and internet experiments. our results indicate that the performance penalties are low both from the application and the network perspectives. we believe the potential benefits of transferring multicast functionality from end systems to routers significantly outweigh the performance penalty incurred","['end system multicast', 'internet protocol', 'protocol layer', 'ip multicast', 'network management', 'higher layer functionality', 'congestion control', 'membership management', 'packet replication', 'performance penalties', 'end-to-end delays', 'narada protocol', 'overlay structure', 'distributed protocol', 'network dynamics', 'application level performance', 'simulation', 'internet experiments', 'network scalability', 'network routers', 'self-organizing protocol']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['end system multicast', 'internet protocol', 'protocol layer', 'ip multicast', 'network management', 'high layer functionality', 'congestion control', 'membership management', 'packet replication', 'performance penalty', 'end - to - end delay', 'narada protocol', 'overlay structure', 'distribute protocol', 'network dynamic', 'application level performance', 'simulation', 'internet experiment', 'network scalability', 'network router', 'self - organize protocol']","['end system multicast introduce duplicate packet', 'implement multicast related functionality', 'ip multicast', 'term end system multicast', 'transfer multicast functionality', 'distribute protocol', 'multicast support', 'packet replication', 'internet protocol', 'protocol layer']"
839,617,Estimation of trifocal tensor using GMM,a novel estimation of a trifocal tensor based on the gaussian mixture model (gmm) is presented. the mixture model is built assuming that the residuals of inliers and outliers belong to different gaussian distributions. the bayesian rule is then employed to detect the inliers for re-estimation. experiments show that the presented method is more precise and relatively unaffected by outliers,"['gmm', 'gaussian mixture model', 'inliers', 'outliers', 'gaussian distributions', 'bayesian rule', 'trifocal tensor estimation', 'motion analysis', 'image data', 'image analysis']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'U', 'U']","['gmm', 'gaussian mixture model', 'inlier', 'outlier', 'gaussian distribution', 'bayesian rule', 'trifocal tensor estimation', 'motion analysis', 'image datum', 'image analysis']","['trifocal tensor base', 'gaussian mixture model', 'gaussian distribution', 'bayesian rule', 'mixture model', 'inlier', 'outlier', 'residual', 'estimation', 'detect']"
840,68,"Human factors research on data modeling: a review of prior research, an extended framework and future research directions","this study reviews and synthesizes human factors research on conceptual data modeling. in addition to analyzing the variables used in earlier studies and summarizing the results of this stream of research, we propose a new framework to help with future efforts in this area. the study finds that prior research has focused on issues that are relevant when conceptual models are used for communication between systems analysts and developers (analyst developer models) whereas the issues important for models that are used to facilitate communication between analysts and users (user-analyst models) have received little attention and, hence, require a significantly stronger role in future research. in addition, we emphasize the importance of building a strong theoretical foundation and using it to guide future empirical work in this area","['human factors', 'conceptual data modeling', 'future efforts', 'analyst developer models', 'user-analyst models', 'database']","['P', 'P', 'P', 'P', 'P', 'U']","['human factor', 'conceptual datum modeling', 'future effort', 'analyst developer model', 'user - analyst model', 'database']","['conceptual datum modeling', 'analyst developer model', 'synthesize human factor research', 'conceptual model', 'analyst model', 'system analyst', 'guide future empirical work', 'future research', 'analyst', 'prior research']"
841,1242,VPP Fortran and the design of HPF/JA extensions,"vpp fortran is a data parallel language that has been designed for the vpp series of supercomputers. in addition to pure data parallelism, it contains certain low-level features that were designed to extract high performance from user programs. a comparison of vpp fortran and high-performance fortran (hpf) 2.0 shows that these low-level features are not available in hpf 2.0. the features include asynchronous interprocessor communication, explicit shadow, and the local directive. they were shown in vpp fortran to be very useful in handling real-world applications, and they have been included in the hpf/ja extensions. they are described in the paper. the hpf/ja language specification version 1.0 is an extension of hpf 2.0 to achieve practical performance for real-world applications and is a result of collaboration in the japan association for hpf (jahpf). some practical programming and tuning procedures with the hpf/ja language specification are described, using the nas parallel benchmark bt as an example","['vpp fortran', 'data parallel language', 'data parallelism', 'high performance', 'asynchronous interprocessor communication', 'explicit shadow', 'benchmark', 'asynchronous communication', 'data locality']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['vpp fortran', 'datum parallel language', 'datum parallelism', 'high performance', 'asynchronous interprocessor communication', 'explicit shadow', 'benchmark', 'asynchronous communication', 'datum locality']","['feature include asynchronous interprocessor communication', 'nas parallel benchmark bt', 'vpp fortran', 'performance fortran', 'ja language specification version', 'datum parallel language', 'ja language specification', 'pure datum parallelism', 'achieve practical performance', 'practical programming']"
842,1207,Packet spacing: an enabling mechanism for delivering multimedia content in computational grids,"streaming multimedia with udp has become increasingly popular over distributed systems like the internet. scientific applications that stream multimedia include remote computational steering of visualization data and video-on-demand teleconferencing over the access grid. however, udp does not possess a self-regulating, congestion-control mechanism; and most best-effort traffic is served by congestion-controlled tcp. consequently, udp steals bandwidth from tcp such that tcp flows starve for network resources. with the volume of internet traffic continuing to increase, the perpetuation of udp-based streaming will cause the internet to collapse as it did in the mid-1980's due to the use of non-congestion-controlled tcp. to address this problem, we introduce the counter-intuitive notion of inter-packet spacing with control feedback to enable udp-based applications to perform well in the next-generation internet and computational grids. when compared with traditional udp-based streaming, we illustrate that our approach can reduce packet loss over 50% without adversely affecting delivered throughput","['streaming multimedia', 'udp', 'distributed systems', 'internet', 'remote computational steering', 'visualization data', 'udp-based streaming', 'inter-packet spacing', 'network protocol', 'transport protocols']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U']","['stream multimedia', 'udp', 'distribute system', 'internet', 'remote computational steering', 'visualization datum', 'udp - base streaming', 'inter - packet spacing', 'network protocol', 'transport protocol']","['udp steal bandwidth', 'stream multimedia', 'tcp flow starve', 'control tcp', 'base streaming', 'internet traffic continue', 'traditional udp', 'reduce packet loss', 'enable udp', 'udp']"
843,95,SIA shelves T+1 decision till 2004,"the securities industry association has decided that a move to t+1 is more than the industry can handle right now. stp, however, will remain a focus","['t+1', 'securities industry association', 'straight-through-processing']","['P', 'P', 'U']","['t+1', 'security industry association', 'straight - through - processing']","['security industry association', 'stp', 'industry', 'move', 'remain', 'decide', 'handle']"
844,553,Application of traditional system design techniques to Web site design,after several decades of computer program construction there emerged a set of principles that provided guidance to produce more manageable programs. with the emergence of the plethora of internet web sites one wonders if similar guidelines are followed in their construction. since this is a new technology no apparent universally accepted methods have emerged to guide the designer in web site construction. this paper reviews the traditional principles of structured programming and the preferred characteristics of web sites. finally a mapping of how the traditional guidelines may be applied to web site construction is presented. the application of the traditional principles of structured programming to the design of a web site can provide a more usable site for the visitors to the site. the additional benefit of using these time-honored techniques is the creation of a web site that will be easier to maintain by the development staff,"['system design techniques', 'structured programming', 'internet web site design']","['P', 'P', 'R']","['system design technique', 'structured programming', 'internet web site design']","['web site construction', 'internet web site', 'structured programming', 'computer program construction', 'web site', 'web site', 'traditional guideline', 'usable site', 'traditional principle', 'manageable program']"
845,984,Bistability of harmonically forced relaxation oscillations,"relaxation oscillations appear in processes which involve transitions between two states characterized by fast and slow time scales. when a relaxation oscillator is coupled to an external periodic force its entrainment by the force results in a response which can include multiple periodicities and bistability. the prototype of these behaviors is the harmonically driven van der pol equation which displays regions in the parameter space of the driving force amplitude where stable orbits of periods 2n+or-1 coexist, flanked by regions of periods 2n+1 and 2n-1. the parameter regions of such bistable orbits are derived analytically for the closely related harmonically driven stoker-haag piecewise discontinuous equation. the results are valid over most of the control parameter space of the system. also considered are the reasons for the more complicated dynamics featuring regions of high multiple periodicity which appear like noise between ordered periodic regions. since this system mimics in detail the less analytically tractable forced van der pol equation, the results suggest extensions to situations where forced relaxation oscillations are a component of the operating mechanisms","['bistability', 'harmonically forced relaxation oscillations', 'external periodic force', 'entrainment', 'van der pol equation', 'harmonically driven stoker-haag piecewise discontinuous equation', 'control parameter space', 'nonlinear dynamics']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['bistability', 'harmonically force relaxation oscillation', 'external periodic force', 'entrainment', 'van der pol equation', 'harmonically drive stoker - haag piecewise discontinuous equation', 'control parameter space', 'nonlinear dynamic']","['drive van der pol equation', 'tractable force van der pol equation', 'force relaxation oscillation', 'relaxation oscillation', 'relaxation oscillator', 'piecewise discontinuous equation', 'stable orbit', 'complicated dynamic', 'bistable orbit', 'periodic force']"
846,1143,A three-source model for the calculation of head scatter factors,"accurate determination of the head scatter factor s/sub c/ is an important issue, especially for intensity modulated radiation therapy, where the segmented fields are often very irregular and much less than the collimator jaw settings. in this work, we report an s/sub c/ calculation algorithm for symmetric, asymmetric, and irregular open fields shaped by the tertiary collimator (a multileaf collimator or blocks) at different source-to-chamber distance. the algorithm was based on a three-source model, in which the photon radiation to the point of calculation was treated as if it originated from three effective sources: one source for the primary photons from the target and two extra-focal photon sources for the scattered photons from the primary collimator and the flattening filter, respectively. the field mapping method proposed by kim et al. [phys. med. biol. 43, 1593-1604 (1998)] was extended to two extra-focal source planes and the scatter contributions were integrated over the projected areas (determined by the detector's eye view) in the three source planes considering the source intensity distributions. the algorithm was implemented using microsoft visual c/c++ in the ms windows environment. the only input data required were head scatter factors for symmetric square fields, which are normally acquired during machine commissioning. a large number of different fields were used to evaluate the algorithm and the results were compared with measurements. we found that most of the calculated s/sub c/'s agreed with the measured values to within 0.4%. the algorithm can also be easily applied to deal with irregular fields shaped by a multileaf collimator that replaces the upper or lower collimator jaws","['three-source model', 'head scatter factors', 'intensity modulated radiation therapy', 'segmented fields', 'fields', 'fields', 'collimator jaw settings', 'calculation algorithm', 'symmetric', 'asymmetric', 'irregular open fields', 'tertiary collimator', 'multileaf collimator', 'blocks', 'source-to-chamber distance', 'photon radiation', 'target', 'extra-focal photon sources', 'scattered photons', 'primary collimator', 'flattening filter', 'field mapping method', 'extra-focal source planes', 'source intensity distributions', 'ms windows environment', 'input data', 'symmetric square fields', 'machine commissioning', 'lower collimator jaws', 'upper collimator jaws']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['three - source model', 'head scatter factor', 'intensity modulate radiation therapy', 'segment field', 'field', 'field', 'collimator jaw setting', 'calculation algorithm', 'symmetric', 'asymmetric', 'irregular open field', 'tertiary collimator', 'multileaf collimator', 'block', 'source - to - chamber distance', 'photon radiation', 'target', 'extra - focal photon source', 'scatter photon', 'primary collimator', 'flatten filter', 'field mapping method', 'extra - focal source plane', 'source intensity distribution', 'ms windows environment', 'input datum', 'symmetric square field', 'machine commission', 'low collimator jaw', 'upper collimator jaw']","['photon radiation', 'focal photon source', 'scatter photon', 'head scatter factor', 'head scatter factor', 'source intensity distribution', 'primary photon', 'radiation therapy', 'scatter contribution', 'segment field']"
847,1106,Virtual projects at Halden [Reactor Project],"the halden man-machine systems (mms) programme for 2002 is intended to address issues related to human factors, control room design, computer-based support system areas and system safety and reliability. the halden mms programme is intended to address extensive experimental work in the human factors, control room design and computer-based support system areas. the work is based on experiments and demonstrations carried out in the experimental facility hammlab. pilot-versions of several operator aids are adopted and integrated to the hammlab simulators and demonstrated in a full dynamic setting. the halden virtual reality laboratory has recently become an integral and important part of the programme","['human factors', 'control room design', 'computer-based support system', 'safety', 'reliability', 'virtual reality', 'halden reactor project', 'man-machine systems programme']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['human factor', 'control room design', 'computer - base support system', 'safety', 'reliability', 'virtual reality', 'halden reactor project', 'man - machine system programme']","['halden virtual reality laboratory', 'halden mms programme', 'hammlab simulator', 'experimental facility hammlab', 'machine system', 'halden man', 'control room design', 'base support system area', 'system safety', 'demonstration carry']"
848,899,Mathematical model of functioning of an insurance company with allowance for advertising expenses,a mathematical model of the functioning of an insurance company with allowance for advertising expenses is suggested. the basic characteristics of the capital of the company and the advertising efficiency are examined in the case in which the advertising expenses are proportional to the capital,"['mathematical model', 'capital', 'insurance company functioning', 'advertising expenses allowance']","['P', 'P', 'R', 'R']","['mathematical model', 'capital', 'insurance company function', 'advertising expense allowance']","['advertising expense', 'advertising efficiency', 'insurance company', 'mathematical model', 'allowance', 'capital', 'company', 'proportional', 'basic characteristic', 'case']"
849,864,Valuing corporate debt: the effect of cross-holdings of stock and debt,"we have developed a simple approach to valuing risky corporate debt when corporations own securities issued by other corporations. we assume that corporate debt can be valued as an option on corporate business asset value, and derive payoff functions when there exist cross-holdings of stock or debt between two firms. next we show that payoff functions with multiple cross-holdings can be solved by the contraction principle. the payoff functions which we derive provide a number of insights about the risk structure of company cross-holdings. first, the modigliani-miller theorem can obtain when there exist cross-holdings between firms. second, by establishing cross-shareholdings each of stock holders distributes a part of its payoff values to the bond holder of the other's firm, so that both firms can decrease credit risks by cross-shareholdings. in the numerical examples, we show that the correlation in firms can be a critical condition for reducing credit risk by cross-holdings of stock using monte carlo simulation. moreover, we show we can calculate the default spread easily when complicated cross-holdings exist, and find which shares are beneficial or disadvantageous","['securities', 'option', 'corporate business asset value', 'payoff functions', 'multiple cross-holdings', 'modigliani-miller theorem', 'cross-shareholdings', 'bond holder', 'credit risks', 'correlation', 'monte carlo simulation', 'risky corporate debt valuation', 'stock holdings', 'debt holdings']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'M']","['security', 'option', 'corporate business asset value', 'payoff function', 'multiple cross - holding', 'modigliani - miller theorem', 'cros - shareholding', 'bond holder', 'credit risk', 'correlation', 'monte carlo simulation', 'risky corporate debt valuation', 'stock holding', 'debt holding']","['value risky corporate debt', 'corporation own security issue', 'corporate business asset value', 'corporate debt', 'stock holder distribute', 'risk structure', 'credit risk', 'other corporation', 'bond holder', 'credit risk']"
850,821,Digital rights (and wrongs),"attempting to grasp the many conflicts and proposed safeguards for intellectual property is extremely difficult. legal, political, economic, and cultural issues-both domestic and international-loom large, almost dwarfing the daunting technological challenges. solutions devised by courts and legislatures and regulatory agencies are always late out of the blocks and fall ever farther behind. recently proposed legislation only illustrates the depth and complexity of the problem","['intellectual property', 'cultural issues', 'economic issues', 'political issues', 'legal issues']","['P', 'M', 'M', 'M', 'M']","['intellectual property', 'cultural issue', 'economic issue', 'political issue', 'legal issue']","['technological challenge', 'propose legislation', 'intellectual property', 'propose safeguard', 'regulatory agency', 'cultural issue', 'many conflict', 'solution devise', 'court', 'legal']"
851,1437,Improving the frequency stability of microwave oscillators by utilizing the dual-mode sapphire-loaded cavity resonator,"the design and experimental testing of a novel control circuit to stabilize the temperature of a sapphire-loaded cavity whispering gallery resonator-oscillator and improve its medium-term frequency stability is presented. finite-element software was used to predict frequencies and quality factors of wge/sub 7,0,0/ and the wgh/sub 9,0,0/ modes near 9 ghz, and separated in frequency by approximately 80 mhz. calculations show that the novel temperature control circuits from the difference frequency can result in a frequency stability of better than one part in 10/sup 13/ at 270 k. also, we present details on the best way to couple orthogonally to two modes of similar frequency but different polarization","['frequency stability', 'microwave oscillators', 'dual-mode sapphire-loaded cavity resonator', 'whispering gallery resonator-oscillator', '9 ghz', 'temperature control circuit', 'difference frequency', 'frequency standard', 'temperature stabilisation', 'finite-element analysis', 'whispering gallery modes', 'high-quality factor', '270 k']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'M', 'R', 'M', 'M']","['frequency stability', 'microwave oscillator', 'dual - mode sapphire - load cavity resonator', 'whisper gallery resonator - oscillator', '9 ghz', 'temperature control circuit', 'difference frequency', 'frequency standard', 'temperature stabilisation', 'finite - element analysis', 'whisper gallery mode', 'high - quality factor', '270 k']","['load cavity whisper gallery resonator', 'temperature control circuit', 'frequency stability', 'oscillator', 'temperature', 'frequency', 'ghz', 'mhz', 'frequency', 'sapphire']"
852,577,A robust H/sub infinity / control approach for induction motors,"this paper deals with the robustness and stability of an induction motor control structure against internal and external disturbances. in the proposed control scheme, we have used an h/sub infinity / controller with field orientation and input-output linearization to achieve the above-specified features. simulation results are included to illustrate the control approach performances","['robust h/sub infinity / control', 'robustness', 'stability', 'induction motors control', 'external disturbances', 'field orientation', 'input-output linearization', 'internal disturbances']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['robust h / sub infinity / control', 'robustness', 'stability', 'induction motors control', 'external disturbance', 'field orientation', 'input - output linearization', 'internal disturbance']","['induction motor control structure', 'external disturbance', 'field orientation', 'control', 'controller', 'stability', 'robustness', 'internal', 'sub infinity', 'linearization']"
853,1167,A new approach to the d-MC problem,"many real-world systems are multi-state systems composed of multi-state components in which the reliability can be computed in terms of the lower bound points of level d, called d-mincuts (d-mcs). such systems (electric power, transportation, etc.) may be regarded as flow networks whose arcs have independent, discrete, limited and multi-valued random capacities. in this paper, all mcs are assumed to be known in advance, and the authors focused on how to verify each d-mc candidate before using d-mcs to calculate the network reliability. the proposed algorithm is more efficient than existing algorithms. the algorithm runs in o(p sigma mn) time, a significant improvement over the previous o(p sigma m/sup 2/) time bounds based on max-flow/min-cut, where p and or are the number of mcs and d-mc candidates, respectively. it is simple, intuitive and uses no complex data structures. an example is given to show how all d-mc candidates are found and verified by the proposed algorithm. then the reliability of this example is computed","['d-mc problem', 'multi-state systems', 'multi-state components', 'd-mincuts', 'flow networks', 'time bounds', 'max-flow/min-cut', 'reliability computation', 'failure analysis algorithm']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['d - mc problem', 'multi - state system', 'multi - state component', 'd - mincut', 'flow network', 'time bound', 'max - flow / min - cut', 'reliability computation', 'failure analysis algorithm']","['network reliability', 'flow network', 'state system', 'sigma mn', 'value random capacity', 'algorithm run', 'algorithm', 'reliability', 'mc candidate', 'algorithm']"
854,1122,Hybrid broadcast for the video-on-demand service,"multicast offers an efficient means of distributing video contents/programs to multiple clients by batching their requests and then having them share a server's video stream. batching customers' requests is either client-initiated or server-initiated. most advanced client-initiated video multicasts are implemented by patching. periodic broadcast, a typical server-initiated approach, can be entirety-based or segment-based. this paper focuses on the performance of the vod service for popular videos. first, we analyze the limitation of conventional patching when the customer request rate is high. then, by combining the advantages of each of the two broadcast schemes, we propose a hybrid broadcast scheme for popular videos, which not only lowers the service latency but also improves clients' interactivity by using an active buffering technique. this is shown to be a good compromise for both lowering service latency and improving the vcr-like interactivity","['video-on-demand', 'multicast', 'conventional patching', 'customer request rate', 'hybrid broadcast scheme', 'interactivity', 'quality-of-service', 'scheduling']","['P', 'P', 'P', 'P', 'P', 'P', 'U', 'U']","['video - on - demand', 'multicast', 'conventional patching', 'customer request rate', 'hybrid broadcast scheme', 'interactivity', 'quality - of - service', 'scheduling']","['initiate video multicast', 'video stream', 'multicast offer', 'vod service', 'hybrid broadcast scheme', 'broadcast scheme', 'distribute video content', 'popular video', 'lower service latency', 'broadcast']"
855,676,Impossible choice [web hosting service provider],selecting a telecoms and web hosting service provider has become a high-stakes game of chance,"['web hosting service provider', 'selection', 'it managers', 'customer service']","['P', 'P', 'U', 'M']","['web host service provider', 'selection', 'it manager', 'customer service']","['web host service provider', 'telecom', 'stake game', 'select', 'become', 'high']"
856,633,Using k-nearest-neighbor classification in the leaves of a tree,"we construct a hybrid (composite) classifier by combining two classifiers in common use - classification trees and k-nearest-neighbor (k-nn). in our scheme we divide the feature space up by a classification tree, and then classify test set items using the k-nn rule just among those training items in the same leaf as the test item. this reduces somewhat the computational load associated with k-nn, and it produces a classification rule that performs better than either trees or the usual k-nn in a number of well-known data sets","['k-nearest-neighbor classification', 'classification trees', 'k-nn rule', 'computational load', 'data sets', 'tree leaves', 'hybrid composite classifier', 'feature space division']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'M']","['k - near - neighbor classification', 'classification tree', 'k - nn rule', 'computational load', 'datum set', 'tree leave', 'hybrid composite classifier', 'feature space division']","['classify test set item use', 'classification tree', 'classification tree', 'classification rule', 'classifier', 'classifier', 'feature space', 'nn rule', 'training item', 'common use']"
857,1266,An intelligent information gathering method for dynamic information mediators,"the internet is spreading into our society rapidly and is becoming one of the information infrastructures that are indispensable for our daily life. in particular, the www is widely used for various purposes such as sharing personal information, academic research, business work, and electronic commerce, and the amount of available information is increasing rapidly. we usually utilize information sources on the internet as individual stand-alone sources, but if we can integrate them, we can add more value to each of them. hence, information mediators, which integrate information distributed on the internet, are drawing attention. in this paper, under the assumption that the information sources to be integrated are updated frequently and asynchronously, we propose an information gathering method that constructs an answer to a query from a user, accessing information sources to be integrated properly within an allowable time period. the proposed method considers the reliability of data in the cache and the quality of answer in order to efficiently access information sources and to provide appropriate answers to the user. as evaluation, we show the effectiveness of the proposed method by using an artificial information integration problem, in which some parameters can be modified, and a real-world flight information service compared with a conventional fifo information gathering method","['intelligent information gathering method', 'dynamic information mediators', 'internet', 'information infrastructures', 'www', 'academic research', 'business work', 'electronic commerce', 'artificial information integration problem', 'real-world flight information service']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['intelligent information gathering method', 'dynamic information mediator', 'internet', 'information infrastructure', 'www', 'academic research', 'business work', 'electronic commerce', 'artificial information integration problem', 'real - world flight information service']","['integrate information distribute', 'world flight information service compare', 'access information source', 'utilize information source', 'access information source', 'artificial information integration problem', 'share personal information', 'information gathering method', 'information source', 'information infrastructure']"
858,1223,Formalising optimal feature weight setting in case based diagnosis as linear programming problems,"many approaches to case based reasoning (cbr) exploit feature weight setting algorithms to reduce the sensitivity to distance functions. we demonstrate that optimal feature weight setting in a special kind of cbr problems can be formalised as linear programming problems. therefore, the optimal weight settings can be calculated in polynomial time instead of searching in exponential weight space using heuristics to get sub-optimal settings. we also demonstrate that our approach can be used to solve classification problems","['optimal feature weight setting', 'case based diagnosis', 'linear programming', 'case based reasoning', 'distance functions', 'polynomial time', 'searching', 'exponential weight space', 'heuristics', 'classification']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['optimal feature weight set', 'case base diagnosis', 'linear programming', 'case base reason', 'distance function', 'polynomial time', 'search', 'exponential weight space', 'heuristic', 'classification']","['exploit feature weight set algorithm', 'optimal feature weight set', 'case base reason', 'optimal weight setting', 'cbr problem', 'linear programming problem', 'distance function', 'cbr', 'exponential weight space', 'many approach']"
859,918,Schema evolution in data warehouses,"we address the issues related to the evolution and maintenance of data warehousing systems, when underlying data sources change their schema capabilities. these changes can invalidate views at the data warehousing system. we present an approach for dynamically adapting views according to schema changes arising on source relations. this type of maintenance concerns both the schema and the data of the data warehouse. the main issue is to avoid the view recomputation from scratch especially when views are defined from multiple sources. the data of the data warehouse is used primarily in organizational decision-making and may be strategic. therefore, the schema of the data warehouse can evolve for modeling new requirements resulting from analysis or data-mining processing. our approach provides means to support schema evolution of the data warehouse independently of the data sources","['schema evolution', 'data warehouses', 'data sources', 'source relations', 'organizational decision-making', 'system maintenance', 'containment', 'structural view maintenance', 'view adaptation', 'sql query', 'data analysis']","['P', 'P', 'P', 'P', 'P', 'R', 'U', 'M', 'R', 'U', 'R']","['schema evolution', 'datum warehouse', 'datum source', 'source relation', 'organizational decision - making', 'system maintenance', 'containment', 'structural view maintenance', 'view adaptation', 'sql query', 'datum analysis']","['datum warehousing system', 'schema change arise', 'adapt view accord', 'datum warehousing system', 'underlie data source change', 'datum warehouse', 'support schema evolution', 'schema capabilitie', 'schema', 'view recomputation']"
860,840,Gender benders [women in computing profession],"as a minority in the upper levels of the computing profession, women are sometimes mistreated through ignorance or malice. some women have learned to respond with wit and panache","['women', 'computing profession']","['P', 'P']","['woman', 'compute profession']","['compute profession', 'woman', 'mistreat', 'ignorance', 'upper level', 'wit', 'malice', 'minority', 'learn', 'respond']"
861,805,Active pitch control in larger scale fixed speed horizontal axis wind turbine systems. I. linear controller design,"this paper reviews and addresses the principles of linear controller design of the fixed speed wind turbine system in above rated wind speed, using pitch angle control of the blades and applying modern control theory. first, the nonlinear equations of the system are built in under some reasonable suppositions. then, the nonlinear equations are linearised at set operating point and digital simulation results are shown in this paper. finally, a linear quadratic optimal feedback controller is designed and the dynamics of the closed circle system are simulated with digital calculation. the advantages and disadvantages of the assumptions and design method are also discussed. because of the inherent characteristics of the linear system control theory, the performance of the linear controller is not sufficient for operating wind turbines, as is discussed","['active pitch control', 'horizontal axis wind turbine systems', 'wind turbines', 'linear controller design', 'fixed speed wind turbine system', 'pitch angle control', 'control theory', 'nonlinear equations', 'digital simulation', 'linear quadratic optimal feedback controller', 'closed circle system', 'linear system control theory', 'aerodynamics', 'drive train dynamics']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'M']","['active pitch control', 'horizontal axis wind turbine system', 'wind turbine', 'linear controller design', 'fix speed wind turbine system', 'pitch angle control', 'control theory', 'nonlinear equation', 'digital simulation', 'linear quadratic optimal feedback controller', 'close circle system', 'linear system control theory', 'aerodynamic', 'drive train dynamic']","['speed wind turbine system', 'linear quadratic optimal feedback controller', 'operate wind turbine', 'use pitch angle control', 'linear system control', 'linear controller design', 'linear controller', 'rate wind speed', 'close circle system', 'modern control']"
862,1413,Web content extraction. A WhizBang! approach,"the extraction technology that whizbang uses consists of a unique approach to scouring the web for current, very specific forms of information. flipdog, for example, checks company web sites for hyperlinks to pages that list job opportunities. it then crawls to the deeper page and, using the whizbang! extraction framework, extracts the key elements of the postings, such as job title, name of employer, job category, and job function. click on a job and you are transferred to the company web site to view the job description as it appears there","['web content extraction', 'flipdog', 'company web sites', 'whizbang! extraction framework', 'job description', 'job-hunting site']","['P', 'P', 'P', 'P', 'P', 'M']","['web content extraction', 'flipdog', 'company web site', 'whizbang ! extraction framework', 'job description', 'job - hunt site']","['check company web site', 'company web site', 'whizbang use consist', 'list job opportunity', 'extraction framework', 'extraction technology', 'whizbang', 'job description', 'job category', 'job title']"
863,1087,Implementation of DIMSIMs for stiff differential systems,"some issues related to the implementation of diagonally implicit multistage integration methods for stiff differential systems are discussed. they include reliable estimation of the local discretization error, construction of continuous interpolants, solution of nonlinear systems of equations by simplified newton iterations, choice of initial stepsize and order, and step and order changing strategy. numerical results are presented which indicate that an experimental matlab code based on type 2 methods of order one, two and three outperforms ode15s code from matlab ode suite on problems whose jacobian has eigenvalues which are close to the imaginary axis","['dimsims', 'stiff differential systems', 'diagonally implicit multistage integration methods', 'reliable estimation', 'local discretization error', 'interpolants', 'nonlinear systems of equations', 'simplified newton iterations', 'experimental matlab code']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['dimsim', 'stiff differential system', 'diagonally implicit multistage integration method', 'reliable estimation', 'local discretization error', 'interpolant', 'nonlinear system of equation', 'simplify newton iteration', 'experimental matlab code']","['implicit multistage integration method', 'matlab ode suite', 'stiff differential system', 'ode15s', 'interpolant', 'matlab', 'local discretization error', 'numerical', 'nonlinear system', 'newton iteration']"
864,1456,Look who's talking [voice recognition],"voice recognition could be the answer to the problem of financial fraud, but in the world of biometric technology, money talks","['voice recognition', 'financial fraud', 'biometric', 'cost']","['P', 'P', 'P', 'U']","['voice recognition', 'financial fraud', 'biometric', 'cost']","['financial fraud', 'biometric technology', 'voice recognition', 'world', 'problem']"
865,796,Quadratic Newton iteration for systems with multiplicity,"newton's iterator is one of the most popular components of polynomial equation system solvers, either from the numeric or symbolic point of view. this iterator usually handles smooth situations only (when the jacobian matrix associated to the system is invertible). this is often a restrictive factor. generalizing newton's iterator is still an open problem: how to design an efficient iterator with a quadratic convergence even in degenerate cases? we propose an answer for an m-adic topology when the ideal m can be chosen generic enough: compared to a smooth case we prove quadratic convergence with a small overhead that grows with the square of the multiplicity of the root","['quadratic newton iteration', 'systems with multiplicity', ""newton's iterator"", 'polynomial equation system solvers', 'jacobian matrix', 'quadratic convergence', 'm-adic topology']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['quadratic newton iteration', 'system with multiplicity', ""newton 's iterator"", 'polynomial equation system solver', 'jacobian matrix', 'quadratic convergence', 'm - adic topology']","['polynomial equation system solver', 'efficient iterator', 'generalize newton', 'quadratic convergence', 'iterator', 'jacobian matrix associate', 'adic topology', 'newton', 'smooth case', 'multiplicity']"
866,1386,When the unexpected happens [disaster planning in banks],"a business disruption can be as simple as a power failure or as complex as a terrorist attack. regardless, you will need to have a plan to minimize interruptions to both your bank and your customers. marketers have a role in this readiness process","['disaster planning', 'planning', 'banks', 'recovery', 'public relations', 'emergency management']","['P', 'P', 'P', 'U', 'U', 'U']","['disaster planning', 'plan', 'bank', 'recovery', 'public relation', 'emergency management']","['business disruption', 'minimize interruption', 'bank', 'customer', 'terrorist attack', 'power failure', 'marketer have', 'plan', 'complex', 'simple']"
867,1002,Selective representing and world-making,"we discuss the thesis of selective representing-the idea that the contents of the mental representations had by organisms are highly constrained by the biological niches within which the organisms evolved. while such a thesis has been defended by several authors elsewhere, our primary concern here is to take up the issue of the compatibility of selective representing and realism. we hope to show three things. first, that the notion of selective representing is fully consistent with the realist idea of a mind-independent world. second, that not only are these two consistent, but that the latter (the realist conception of a mind-independent world) provides the most powerful perspective from which to motivate and understand the differing perceptual and cognitive profiles themselves. third, that the (genuine and important) sense in which organism and environment may together constitute an integrated system of scientific interest poses no additional threat to the realist conception","['selective representing', 'world-making', 'mental representations', 'organisms', 'realism', 'mind-independent world', 'cognitive profiles']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['selective represent', 'world - make', 'mental representation', 'organism', 'realism', 'mind - independent world', 'cognitive profile']","['organism evolve', 'biological niche', 'selective represent', 'mental representation', 'realist conception', 'differ perceptual', 'scientific interest pose', 'realist idea', 'cognitive profile', 'realism']"
868,1047,Dynamics and control of initialized fractional-order systems,"due to the importance of historical effects in fractional-order systems, this paper presents a general fractional-order system and control theory that includes the time-varying initialization response. previous studies have not properly accounted for these historical effects. the initialization response, along with the forced response, for fractional-order systems is determined. the scalar fractional-order impulse response is determined, and is a generalization of the exponential function. stability properties of fractional-order systems are presented in the complex w-plane, which is a transformation of the s-plane. time responses are discussed with respect to pole positions in the complex w-plane and frequency response behavior is included. a fractional-order vector space representation, which is a generalization of the state space concept, is presented including the initialization response. control methods for vector representations of initialized fractional-order systems are shown. finally, the fractional-order differintegral is generalized to continuous order-distributions which have the possibility of including all fractional orders in a transfer function","['dynamics', 'control', 'initialized fractional-order systems', 'initialization response', 'forced response', 'impulse response', 'exponential function', 'vector space representation', 'state space concept', 'fractional-order differintegral', 'transfer function']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['dynamic', 'control', 'initialize fractional - order system', 'initialization response', 'force response', 'impulse response', 'exponential function', 'vector space representation', 'state space concept', 'fractional - order differintegral', 'transfer function']","['fractional order', 'scalar fractional', 'initialize fractional', 'fractional', 'order vector', 'vector representation', 'order impulse response', 'order system', 'order differintegral', 'order system']"
869,880,"Computing 2002: democracy, education, and the future","computer scientists, computer engineers, information technologists, and their collective products have grown and changed in quantity, quality, and nature. in the first decade of this new century, it should become apparent to everyone that the computing and information fields, broadly defined, will have a profound impact on every element of every person's life. the author considers how women and girls of the world have been neither educated for computing nor served by computing. globally, women's participation in computer science grew for a while, then dropped precipitously. computing, science, engineering, and society will suffer if this decline continues, because women have different perspectives on technology, what it is important for, how it should be built, which projects should be funded, and so on. to create a positive future, to assure that women equally influence the future, computing education must change","['democracy', 'future', 'women', 'girls', 'society', 'computer science education', 'gender issues']","['P', 'P', 'P', 'P', 'P', 'R', 'U']","['democracy', 'future', 'woman', 'girl', 'society', 'computer science education', 'gender issue']","['compute education', 'computer science grow', 'computer engineer', 'computer scientist', 'information technologist', 'woman have', 'compute', 'woman', 'technology', 'become apparent']"
870,1303,Reply to Carreira-Perpinan and Goodhill [mathematics in biology],"in a paper by carreira-perpinan and goodhill (see ibid., vol.14, no.7, p.1545-60, 2002) the authors apply mathematical arguments to biology. swindale et al. think it is inappropriate to apply the standards of proof required in mathematics to the acceptance or rejection of scientific hypotheses. to give some examples, showing that data are well described by a linear model does not rule out an infinity of other possible models that might give better descriptions of the data. proving in a mathematical sense that the linear model was correct would require ruling out all other possible models, a hopeless task. similarly, to demonstrate that two dna samples come from the same individual, it is sufficient to show a match between only a few regions of the genome, even though there remains a very large number of additional comparisons that could be done, any one of which might potentially disprove the match. this is unacceptable in mathematics, but in the real world, it is a perfectly reasonable basis for belief","['biology', 'mathematical arguments', 'scientific hypotheses', 'linear model', 'dna', 'genome', 'hypothesis testing', 'cortical maps', 'neural nets']","['P', 'P', 'P', 'P', 'P', 'P', 'U', 'U', 'U']","['biology', 'mathematical argument', 'scientific hypothesis', 'linear model', 'dna', 'genome', 'hypothesis testing', 'cortical map', 'neural net']","['scientific hypothesis', 'dna sample come', 'mathematical argument', 'other possible model', 'linear model', 'genome', 'disprove', 'proof require', 'biology', 'mathematical']"
871,1346,Automatic multilevel thresholding for image segmentation by the growing time adaptive self-organizing map,"in this paper, a growing tasom (time adaptive self-organizing map) network called ""gtasom"" along with a peak finding process is proposed for automatic multilevel thresholding. the proposed gtasom is tested for image segmentation. experimental results demonstrate that the gtasom is a reliable and accurate tool for image segmentation and its results outperform other thresholding methods","['automatic multilevel thresholding', 'image segmentation', 'growing time adaptive self-organizing map', 'growing tasom', 'gtasom', 'peak finding process']","['P', 'P', 'P', 'P', 'P', 'P']","['automatic multilevel thresholding', 'image segmentation', 'grow time adaptive self - organize map', 'grow tasom', 'gtasom', 'peak finding process']","['automatic multilevel thresholding', 'image segmentation', 'organizing map', 'time adaptive self', 'peak finding process', 'grow tasom', 'propose gtasom', 'gtasom', 'network call', 'accurate tool']"
872,713,Efficient feasibility testing for dial-a-ride problems,"dial-a-ride systems involve dispatching a vehicle to satisfy demands from a set of customers who call a vehicle-operating agency requesting that an item tie picked up from a specific location and delivered to a specific destination. dial-a-ride problems differ from other routing and scheduling problems, in that they typically involve service-related constraints. it is common to have maximum wait time constraints and maximum ride time constraints. in the presence of maximum wait time and maximum ride time restrictions, it is not clear how to efficiently determine, given a sequence of pickups and deliveries, whether a feasible schedule exists. we demonstrate that this, in fact, can be done in linear time","['feasibility testing', 'dial-a-ride problems', 'dispatching', 'vehicle-operating agency', 'routing', 'scheduling', 'service-related constraints', 'maximum wait time constraints', 'maximum ride time constraints']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['feasibility testing', 'dial - a - ride problem', 'dispatch', 'vehicle - operate agency', 'route', 'scheduling', 'service - relate constraint', 'maximum wait time constraint', 'maximum ride time constraint']","['ride system involve dispatch', 'maximum ride time constraint', 'maximum ride time restriction', 'scheduling problem', 'have maximum wait time constraint', 'feasible schedule', 'other routing', 'ride problem', 'operate agency request', 'delivery']"
873,756,A new high resolution color flow system using an eigendecomposition-based adaptive filter for clutter rejection,"we present a new signal processing strategy for high frequency color flow mapping in moving tissue environments. a new application of an eigendecomposition-based clutter rejection filter is presented with modifications to deal with high blood-to-clutter ratios (bcr). additionally, a new method for correcting blood velocity estimates with an estimated tissue motion profile is detailed. the performance of the clutter filter and velocity estimation strategies is quantified using a new swept-scan signal model. in vivo color flow images are presented to illustrate the potential of the system for mapping blood flow in the microcirculation with external tissue motion","['eigendecomposition-based adaptive filter', 'signal processing strategy', 'high frequency color flow mapping', 'moving tissue environments', 'clutter rejection filter', 'high blood-to-clutter ratios', 'estimated tissue motion profile', 'swept-scan signal model', 'in vivo color flow images', 'microcirculation', 'high resolution colour flow system', 'hf colour flow mapping', 'blood velocity estimates correction', 'blood flow mapping', 'echoes', 'clutter suppression performance']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'R', 'R', 'U', 'M']","['eigendecomposition - base adaptive filter', 'signal processing strategy', 'high frequency color flow mapping', 'move tissue environment', 'clutter rejection filter', 'high blood - to - clutter ratio', 'estimate tissue motion profile', 'sweep - scan signal model', 'in vivo color flow image', 'microcirculation', 'high resolution colour flow system', 'hf colour flow mapping', 'blood velocity estimate correction', 'blood flow mapping', 'echo', 'clutter suppression performance']","['vivo color flow image', 'clutter filter', 'mapping blood flow', 'frequency color flow mapping', 'tissue motion profile', 'blood velocity', 'eigendecomposition', 'move tissue', 'microcirculation', 'clutter']"
874,838,"Pool halls, chips, and war games: women in the culture of computing","computers are becoming ubiquitous in our society and they offer superb opportunities for people in jobs and everyday life. but there is a noticeable sex difference in use of computers among children. this article asks why computers are more attractive to boys than to girls and offers a cultural framework for explaining the apparent sex differences. although the data are fragmentary, the world of computing seems to be more consistent with male adolescent culture than with feminine values and goals. furthermore, both arcade and educational software is designed with boys in mind. these observations lead us to speculate that computing is neither inherently difficult nor uninteresting to girls, but rather that computer games and other software might have to be designed differently for girls. programs to help teachers instill computer efficacy in all children also need to be developed","['women', 'culture of computing', 'sex difference', 'children', 'male adolescent culture', 'educational software', 'computer games', 'teachers']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['woman', 'culture of compute', 'sex difference', 'child', 'male adolescent culture', 'educational software', 'computer game', 'teacher']","['male adolescent culture', 'help teacher instill computer efficacy', 'computer game', 'educational software', 'feminine value', 'apparent sex difference', 'become ubiquitous', 'noticeable sex difference', 'cultural framework', 'other software']"
875,71,A study of computer attitudes of non-computing students of technical colleges in Brunei Darussalam,"the study surveyed 268 non-computing students among three technical colleges in brunei darussalam. the study validated an existing instrument to measure computer attitudes of non-computing students, and identified factors that contributed to the formation of their attitudes. the findings show that computer experience and educational qualification are associated with students' computer attitudes. in contrast, variables such as gender, age, ownership of a personal computer (pc), geographical location of institution, and prior computer training appeared to have no impact on computer attitudes","['computer attitudes', 'technical colleges', 'survey', 'computer experience', 'educational qualification', 'gender', 'age', 'computer training', 'noncomputing students', 'personal computer ownership', 'educational computing', 'end user computing']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'R', 'M']","['computer attitude', 'technical college', 'survey', 'computer experience', 'educational qualification', 'gender', 'age', 'computer training', 'noncompute student', 'personal computer ownership', 'educational computing', 'end user computing']","['measure computer attitude', 'computer attitude', 'compute student', 'personal computer', 'prior computer training appear', 'computer experience', 'educational qualification', 'attitude', 'technical college', 'brunei darussalam']"
876,925,A fundamental investigation into large strain recovery of one-way shape memory alloy wires embedded in flexible polyurethanes,"shape memory alloys (smas) are being embedded in or externally attached to smart structures because of the large amount of actuation deformation and force that these materials are capable of producing when they are heated. previous investigations have focused primarily on using single or opposing sma wires exhibiting the two-way shape memory effect (sme) because of the simplicity with which the repeatable actuation behavior of the structure can be predicted. this repeatable actuation behavior is achieved at the expense of reduced levels of recoverable deformation. alternatively, many potential smart structure applications will employ multiple sma wires exhibiting a permanent one-way sme to simplify fabrication and increase the recoverable strains in the structure. to employ the one-way wires, it is necessary to investigate how they affect the recovery of large strains when they are embedded in a structure. in this investigation, the large strain recovery of a one-way sma wire embedded in a flexible polyurethane is characterized using the novel deformation measurement technique known as digital image correlation. these results are compared with a simple actuation model and a three-dimensional finite element analysis of the structure using the brinson model for describing the thermomechanical behavior of the sma. results indicate that the level of actuation strain in the structure is substantially reduced by the inelastic behavior of the one-way sma wires, and there are significant differences between the deformations of the matrix material adjacent to the sma wires and in the region surrounding it. the transformation behavior of the sma wires was also determined to be volume preserving, which had a significant effect on the transverse strain fields","['strain recovery', 'one-way shape memory', 'alloy wires', 'flexible polyurethanes', 'flexible polyurethanes', 'smart structures', 'actuation deformation', 'deformations', 'sma wires', 'two-way shape memory effect', 'recoverable strains', 'three-dimensional finite element analysis', 'actuation strain', 'matrix material', 'transverse strain fields', 'flexible polyurethane', 'embedded sensor']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['strain recovery', 'one - way shape memory', 'alloy wire', 'flexible polyurethane', 'flexible polyurethane', 'smart structure', 'actuation deformation', 'deformation', 'sma wire', 'two - way shape memory effect', 'recoverable strain', 'three - dimensional finite element analysis', 'actuation strain', 'matrix material', 'transverse strain field', 'flexible polyurethane', 'embed sensor']","['shape memory alloy', 'flexible polyurethane', 'actuation deformation', 'recoverable deformation', 'deformation measurement technique', 'actuation strain', 'sma wire embed', 'thermomechanical', 'shape memory', 'multiple sma wire']"
877,960,Bisimulation minimization and symbolic model checking,"state space minimization techniques are crucial for combating state explosion. a variety of explicit-state verification tools use bisimulation minimization to check equivalence between systems, to minimize components before composition, or to reduce a state space prior to model checking. experimental results on bisimulation minimization in symbolic model checking contexts, however, are mixed. we explore bisimulation minimization as an optimization in symbolic model checking of invariance properties. we consider three bisimulation minimization algorithms. from each, we produce a bdd-based model checker for invariant properties and compare this model checker to a conventional one based on backwards reachability. our comparisons, both theoretical and experimental, suggest that bisimulation minimization is not viable in the context of invariance verification, because performing the minimization requires as many, if not more, computational resources as model checking the unminimized system through backwards reachability","['bisimulation minimization', 'symbolic model checking', 'state space minimization techniques', 'state explosion', 'explicit-state verification tools', 'experimental results', 'optimization', 'invariance properties', 'backwards reachability', 'invariance verification', 'bdd', 'binary decision diagram']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'U']","['bisimulation minimization', 'symbolic model check', 'state space minimization technique', 'state explosion', 'explicit - state verification tool', 'experimental result', 'optimization', 'invariance property', 'backwards reachability', 'invariance verification', 'bdd', 'binary decision diagram']","['symbolic model check context', 'bisimulation minimization algorithm', 'symbolic model check', 'explore bisimulation minimization', 'bisimulation minimization', 'state verification tool', 'model checker', 'model check', 'state space minimization technique', 'check equivalence']"
878,123,A new identification approach for FIR models,"the identification of stochastic discrete systems disturbed with noise is discussed in this brief. the concept of general prediction error (gpe) criterion is introduced for the time-domain estimate with optimal frequency estimation (ofe) introduced for the frequency-domain estimate. the two estimation methods are combined to form a new identification algorithm, which is called the empirical frequency-domain optimal parameter (efop) estimate, for the finite impulse response (fir) model interfered by noise. the algorithm theoretically provides the global optimum of the model frequency-domain estimate. some simulation examples are given to illustrate the new identification method","['identification approach', 'fir models', 'stochastic discrete systems', 'time-domain estimate', 'optimal frequency estimation', 'frequency-domain estimate', 'general prediction error criterion', 'empirical frequency-domain optimal parameter estimate']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['identification approach', 'fir model', 'stochastic discrete system', 'time - domain estimate', 'optimal frequency estimation', 'frequency - domain estimate', 'general prediction error criterion', 'empirical frequency - domain optimal parameter estimate']","['optimal frequency estimation', 'stochastic discrete system disturb', 'empirical frequency', 'model frequency', 'estimation method', 'new identification algorithm', 'domain optimal parameter', 'general prediction error', 'domain estimate', 'frequency']"
879,792,"Remember e-commerce? Yeah, well, it's still here","sandy kemper, the always outspoken ceo of successful e-commerce company escout, offers his views on the purported demise of ""commerce"" in e-commerce, and what opportunities lie ahead for those bankers bold enough to act in a market turned tentative by early excesses","['e-commerce', 'escout', 'bankers']","['P', 'P', 'P']","['e - commerce', 'escout', 'banker']","['commerce company escout', 'sandy kemper', 'outspoken ceo', 'banker bold', 'market turn tentative', 'commerce', 'purport demise', 'opportunity lie', 'view', 'offer']"
880,1382,Loop restructuring for data I/O minimization on limited on-chip memory embedded processors,"in this paper, we propose a framework for analyzing the flow of values and their reuse in loop nests to minimize data traffic under the constraints of limited on-chip memory capacity and dependences. our analysis first undertakes fusion of possible loop nests intra-procedurally and then performs loop distribution. the analysis discovers the closeness factor of two statements which is a quantitative measure of data traffic saved per unit memory occupied if the statements were under the same loop nest over the case where they are under different loop nests. we then develop a greedy algorithm which traverses the program dependence graph to group statements together under the same loop nest legally to promote maximal reuse per unit of memory occupied. we implemented our framework in petit, a tool for dependence analysis and loop transformations. we compared our method with one based on tiling of fused loop nest and one based on a greedy strategy to purely maximize reuse. we show that our methods work better than both of these strategies in most cases for processors such as tms320cxx, which have a very limited amount of on-chip memory. the improvements in data i/o range from 10 to 30 percent over tiling and from 10 to 40 percent over maximal reuse for jpeg loops","['loop restructuring', 'data i/o minimization', 'on-chip memory', 'embedded processors', 'data traffic', 'closeness factor', 'program dependence graph', 'petit', 'fused loop nest', 'loop fusion', 'data locality', 'dsp']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'U']","['loop restructuring', 'datum I / o minimization', 'on - chip memory', 'embed processor', 'datum traffic', 'closeness factor', 'program dependence graph', 'petit', 'fuse loop nest', 'loop fusion', 'datum locality', 'dsp']","['chip memory capacity', 'fuse loop nest', 'chip memory', 'possible loop nest intra', 'same loop nest', 'different loop nest', 'loop nest', 'memory occupy', 'program dependence graph', 'maximize reuse']"
881,844,Women in computing history,"exciting inventions, innovative technology, human interaction, and intriguing politics fill computing history. however, the recorded history is mainly composed of male achievements and involvements, even though women have played substantial roles. this situation is not unusual. most science fields are notorious for excluding, undervaluing, or overlooking the accomplishments of their female scientists. as lee points out, it is up to the historians and others to remedy this imbalance. steps have been taken towards this goal through publishing biographies on women in technology, and through honoring the pioneers with various awards such as the ghc'97 pioneering awards, the witi hall of fame, and the awc lovelace award. a few online sites contain biographies of women in technology. however, even with these resources, many women who have contributed significantly to computer science are still to be discovered","['women', 'computing history']","['P', 'P']","['woman', 'compute history']","['few online site contain biography', 'intriguing politic fill compute history', 'awc lovelace award', 'female scientist', 'various award such', 'pioneer award', 'publish biography', 'most science field', 'innovative technology', 'many woman']"
882,801,"International customers, suppliers, and document delivery in a fee-based information service","the purdue university libraries library fee-based information service, the technical information service (tis), works with both international customers and international suppliers to meet its customers' needs for difficult and esoteric document requests. successful completion of these orders requires the ability to verify fragmentary citations; ascertain documents' availability; obtain pricing information; calculate inclusive cost quotes; meet customers' deadlines; accept international payments; and ship across borders. while international orders make tip a small percent of the total workload, these challenging and rewarding orders meet customers' needs and offer continuous improvement opportunities to the staff","['international customers', 'document delivery', 'technical information service', 'international suppliers', 'document requests', 'pricing information', 'inclusive cost quotes', 'international payments', 'purdue university libraries fee-based information service', 'fragmentary citation verification', 'document availability', 'customer deadline meeting', 'continuous staff improvement']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'R', 'R', 'R']","['international customer', 'document delivery', 'technical information service', 'international supplier', 'document request', 'price information', 'inclusive cost quote', 'international payment', 'purdue university librarie fee - base information service', 'fragmentary citation verification', 'document availability', 'customer deadline meeting', 'continuous staff improvement']","['purdue university librarie library fee', 'technical information service', 'accept international payment', 'rewarding order meet customer', 'obtain pricing information', 'international order', 'base information service', 'esoteric document request', 'international customer', 'international supplier']"
883,1417,Craigslist: virtual community maintains human touch,"if it works why change it? this might have been the thought on the minds of dot com executives back when internet businesses were booming, and most of the web content was free. web sites were overflowing with advertisements of every kind and size. now that dot com principals know better, web ads are no longer the only path to revenue generation. community portals, however, never seemed to have many ads to begin with, and their content stayed truer to who they served. many of them started off as simple places for users to list announcements, local events, want ads, real estate, and mingle with other local users. the author saw the need for san franciscans to have a place to do all of that for free, without any annoying advertising, and ended up offering much more to his community with the creation of craigslist. ""[polling users] was a good way for us to connect with our members, this is the way to operate successfully in situations like these - your members come first.""","['craigslist', 'virtual community', 'internet businesses', 'web content', 'revenue generation', 'community portals', 'announcements', 'local events', 'want ads', 'real estate', 'san francisco bay community']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['craigslist', 'virtual community', 'internet business', 'web content', 'revenue generation', 'community portal', 'announcement', 'local event', 'want ad', 'real estate', 'san francisco bay community']","['web ad', 'have many ad', 'annoying advertising', 'want ad', 'advertisement', 'polling user', 'dot com executive', 'other local user', 'internet business', 'web site']"
884,1083,Differential algebraic systems anew,"it is proposed to figure out the leading term in differential algebraic systems more precisely. low index linear systems with those properly stated leading terms are considered in detail. in particular, it is asked whether a numerical integration method applied to the original system reaches the inherent regular ode without conservation, i.e., whether the discretization and the decoupling commute in some sense. in general one cannot expect this commutativity so that additional difficulties like strong stepsize restrictions may arise. moreover, abstract differential algebraic equations in infinite-dimensional hilbert spaces are introduced, and the index notion is generalized to those equations. in particular, partial differential algebraic equations are considered in this abstract formulation","['differential algebraic systems', 'low index linear systems', 'numerical integration method', 'inherent regular ode', 'commutativity', 'stepsize restrictions', 'abstract differential algebraic equations']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['differential algebraic system', 'low index linear system', 'numerical integration method', 'inherent regular ode', 'commutativity', 'stepsize restriction', 'abstract differential algebraic equation']","['partial differential algebraic equation', 'abstract differential algebraic equation', 'differential algebraic system', 'index linear system', 'numerical integration method apply', 'dimensional hilbert space', 'inherent regular ode', 'index notion', 'discretization', 'decouple commute']"
885,1452,Creating Web-based listings of electronic journals without creating extra work,"creating up-to-date listings of electronic journals is challenging due to frequent changes in titles available and in urls for electronic journal titles. however, many library users may want to browse web pages which contain listings of electronic journals arranged by title and/or academic disciplines. this case study examines the development of a system which automatically exports data from the online catalog and incorporates it into dynamically-generated web sites. these sites provide multiple access points for journals, include web-based interfaces enabling subject specialists to manage the list of titles which appears in their subject area. because data are automatically extracted from the catalog, overlap in updating titles and urls is avoided. following the creation of this system, usage of electronic journals dramatically increased and feedback has been positive. future challenges include developing more frequent updates and motivating subject specialists to more regularly monitor new titles","['web-based listings', 'electronic journals', 'url', 'library', 'web pages', 'case study', 'online catalog', 'web sites', 'feedback', 'technical services', 'public services partnerships']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'U']","['web - base listing', 'electronic journal', 'url', 'library', 'web page', 'case study', 'online catalog', 'web site', 'feedback', 'technical service', 'public service partnership']","['browse web page', 'electronic journal title', 'electronic journal arrange', 'generate web site', 'electronic journal', 'base interface enable subject specialist', 'update title', 'journal', 'many library user', 'include web']"
886,637,A digital fountain approach to asynchronous reliable multicast,"the proliferation of applications that must reliably distribute large, rich content to a vast number of autonomous receivers motivates the design of new multicast and broadcast protocols. we describe an ideal, fully scalable protocol for these applications that we call a digital fountain. a digital fountain allows any number of heterogeneous receivers to acquire content with optimal efficiency at times of their choosing. moreover, no feedback channels are needed to ensure reliable delivery, even in the face of high loss rates. we develop a protocol that closely approximates a digital fountain using two new classes of erasure codes that for large block sizes are orders of magnitude faster than standard erasure codes. we provide performance measurements that demonstrate the feasibility of our approach and discuss the design, implementation, and performance of an experimental system","['digital fountain', 'asynchronous reliable multicast', 'autonomous receivers', 'broadcast protocols', 'scalable protocol', 'heterogeneous receivers', 'optimal efficiency', 'high loss rates', 'erasure codes', 'large block size', 'performance measurements', 'multicast protocol', 'experimental system performance', 'internet', 'fec codes', 'forward error correction', 'rs codes', 'tornado codes', 'luby transform codes', 'bulk data distribution', 'ip multicast', 'simulation results', 'interoperability', 'content distribution methods', 'reed-solomon codes', 'decoder']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U', 'M', 'U', 'M', 'M', 'M', 'M', 'M', 'U', 'U', 'M', 'M', 'U']","['digital fountain', 'asynchronous reliable multicast', 'autonomous receiver', 'broadcast protocol', 'scalable protocol', 'heterogeneous receiver', 'optimal efficiency', 'high loss rate', 'erasure code', 'large block size', 'performance measurement', 'multicast protocol', 'experimental system performance', 'internet', 'fec code', 'forward error correction', 'rs code', 'tornado code', 'luby transform code', 'bulk datum distribution', 'ip multicast', 'simulation result', 'interoperability', 'content distribution method', 'reed - solomon code', 'decoder']","['broadcast protocol', 'standard erasure code', 'scalable protocol', 'new multicast', 'erasure code', 'digital fountain allow', 'digital fountain use', 'digital fountain', 'feedback channel', 'protocol']"
887,1262,The development and evaluation of SHOKE2000: the PCI-based FPGA card,"this paper describes a pci-based fpga card, shoke2000, which was developed in order to study reconfigurable computing. since the latest field programmable gate arrays (fpga) consist of input/output (i/o) configurable blocks as well as internal configurable logic blocks, they not only realize various user logic circuits but also connect with popular i/o standards easily. these features enable fpga to connect several devices with different interfaces, and thus new reconfigurable systems would be realizable by connecting the fpga with devices such as digital signal processors (dsp) and analog devices. this paper describes the basic functions of shoke2000, which was developed for realizing hybrid reconfigurable systems consisting of fpga, dsp, and analog devices. we also present application examples of shoke2000, including a simple image recognition application, a distributed shared memory computer cluster, and teaching materials for computer education","['shoke2000', 'fpga card', 'fpga', 'reconfigurable computing', 'field programmable gate arrays', 'user logic circuits', 'i/o standard', 'interfaces', 'digital signal processors', 'dsp', 'analog devices', 'hybrid reconfigurable systems', 'image recognition application', 'distributed shared memory computer cluster', 'teaching materials', 'computer education', 'pci', 'intellectual property']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'U']","['shoke2000', 'fpga card', 'fpga', 'reconfigurable computing', 'field programmable gate array', 'user logic circuit', 'I / o standard', 'interface', 'digital signal processor', 'dsp', 'analog device', 'hybrid reconfigurable system', 'image recognition application', 'distribute share memory computer cluster', 'teach material', 'computer education', 'pci', 'intellectual property']","['late field programmable gate array', 'realize hybrid reconfigurable system consist', 'feature enable fpga', 'base fpga card', 'reconfigurable computing', 'digital signal processor', 'new reconfigurable system', 'distribute share memory computer cluster', 'internal configurable logic block', 'fpga']"
888,1227,Will new Palms win laurels.?,"palmsource's latest operating system for mobile devices harnesses the arm architecture to support more powerful business software, but there are concerns over compatibility with older applications","['palmsource', 'operating system', 'mobile devices', 'arm architecture', 'compatibility', 'palm os 5.0']","['P', 'P', 'P', 'P', 'P', 'M']","['palmsource', 'operating system', 'mobile device', 'arm architecture', 'compatibility', 'palm os 5.0']","['mobile device', 'late operating system', 'arm architecture', 'powerful business software', 'palmsource', 'compatibility', 'support', 'be concern']"
889,959,Silicon debug of a PowerPC TM microprocessor using model checking,"when silicon is available, newly designed microprocessors are tested in specially equipped hardware laboratories, where real applications can be run at hardware speeds. however, the large volumes of code being run, plus the limited access to the internal nodes of the chip, make it very difficult to characterize the nature of any failures that occur. we describe how temporal logic model checking was used to quickly characterize a design error exhibited during hardware testing of a powerpc microprocessor. we outline the conditions under which model checking can efficiently characterize such failures, and show how the particular error we detected could have been revealed early in the design cycle, by model checking a short and simple correctness specification. we discuss the implications of this for verification methodologies over the full design cycle","['model checking', 'temporal logic', 'hardware testing', 'powerpc microprocessor', 'correctness specification', 'verification methodologies', 'circuit design error', 'computation tree logic', 'circuit debugging']","['P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'M']","['model check', 'temporal logic', 'hardware testing', 'powerpc microprocessor', 'correctness specification', 'verification methodology', 'circuit design error', 'computation tree logic', 'circuit debugging']","['temporal logic model check', 'hardware testing', 'powerpc microprocessor', 'design microprocessor', 'hardware laboratory', 'model check', 'simple correctness specification', 'characterize such failure', 'hardware speed', 'verification methodology']"
890,573,"ECG-gated /sup 18/F-FDG positron emission tomography. Single test evaluation of segmental metabolism, function and contractile reserve in patients with coronary artery disease and regional dysfunction","/sup 18/f-fluorodeoxyglucose (/sup 18/f-fdg)-positron emission tomography (pet) provides information about myocardial glucose metabolism to diagnose myocardial viability. additional information about the functional status is necessary. comparison of tomographic metabolic pet with data from other imaging techniques is always hampered by some transfer uncertainty and scatter. we wanted to evaluate a new fourier-based ecg-gated pet technique using a high resolution scanner providing both metabolic and functional data with respect to feasibility in patients with diseased left ventricles. forty-five patients with coronary artery disease and at least one left ventricular segment with severe hypokinesis or akinesis at biplane cineventriculography were included. a new fourier-based ecg-gated metabolic /sup 18/f-fdg-pet was performed in these patients. function at rest and /sup 18/f-fdg uptake were examined in the pet study using a 36-segment model. segmental comparison with ventriculography revealed a high reliability in identifying dysfunctional segments (>96%). /sup 18/f-fdg uptake of normokinetic/hypokinetic/akinetic segments was 75.4+or-7.5, 65.3+or-10.5, and 35.9+or-15.2% (p<0.001). in segments >or=70% /sup 18/f-fdg uptake no akinesia was observed. no residual function was found below 40% /sup 18/f-fdg uptake. an additional dobutamine test was performed and revealed inotropic reserve (viability) in 42 akinetic segments and 45 hypokinetic segments. ecg-gated metabolic pet with pixel-based fourier smoothing provides reliable data on regional function. assessment of metabolism and function makes complete judgement of segmental status feasible within a single study without any transfer artefacts or test-to-test variability. the results indicate the presence of considerable amounts of viable myocardium in regions with an uptake of 40-50% /sup 18/f-fdg","['functional', 'patients', 'coronary artery disease', 'regional dysfunction', 'myocardial glucose metabolism', 'myocardial viability', 'transfer uncertainty', 'fourier-based ecg-gated pet technique', 'high resolution scanner', 'diseased left ventricles', 'left ventricular segment', 'severe hypokinesis', 'akinesis', 'biplane cineventriculography', 'ventriculography', 'dysfunctional segments', 'normokinetic/hypokinetic/akinetic segments', 'akinetic segments', 'residual function', 'dobutamine test', 'inotropic reserve', 'hypokinetic segments', 'pixel-based fourier smoothing', 'regional function', 'segmental status', 'transfer artefacts', 'viable myocardium', 'fourier-based ecg-gated metabolic /sup 18/f-fluorodeoxyglucose-positron emission tomography', '/sup 18/f-fluorodeoxyglucose uptake', 'thirty six-segment model']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'R', 'M']","['functional', 'patient', 'coronary artery disease', 'regional dysfunction', 'myocardial glucose metabolism', 'myocardial viability', 'transfer uncertainty', 'fourier - base ecg - gate pet technique', 'high resolution scanner', 'diseased left ventricle', 'leave ventricular segment', 'severe hypokinesis', 'akinesis', 'biplane cineventriculography', 'ventriculography', 'dysfunctional segment', 'normokinetic / hypokinetic / akinetic segment', 'akinetic segment', 'residual function', 'dobutamine test', 'inotropic reserve', 'hypokinetic segment', 'pixel - base fourier smoothing', 'regional function', 'segmental status', 'transfer artefact', 'viable myocardium', 'fourier - base ecg - gate metabolic /sup 18 / f - fluorodeoxyglucose - positron emission tomography', '/sup 18 / f - fluorodeoxyglucose uptake', 'thirty six - segment model']","['myocardial glucose metabolism', 'tomographic metabolic pet', 'gate metabolic pet', 'diagnose myocardial', 'ventriculography reveal', 'coronary artery disease', 'diseased left ventricle', 'leave ventricular segment', 'gate metabolic', 'emission tomography']"
891,1163,Evaluating the complexity of index sets for families of general recursive functions in the arithmetic hierarchy,the complexity of index sets of families of general recursive functions is evaluated in the kleene-mostowski arithmetic hierarchy,"['general recursive functions', 'arithmetic hierarchy', 'kleene-mostowski arithmetic hierarchy', 'index sets complexity']","['P', 'P', 'P', 'R']","['general recursive function', 'arithmetic hierarchy', 'kleene - mostowski arithmetic hierarchy', 'index set complexity']","['general recursive function', 'index set', 'complexity', 'kleene', 'family', 'evaluate']"
892,1126,A note on an axiomatization of the core of market games,"as shown by peleg (1993), the core of market games is characterized by nonemptiness, individual rationality, superadditivity, the weak reduced game property, the converse reduced game property, and weak symmetry. it was not known whether weak symmetry was logically independent. with the help of a certain transitive 4-person tu game, it is shown that weak symmetry is redundant in this result. hence, the core on market games is axiomatized by the remaining five properties, if the universe of players contains at least four members","['individual rationality', 'weak reduced game property', 'converse reduced game property', 'weak symmetry', 'transitive 4-person tu game', 'redundant', 'market game core axiomatization', 'nonempty games', 'superadditive games']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['individual rationality', 'weak reduce game property', 'converse reduce game property', 'weak symmetry', 'transitive 4 - person tu game', 'redundant', 'market game core axiomatization', 'nonempty game', 'superadditive game']","['weak reduce game property', 'converse reduce game property', 'market game', 'weak symmetry', 'player contain', 'person tu game', 'individual rationality', 'certain transitive', 'axiomatize', 'superadditivity']"
893,999,The importance of continuity: a reply to Chris Eliasmith,"in his reply to eliasmith (see ibid., vol.11, p.417-26, 2001) poznanski considers how the notion of continuity of dynamic representations serves as a beacon for an integrative neuroscience to emerge. he considers how the importance of continuity has come under attack from eliasmith (2001) who claims: (i) continuous nature of neurons is not relevant to the information they process, and (ii) continuity is not important for understanding cognition because the various sources of noise introduce uncertainty into spike arrival times, so encoding and decoding spike trains must be discrete at some level","['continuity', 'dynamic representations', 'integrative neuroscience', 'neurons', 'cognition', 'uncertainty', 'spike arrival times', 'spike trains', 'cognitive systems', 'neural nets']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'U']","['continuity', 'dynamic representation', 'integrative neuroscience', 'neuron', 'cognition', 'uncertainty', 'spike arrival time', 'spike train', 'cognitive system', 'neural net']","['decode spike train', 'dynamic representation serve', 'integrative neuroscience', 'understand cognition', 'neuron', 'continuous nature', 'poznanski consider', 'spike', 'continuity', 'various source']"
894,88,Planning linear construction projects: automated method for the generation of earthwork activities,"earthworks planning for road construction projects is a complex operation and the planning rules used are usually intuitive and not well defined. an approach to automate the earthworks planning process is described and the basic techniques that are used are outlined. a computer-based system has been developed, initially to help planners use existing techniques more efficiently. with their input, the system has been extended to incorporate a knowledge base and a simulation of the earthworks processes. as well as creating activity sets in a much shorter time, the system has shown that for a real project, the model is able to generate activity sets that are comparable to those generated by a project planner","['linear construction projects', 'earthwork activities', 'road construction projects', 'planning rules', 'earthworks planning process', 'computer-based system', 'knowledge base']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['linear construction project', 'earthwork activity', 'road construction project', 'plan rule', 'earthwork planning process', 'computer - base system', 'knowledge base']","['earthwork planning process', 'earthwork plan', 'road construction project', 'create activity set', 'generate activity set', 'earthwork process', 'planner use exist technique', 'plan rule', 'automate', 'knowledge base']"
895,75,A portable Auto Attendant System with sophisticated dialog structure,"an attendant system connects the caller to the party he/she wants to talk to. traditional systems require the caller to know the full name of the party. if the caller forgets the name, the system fails to provide service for the caller. in this paper we propose a portable auto attendant system (aas) with sophisticated dialog structure that gives a caller more flexibility while calling. the caller may interact with the system to request a phone number by providing just a work area, specialty, surname, or title, etc. if the party is absent, the system may provide extra information such as where he went, when he will be back, and what he is doing. the system is built modularly, with components such as speech recognizer, language model, dialog manager and text-to-speech that can be replaced if necessary. by simply changing the personnel record database, the system can easily be ported to other companies. the sophisticated dialog manager applies many strategies to allow natural interaction between user and system. functions such as fuzzy request, user repairing, and extra information query, which are not provided by other systems, are integrated into our system. experimental results and comparisons to other systems show that our approach provides a more user friendly and natural interaction for auto attendant system","['auto attendant system', 'attendant system', 'speech recognizer', 'dialog manager', 'fuzzy request', 'clear request', 'semantic frame', 'spoken dialog systems', 'telephone', 'telephone-based system']","['P', 'P', 'P', 'P', 'P', 'M', 'U', 'M', 'U', 'M']","['auto attendant system', 'attendant system', 'speech recognizer', 'dialog manager', 'fuzzy request', 'clear request', 'semantic frame', 'speak dialog system', 'telephone', 'telephone - base system']","['portable auto attendant system', 'sophisticated dialog manager apply many', 'personnel record database', 'attendant system connect', 'dialog manager', 'sophisticated dialog structure', 'caller more flexibility', 'caller forget', 'phone number', 'speech recognizer']"
896,921,Processing of complexly shaped multiply connected domains in finite element mesh generation,"large number of finite element models in modern materials science and engineering is defined on complexly shaped domains, quite often multiply connected. generation of quality finite element meshes on such domains, especially in cases when the mesh must be 100% quadrilateral, is highly problematic. this paper describes mathematical fundamentals and practical -implementation of a powerful method and algorithm allowing transformation of multiply connected domains of arbitrary geometrical complexity into a set of simple domains; the latter can then be processed by broadly available finite element mesh generators. the developed method was applied to a number of complex geometries, including those arising in analysis of parasitic inductances and capacitances in printed circuit boards. the quality of practical results produced by the method and its programming implementation provide evidence that the algorithm can be applied to other finite element models with various physical backgrounds","['complexly shaped multiply connected domains', 'finite element mesh generation', 'finite element models', 'arbitrary geometrical complexity', 'set of simple domains', 'parasitic inductances', 'printed circuit boards', 'programming implementation', 'quadrilateral mesh', 'domains transformation', 'parasitic capacitances', 'metal forming processes', 'structural engineering models', 'iterative basis', 'general domain subdivision algorithm', 'artificial cut', 'automatic step calculation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'M', 'U', 'M', 'U', 'U']","['complexly shape multiply connect domain', 'finite element mesh generation', 'finite element model', 'arbitrary geometrical complexity', 'set of simple domain', 'parasitic inductance', 'print circuit board', 'programming implementation', 'quadrilateral mesh', 'domain transformation', 'parasitic capacitance', 'metal form process', 'structural engineering model', 'iterative basis', 'general domain subdivision algorithm', 'artificial cut', 'automatic step calculation']","['finite element mesh generator', 'quality finite element mesh', 'arbitrary geometrical complexity', 'parasitic inductance', 'finite element model', 'mesh', 'complexly shape domain', 'complex geometry', 'print circuit board', 'algorithm allow transformation']"
897,964,"Modeling group foraging: individual suboptimality, interference, and a kind of matching","a series of agent-based models support the hypothesis that behaviors adapted to a group situation may be suboptimal (or ""irrational"") when expressed by an isolated individual. these models focus on two areas of current concern in behavioral ecology and experimental psychology: the ""interference function"" (which relates the intake rate of a focal forager to the density of conspecifics) and the ""matching law"" (which formalizes the observation that many animals match the frequency of their response to different stimuli in proportion to the reward obtained from each stimulus type). each model employs genetic algorithms to evolve foraging behaviors for multiple agents in spatially explicit environments, structured at the level of situated perception and action. a second concern of the article is to extend the understanding of both matching and interference per se by modeling at this level","['group foraging', 'individual suboptimality', 'agent-based models', 'group situation', 'isolated individual', 'behavioral ecology', 'experimental psychology', 'interference function', 'focal forager', 'matching law', 'genetic algorithms', 'multiple agents', 'spatially explicit environments', 'situated perception', 'suboptimal behavior', 'situated action']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['group forage', 'individual suboptimality', 'agent - base model', 'group situation', 'isolate individual', 'behavioral ecology', 'experimental psychology', 'interference function', 'focal forager', 'matching law', 'genetic algorithm', 'multiple agent', 'spatially explicit environment', 'situate perception', 'suboptimal behavior', 'situate action']","['evolve forage behavior', 'behavioral ecology', 'model employ genetic algorithm', 'behavior adapt', 'experimental psychology', 'many animal match', 'explicit environment', 'different stimulus', 'multiple agent', 'situate perception']"
898,127,Asymptotical stability in discrete-time neural networks,"in this work, we present a proof of the existence of a fixed point and a generalized sufficient condition that guarantees the stability of it in discrete-time neural networks by using the lyapunov function method. we also show that for both symmetric and asymmetric connections, the unique attractor is a fixed point when several conditions are satisfied. this is an extended result of chen and aihara (see physica d, vol. 104, no. 3/4, p. 286-325, 1997). in particular, we further study the stability of equilibrium in discrete-time neural networks with the connection weight matrix in form of an interval matrix. finally, several examples are shown to illustrate and reinforce our theory","['asymptotical stability', 'stability', 'discrete-time neural networks', 'fixed point', 'generalized sufficient condition', 'lyapunov function method', 'asymmetric connections', 'unique attractor', 'connection weight matrix', 'interval matrix', 'symmetric connections', 'equilibrium stability']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['asymptotical stability', 'stability', 'discrete - time neural network', 'fix point', 'generalize sufficient condition', 'lyapunov function method', 'asymmetric connection', 'unique attractor', 'connection weight matrix', 'interval matrix', 'symmetric connection', 'equilibrium stability']","['time neural network', 'lyapunov function', 'unique attractor', 'interval matrix', 'stability', 'asymmetric connection', 'equilibrium', 'generalize sufficient condition', 'connection', 'discrete']"
899,1307,Law librarians' survey: are academic law librarians in decline?,"the author reports on the results of one extra element in the biall/sptl survey, designed to acquire further information about academic law librarians. the survey has fulfilled the aim of providing a snapshot of the academic law library profession and has examined the concerns that have been raised. perhaps most importantly, it has shown that more long-term work needs to be done to monitor the situation effectively. we hope that biall will take on this challenge and help to maintain the status of academic law librarians and aid them in their work","['survey', 'academic law library', 'academic law librarians', 'biall/sptl']","['P', 'P', 'P', 'P']","['survey', 'academic law library', 'academic law librarian', 'biall / sptl']","['academic law library profession', 'academic law librarian', 'sptl survey', 'biall', 'author report', 'acquire further information', 'survey', 'examine', 'result', 'term work need']"
900,1342,Defending against flooding-based distributed denial-of-service attacks: a tutorial,"flooding-based distributed denial-of-service (ddos) attack presents a very serious threat to the stability of the internet. in a typical ddos attack, a large number of compromised hosts are amassed to send useless packets to jam a victim, or its internet connection, or both. in the last two years, it was discovered that ddos attack methods and tools are becoming more sophisticated, effective, and also more difficult to trace to the real attackers. on the defense side, current technologies are still unable to withstand large-scale attacks. the main purpose of this article is therefore twofold. the first one is to describe various ddos attack methods, and to present a systematic review and evaluation of the existing defense mechanisms. the second is to discuss a longer-term solution, dubbed the internet-firewall approach, that attempts to intercept attack packets in the internet core, well before reaching the victim","['flooding-based distributed denial-of-service attacks', 'tutorial', 'ddos attack methods', 'large-scale attacks', 'internet stability', 'ddos attack tools', 'internet firewall', 'attack packets interception', 'reflector attacks', 'distributed attack detection']","['P', 'P', 'P', 'P', 'R', 'R', 'M', 'R', 'M', 'M']","['flooding - base distribute denial - of - service attack', 'tutorial', 'ddo attack method', 'large - scale attack', 'internet stability', 'ddo attack tool', 'internet firewall', 'attack packet interception', 'reflector attack', 'distribute attack detection']","['describe various ddo attack method', 'ddo attack method', 'typical ddo attack', 'ddo', 'intercept attack packet', 'firewall approach', 'base distribute denial', 'send useless packet', 'real attacker', 'scale attack']"
901,717,A network simplex algorithm with O(n) consecutive degenerate pivots,"we suggest a pivot rule for the primal simplex algorithm for the minimum cost flow problem, known as the network simplex algorithm. due to degeneracy, cycling may occur in the network simplex algorithm. the cycling can be prevented by maintaining strongly feasible bases proposed by cunningham (1976); however, if we do not impose any restrictions on the entering variables, the algorithm can still perform an exponentially long sequence of degenerate pivots. this phenomenon is known as stalling. researchers have suggested several pivot rules with the following bounds on the number of consecutive degenerate pivots: m, n/sup 2/, k(k + 1)/2, where n is the number of nodes in the network, m is the number of arcs in the network, and k is the number of degenerate arcs in the basis. (observe that k <or= n.) in this paper, we describe an anti-stalling pivot rule that ensures that the network simplex algorithm performs at most k consecutive degenerate pivots. this rule uses a negative cost augmenting cycle to identify a sequence of entering variables","['network simplex algorithm', 'degenerate pivots', 'minimum cost flow problem', 'degeneracy', 'cycling', 'stalling', 'anti-stalling pivot rule', 'negative cost augmenting cycle']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['network simplex algorithm', 'degenerate pivot', 'minimum cost flow problem', 'degeneracy', 'cycle', 'stall', 'anti - stalling pivot rule', 'negative cost augment cycle']","['primal simplex algorithm', 'network simplex algorithm', 'minimum cost flow problem', 'negative cost augment cycle', 'consecutive degenerate pivot', 'stall pivot rule', 'feasible basis propose', 'suggest several pivot rule', 'degenerate pivot', 'algorithm']"
902,752,Presenting-a better mousetrap [Leeza outboard video signal processor],"scaling interlaced video to match high-resolution plasma, lcd, and dlp displays is a tough job, but key digital's leeza is zip to the tack. and it's digitally bilingual, too. there's no question that outboard video signal processors like leeza help overcome the inherent limitations of fixed-pixel displays. being able to match a native display rate with heavily processed video makes the viewing experience much more enjoyable. but it seemed that 70% of the improvement in image quality came from using a digital interface to the dvd player, as most noise and picture artifacts are introduced in the analog video encoding process","['leeza', 'outboard video signal processors', 'dlp displays', 'fixed-pixel displays', 'heavily processed video', 'lcd displays', 'plasma displays']","['P', 'P', 'P', 'P', 'P', 'R', 'R']","['leeza', 'outboard video signal processor', 'dlp display', 'fix - pixel display', 'heavily process video', 'lcd display', 'plasma display']","['pixel display', 'scale interlace video', 'outboard video signal processor', 'resolution plasma', 'dlp display', 'digital interface', 'native display rate', 'image quality', 'key digital', 'view experience']"
903,879,Well behaved women rarely make history!,"the author considers women in the history of computer science. prior to the eniac, women were extremely important to the computing business as ""computers"". just as women had taken over the tasks as secretaries in the late 1800s with the advent of the typewriter, and in the early 1900s staffing telephone exchanges, so computing relied on women as the ""workhorses"" of the business","['women', 'history', 'computer science', 'eniac', 'business', 'gender issues']","['P', 'P', 'P', 'P', 'P', 'U']","['woman', 'history', 'computer science', 'eniac', 'business', 'gender issue']","['staff telephone exchange', 'compute business', 'author consider woman', 'computing rely', 'computer science', 'computer', 'eniac', 'typewriter', 'secretary', 'woman']"
904,1006,Robust model-order reduction of complex biological processes,"this paper addresses robust model-order reduction of a high dimensional nonlinear partial differential equation (pde) model of a complex biological process. based on a nonlinear, distributed parameter model of the same process which was validated against experimental data of an existing, pilot-scale biological nutrient removal (bnr) activated sludge plant, we developed a state-space model with 154 state variables. a general algorithm for robustly reducing the nonlinear pde model is presented and, based on an investigation of five state-of-the-art model-order reduction techniques, we are able to reduce the original model to a model with only 30 states without incurring pronounced modelling errors. the singular perturbation approximation balanced truncating technique is found to give the lowest modelling errors in low frequency ranges and hence is deemed most suitable for controller design and other real-time applications","['robust model-order reduction', 'complex biological processes', 'state-space model', 'modelling errors', 'singular perturbation approximation balanced truncating technique', 'controller design', 'high dimensional nonlinear partial differential equation model', 'nonlinear distributed parameter model', 'pilot-scale bnr activated sludge plant', 'hankel singular values', 'biological nutrient removal activated sludge processes']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'R']","['robust model - order reduction', 'complex biological process', 'state - space model', 'model error', 'singular perturbation approximation balance truncating technique', 'controller design', 'high dimensional nonlinear partial differential equation model', 'nonlinear distribute parameter model', 'pilot - scale bnr activate sludge plant', 'hankel singular value', 'biological nutrient removal activate sludge process']","['nonlinear pde model', 'dimensional nonlinear partial differential equation', 'singular perturbation approximation balance truncating', 'low modelling error', 'robust model', 'parameter model', 'pronounce model error', 'order reduction technique', 'scale biological nutrient removal', 'nonlinear']"
905,1043,Fractional motion control: application to an XY cutting table,"in path tracking design, the dynamic of actuators must be taken into account in order to reduce overshoots appearing for small displacements. a new approach to path tracking using fractional differentiation is proposed with its application on a xy cutting table. it permits the generation of optimal movement reference-input leading to a minimum path completion time, taking into account both maximum velocity, acceleration and torque and the bandwidth of the closed-loop system. fractional differentiation is used here through a davidson-cole filter. a methodology aiming at improving the accuracy especially on checkpoints is presented. the reference-input obtained is compared with spline function. both are applied to an xy cutting table model and actuator outputs compared","['fractional motion control', 'xy cutting table', 'path tracking design', 'actuators', 'fractional differentiation', 'optimization', 'minimum path completion time', 'closed-loop system', 'davidson-cole filter', 'spline function']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['fractional motion control', 'xy cut table', 'path tracking design', 'actuator', 'fractional differentiation', 'optimization', 'minimum path completion time', 'close - loop system', 'davidson - cole filter', 'spline function']","['fractional differentiation', 'xy cut table model', 'path tracking design', 'path tracking', 'xy cut table', 'actuator', 'spline function', 'cole filter', 'acceleration', 'minimum path completion']"
906,884,A hybrid-neural network and population learning algorithm approach to solving reliability optimization problem,proposes a hybrid approach integrating a dedicated artificial neural network and population learning algorithm applied to maximising system reliability under cost and technical feasibility constraints. the paper includes a formulation of the system reliability optimisation (sro) problem and a description of the dedicated neural network trained by applying the population learning algorithm. a solution to the example sro problem is shown and results of the computational experiment are presented and discussed,"['population learning algorithm', 'reliability optimization problem', 'hybrid approach', 'dedicated artificial neural network', 'system reliability', 'technical feasibility constraints', 'cost constraints']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['population learn algorithm', 'reliability optimization problem', 'hybrid approach', 'dedicated artificial neural network', 'system reliability', 'technical feasibility constraint', 'cost constraint']","['system reliability optimisation', 'maximise system reliability', 'population learning algorithm apply', 'dedicated artificial neural network', 'population learn algorithm', 'dedicate neural network train', 'technical feasibility constraint', 'example sro problem', 'hybrid approach', 'sro']"
907,1187,Ethernet networks: getting down to business,"while it seems pretty clear that ethernet has won the battle for the mindshare as the network of choice for the factory floor, there's still a war to be won in implementation as cutting-edge manufacturers begin to adopt the technology on a widespread basis","['ethernet', 'factory floor', 'cutting-edge manufacturers', 'supervisory level']","['P', 'P', 'P', 'U']","['ethernet', 'factory floor', 'cut - edge manufacturer', 'supervisory level']","['ethernet', 'network', 'edge manufacturer', 'mindshare', 'technology', 'factory floor', 'battle', 'war', 'seem', 'implementation']"
908,905,Ultra-high speed positioning control of a gravure engraving unit using a discrete-time two-degree-of-freedom H/sub infinity / control,"the piezoelectric actuator has high-speed response in comparison with the electro-magnetic actuator. however, it is not easy to achieve both high-speed and high-precision response by feedforward control only because the piezoelectric element has nonlinear properties such as the hysteresis effect. thus, feedback control is required to achieve good performance. we develop a control design method to achieve both high-speed and high-precision response for piezoelectric actuators using the discrete-time h/sub infinity / control method and the two-degree-of-freedom control scheme. the effectiveness of our proposed method has been shown by simulation and experimental results. the most important contribution of our study is that our method can be directly applied to commercial machines","['ultra-high speed positioning control', 'gravure engraving unit', 'discrete-time two-degree-of-freedom h/sub infinity / control', 'piezoelectric actuator', 'high-precision response', 'feedforward', 'nonlinear properties', 'hysteresis', 'feedback control', 'control design method', 'digital control system']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['ultra - high speed positioning control', 'gravure engrave unit', 'discrete - time two - degree - of - freedom h / sub infinity / control', 'piezoelectric actuator', 'high - precision response', 'feedforward', 'nonlinear property', 'hysteresis', 'feedback control', 'control design method', 'digital control system']","['piezoelectric actuator', 'piezoelectric actuator', 'magnetic actuator', 'feedback control', 'hysteresis effect', 'feedforward control', 'control', 'nonlinear property such', 'precision response', 'speed response']"
909,146,Design patterns for high availability,"it is possible to achieve five-nines reliability with everyday commercial-quality hardware and software. the key is the way in which these components are combined. the design of high availability systems is based on a combination of redundant hardware components and software to manage fault detection and correction without human intervention. the author quickly reviews some definitions tied to high availability and fault management, and then goes on to discuss some hardware and software design patterns for fault tolerant systems","['high availability systems', 'redundant hardware components', 'fault detection', 'software design patterns', 'fault tolerant systems', 'hardware reliability', 'software reliability', 'fault correction', 'checkpointing', 'software redundancy']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'U', 'R']","['high availability system', 'redundant hardware component', 'fault detection', 'software design pattern', 'fault tolerant system', 'hardware reliability', 'software reliability', 'fault correction', 'checkpointe', 'software redundancy']","['redundant hardware component', 'high availability system', 'manage fault detection', 'quality hardware', 'nine reliability', 'high availability', 'software design pattern', 'fault management', 'hardware', 'software']"
910,597,Quick media response averts PR disaster,"sometimes it's not what you do, but how you do it. after hackers broke the blocking code on the home version of its popular cyber patrol internet filtering software and posted it on the internet, marketers at microsystems software pulled out a playbook of standard crisis management and pr techniques. but the cyber patrol pr team including outside pr counsel and the company's outside law firm, used those tools aggressively in order to turn the tide of public and media opinion away from the hackers, who initially were hailed as folk heroes, and in favor of the company's interests, to save the product's and the company's reputations and inherent value. and the entire team managed to move at internet speed: the crisis was essentially over in about three weeks","['media response', 'cyber patrol internet filtering software', 'microsystems software', 'crisis management', 'public relations']","['P', 'P', 'P', 'P', 'M']","['medium response', 'cyber patrol internet filtering software', 'microsystem software', 'crisis management', 'public relation']","['popular cyber patrol internet filtering software', 'standard crisis management', 'cyber patrol', 'hacker break', 'microsystem software pull', 'internet speed', 'block code', 'hacker', 'outside law firm', 'entire team manage']"
911,940,Tools for the analysis of dose optimization. I. Effect-volume histogram,"with the advent of dose optimization algorithms, predominantly for intensity-modulated radiotherapy (imrt), computer software has progressed beyond the point of being merely a tool at the hands of an expert and has become an active, independent mediator of the dosimetric conflicts between treatment goals and risks. to understand and control the internal decision finding as well as to provide means to influence it, a tool for the analysis of the dose distribution is presented which reveals the decision-making process performed by the algorithm. the internal trade-offs between partial volumes receiving high or low doses are driven by functions which attribute a weight to each volume element. the statistics of the distribution of these weights is cast into an effect-volume histogram (evh) in analogy to dose-volume histograms. the analysis of the evh reveals which traits of the optimum dose distribution result from the defined objectives, and which are a random consequence of under- or misspecification of treatment goals. the evh can further assist in the process of finding suitable objectives and balancing conflicting objectives. if biologically inspired objectives are used, the evh shows the distribution of local dose effect relative to the prescribed level","['effect-volume histogram', 'dose optimization algorithms', 'intensity-modulated radiotherapy', 'computer software', 'dosimetric conflicts', 'treatment goals', 'decision-making process', 'partial volumes', 'low doses', 'treatment risks', 'high doses', 'volume element weights', 'treatment planning', 'objective function', 'insufficient target coverage', 'exponential law', 'cell survival', 'one-sided quadratic penalties', 'quadratic overdose penalty']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'R', 'U', 'U', 'U', 'U', 'U']","['effect - volume histogram', 'dose optimization algorithm', 'intensity - modulate radiotherapy', 'computer software', 'dosimetric conflict', 'treatment goal', 'decision - make process', 'partial volume', 'low dose', 'treatment risk', 'high dose', 'volume element weight', 'treatment planning', 'objective function', 'insufficient target coverage', 'exponential law', 'cell survival', 'one - side quadratic penalty', 'quadratic overdose penalty']","['dose optimization algorithm', 'optimum dose distribution result', 'modulate radiotherapy', 'volume histogram', 'low dose', 'volume histogram', 'dosimetric conflict', 'dose distribution', 'balance conflict objective', 'partial volume receive high']"
912,14,Application of hybrid models for prediction and optimization of enzyme fermentation process. A comparative study,"the paper presents a comparison of the biotechnological process prediction and optimization results obtained by using different structure hybrid mathematical models for modeling of the same bioprocess. the hybrid models under investigation consist of the product mass balance equation in which different means - an artificial neural network, fuzzy-neural network and cell age distribution based calculation scheme - are incorporated for modeling the specific biosynthesis rate of a desired product. experimental data from alpha -amylase laboratory and industrial fermentation processes are used for model parameter identification and the process prediction tests","['hybrid models', 'optimization', 'enzyme fermentation', 'mathematical models', 'bioprocess', 'product mass balance equation', 'fuzzy-neural network', 'cell age distribution', 'biosynthesis rate', 'identification', 'industrial processes']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['hybrid model', 'optimization', 'enzyme fermentation', 'mathematical model', 'bioprocess', 'product mass balance equation', 'fuzzy - neural network', 'cell age distribution', 'biosynthesis rate', 'identification', 'industrial process']","['biotechnological process prediction', 'industrial fermentation process', 'different structure hybrid mathematical model', 'bioprocess', 'artificial neural network', 'hybrid model', 'biosynthesis rate', 'model parameter', 'optimization result obtain', 'product mass balance equation']"
913,1286,Self-describing Turing machines,"after a sketchy historical account on the question of self-describeness and self-reproduction, and after discussing the definition of suitable encodings for self-describeness, we give the construction of several self-describing turing machines, namely self-describing machines with, respectively, 350, 267, 224 and 206 instructions","['self-describing turing machines', 'self-describeness', 'self-reproduction', 'encodings']","['P', 'P', 'P', 'P']","['self - describe ture machine', 'self - describeness', 'self - reproduction', 'encoding']","['describe ture machine', 'describe machine', 'describeness', 'several self', 'suitable encoding', 'self', 'reproduction', 'definition', 'sketchy historical account', 'construction']"
914,696,Design and implementation of a new sliding-mode observer for speed-sensorless control of induction machine,"in this letter, a new sliding-mode-sensorless control algorithm is proposed for the field-oriented induction machine drive. in the proposed algorithm, the terms containing flux, speed, and rotor time constant, which are common in both current and flux equations, in the current model of the induction machine are estimated by a sliding function. the flux and speed estimation accuracy is guaranteed when the error between the actual current and observed current converges to zero. hence, the fourth-order system is reduced to two second-order systems, and the speed estimation becomes very simple and robust to the parameter uncertainties. the new approach is verified by simulation and experimental results","['sliding-mode observer', 'speed-sensorless control', 'speed', 'induction machine', 'flux', 'rotor time constant', 'flux equations', 'current model', 'sliding function', 'speed estimation accuracy', 'parameter uncertainties', 'induction motor drive', 'sensorless control', 'current equations', 'fourth-order system reduction']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'R', 'M']","['slide - mode observer', 'speed - sensorless control', 'speed', 'induction machine', 'flux', 'rotor time constant', 'flux equation', 'current model', 'slide function', 'speed estimation accuracy', 'parameter uncertainty', 'induction motor drive', 'sensorless control', 'current equation', 'fourth - order system reduction']","['sensorless control algorithm', 'orient induction machine drive', 'induction machine', 'slide', 'rotor', 'field', 'flux', 'speed estimation', 'current', 'speed']"
915,1022,Bad pixel identification by means of principal components analysis,"bad pixels are defined as those pixels showing a temporal evolution of the signal different from the rest of the pixels of a given array. principal component analysis helps us to understand the definition of a statistical distance associated with each pixels, and using this distance it is possible to identify those pixels labeled as bad pixels. the spatiality of a pixel is also calculated. an assumption about the normality of the distribution of the distances of the pixels is revised. although the influence on the robustness of the identification algorithm is negligible, the definition of a parameter related with this nonnormality helps to identify those principal components and eigenimages responsible for the departure from a multinormal distribution. the method for identifying the bad pixels is successfully applied to a set of frames obtained from a ccd visible and a focal plane array (fpa) ir camera","['bad pixel identification', 'principal components analysis', 'temporal evolution', 'statistical distance', 'robustness', 'identification algorithm', 'eigenimages', 'multinormal distribution', 'focal plane array', 'ir camera', 'ccd visible camera']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['bad pixel identification', 'principal component analysis', 'temporal evolution', 'statistical distance', 'robustness', 'identification algorithm', 'eigenimage', 'multinormal distribution', 'focal plane array', 'ir camera', 'ccd visible camera']","['bad pixel', 'pixel label', 'pixel show', 'pixel', 'principal component analysis', 'eigenimage responsible', 'pixel', 'identification algorithm', 'focal plane array', 'principal component']"
916,1067,Quantum-information processing by nuclear magnetic resonance: Experimental implementation of half-adder and subtractor operations using an oriented spin-7/2 system,"the advantages of using quantum systems for performing many computational tasks have already been established. several quantum algorithms have been developed which exploit the inherent property of quantum systems such as superposition of states and entanglement for efficiently performing certain tasks. the experimental implementation has been achieved on many quantum systems, of which nuclear magnetic resonance has shown the largest progress in terms of number of qubits. this paper describes the use of a spin-7/2 as a three-qubit system and experimentally implements the half-adder and subtractor operations. the required qubits are realized by partially orienting /sup 133/cs nuclei in a liquid-crystalline medium, yielding a quadrupolar split well-resolved septet. another feature of this paper is the proposal that labeling of quantum states of system can be suitably chosen to increase the efficiency of a computational task","['quantum-information processing', 'nuclear magnetic resonance', 'subtractor operations', 'oriented spin-7/2 system', 'quantum systems', 'computational tasks', 'computational tasks', 'quantum algorithms', 'entanglement', 'qubits', 'three-qubit system', '/sup 133/cs nuclei', '/sup 133/cs', 'liquid-crystalline medium', 'quadrupolar split well-resolved septet', 'quantum states', 'half-adder operations', 'state superposition', 'computational task']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'P']","['quantum - information processing', 'nuclear magnetic resonance', 'subtractor operation', 'orient spin-7/2 system', 'quantum system', 'computational task', 'computational task', 'quantum algorithm', 'entanglement', 'qubit', 'three - qubit system', '/sup 133 / cs nuclei', '/sup 133 / cs', 'liquid - crystalline medium', 'quadrupolar split well - resolve septet', 'quantum state', 'half - adder operation', 'state superposition', 'computational task']","['many quantum system', 'several quantum algorithm', 'quantum system', 'quantum state', 'qubit system', 'nuclear magnetic resonance', 'quadrupolar split', 'require qubit', 'qubit', 'perform many computational task']"
917,818,Clausal resolution in a logic of rational agency,"a resolution based proof system for a temporal logic of possible belief is presented. this logic is the combination of the branching-time temporal logic ctl (representing change over time) with the modal logic kd45 (representing belief). such combinations of temporal or dynamic logics and modal logics are useful for specifying complex properties of multi-agent systems. proof methods are important for developing verification techniques for these complex multi-modal logics. soundness, completeness and termination of the proof method are shown and simple examples illustrating its use are given","['resolution based proof system', 'temporal logic', 'belief', 'branching-time temporal logic', 'ctl', 'modal logic', 'kd45', 'dynamic logics', 'multi-agent systems', 'multi-modal logics', 'rational agents']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['resolution base proof system', 'temporal logic', 'belief', 'branch - time temporal logic', 'ctl', 'modal logic', 'kd45', 'dynamic logic', 'multi - agent system', 'multi - modal logic', 'rational agent']","['time temporal logic ctl', 'temporal logic', 'modal logic kd45', 'modal logic', 'resolution base proof system', 'dynamic logic', 'represent belief', 'agent system', 'develop verification technique', 'possible belief']"
918,1323,Editorial system vendors focus on Adobe and the future,"looking over the newspaper-system market, we note that the mac is getting new respect. adobe indesign has established itself as a solid alternative to quark xpress for pagination. positioning themselves for the long run, developers are gradually shifting to new software architectures","['newspaper-system market', 'adobe indesign', 'pagination', 'macintosh', 'publishing']","['P', 'P', 'P', 'U', 'U']","['newspaper - system market', 'adobe indesign', 'pagination', 'macintosh', 'publish']","['adobe indesign', 'quark xpress', 'mac', 'solid alternative', 'pagination', 'newspaper', 'developer', 'system market', 'new respect', 'note']"
919,1366,A fuzzy-soft learning vector quantization for control chart pattern recognition,"this paper presents a supervised competitive learning network approach, called a fuzzy-soft learning vector quantization, for control chart pattern recognition. unnatural patterns in control charts mean that there are some unnatural causes for variations in statistical process control (spc). hence, control chart pattern recognition becomes more important in spc. in order to detect effectively the patterns for the six main types of control charts, pham and oztemel (1994) described a class of pattern recognizers for control charts based on the learning vector quantization (lvq) such as lvq, lvq2 and lvq-x etc. in this paper, we propose a new supervised lvq for control charts based on a fuzzy-soft competitive learning network. the proposed fuzzy-soft lvq (fs-lvq) uses a fuzzy relaxation technique and simultaneously updates all neurons. it can increase correct recognition accuracy and also decrease the learning time. comparisons between lvq, lvq-x and fs-lvq are made","['fuzzy-soft learning vector quantization', 'control chart pattern recognition', 'supervised competitive learning network approach', 'unnatural patterns', 'statistical process control', 'spc', 'supervised lvq', 'fuzzy relaxation technique', 'correct recognition accuracy', 'learning time', 'simultaneous neuron update', 'numerical results', 'manufacturing process']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'M']","['fuzzy - soft learn vector quantization', 'control chart pattern recognition', 'supervise competitive learn network approach', 'unnatural pattern', 'statistical process control', 'spc', 'supervise lvq', 'fuzzy relaxation technique', 'correct recognition accuracy', 'learn time', 'simultaneous neuron update', 'numerical result', 'manufacturing process']","['control chart pattern recognition', 'soft learn vector quantization', 'supervise competitive learn network', 'learn vector quantization', 'soft competitive learn network', 'control chart base', 'new supervised lvq', 'control chart', 'statistical process control', 'soft lvq']"
920,733,VoIP makeover transforms ugly duckling network,"surrey county council's swan project is europe's biggest implementation of voice over ip. six wans and countless lans are are being consolidated into a single network covering 6,000 users at 200 sites. the contract was signed in october 2001 for pounds 13m over five years and rollout will be completed in may 2003","['surrey county council', 'swan', 'wan', 'voice over ip', 'lan']","['P', 'P', 'P', 'P', 'P']","['surrey county council', 'swan', 'wan', 'voice over ip', 'lan']","['surrey county council', 'countless lan', 'swan project', 'single network cover', 'ip', 'voice', 'wan', 'big implementation', 'contract', 'europe']"
921,776,Information access for all: meeting the needs of deaf and hard of hearing people,"discusses the nature of deafness and hearing impairments, with particular reference to the impact which the onset of hearing loss presents at various ages. the author goes on to present practical tips for interacting with deaf and hard of hearing clients in various communication contexts, including sightreading, tty communications, and asl interpreters. an annotated list of suggested readings is appended","['information access', 'deafness', 'hearing impairments', 'hard of hearing clients', 'communication contexts', 'sightreading', 'tty communications', 'asl interpreters', 'deaf clients']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['information access', 'deafness', 'hear impairment', 'hard of hear client', 'communication context', 'sightread', 'tty communication', 'asl interpreter', 'deaf client']","['hear impairment', 'hear client', 'hear loss', 'deafness', 'deaf', 'asl interpreter', 'tty communication', 'various communication context', 'include sightread', 'present practical tip']"
922,860,'Virtual Family': an approach to introducing Java programming,"this paper introduces and discusses virtual family (vf): a gender-neutral game-based software that introduces java programming. vf provides a completely functioning game that students extend and enhance via programming. we discuss the background and context within which virtual family was developed and other available multimedia resources for teaching programming. the paper then goes on to describe virtual family's concept and design. finally, feedback received from virtual family teaching workshops is related, as well as preliminary results from using vf in high-school teaching units. virtual family is under development in a research lab at the university of british columbia and is an initiative of supporting women in information technology (swift). swift is a five-year research action and implementation project to increase the participation of women in information technology","['virtual family', 'gender-neutral game-based software', 'multimedia resources', 'teaching workshops', 'high-school teaching units', 'supporting women in information technology', 'java programming teaching']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['virtual family', 'gender - neutral game - base software', 'multimedia resource', 'teach workshop', 'high - school teaching unit', 'support woman in information technology', 'java programming teaching']","['virtual family teaching workshop', 'introduce java programming', 'discuss virtual family', 'describe virtual family', 'teach programming', 'virtual family', 'other available multimedia resource', 'school teaching unit', 'support woman', 'use vf']"
923,825,Genetic algorithm-neural network estimation of Cobb angle from torso asymmetry in scoliosis,"scoliosis severity, measured by the cobb angle, was estimated by artificial neural network from indices of torso surface asymmetry using a genetic algorithm to select the optimal set of input torso indices. estimates of the cobb angle were accurate within 5 degrees in two-thirds, and within 10 degrees in six-sevenths, of a test set of 115 scans of 48 scoliosis patients, showing promise for future longitudinal studies to detect scoliosis progression without use of x-rays","['genetic algorithm', 'cobb angle', 'artificial neural network', 'torso surface asymmetry', 'input torso indices', 'scoliosis patients', 'scoliosis progression']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['genetic algorithm', 'cobb angle', 'artificial neural network', 'torso surface asymmetry', 'input torso index', 'scoliosis patient', 'scoliosis progression']","['detect scoliosis progression', 'scoliosis severity', 'scoliosis patient', 'torso surface asymmetry', 'cobb angle', 'input torso index', 'genetic algorithm', 'longitudinal study', 'artificial neural network', 'scan']"
924,1433,The role and future of subject classification: the exploitation of resources,"it is imperative that the library information systems (lis) profession and lis educators appreciate fully the contribution that classification makes to the discipline and that it is no longer seen as the domain of the academic, isolated theorist, but becomes an integral part of our understanding of the contribution that the lis community can make to society as a whole - as well as to particular areas such as legal information","['subject classification', 'library information systems', 'lis', 'legal information', 'information resources']","['P', 'P', 'P', 'P', 'R']","['subject classification', 'library information system', 'lis', 'legal information', 'information resource']","['library information system', 'lis educator appreciate', 'lis community', 'lis', 'isolate theorist', 'classification make', 'society', 'academic', 'profession', 'particular area such']"
925,91,IT challenge: cross selling [finance],"like most financial institutions, fleetboston, fidelity and berkshire group of companies are being charged with developing a strong technology platform that will allow them to cross sell their products and services. they discuss their solutions, advice and technology choices","['cross selling', 'financial institutions', 'fleetboston', 'fidelity', 'berkshire group']","['P', 'P', 'P', 'P', 'P']","['cross sell', 'financial institution', 'fleetboston', 'fidelity', 'berkshire group']","['strong technology platform', 'most financial institution', 'berkshire group', 'company', 'fidelity', 'cross sell', 'fleetboston', 'service', 'product', 'develop']"
926,557,Noise and the PSTH response to current transients: II. Integrate-and-fire model with slow recovery and application to motoneuron data,"for pt.i see ibid., vol.11, no.2 , p.135-151( 2001). a generalized version of the integrate-and-fire model is presented that qualitatively reproduces firing rates and membrane trajectories of motoneurons. the description is based on the spike-response model and includes three different time constants: the passive membrane time constant, a recovery time of the input conductance after each spike, and a time constant of the spike afterpotential. the effect of stochastic background input on the peristimulus time histogram (psth) response to spike input is calculated analytically. model results are compared with the experimental data of poliakov et al. (1996). the linearized theory shows that the psth response to an input spike is proportional to a filtered version of the postsynaptic potential generated by the input spike. the shape of the filter depends on the background activity. the full nonlinear theory is in close agreement with simulated psth data","['psth', 'integrate-and-fire model', 'motoneuron', 'firing rates', 'membrane trajectories', 'spike-response model', 'passive membrane time constant', 'recovery time', 'spike afterpotential']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['psth', 'integrate - and - fire model', 'motoneuron', 'fire rate', 'membrane trajectory', 'spike - response model', 'passive membrane time constant', 'recovery time', 'spike afterpotential']","['spike afterpotential', 'spike input', 'input spike', 'stochastic background input', 'postsynaptic potential generate', 'motoneuron', 'membrane trajectory', 'peristimulus time histogram', 'input conductance', 'passive membrane time constant']"
927,980,Convergence of Runge-Kutta methods for nonlinear parabolic equations,"we study time discretizations of fully nonlinear parabolic differential equations. our analysis uses the fact that the linearization along the exact solution is a uniformly sectorial operator. we derive smooth and nonsmooth-data error estimates for the backward euler method, and we prove convergence for strongly a (v)-stable runge-kutta methods. for the latter, the order of convergence for smooth solutions is essentially determined by the stage order of the method. numerical examples illustrating the convergence estimates are presented","['linearization', 'time discretizations', 'nonlinear parabolic differential equations', 'uniformly sectorial operator', 'nonsmooth-data error estimates', 'backward euler method', 'runge-kutta method convergence', 'data error estimates']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['linearization', 'time discretization', 'nonlinear parabolic differential equation', 'uniformly sectorial operator', 'nonsmooth - data error estimate', 'backward euler method', 'runge - kutta method convergence', 'datum error estimate']","['nonlinear parabolic differential equation', 'backward euler method', 'kutta method', 'study time discretization', 'uniformly sectorial operator', 'numerical example', 'convergence estimate', 'datum error estimate', 'linearization', 'derive smooth']"
928,1147,Angular disparity in ETACT scintimammography,"emission tuned aperture computed tomography (etact) has been previously shown to have the potential for the detection of small tumors (<1 cm) in scintimammography. however, the optimal approach to the application of etact in the clinic has yet to be determined. therefore, we sought to determine the effect of the angular disparity between the etact projections on image quality through the use of a computer simulation. a small, spherical tumor of variable size (5, 7.5 or 10 mm) was placed at the center of a hemispherical breast (15 cm diameter). the tumor to nontumor ratio was either 5:1 or 10:1. the detector was modeled to be a gamma camera fitted with a 4-mm-diam pinhole collimator. the pinhole-to-detector and the pinhole-to-tumor distances were 25 and 15 cm, respectively. a ray tracing technique was used to generate three sets of projections (10 degrees , 15 degrees , and 20 degrees , angular disparity). these data were blurred to a resolution consistent with the 4 mm pinhole. the tact reconstruction method was used to reconstruct these three image sets. the tumor contrast and the axial spatial resolution was measured. smaller angular disparity led to an improvement in image contrast but at a cost of degraded axial spatial resolution. the improvement in contrast is due to a slight improvement in the in-plane spatial resolution. since improved contrast should lead to better tumor detectability, smaller angular disparity should be used. however, the difference in contrast between 10 degrees and 15 degrees was very slight and therefore a reasonable clinical choice for angular disparity is 15 degrees","['angular disparity', 'small tumors', 'image quality', 'computer simulation', 'spherical tumor', 'hemispherical breast', 'gamma camera', 'pinhole collimator', 'pinhole-to-tumor distances', 'ray tracing technique', 'image sets', 'axial spatial resolution', 'in-plane spatial resolution', 'clinical choice', 'emission tuned aperture computed tomography scintimammography', 'pinhole-to-detector distances', 'tuned aperture computed tomography reconstruction method']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['angular disparity', 'small tumor', 'image quality', 'computer simulation', 'spherical tumor', 'hemispherical breast', 'gamma camera', 'pinhole collimator', 'pinhole - to - tumor distance', 'ray tracing technique', 'image set', 'axial spatial resolution', 'in - plane spatial resolution', 'clinical choice', 'emission tune aperture compute tomography scintimammography', 'pinhole - to - detector distance', 'tune aperture compute tomography reconstruction method']","['scintimammography', 'degraded axial spatial resolution', 'compute tomography', 'axial spatial resolution', 'spherical tumor', 'tumor distance', 'small tumor', 'tumor contrast', 'etact projection', 'gamma camera fit']"
929,1102,Design and implementation of a reusable and extensible HL7 encoding/decoding framework,"the health level seven (hl7), an international standard for electronic data exchange in all health care environments, enables disparate computer applications to exchange key sets of clinical and administrative information. above all, it defines the standard hl7 message formats prescribed by the standard encoding rules. in this paper, we propose a flexible, reusable, and extensible hl7 encoding and decoding framework using a message object model (mom) and message definition repository (mdr). the mom provides an abstract hl7 message form represented by a group of objects and their relationships. it reflects logical relationships among the standard hl7 message elements such as segments, fields, and components, while enforcing the key structural constraints imposed by the standard. since the mom completely eliminates the dependency of the hl7 encoder and decoder on platform-specific data formats, it makes it possible to build the encoder and decoder as reusable standalone software components, enabling the interconnection of arbitrary heterogeneous hospital information systems (his) with little effort. moreover, the mdr, an external database of key definitions for hl7 messages, helps make the encoder and decoder as resilient as possible to future modifications of the standard hl7 message formats. it is also used by the encoder and decoder to perform a well-formedness check for their respective inputs (i.e., hl7 message objects expressed in the mom and encoded hl7 message strings). although we implemented a prototype version of the encoder and decoder using java, they can be easily packaged and delivered as standalone components using the standard component frameworks","['health level seven', 'international standard', 'electronic data exchange', 'health care environments', 'administrative information', 'hl7 message formats', 'his', 'message object model', 'mom', 'message definition repository', 'mdr', 'logical relationships', 'structural constraints', 'standalone software components', 'heterogeneous hospital information systems', 'external database', 'key definitions', 'java', 'reusable framework', 'extensible encoding/decoding framework', 'abstract message form', 'activex', 'javabean', 'corba', 'clinical information']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'U', 'U', 'U', 'R']","['health level seven', 'international standard', 'electronic datum exchange', 'health care environment', 'administrative information', 'hl7 message format', 'his', 'message object model', 'mom', 'message definition repository', 'mdr', 'logical relationship', 'structural constraint', 'standalone software component', 'heterogeneous hospital information system', 'external database', 'key definition', 'java', 'reusable framework', 'extensible encoding / decode framework', 'abstract message form', 'activex', 'javabean', 'corba', 'clinical information']","['standard hl7 message format prescribe', 'encode hl7 message string', 'standard hl7 message format', 'reusable standalone software component', 'arbitrary heterogeneous hospital information system', 'abstract hl7 message form represent', 'extensible hl7 encode', 'standard hl7 message element such', 'decode framework use', 'specific datum format']"
930,938,Fast accurate MEG source localization using a multilayer perceptron trained with real brain noise,"iterative gradient methods such as levenberg-marquardt (lm) are in widespread use for source localization from electroencephalographic (eeg) and magnetoencephalographic (meg) signals. unfortunately, lm depends sensitively on the initial guess, necessitating repeated runs. this, combined with lm's high per-step cost, makes its computational burden quite high. to reduce this burden, we trained a multilayer perceptron (mlp) as a realtime localizer. we used an analytical model of quasistatic electromagnetic propagation through a spherical head to map randomly chosen dipoles to sensor activities according to the sensor geometry of a 4d neuroimaging neuromag-122 meg system, and trained a mlp to invert this mapping in the absence of noise or in the presence of various sorts of noise such as white gaussian noise, correlated noise, or real brain noise. a mlp structure was chosen to trade off computation and accuracy. this mlp was trained four times, with each type of noise. we measured the effects of initial guesses on lm performance, which motivated a hybrid mlp-start-lm method, in which the trained mlp initializes lm. we also compared the localization performance of lm, mlps, and hybrid mlp-start-lms for realistic brain signals. trained mlps are much faster than other methods, while the hybrid mlp-start-lms are faster and more accurate than fixed-4-start-lm. in particular, the hybrid mlp-start-lm initialized by a mlp trained with the real brain noise dataset is 60 times faster and is comparable in accuracy to random-20-start-lm, and this hybrid system (localization error: 0.28 cm, computation time: 36 ms) shows almost as good performance as optimal-1-start-lm (localization error: 0.23 cm, computation time: 22 ms), which initializes lm with the correct dipole location. mlps trained with noise perform better than the mlp trained without noise, and the mlp trained with real brain noise is almost as good an initial guesser for lm as the correct dipole location","['meg source localization', 'multilayer perceptron', 'real brain noise', 'iterative gradient methods', 'analytical model', 'quasistatic electromagnetic propagation', 'spherical head', 'white gaussian noise', 'correlated noise', 'fast accurate localization', 'real-time localizer', 'computation accuracy', 'levenberg-marquardt method', 'forward model']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'R', 'R', 'M']","['meg source localization', 'multilayer perceptron', 'real brain noise', 'iterative gradient method', 'analytical model', 'quasistatic electromagnetic propagation', 'spherical head', 'white gaussian noise', 'correlate noise', 'fast accurate localization', 'real - time localizer', 'computation accuracy', 'levenberg - marquardt method', 'forward model']","['train mlp initialize lm', 'iterative gradient method', 'brain noise dataset', 'quasistatic electromagnetic propagation', 'multilayer perceptron', 'mlp train', 'train mlp', 'mlp train', '4d neuroimage', 'realistic brain signal']"
931,656,The cataloger's workstation revisited: utilizing Cataloger's Desktop,"a few years into the development of cataloger's desktop, an electronic cataloging tool aggregator available through the library of congress, is an opportune time to assess its impact on cataloging operations. a search for online cataloging tools on the internet indicates a proliferation of cataloging tool aggregators; which provide access to online documentation related to cataloging practices and procedures. cataloger's desktop stands out as a leader among these aggregators. results of a survey to assess 159 academic arl and large public libraries' reasons for use or non-use of cataloger's desktop highlight the necessity of developing strategies for its successful implementation including training staff, providing documentation, and managing technical issues","[""cataloger's workstation"", ""cataloger's desktop"", 'electronic cataloging tool', 'cataloging tool aggregators', 'online cataloging tools', 'internet', 'online documentation', 'documentation', 'academic arl', 'large public libraries', 'managing technical issues', 'staff training']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","[""cataloger 's workstation"", ""cataloger 's desktop"", 'electronic catalog tool', 'catalog tool aggregator', 'online catalog tool', 'internet', 'online documentation', 'documentation', 'academic arl', 'large public library', 'manage technical issue', 'staff training']","['electronic catalog tool aggregator available', 'catalog tool aggregator', 'online catalog tool', 'catalog practice', 'catalog operation', 'successful implementation include training staff', 'cataloger', 'online documentation relate', 'provide documentation', 'large public library']"
932,613,Comparison between discrete STFT and wavelets for the analysis of power quality events,"this paper deals with the comparison of signal processing tools for power quality analysis. two signal processing techniques are considered: the wavelet filters and the discrete short-time fourier transforms (stft). then, examples of the two most frequent disturbances met in the power system are chosen. an adjustable speed drive with a six-pulse converter using emtp/atp is designed and normal energizing of utility capacitors is presented . the analysis is tested on a system consisting of 13 buses and is representative of a medium-sized industrial plant. finally, each kind of electrical disturbance is analyzed with examples representing each tool. a qualitative comparison of results shows the advantages and drawbacks of each signal processing technique applied to power quality analysis","['discrete stft', 'wavelets', 'power quality events', 'signal processing tools', 'signal processing techniques', 'wavelet filters', 'discrete short-time fourier transforms', 'short-time fourier transforms', 'adjustable speed drive', 'six-pulse converter', 'emtp/atp', 'utility capacitors', 'medium-sized industrial plant', 'electrical disturbance']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['discrete stft', 'wavelet', 'power quality event', 'signal processing tool', 'signal processing technique', 'wavelet filter', 'discrete short - time fourier transform', 'short - time fouri transform', 'adjustable speed drive', 'six - pulse converter', 'emtp / atp', 'utility capacitor', 'medium - sized industrial plant', 'electrical disturbance']","['wavelet filter', 'power quality analysis', 'utility capacitor', 'pulse converter', 'electrical disturbance', 'fouri transform', 'signal processing technique', 'signal processing tool', 'power system', 'signal processing']"
933,1246,Why information departments are becoming academic,"this article outlines the increasing convergence between academia and business over the last decade or so, and the mutual benefits that this closer association has brought. it also looks at the growing importance of the information profession, suggesting that this is leading to a greater need for specialist skills, as reflected by the rise in academic courses in this area. however, it argues that increasing specialization must not lead to insularity; if information professionals are truly concerned with gaining a competitive advantage, they must not close their minds to the potential benefits of working with external, non specialist, partners. the benefits that business has reaped from academia, it is contended, suggest that this may also be a fruitful avenue for information departments to explore","['information departments', 'academia', 'business', 'information profession', 'specialist skills', 'academic courses', 'information science', 'universities']","['P', 'P', 'P', 'P', 'P', 'P', 'M', 'U']","['information department', 'academia', 'business', 'information profession', 'specialist skill', 'academic course', 'information science', 'university']","['information profession', 'information professional', 'academic course', 'information department', 'increase specialization', 'specialist skill', 'competitive advantage', 'academia', 'business', 'potential benefit']"
934,1203,Technology decisions 2002,"the paper looks at the critical hardware, software, and services choices manufacturers are making as they begin to emerge from the recession and position themselves for the future","['services choices', 'manufacturing industries', 'information technology', 'management of change', 'customer relationship management', 'enterprise resource planning']","['P', 'M', 'M', 'U', 'U', 'U']","['service choice', 'manufacture industry', 'information technology', 'management of change', 'customer relationship management', 'enterprise resource planning']","['service choice manufacturer', 'critical hardware', 'paper look', 'recession', 'software', 'emerge', 'begin', 'make', 'position']"
935,1058,Bigger is better: the influence of physical size on aesthetic preference judgments,"the hypothesis that the physical size of an object can influence aesthetic preferences was investigated. in a series of four experiments, participants were presented with pairs of abstract stimuli and asked to indicate which member of each pair they preferred. a preference for larger stimuli was found on the majority of trials using various types of stimuli, stimuli of various sizes, and with both adult and 3-year-old participants. this preference pattern was disrupted only when participants had both stimuli that provided a readily accessible alternative source of preference-evoking information and sufficient attentional resources to make their preference judgments","['aesthetic preference judgments', 'abstract stimuli', 'preference pattern', 'preference-evoking information', 'attentional resources', 'physical size influence', 'decision making', 'preference formation', 'judgment cues', 'adult participants', 'child participants']","['P', 'P', 'P', 'P', 'P', 'R', 'M', 'M', 'M', 'R', 'M']","['aesthetic preference judgment', 'abstract stimulus', 'preference pattern', 'preference - evoke information', 'attentional resource', 'physical size influence', 'decision make', 'preference formation', 'judgment cue', 'adult participant', 'child participant']","['influence aesthetic preference', 'large stimulus', 'preference pattern', 'abstract stimulus', 'physical size', 'trial use various type', 'preference', 'stimulus', 'various size', 'sufficient attentional resource']"
936,1359,On fuzzy and probabilistic control charts,"in this article, different procedures of constructing control charts for linguistic data, based on fuzzy and probability theory, are discussed. three sets of membership functions, with different degrees of fuzziness, are proposed for fuzzy approaches. a comparison between fuzzy and probability approaches, based on the average run length and samples under control, is conducted for real data. contrary to the conclusions of raz and wang (1990) the choice of degree of fuzziness affected the sensitivity of control charts","['probabilistic control charts', 'linguistic data', 'membership functions', 'average run length', 'sensitivity', 'fuzzy control charts', 'control chart construction', 'fuzziness degree', 'fuzzy subsets', 'porcelain products']","['P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'M', 'U']","['probabilistic control chart', 'linguistic datum', 'membership function', 'average run length', 'sensitivity', 'fuzzy control chart', 'control chart construction', 'fuzziness degree', 'fuzzy subset', 'porcelain product']","['construct control chart', 'linguistic datum', 'fuzzy approach', 'fuzzy', 'fuzziness affect', 'fuzziness', 'probability approach', 'probability theory', 'datum', 'membership function']"
937,749,Numerical modeling of the flow in stenosed coronary artery. The relationship between main hemodynamic parameters,"the severity of coronary arterial stenosis is usually measured by either simple geometrical parameters, such as percent diameter stenosis, or hemodynamically based parameters, such as the fractional flow reserve (ffr) or coronary flow reserve (cfr). the present study aimed to establish a relationship between actual hemodynamic conditions and the parameters that define stenosis severity in the clinical setting. we used a computational model of the blood flow in a vessel with a blunt stenosis and an autoregulated vascular bed to simulate a stenosed blood vessel. a key point in creating realistic simulations is to properly model arterial autoregulation. a constant flow regulation mechanism resulted in cfr and ffr values that were within the physiological range, while a constant wall-shear stress model yielded unrealistic values. the simulation tools developed in the present study may be useful in the clinical assessment of single and multiple stenoses by means of minimally invasive methods","['numerical modeling', 'hemodynamic parameters', 'coronary arterial stenosis', 'stenosis severity', 'clinical setting', 'computational model', 'blood flow', 'blunt stenosis', 'autoregulated vascular bed', 'simulation', 'stenosed blood vessel', 'arterial autoregulation', 'constant flow regulation mechanism', 'physiological range', 'minimally invasive methods', 'constant wall shear stress model']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['numerical modeling', 'hemodynamic parameter', 'coronary arterial stenosis', 'stenosis severity', 'clinical setting', 'computational model', 'blood flow', 'blunt stenosis', 'autoregulate vascular bed', 'simulation', 'stenose blood vessel', 'arterial autoregulation', 'constant flow regulation mechanism', 'physiological range', 'minimally invasive method', 'constant wall shear stress model']","['coronary arterial stenosis', 'coronary flow reserve', 'model arterial autoregulation', 'autoregulate vascular', 'stenosis severity', 'stenose blood vessel', 'fractional flow reserve', 'percent diameter stenosis', 'stenosis', 'blood flow']"
938,862,Two efficient algorithms for the generalized maximum balanced flow problem,"minoux (1976) considered the maximum balanced flow problem, i.e. the problem of finding a maximum flow in a two-terminal network n = (v,a) with source s and sink t satisfying the constraint that any arc-flow of n is bounded by a fixed proportion of the total flow value from s to t, where v is vertex set and a is arc set. as a generalization, we focus on the problem of maximizing the total flow value of a generalized flow in n with gains gamma (a) > 0 (a in a) where any arc-flow is bounded by a fixed proportion of the total flow value, where gamma (a)f(a) units arrive at the vertex w for each arc-flow f(a) (a identical to ( upsilon , w) in a) entering vertex upsilon in a generalized flow. our main results are to propose two polynomial algorithms for this problem. the first algorithm runs in o(mm(n, m, b') log b) time, where b is the maximum absolute value among integral values used by an instance of the problem, and m(n, m, b') denotes the complexity of solving a generalized maximum flow problem in a network with n vertices, and m arcs, and a rational instance expressed with integers between 1 and b'. in the second algorithm, using a parameterized technique, runs in o({m(n, m, b')}/sup 2/) time","['generalized maximum balanced flow problem', 'two-terminal network', 'polynomial algorithms', 'parameterized technique']","['P', 'P', 'P', 'P']","['generalize maximum balanced flow problem', 'two - terminal network', 'polynomial algorithm', 'parameterized technique']","['generalize maximum flow problem', 'maximum balanced flow problem', 'maximum flow', 'total flow value', 'generalize flow', 'enter vertex upsilon', 'polynomial algorithm', 'first algorithm run', 'second algorithm', 'flow']"
939,827,Williams nears end of Chapter 11 [telecom],"leucadia national corp. comes through with a $330 million boost for williams communications, which should keep the carrier afloat through the remainder of its bankruptcy","['williams communications', 'bankruptcy', 'leucadia national corp']","['P', 'P', 'M']","['williams communication', 'bankruptcy', 'leucadia national corp']","['leucadia national corp', 'williams communication', 'carrier afloat', 'boost', 'keep', 'remainder']"
940,1431,Cataloguing to help law library users,"the author takes a broader view of the catalogue than is usual; we can include within it items that have locations other than the office/library itself. this may well start with internet resources, but can perfectly appropriately continue with standard works not held in the immediate collection but available in some other accessible collection, such as the local reference library. the essential feature is to include entries for the kind of material sought by users, with the addition of a location mark indicating where they can find it","['cataloguing', 'law library users', 'internet resources', 'reference library', 'location mark']","['P', 'P', 'P', 'P', 'P']","['catalogue', 'law library user', 'internet resource', 'reference library', 'location mark']","['local reference library', 'other accessible collection', 'include entry', 'location mark indicate', 'internet resource', 'catalogue', 'library', 'have location other', 'immediate collection', 'include']"
941,654,A question of perspective: assigning Library of Congress subject headings to classical literature and ancient history,"this article explains the concept of world view and shows how the world view of cataloguers influences the development and assignment of subject headings to works about other cultures and civilizations, using works from classical literature and ancient history as examples. cataloguers are encouraged to evaluate the headings they assign to works in classical literature and ancient history in terms of the world views of ancient greece and rome so that headings reflect the contents of the works they describe and give fuller expression to the diversity of thoughts and themes that characterize these ancient civilizations","['classical literature', 'ancient history', 'world view', 'cultures', 'civilizations', 'ancient greece', 'library of congress subject heading assignment', 'ancient rome']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['classical literature', 'ancient history', 'world view', 'culture', 'civilization', 'ancient greece', 'library of congress subject heading assignment', 'ancient rome']","['ancient history', 'classical literature', 'ancient greece', 'cataloguer influence', 'world view', 'other culture', 'world view', 'subject heading', 'civilization', 'cataloguer']"
942,611,Intelligent optimal sieving method for FACTS device control in multi-machine systems,"a multi-target oriented optimal control strategy for facts devices installed in multi-machine power systems is presented in this paper, which is named the intelligent optimal sieving control (iosc) method. this new method divides the facts device output region into several parts and selects one typical value from each part, which is called output candidate. then, an intelligent optimal sieve is constructed, which predicts the impacts of each output candidate on a power system and sieves out an optimal output from all of the candidates. the artificial neural network technologies and fuzzy methods are applied to build the intelligent sieve. finally, the real control signal of facts devices is calculated according to the selected optimal output through inverse system method. simulation has been done on a three-machine power system and the results show that the proposed iosc controller can effectively attenuate system oscillations and enhance the power system transient stability","['intelligent optimal sieving method', 'intelligent optimal sieve', 'facts', 'facts device control', 'multi-machine systems', 'multi-target oriented optimal control strategy', 'artificial neural network technologies', 'fuzzy methods', 'control signal', 'selected optimal output', 'inverse system method', 'three-machine power system', 'intelligent control', 'system oscillations attenuation', 'power system transient stability enhancement']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['intelligent optimal sieving method', 'intelligent optimal sieve', 'fact', 'fact device control', 'multi - machine system', 'multi - target orient optimal control strategy', 'artificial neural network technology', 'fuzzy method', 'control signal', 'select optimal output', 'inverse system method', 'three - machine power system', 'intelligent control', 'system oscillation attenuation', 'power system transient stability enhancement']","['intelligent optimal sieving control', 'intelligent optimal sieve', 'optimal control strategy', 'intelligent sieve', 'fact device output region', 'select optimal output', 'machine power system', 'machine power system', 'iosc controller', 'optimal output']"
943,1244,Applied ethics in business information units,"the primary thesis of this paper is that business information professionals commonly overlook ethical dilemmas in the workplace. although the thesis remains unproven, the author highlights, by way of real and hypothetical case studies, a number of situations in which ethical tensions can be identified, and suggests that information professionals need to be more aware of the moral context of their actions. resolving ethical dilemmas should be one of the aims of competent information professionals and their managers, although it is recognized that dilemmas often cannot easily be resolved. a background to the main theories of applied ethics forms the framework for later discussion","['applied ethics', 'business information units', 'business information professionals', 'ethical dilemmas', 'moral context']","['P', 'P', 'P', 'P', 'P']","['apply ethic', 'business information unit', 'business information professional', 'ethical dilemma', 'moral context']","['resolve ethical dilemma', 'overlook ethical dilemma', 'business information professional', 'ethical tension', 'apply ethic form', 'competent information professional', 'information professional need', 'moral context', 'hypothetical case study', 'dilemmas']"
944,1201,Moving into the mainstream [product lifecycle management],"product lifecycle management (plm) is widely recognised by most manufacturing companies, as manufacturers begin to identify and implement targeted projects intended to deliver return-on investment in a timely fashion. vendors are also releasing second-generation plm products that are packaged, out-of-the-box solutions","['product lifecycle management', 'manufacturing companies', 'product data management', 'product development', 'enterprise resource planning']","['P', 'P', 'M', 'M', 'U']","['product lifecycle management', 'manufacture company', 'product datum management', 'product development', 'enterprise resource planning']","['product lifecycle management', 'generation plm product', 'most manufacturing company', 'manufacturer begin', 'plm', 'implement target project intend', 'vendor', 'release second', 'deliver return', 'package']"
945,555,Computing transient gating charge movement of voltage-dependent ion channels,"the opening of voltage-gated sodium, potassium, and calcium ion channels has a steep relationship with voltage. in response to changes in the transmembrane voltage, structural movements of an ion channel that precede channel opening generate a capacitative gating current. the net gating charge displacement due to membrane depolarization is an index of the voltage sensitivity of the ion channel activation process. understanding the molecular basis of voltage-dependent gating of ion channels requires the measurement and computation of the gating charge, q. we derive a simple and accurate semianalytic approach to computing the voltage dependence of transient gating charge movement (q-v relationship) of discrete markov state models of ion channels using matrix methods. this approach allows rapid computation of q-v curves for finite and infinite length step depolarizations and is consistent with experimentally measured transient gating charge. this computational approach was applied to shaker potassium channel gating, including the impact of inactivating particles on potassium channel gating currents","['transient gating charge movement', 'charge movement', 'ion channels', 'transmembrane voltage', 'gating current', 'markov state model', 'inactivation', 'action potentials', 'immobilization']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'U', 'U']","['transient gate charge movement', 'charge movement', 'ion channel', 'transmembrane voltage', 'gate current', 'markov state model', 'inactivation', 'action potential', 'immobilization']","['transient gate charge movement', 'transient gate charge', 'shaker potassium channel gate', 'calcium ion channel', 'ion channel activation process', 'capacitative gate current', 'ion channel', 'ion channel', 'gate charge displacement', 'transmembrane voltage']"
946,982,Abundance of mosaic patterns for CNN with spatially variant templates,"this work investigates the complexity of one-dimensional cellular neural network mosaic patterns with spatially variant templates on finite and infinite lattices. various boundary conditions are considered for finite lattices and the exact number of mosaic patterns is computed precisely. the entropy of mosaic patterns with periodic templates can also be calculated for infinite lattices. furthermore, we show the abundance of mosaic patterns with respect to template periods and, which differ greatly from cases with spatially invariant templates","['mosaic patterns', 'cnn', 'spatially variant templates', 'one-dimensional cellular neural network', 'infinite lattices', 'finite lattices', 'boundary conditions', 'spatial entropy', 'transition matrix']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'U']","['mosaic pattern', 'cnn', 'spatially variant template', 'one - dimensional cellular neural network', 'infinite lattice', 'finite lattice', 'boundary condition', 'spatial entropy', 'transition matrix']","['dimensional cellular neural network mosaic pattern', 'mosaic pattern', 'infinite lattice', 'finite lattice', 'periodic template', 'variant template', 'entropy', 'template period', 'complexity', 'various boundary condition']"
947,1145,Mammogram synthesis using a 3D simulation. II. Evaluation of synthetic mammogram texture,"we have evaluated a method for synthesizing mammograms by comparing the texture of clinical and synthetic mammograms. the synthesis algorithm is based upon simulations of breast tissue and the mammographic imaging process. mammogram texture was synthesized by projections of simulated adipose tissue compartments. it was hypothesized that the synthetic and clinical texture have similar properties, assuming that the mammogram texture reflects the 3d tissue distribution. the size of the projected compartments was computed by mathematical morphology. the texture energy and fractal dimension were also computed and analyzed in terms of the distribution of texture features within four different tissue regions in clinical and synthetic mammograms. comparison of the cumulative distributions of the mean features computed from 95 mammograms showed that the synthetic images simulate the mean features of the texture of clinical mammograms. correlation of clinical and synthetic texture feature histograms, averaged over all images, showed that the synthetic images can simulate the range of features seen over a large group of mammograms. the best agreement with clinical texture was achieved for simulated compartments with radii of 4-13.3 mm in predominantly adipose tissue regions, and radii of 2.7-5.33 and 1.3-2.7 mm in retroareolar and dense fibroglandular tissue regions, respectively","['mammogram synthesis', '3d simulation', 'synthetic mammogram texture', 'adipose tissue compartments', '3d tissue distribution', 'mathematical morphology', 'fractal dimension', 'cumulative distributions', 'synthetic images', 'dense fibroglandular tissue regions', 'breast tissue simulation', 'retroareolar tissue regions', 'x-ray image acquisition', 'computationally compressed phantom']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M', 'M']","['mammogram synthesis', '3d simulation', 'synthetic mammogram texture', 'adipose tissue compartment', '3d tissue distribution', 'mathematical morphology', 'fractal dimension', 'cumulative distribution', 'synthetic image', 'dense fibroglandular tissue region', 'breast tissue simulation', 'retroareolar tissue region', 'x - ray image acquisition', 'computationally compress phantom']","['mammogram texture reflect', 'synthetic texture feature histogram', 'mammogram texture', 'mammographic imaging process', 'synthetic mammogram', 'clinical mammogram', 'simulate adipose tissue compartment', 'synthesize mammogram', 'dense fibroglandular tissue region', 'mammogram show']"
948,1100,Evaluation of existing and new feature recognition algorithms. 2. Experimental results,"for pt.1 see ibid., p.839-851. this is the second of two papers investigating the performance of general-purpose feature detection techniques. the first paper describes the development of a methodology to synthesize possible general feature detection face sets. six algorithms resulting from the synthesis have been designed and implemented on a sun workstation in c++ using acis as the geometric modelling system. in this paper, extensive tests and comparative analysis are conducted on the feature detection algorithms, using carefully selected components from the public domain, mostly from the national design repository. the results show that the new and enhanced algorithms identify face sets that previously published algorithms cannot detect. the tests also show that each algorithm can detect, among other types, a certain type of feature that is unique to it. hence, most of the algorithms discussed in this paper would have to be combined to obtain complete coverage","['feature recognition algorithms', 'general-purpose feature detection techniques', 'face sets', 'national design repository', 'convex hull', 'concavity']","['P', 'P', 'P', 'P', 'U', 'U']","['feature recognition algorithm', 'general - purpose feature detection technique', 'face set', 'national design repository', 'convex hull', 'concavity']","['feature detection face set', 'feature detection algorithm', 'enhance algorithm identify face set', 'purpose feature detection technique', 'geometric modelling system', 'detect', 'algorithm', 'sun workstation', 'algorithm', 'feature']"
949,93,Help-desk support is key to wireless success [finance],"a well thought out help desk can make or break an institution's mobile play. schwab, ameritrade and rbc are taking their support function seriously","['wireless', 'finance', 'help desk', 'schwab', 'ameritrade', 'rbc']","['P', 'P', 'P', 'P', 'P', 'P']","['wireless', 'finance', 'help desk', 'schwab', 'ameritrade', 'rbc']","['mobile play', 'support function', 'help desk', 'schwab', 'ameritrade', 'rbc', 'break', 'institution', 'think', 'take']"
950,568,Modeling cutting temperatures for turning inserts with various tool geometries and materials,"temperatures are of interest in machining because cutting tools often fail by thermal softening or temperature-activated wear. many models for cutting temperatures have been developed, but these models consider only simple tool geometries such as a rectangular slab with a sharp corner. this report describes a finite element study of tool temperatures in cutting that accounts for tool nose radius and included angle effects. a temperature correction factor model that can be used in the design and selection of inserts is developed to account for these effects. a parametric mesh generator is used to generate the finite element models of tool and inserts of varying geometries. the steady-state temperature response is calculated using nastran solver. several finite element analysis (fea) runs are performed to quantify the effects of inserts included angle, nose radius, and materials for the insert and the tool holder on the cutting temperature at the insert rake face. the fea results are then utilized to develop a temperature correction factor model that accounts for these effects. the temperature correction factor model is integrated with an analytical temperature model for rectangular inserts to predict cutting temperatures for contour turning with inserts of various shapes and nose radii. finally, experimental measurements of cutting temperature using the tool-work thermocouple technique are performed and compared with the predictions of the new temperature model. the comparisons show good agreement","['turning inserts', 'tool geometries', 'machining', 'tool nose radius', 'temperature correction factor', 'parametric mesh generator', 'finite element models', 'cutting temperature model', 'insert shape effects']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['turn insert', 'tool geometry', 'machine', 'tool nose radius', 'temperature correction factor', 'parametric mesh generator', 'finite element model', 'cut temperature model', 'insert shape effect']","['cut temperature use', 'predict cut temperature', 'tool temperature', 'cut temperature', 'cut temperature', 'cut tool', 'machine', 'temperature model', 'tool geometry such', 'tool nose radius']"
951,1178,Network-centric systems,the author describes a graduate-level course that addresses cutting-edge issues in network-centric systems while following a more traditional graduate seminar format,"['network-centric systems', 'graduate level course']","['P', 'M']","['network - centric system', 'graduate level course']","['centric system', 'network', 'edge issue', 'address cut', 'graduate', 'level course', 'author describe', 'follow']"
952,1284,A linear time special case for MC games,"mc games are infinite duration two-player games played on graphs. deciding the winner in mc games is equivalent to the the modal mu-calculus model checking. in this article we provide a linear time algorithm for a class of mc games. we show that, if all cycles in each strongly connected component of the game graph have at least one common vertex, the winner can be found in linear time. our results hold also for parity games, which are equivalent to mc games","['linear time special case', 'mc games', 'two-player games', 'modal mu-calculus model checking', 'linear time algorithm']","['P', 'P', 'P', 'P', 'P']","['linear time special case', 'mc game', 'two - player game', 'modal mu - calculus model check', 'linear time algorithm']","['linear time algorithm', 'player game play', 'parity game', 'game graph have', 'mc game', 'modal mu', 'calculus model check', 'common vertex', 'linear time', 'infinite duration']"
953,694,A novel genetic algorithm for the design of a signed power-of-two coefficient quadrature mirror filter lattice filter bank,"a novel genetic algorithm (ga) for the design of a canonical signed power-of-two (spt) coefficient lattice structure quadrature mirror filter bank is presented. genetic operations may render the spt representation of a value noncanonical. a new encoding scheme is introduced to encode the spt values. in this new scheme, the canonical property of the spt values is preserved under genetic operations. additionally, two new features that drastically improve the performance of our ga are introduced. (1) an additional level of natural selection is introduced to simulate the effect of natural selection when sperm cells compete to fertilize an ovule; this dramatically improves the offspring survival rate. a conventional ga is analogous to intracytoplasmic sperm injection and has an extremely low offspring survival rate, resulting in very slow convergence. (2) the probability of mutation for each codon of a chromosome is weighted by the reciprocal of its effect. because of these new features, the performance of our new ga outperforms conventional gas","['genetic algorithm', 'quadrature mirror filter', 'lattice filter bank', 'encoding scheme', 'natural selection', 'offspring survival rate', 'signed power-of-two coefficient lattice structure', 'qmf', 'chromosome codon', 'signal processing', 'perfect reconstruction']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'U', 'R', 'U', 'U']","['genetic algorithm', 'quadrature mirror filter', 'lattice filter bank', 'encode scheme', 'natural selection', 'offspring survival rate', 'sign power - of - two coefficient lattice structure', 'qmf', 'chromosome codon', 'signal processing', 'perfect reconstruction']","['coefficient lattice structure quadrature mirror filter bank', 'genetic algorithm', 'sperm cell compete', 'genetic operation', 'low offspring survival rate', 'natural selection', 'offspring survival rate', 'mutation', 'sperm injection', 'new encoding scheme']"
954,1279,"Place/Transition Petri net evolutions: recording ways, analysis and synthesis","four semantic domains for place/transition petri nets and their relationships are considered. they are monoids of respectively: firing sequences, processes, traces and dependence graphs. for each of them the analysis and synthesis problem is stated and solved. the monoid of processes is defined in a non-standard way, nets under consideration involve weights of arrows and capacities (finite or infinite) of places. however, the analysis and synthesis tasks require nets to be pure, i.e. each of their transition must have the pre-set and post-set disjoint","['place/transition petri net evolutions', 'semantic domains', 'monoids', 'firing sequences', 'dependence graphs', 'post-set disjoint', 'pre-set disjoint']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['place / transition petri net evolution', 'semantic domain', 'monoid', 'fire sequence', 'dependence graph', 'post - set disjoint', 'pre - set disjoint']","['transition petri net', 'synthesis task require net', 'semantic domain', 'process', 'dependence graph', 'net', 'synthesis problem', 'transition', 'monoid', 'consideration involve weight']"
955,1185,Trading exchanges: online marketplaces evolve,looks at how trading exchanges are evolving rapidly to help manufacturers keep up with customer demand,"['trading exchanges', 'online marketplaces', 'manufacturers', 'customer demand', 'enterprise platforms', 'supply chain management', 'enterprise resource planning', 'core software platform', 'private exchanges', 'integration technology', 'middleware', 'xml standards', 'content management capabilities']","['P', 'P', 'P', 'P', 'U', 'U', 'U', 'U', 'M', 'U', 'U', 'U', 'U']","['trading exchange', 'online marketplace', 'manufacturer', 'customer demand', 'enterprise platform', 'supply chain management', 'enterprise resource planning', 'core software platform', 'private exchange', 'integration technology', 'middleware', 'xml standard', 'content management capability']","['trading exchange', 'help manufacturer keep', 'evolve', 'look']"
956,907,Development of an integrated and open-architecture precision motion control system,"in this paper, the development of an integrated and open-architecture precision motion control system is presented. the control system is generally applicable, but it is developed with a particular focus on direct drive servo systems based on linear motors. the overall control system is comprehensive, comprising of various selected control and instrumentation components, integrated within a configuration of hardware architecture centred around a dspace ds1004 dsp processor board. these components include a precision composite controller (comprising of feedforward and feedback control), a disturbance observer, an adaptive notch filter, and a geometrical error compensator. the hardware architecture, software development platform, user interface, and all constituent control components are described","['open-architecture', 'precision', 'motion control', 'direct drive servo systems', 'linear motors', 'composite controller', 'feedforward', 'feedback', 'adaptive notch filter', 'geometrical error compensation', 'dspace ds1004 processor']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['open - architecture', 'precision', 'motion control', 'direct drive servo system', 'linear motor', 'composite controller', 'feedforward', 'feedback', 'adaptive notch filter', 'geometrical error compensation', 'dspace ds1004 processor']","['architecture precision motion control system', 'direct drive servo system base', 'constituent control component', 'dsp processor board', 'control system', 'linear motor', 'feedback control', 'disturbance observer', 'control', 'adaptive notch filter']"
957,144,Development of a 3.5 inch magneto-optical disk with a capacity of 2.3 GB,"the recording capacity of gigamo media was enlarged from 1.3 gb to 2.3 gb for 3.5 inch magneto-optical (mo) disks while maintaining downward compatibility. for the new gigamo technology, a land and groove recording method was applied in addition to magnetically induced super resolution (msr) media. furthermore, a novel address format suitable for the land and groove recording method was adopted. the specifications of the new gigamo media were examined to satisfy requirements for practical use with respect to margins. durability of more than 10/sup 6/ rewritings and an enough lifetime were confirmed","['3.5 inch', 'magneto-optical disk', '2.3 gb', 'recording capacity', 'gigamo media', 'magnetically induced super resolution', 'msr', 'address format', 'lifetime', 'mo disks', 'land-groove recording method', 'rewriting durability', 'crosstalk', 'sin-gdfeco-gdfe-tbfeco-sin-al']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'R', 'U', 'U']","['3.5 inch', 'magneto - optical disk', '2.3 gb', 'recording capacity', 'gigamo medium', 'magnetically induce super resolution', 'msr', 'address format', 'lifetime', 'mo disk', 'land - groove recording method', 'rewrite durability', 'crosstalk', 'sin - gdfeco - gdfe - tbfeco - sin - al']","['new gigamo medium', 'groove record', 'gigamo medium', 'new gigamo technology', 'inch magneto', 'recording capacity', 'super resolution', 'disk', 'address format suitable', 'gb']"
958,595,Six common enterprise programming mistakes,"instead of giving you tips to use in your programming (at least directly), i want to look at some common mistakes made in enterprise programming. instead of focusing on what to do, i want to look at what you should not do. most programmers take books like mine and add in the good things, but they leave their mistakes in the very same programs! so i touch on several common errors i see in enterprise programming, and then briefly mention how to avoid those mistakes","['enterprise programming mistakes', 'common errors', 'data store', 'database', 'xml', 'enterprise javabeans', 'vendor-specific programming']","['P', 'P', 'U', 'U', 'U', 'M', 'M']","['enterprise programming mistake', 'common error', 'datum store', 'database', 'xml', 'enterprise javabean', 'vendor - specific programming']","['enterprise programming', 'several common error', 'common mistake', 'mistake', 'most programmer', 'tip', 'programming', 'same program', 'avoid', 'use']"
959,942,Micro-optical realization of arrays of selectively addressable dipole traps: a scalable configuration for quantum computation with atomic qubits,"we experimentally demonstrate novel structures for the realization of registers of atomic qubits: we trap neutral atoms in one- and two-dimensional arrays of far-detuned dipole traps obtained by focusing a red-detuned laser beam with a microfabricated array of microlenses. we are able to selectively address individual trap sites due to their large lateral separation of 125 mu m. we initialize and read out different internal states for the individual sites. we also create two interleaved sets of trap arrays with adjustable separation, as required for many proposed implementations of quantum gate operations","['scalable configuration', 'quantum computation', 'atomic qubits', 'registers', 'neutral atoms', 'far-detuned dipole traps', 'red-detuned laser beam', 'microfabricated array', 'microlenses', 'internal states', 'quantum gate operations']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['scalable configuration', 'quantum computation', 'atomic qubit', 'register', 'neutral atom', 'far - detune dipole trap', 'red - detune laser beam', 'microfabricate array', 'microlense', 'internal state', 'quantum gate operation']","['atomic qubit', 'detune dipole trap', 'trap array', 'microfabricate array', 'address individual trap site', 'detune laser beam', 'trap', 'register', 'microlense', 'dimensional array']"
960,1364,An adaptive sphere-fitting method for sequential tolerance control,"the machining of complex parts typically involves a logical and chronological sequence of n operations on m machine tools. because manufacturing datums cannot always match design constraints, some of the design specifications imposed on the part are usually satisfied by distinct subsets of the n operations prescribed in the process plan. conventional tolerance control specifies a fixed set point for each operation and a permissible variation about this set point to insure compliance with the specifications, whereas sequential tolerance control (stc) uses real-time measurement information at the completion of one stage to reposition the set point for subsequent operations. however, it has been shown that earlier sphere-fitting methods for stc can lead to inferior solutions when the process distributions are skewed. this paper introduces an extension of stc that uses an adaptive sphere-fitting method that significantly improves the yield in the presence of skewed distributions as well as significantly reducing the computational effort required by earlier probabilistic search methods","['adaptive sphere-fitting method', 'sequential tolerance control', 'machine tools', 'design constraints', 'compliance', 'real-time measurement information', 'skewed distributions', 'computational effort', 'yield improvement']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['adaptive sphere - fitting method', 'sequential tolerance control', 'machine tool', 'design constraint', 'compliance', 'real - time measurement information', 'skewed distribution', 'computational effort', 'yield improvement']","['sequential tolerance control', 'machine', 'match design constraint', 'machine tool', 'conventional tolerance control specifie', 'manufacture datum', 'design specification impose', 'early sphere', 'fitting method', 'process plan']"
961,731,Aggregate bandwidth estimation in stored video distribution systems,"multimedia applications like video on demand, distance learning, internet video broadcast, etc. will play a fundamental role in future broadband networks. a common aspect of such applications is the transmission of video streams that require a sustained relatively high bandwidth with stringent requirements of quality of service. in this paper various original algorithms for evaluating, in a video distribution system, a statistical estimation of aggregate bandwidth needed by a given number of smoothed video streams are proposed and discussed. the variable bit rate traffic generated by each video stream is characterized by its marginal distribution and by conditional probabilities between rates of temporary closed streams. the developed iterative algorithms evaluate an upper and lower bound of needed bandwidth for guaranteeing a given loss probability. the obtained results are compared with simulations and with other results, based on similar assumptions, already presented in the literature. some considerations on the developed algorithms are made, in order to evaluate the effectiveness of the proposed methods","['aggregate bandwidth estimation', 'stored video distribution systems', 'multimedia applications', 'video on demand', 'distance learning', 'internet video broadcast', 'broadband networks', 'quality of service', 'statistical estimation', 'variable bit rate traffic', 'marginal distribution', 'conditional probabilities', 'temporary closed streams', 'iterative algorithms', 'lower bound', 'loss probability', 'simulations', 'video streams transmission', 'upper bound', 'vod', 'video coding', 'qos']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'U', 'M', 'U']","['aggregate bandwidth estimation', 'store video distribution system', 'multimedia application', 'video on demand', 'distance learning', 'internet video broadcast', 'broadband network', 'quality of service', 'statistical estimation', 'variable bit rate traffic', 'marginal distribution', 'conditional probability', 'temporary closed stream', 'iterative algorithm', 'lower bound', 'loss probability', 'simulation', 'video stream transmission', 'upper bind', 'vod', 'video coding', 'qos']","['smooth video stream', 'internet video broadcast', 'variable bit rate traffic generate', 'video stream', 'video stream', 'aggregate bandwidth need', 'future broadband network', 'video distribution', 'need bandwidth', 'bandwidth']"
962,774,Keeping Web accessibility in mind: I&R services for all,"after presenting three compelling reasons for making web sites accessible to persons with a broad range of disabilities (it's the morally right thing to do, it's the smart thing to do from an economic perspective, and it's required by law), the author discusses design issues that impact persons with particular types of disabilities. she presents practical advice for assessing and addressing accessibility problems. an extensive list of resources for further information is appended, as is a list of sites which simulate the impact of specific accessibility problems on persons with disabilities","['web site accessibility', 'disabilities', 'information and referral services']","['P', 'P', 'M']","['web site accessibility', 'disability', 'information and referral service']","['make web site accessible', 'specific accessibility problem', 'address accessibility problem', 'author discuss design issue', 'disability', 'impact person', 'present practical advice', 'economic perspective', 'site', 'resource']"
963,1449,Raising the standard of management education for electronic commerce professionals,"the teaching of electronic commerce in universities has become a growth industry in itself. the rapid expansion of electronic commerce programmes raises the question of what actually is being taught. the association of electronic commerce as primarily a technical or information technology (it) phenomenon has not been sufficient to constrain it to it and information systems departments. business schools have been keen entrants into the electronic commerce coursework race and they are developing electronic commerce programmes in an environment where there is no agreed definition of the term. this paper draws on the work of kenneth boulding who argued that the dynamics of change in society are largely a product of changing skills and the way these skills are arranged into roles at the organizational level. it is argued that an overly technical interpretation of electronic commerce narrows the skills being acquired as part of formal education. universities, under pressure from the market and technological change, are changing their roles resulting in a further narrowing of the breadth of issues that is seen as legitimate to be included as electronic commerce. the outcome is that aspiring electronic commerce professionals are not being exposed to a wide enough agenda of ideas and concepts that will assist them to make better business decisions","['electronic commerce professionals', 'universities', 'it', 'information technology', 'information systems', 'business schools', 'kenneth boulding', 'organizational level', 'formal education', 'management education standards improvement']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['electronic commerce professional', 'university', 'it', 'information technology', 'information system', 'business school', 'kenneth boulding', 'organizational level', 'formal education', 'management education standard improvement']","['aspire electronic commerce professional', 'develop electronic commerce programme', 'electronic commerce coursework race', 'electronic commerce programme', 'electronic commerce narrow', 'electronic commerce', 'information system department', 'technological change', 'information technology', 'technical interpretation']"
964,1098,Instability phenomena in the gas-metal arc welding self-regulation process,"arc instability is a very important determinant of weld quality. the instability behaviour of the gas-metal arc welding (gmaw) process is characterized by strong oscillations in arc length and current. in the paper, a model of the gmaw process is developed using an exact arc voltage characteristic. this model is used to study stability of the self-regulation process and to develop a simulation program that helps to understand the transient or dynamic nature of the gmaw process and relationships among current, electrode extension and contact tube-work distance. the process is shown to exhibit instabilities at both long electrode extension and normal extension. results obtained from simulation runs of the model were also experimentally confirmed by the present author, as reported in this study. in order to explain the concept of the instability phenomena, the metal transfer mode and the arc voltage-current characteristic were examined. based on this examination, the conclusion of this study is that their combined effects lead to the oscillations in arc current and length","['instability phenomena', 'gas-metal arc welding', 'self-regulation process', 'arc instability', 'weld quality', 'gmaw process', 'exact arc voltage characteristic', 'metal transfer mode']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['instability phenomenon', 'gas - metal arc welding', 'self - regulation process', 'arc instability', 'weld quality', 'gmaw process', 'exact arc voltage characteristic', 'metal transfer mode']","['metal arc welding', 'arc current', 'arc instability', 'arc voltage characteristic', 'arc voltage', 'arc length', 'weld quality', 'long electrode extension', 'instability phenomenon', 'electrode extension']"
965,1020,Supersampling multiframe blind deconvolution resolution enhancement of adaptive optics compensated imagery of low earth orbit satellites,we describe a postprocessing methodology for reconstructing undersampled image sequences with randomly varying blur that can provide image enhancement beyond the sampling resolution of the sensor. this method is demonstrated on simulated imagery and on adaptive-optics-(ao)-compensated imagery taken by the starfire optical range 3.5-m telescope that has been artificially undersampled. also shown are the results of multiframe blind deconvolution of some of the highest quality optical imagery of low earth orbit satellites collected with a ground-based telescope to date. the algorithm used is a generalization of multiframe blind deconvolution techniques that include a representation of spatial sampling by the focal plane array elements based on a forward stochastic model. this generalization enables the random shifts and shape of the ao-compensated point spread function (psf) to be used to partially eliminate the aliasing effects associated with sub-nyquist sampling of the image by the focal plane array. the method could be used to reduce resolution loss that occurs when imaging in wide-field-of-view (fov) modes,"['supersampling multiframe blind deconvolution resolution enhancement', 'multiframe blind deconvolution', 'adaptive optics compensated imagery', 'low earth orbit satellites', 'postprocessing methodology', 'randomly varying blur', 'image enhancement', 'simulated imagery', 'ground-based telescope', 'spatial sampling', 'focal plane array elements', 'forward stochastic model', 'random shifts', 'ao-compensated point spread function', 'aliasing effects', 'sub-nyquist sampling', 'resolution loss', 'undersampled image sequence reconstruction', 'sensor sampling resolution', 'starfire optical range telescope', 'wide-field-of-view modes', '3.5 m']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'U']","['supersampling multiframe blind deconvolution resolution enhancement', 'multiframe blind deconvolution', 'adaptive optic compensate imagery', 'low earth orbit satellite', 'postprocesse methodology', 'randomly vary blur', 'image enhancement', 'simulate imagery', 'ground - base telescope', 'spatial sampling', 'focal plane array element', 'forward stochastic model', 'random shift', 'ao - compensate point spread function', 'aliasing effect', 'sub - nyquist sampling', 'resolution loss', 'undersample image sequence reconstruction', 'sensor sample resolution', 'starfire optical range telescope', 'wide - field - of - view mode', '3.5 m']","['reconstruct undersampled image sequence', 'multiframe blind deconvolution technique', 'multiframe blind deconvolution', 'high quality optical imagery', 'low earth orbit satellite collect', 'starfire optical range', 'sample resolution', 'focal plane array', 'reduce resolution loss', 'spatial sampling']"
966,1065,Quantum universal variable-length source coding,"we construct an optimal quantum universal variable-length code that achieves the admissible minimum rate, i.e., our code is used for any probability distribution of quantum states. its probability of exceeding the admissible minimum rate exponentially goes to 0. our code is optimal in the sense of its exponent. in addition, its average error asymptotically tends to 0","['quantum universal variable-length source coding', 'optimal quantum universal variable-length code', 'admissible minimum rate', 'probability distribution', 'quantum states', 'exponent', 'average error', 'quantum information theory', 'quantum cryptography', 'optimal code']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'R']","['quantum universal variable - length source code', 'optimal quantum universal variable - length code', 'admissible minimum rate', 'probability distribution', 'quantum state', 'exponent', 'average error', 'quantum information theory', 'quantum cryptography', 'optimal code']","['optimal quantum universal variable', 'quantum state', 'admissible minimum rate', 'length code', 'probability distribution', 'code', 'optimal', 'exponent', 'exceed', 'average error']"
967,8,New investors get steal of a deal [Global Crossing],"hutchison telecommunications and singapore technologies take control of global crossing for a lot less money than they originally offered. the deal leaves the bankrupt carrier intact, but doesn't put it in the clear just yet","['global crossing', 'hutchison telecommunications', 'singapore technologies', 'bankrupt']","['P', 'P', 'P', 'P']","['global crossing', 'hutchison telecommunication', 'singapore technology', 'bankrupt']","['global crossing', 'hutchison telecommunication', 'singapore technology take control', 'bankrupt carrier intact', 'lot less money', 'deal leave', 'clear', 'put', 'offer']"
968,923,Design and manufacture of a lightweight piezo-composite curved actuator,"in this paper we are concerned with the design, manufacture and performance test of a lightweight piezo-composite curved actuator (called lipca) using a top carbon fiber composite layer with near-zero coefficient of thermal expansion (cte), a middle pzt ceramic wafer, and a bottom glass/epoxy layer with a high cte. the main point of the design for lipca is to replace the heavy metal layers of thunder tm by lightweight fiber reinforced plastic layers without losing the capabilities for generating high force and large displacement. it is possible to save up to about 40% of the weight if we replace the metallic backing material by the light fiber composite layer. we can also have design flexibility by selecting the fiber direction and the size of prepreg layers. in addition to the lightweight advantage and design flexibility, the proposed device can be manufactured without adhesive layers when we use an epoxy resin prepreg system. glass/epoxy prepregs, a ceramic wafer with electrode surfaces, and a carbon prepreg were simply stacked and cured at an elevated temperature (177 degrees c) after following an autoclave bagging process. we found that the manufactured composite laminate device had a sufficient curvature after being detached from a flat mould. an analysis method using the classical lamination theory is presented to predict the curvature of lipca after curing at an elevated temperature. the predicted curvatures are in quite good agreement with the experimental values. in order to investigate the merits of lipca, performance tests of both lipca and thunder tm have been conducted under the same boundary conditions. from the experimental actuation tests, it was observed that the developed actuator could generate larger actuation displacement than thunder tm","['lightweight piezo-composite curved actuator', 'performance test', 'performance test', 'lipca', 'carbon fiber composite layer', 'near-zero coefficient of thermal expansion', 'pzt ceramic wafer', 'glass/epoxy layer', 'thunder', 'fiber reinforced plastic layers', '177 degrees c', 'predicted curvatures', 'boundary conditions', 'performance tests', '177 degc']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M']","['lightweight piezo - composite curved actuator', 'performance test', 'performance test', 'lipca', 'carbon fiber composite layer', 'near - zero coefficient of thermal expansion', 'pzt ceramic wafer', 'glass / epoxy layer', 'thunder', 'fiber reinforce plastic layer', '177 degree c', 'predict curvature', 'boundary condition', 'performance test', '177 degc']","['lightweight fiber reinforce plastic layer', 'manufacture composite laminate device', 'top carbon fiber composite layer', 'composite curved actuator', 'lightweight piezo', 'light fiber composite layer', 'pzt ceramic wafer', 'metallic backing material', 'ceramic wafer', 'epoxy resin prepreg']"
969,966,Controlling in between the Lorenz and the Chen systems,"this letter investigates a new chaotic system and its role as a joint function between two complex chaotic systems, the lorenz and the chen systems, using a simple variable constant controller. with the gradual tuning of the controller, the controlled system evolves from the canonical lorenz attractor to the chen attractor through the new transition chaotic attractor. this evolving procedure reveals the forming mechanisms of all similar and closely related chaotic systems, and demonstrates that a simple control technique can be very useful in generating and analyzing some complex chaotic dynamical phenomena","['chen system', 'tuning', 'lorenz attractor', 'chen attractors', 'transition chaotic attractor', 'lorenz system']","['P', 'P', 'P', 'P', 'P', 'R']","['chen system', 'tune', 'lorenz attractor', 'chen attractor', 'transition chaotic attractor', 'lorenz system']","['new transition chaotic attractor', 'canonical lorenz attractor', 'complex chaotic system', 'new chaotic system', 'chen attractor', 'relate chaotic system', 'simple variable constant controller', 'control system evolve', 'chen systems', 'lorenz']"
970,125,A fast implementation of correlation of long data sequences for coherent receivers,coherent reception depends upon matching of phase between the transmitted and received signal. fast convolution techniques based on fast fourier transform (fft) are widely used for extracting time delay information from such matching. the latency in processing a large data window of the received signal is a serious overhead for mission critical real time applications. the implementation of a parallel algorithm for correlation of long data sequences in multiprocessor environment is demonstrated here. the algorithm does processing while acquiring the received signal and reduces the computation overhead considerably because of inherent parallelism,"['correlation', 'long data sequences', 'coherent receivers', 'received signal', 'fast fourier transform', 'time delay information', 'latency', 'mission critical real time applications', 'parallel algorithm', 'multiprocessor environment', 'computation', 'transmitted signal']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['correlation', 'long datum sequence', 'coherent receiver', 'receive signal', 'fast fouri transform', 'time delay information', 'latency', 'mission critical real time application', 'parallel algorithm', 'multiprocessor environment', 'computation', 'transmit signal']","['coherent reception', 'fast fouri transform', 'parallel algorithm', 'fast convolution technique', 'extract time delay information', 'latency', 'fft', 'multiprocessor', 'receive signal', 'long datum sequence']"
971,77,Modeling frequently accessed wireless data with weak consistency,"to reduce the response times of wireless data access in a mobile network, caches are utilized in wireless handheld devices. if the original data entry has been updated, the cached data in the handheld device becomes stale. thus, a mechanism is required to predict when the cached copy will expire. this paper studies a weakly consistent data access mechanism that computes the time-to-live (ttl) interval to predict the expiration time. we propose an analytic model to investigate this ttl-based algorithm for frequently accessed data. the analytic model is validated against simulation experiments. our study quantitatively indicates how the ttl-based algorithm reduces the wireless communication cost by increasing the probability of stale accesses. depending on the requirements of the application, appropriate parameter values can be selected based on the guidelines provided","['weak consistency', 'wireless data access', 'mobile network', 'caches', 'wireless handheld devices', 'data entry', 'analytic model', 'simulation experiments', 'wireless communication cost', 'frequently accessed wireless data modeling', 'response time reduction', 'time-to-live interval', 'expiration time prediction', 'stale access probability']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'R', 'R', 'R']","['weak consistency', 'wireless datum access', 'mobile network', 'caches', 'wireless handheld device', 'datum entry', 'analytic model', 'simulation experiment', 'wireless communication cost', 'frequently access wireless datum modeling', 'response time reduction', 'time - to - live interval', 'expiration time prediction', 'stale access probability']","['wireless datum access', 'wireless handheld device', 'consistent datum access mechanism', 'mobile network', 'cache datum', 'stale access', 'access datum', 'caches', 'wireless communication', 'original datum entry']"
972,608,How closely can a personal computer clock track the UTC timescale via the Internet?,"nowadays many software packages allow you to keep the clock of your personal computer synchronized to time servers spread over the internet. we present how a didactic laboratory can evaluate, in a statistical sense, the minimum synch error of this process (the other extreme, the maximum, is guaranteed by the code itself). the measurement set-up utilizes the global positioning system satellite constellation in 'common view' between two similar timing stations: one acts as a time server for the other, so the final timing difference at the second station represents the total synch error through the internet. data recorded over batches of 10000 samples show a typical rms value of 35 ms. this measurement configuration allows students to obtain a much better understanding of the synch task and pushes them, at all times, to look for an experimental verification of data results, even when they come from the most sophisticated 'black boxes' now readily available off the shelf","['personal computer clock', 'utc timescale', 'internet', 'software packages', 'time servers', 'didactic laboratory', 'statistical sense', 'synch error', 'global positioning system satellite constellation', 'final timing difference', 'black boxes']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['personal computer clock', 'utc timescale', 'internet', 'software package', 'time server', 'didactic laboratory', 'statistical sense', 'synch error', 'global positioning system satellite constellation', 'final timing difference', 'black box']","['global positioning system satellite constellation', 'personal computer synchronize', 'minimum synch error', 'time server spread', 'similar timing station', 'total synch error', 'synch task', 'final timing difference', 'experimental verification', 'time server']"
973,1218,Knowledge acquisition for expert systems in accounting and financial problem domains,"since the mid-1980s, expert systems have been developed for a variety of problems in accounting and finance. the most commonly cited problems in developing these systems are the unavailability of the experts and knowledge engineers and difficulties with the rule extraction process. within the field of artificial intelligence, this has been called the 'knowledge acquisition' (ka) problem and has been identified as a major bottleneck in the expert system development process. recent empirical research reveals that certain ka techniques are significantly more efficient than others in helping to extract certain types of knowledge within specific problem domains. this paper presents a mapping between these empirical studies and a generic taxonomy of expert system problem domains. to accomplish this, we first examine the range of problem domains and suggest a mapping of accounting and finance tasks to a generic problem domain taxonomy. we then identify and describe the most prominent ka techniques employed in developing expert systems in accounting and finance. after examining and summarizing the existing empirical ka work, we conclude by showing how the empirical ka research in the various problem domains can be used to provide guidance to developers of expert systems in the fields of accounting and finance","['knowledge acquisition', 'expert systems', 'accounting', 'finance', 'rule extraction process', 'artificial intelligence', 'problem domain taxonomy']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['knowledge acquisition', 'expert system', 'account', 'finance', 'rule extraction process', 'artificial intelligence', 'problem domain taxonomy']","['expert system development process', 'expert system problem domain', 'develop expert system', 'generic problem domain taxonomy', 'knowledge acquisition', 'expert system', 'knowledge engineer', 'finance task', 'empirical ka research', 'prominent ka technique employ']"
974,1119,A component-based software configuration management model and its supporting system,"software configuration management (scm) is an important key technology in software development. component-based software development (cbsd) is an emerging paradigm in software development. however, to apply cbsd effectively in real world practice, supporting scm in cbsd needs to be further investigated. in this paper, the objects that need to be managed in cbsd is analyzed and a component-based scm model is presented. in this model, components, as the integral logical constituents in a system, are managed as the basic configuration items in scm, and the relationships between/among components are defined and maintained. based on this model, a configuration management system is implemented","['component-based software configuration management model', 'software development', 'integral logical constituents', 'software reuse', 'version control']","['P', 'P', 'P', 'M', 'U']","['component - base software configuration management model', 'software development', 'integral logical constituent', 'software reuse', 'version control']","['software configuration management', 'configuration management system', 'base software development', 'basic configuration item', 'software development', 'integral logical constituent', 'component', 'component', 'base scm model', 'scm']"
975,1004,Games machines play,"individual rationality, or doing what is best for oneself, is a standard model used to explain and predict human behavior, and von neumann-morgenstern game theory is the classical mathematical formalization of this theory in multiple-agent settings. individual rationality, however, is an inadequate model for the synthesis of artificial social systems where cooperation is essential, since it does not permit the accommodation of group interests other than as aggregations of individual interests. satisficing game theory is based upon a well-defined notion of being good enough, and does accommodate group as well as individual interests through the use of conditional preference relationships, whereby a decision maker is able to adjust its preferences as a function of the preferences, and not just the options, of others. this new theory is offered as an alternative paradigm to construct artificial societies that are capable of complex behavior that goes beyond exclusive self interest","['individual rationality', 'human behavior', 'game theory', 'multiple-agent', 'artificial social systems', 'cooperation', 'conditional preference relationships', 'artificial societies', 'self interest', 'decision theory', 'group rationality']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R']","['individual rationality', 'human behavior', 'game theory', 'multiple - agent', 'artificial social system', 'cooperation', 'conditional preference relationship', 'artificial society', 'self interest', 'decision theory', 'group rationality']","['artificial social system', 'construct artificial society', 'satisfice game theory', 'morgenstern game theory', 'predict human behavior', 'group interest other', 'classical mathematical formalization', 'conditional preference relationship', 'complex behavior', 'individual interest']"
976,1041,Fractional differentiation in passive vibration control,"from a single-degree-of-freedom model used to illustrate the concept of vibration isolation, a method to transform the design for a suspension into a design for a robust controller is presented. fractional differentiation is used to model the viscoelastic behaviour of the suspension. the use of fractional differentiation not only permits optimisation of just four suspension parameters, showing the 'compactness' of the fractional derivative operator, but also leads to robustness of the suspension's performance to uncertainty of the sprung mass. as an example, an engine suspension is studied","['fractional differentiation', 'passive vibration control', 'vibration isolation', 'suspension', 'robust controller', 'viscoelastic behaviour', 'sprung mass', 'engine suspension']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P']","['fractional differentiation', 'passive vibration control', 'vibration isolation', 'suspension', 'robust controller', 'viscoelastic behaviour', 'spring mass', 'engine suspension']","['fractional derivative operator', 'fractional differentiation', 'robust controller', 'engine suspension', 'suspension parameter', 'vibration isolation', 'suspension', 'viscoelastic behaviour', 'robustness', 'freedom model']"
977,886,A fractional-flow model of serial manufacturing systems with rework and its reachability and controllability properties,"a dynamic fractional-flow model of a serial manufacturing system incorporating rework is considered. using some results on reachability and controllability of positive linear systems the ability of serial manufacturing systems with rework to ""move in space"", that is their reachability and controllability properties, are studied. these properties are important not only for optimising the performance of the manufacturing system, possibly off-line, but also to improve its functioning by using feedback control online","['serial manufacturing systems', 'rework', 'reachability', 'controllability', 'dynamic fractional-flow model', 'positive linear systems', 'feedback control', 'performance optimisation']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['serial manufacturing system', 'rework', 'reachability', 'controllability', 'dynamic fractional - flow model', 'positive linear system', 'feedback control', 'performance optimisation']","['serial manufacturing system', 'serial manufacturing system', 'dynamic fractional', 'positive linear system', 'controllability property', 'controllability', 'manufacture system', 'flow model', 'reachability', 'rework']"
978,1428,Syndicators turn to the enterprise,"syndicators have started reshaping offerings, products, and services towards the marketplace that was looking for enterprise-wide content syndication technology and service. syndication companies are turning themselves into infrastructure companies. many syndication companies are now focusing their efforts on enterprise clients instead of the risky dot coms","['enterprise-wide content syndication technology', 'infrastructure companies', 'enterprise clients', 'business model', 'aggregator', 'business web sites', 'customer base']","['P', 'P', 'P', 'U', 'U', 'U', 'U']","['enterprise - wide content syndication technology', 'infrastructure company', 'enterprise client', 'business model', 'aggregator', 'business web site', 'customer base']","['wide content syndication technology', 'many syndication company', 'syndication company', 'enterprise client', 'infrastructure company', 'start reshape offering', 'enterprise', 'syndicator', 'service', 'marketplace']"
979,1305,Learning nonregular languages: a comparison of simple recurrent networks and LSTM,"rodriguez (2001) examined the learning ability of simple recurrent nets (srns) (elman, 1990) on simple context-sensitive and context-free languages. in response to rodriguez's (2001) article, we compare the performance of simple recurrent nets and long short-term memory recurrent nets on context-free and context-sensitive languages","['lstm', 'context-free languages', 'performance', 'short-term memory recurrent nets', 'context-sensitive languages', 'nonregular language learning', 'recurrent neural networks']","['P', 'P', 'P', 'P', 'P', 'R', 'M']","['lstm', 'context - free language', 'performance', 'short - term memory recurrent net', 'context - sensitive language', 'nonregular language learning', 'recurrent neural network']","['term memory recurrent net', 'simple recurrent net', 'simple context', 'free language', 'learn ability', 'long short', 'context', 'srn', 'sensitive', 'elman']"
980,1340,Orthogonal decompositions of complete digraphs,"a family g of isomorphic copies of a given digraph g is said to be an orthogonal decomposition of the complete digraph d/sub n/ by g, if every arc of d/sub n/ belongs to exactly one member of g and the union of any two different elements from g contains precisely one pair of reverse arcs. given a digraph h, an h family mh is the vertex-disjoint union of m copies of h . in this paper, we consider orthogonal decompositions by h-families. our objective is to prove the existence of such an orthogonal decomposition whenever certain necessary conditions hold and m is sufficiently large","['orthogonal decompositions', 'complete digraphs', 'isomorphic copies', 'vertex-disjoint union', 'necessary conditions']","['P', 'P', 'P', 'P', 'P']","['orthogonal decomposition', 'complete digraph', 'isomorphic copy', 'vertex - disjoint union', 'necessary condition']","['consider orthogonal decomposition', 'orthogonal decomposition', 'complete digraph', 'give digraph', 'disjoint union', 'digraph', 'isomorphic copy', 'reverse arcs', 'vertex', 'different element']"
981,715,The quadratic 0-1 knapsack problem with series-parallel support,"we consider various special cases of the quadratic 0-1 knapsack problem (qkp) for which the underlying graph structure is fairly simple. for the variant with edge series-parallel graphs, we give a dynamic programming algorithm with pseudo-polynomial time complexity, and a fully polynomial time approximation scheme. in strong contrast to this, the variant with vertex series-parallel graphs is shown to be strongly np-complete","['quadratic 0-1 knapsack problem', 'series-parallel support', 'underlying graph structure', 'dynamic programming algorithm', 'pseudo-polynomial time complexity', 'fully polynomial time approximation scheme', 'np-complete problem']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['quadratic 0 - 1 knapsack problem', 'series - parallel support', 'underlie graph structure', 'dynamic programming algorithm', 'pseudo - polynomial time complexity', 'fully polynomial time approximation scheme', 'np - complete problem']","['knapsack problem', 'dynamic programming algorithm', 'parallel graph', 'polynomial time approximation scheme', 'polynomial time complexity', 'vertex series', 'graph structure', 'consider various special case', 'quadratic', 'edge series']"
982,750,Automated cerebrum segmentation from three-dimensional sagittal brain MR images,"we present a fully automated cerebrum segmentation algorithm for full three-dimensional sagittal brain mr images. first, cerebrum segmentation from a midsagittal brain mr image is performed utilizing landmarks, anatomical information, and a connectivity-based threshold segmentation algorithm as previously reported. recognizing that the cerebrum in laterally adjacent slices tends to have similar size and shape, we use the cerebrum segmentation result from the midsagittal brain mr image as a mask to guide cerebrum segmentation in adjacent lateral slices in an iterative fashion. this masking operation yields a masked image (preliminary cerebrum segmentation) for the next lateral slice, which may truncate brain region(s). truncated regions are restored by first finding end points of their boundaries, by comparing the mask image and masked image boundaries, and then applying a connectivity-based algorithm. the resulting final extracted cerebrum image for this slice is then used as a mask for the next lateral slice. the algorithm yielded satisfactory fully automated cerebrum segmentations in three-dimensional sagittal brain mr images, and had performance superior to conventional edge detection algorithms for segmentation of cerebrum from 3d sagittal brain mr images","['fully automated cerebrum segmentation algorithm', 'midsagittal brain mr image', 'landmarks', 'anatomical information', 'connectivity-based threshold segmentation algorithm', 'laterally adjacent slices', 'masking operation', 'masked image boundaries', 'connectivity-based algorithm', 'full 3d sagittal brain mr images', 'brain region truncation', 'boundary end points']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R']","['fully automate cerebrum segmentation algorithm', 'midsagittal brain mr image', 'landmark', 'anatomical information', 'connectivity - base threshold segmentation algorithm', 'laterally adjacent slice', 'mask operation', 'mask image boundary', 'connectivity - base algorithm', 'full 3d sagittal brain mr image', 'brain region truncation', 'boundary end point']","['automate cerebrum segmentation algorithm', 'automate cerebrum segmentation', 'guide cerebrum segmentation', 'threshold segmentation algorithm', 'cerebrum segmentation', 'final extract cerebrum image', 'midsagittal brain mr image', 'dimensional sagittal brain mr image', 'edge detection algorithm', 'mask image boundary']"
983,846,Female computer science doctorates: what does the survey of earned doctorates reveal?,"based on the national center for education statistics (2000), in the 1997-1998 academic year 26.7% of earned bachelors' degrees, 29.0% of earned masters' degrees and 16.3% of earned doctorates' degrees in computer science were awarded to women. as these percentages suggest, women are underrepresented at all academic levels in computer science (camp, 1997). the most severe shortage occurs at the top level-the doctorate in computer science. we know very little about the women who persist to the top level of academic achievement in computer science. this paper examines a subset of data collected through the survey of earned doctorates (sed). the specific focus of this paper is to identify trends that have emerged from the sed with respect to females completing doctorates in computer science between the academic years 1990-1991 and 1999-2000. although computer science doctorates include doctorates in information science, prior research (camp, 1997) suggests that the percentage of women completing doctorates in information science as compared to computer science is low. the specific research questions are: 1. how does the percentage of women who complete doctorates in computer science compare to those that complete doctorates in other fields? 2. how does the length of time in school and the sources of funding differ for females as compared to males who complete doctorates in computer science? 3. where do women go after completing doctorates in computer science and what positions do they acquire? how do these experiences differ from their male peers?","['female computer science doctorates', 'survey of earned doctorates', 'information science']","['P', 'P', 'P']","['female computer science doctorate', 'survey of earn doctorate', 'information science']","['computer science doctorate include doctorate', 'woman complete doctorate', 'female complete doctorate', 'earn doctorate', 'academic achievement', 'complete doctorate', 'earn bachelor', 'education statistic', 'academic year', 'academic level']"
984,803,The mutual effects of grid and wind turbine voltage stability control,this note considers the results of wind turbine modelling and power system stability investigations. voltage stability of the power grid with grid-connected wind turbines will be improved by using blade angle control for a temporary reduction of the wind turbine power during and shortly after a short circuit fault in the grid,"['wind turbine voltage stability control', 'wind turbine modelling', 'power system stability', 'power grid', 'grid-connected wind turbines', 'blade angle control', 'short circuit fault', 'grid voltage stability control', 'wind turbine power reduction', 'offshore wind turbines']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'M']","['wind turbine voltage stability control', 'wind turbine modelling', 'power system stability', 'power grid', 'grid - connect wind turbine', 'blade angle control', 'short circuit fault', 'grid voltage stability control', 'wind turbine power reduction', 'offshore wind turbine']","['wind turbine power', 'wind turbine modelling', 'wind turbine', 'voltage stability', 'power system stability', 'use blade angle control', 'power grid', 'short circuit fault', 'grid', 'note']"
985,1415,The disconnect continues [digital content providers],"the relationships between the people who buy digital content and those who sell it are probably more acrimonious than ever before, says dick curtis, a director and lead analyst for the research firm outsell inc., where he covers econtent contract and negotiation strategies. several buyers agree with his observation. they cite aggressive sales tactics, an unwillingness to deliver content in formats buyers need, a reluctance to provide licensing terms that take into account the structure of today's corporations, and inadequate service and support as a few of the factors underlying the acrimony. still, many buyers remain optimistic that compromises can be reached on some of these issues. but first, they say, sellers must truly understand the econtent needs of today's enterprises","['digital content', 'econtent contract', 'sales tactics', 'econtent negotiation', 'econtent buyers', 'news databases', 'web site']","['P', 'P', 'P', 'R', 'R', 'U', 'U']","['digital content', 'econtent contract', 'sale tactic', 'econtent negotiation', 'econtent buyer', 'news database', 'web site']","['research firm outsell inc', 'buy digital content', 'format buyer need', 'cite aggressive sale tactic', 'many buyer remain optimistic', 'cover econtent contract', 'provide licensing term', 'negotiation strategy', 'several buyer agree', 'deliver content']"
986,1081,Stability of W-methods with applications to operator splitting and to geometric theory,"we analyze the stability properties of w-methods applied to the parabolic initial value problem u' + au = bu. we work in an abstract banach space setting, assuming that a is the generator of an analytic semigroup and that b is relatively bounded with respect to a. since w-methods treat the term with a implicitly, whereas the term involving b is discretized in an explicit way, they can be regarded as splitting methods. as an application of our stability results, convergence for nonsmooth initial data is shown. moreover, the layout of a geometric theory for discretizations of semilinear parabolic problems u' + au = f (u) is presented","['operator splitting', 'geometric theory', 'parabolic initial value problem', 'abstract banach space', 'analytic semigroup', 'nonsmooth initial data', 'w-methods stability', 'linearly implicit runge-kutta methods']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['operator splitting', 'geometric theory', 'parabolic initial value problem', 'abstract banach space', 'analytic semigroup', 'nonsmooth initial datum', 'w - method stability', 'linearly implicit runge - kutta method']","['semilinear parabolic problem', 'analytic semigroup', 'parabolic initial value problem', 'abstract banach space set', 'stability property', 'discretization', 'method treat', 'splitting method', 'nonsmooth initial datum', 'stability']"
987,1450,Networking in the palm of your hand [PDA buyer's guide],"as pdas move beyond the personal space and into the enterprise, you need to get a firm grip on the options available for your users. what operating system do you choose? what features do you and your company need? how will these devices fit into the existing corporate infrastructure? what about developer support?","['pdas', ""buyer's guide"", 'operating system', 'corporate infrastructure', 'developer support']","['P', 'P', 'P', 'P', 'P']","['pda', ""buyer 's guide"", 'operating system', 'corporate infrastructure', 'developer support']","['exist corporate infrastructure', 'pdas move', 'enterprise', 'developer support', 'operating system', 'device fit', 'firm grip', 'company need', 'option available', 'feature']"
988,1338,The chromatic spectrum of mixed hypergraphs,"a mixed hypergraph is a triple h = (x, c, d), where x is the vertex set, and each of c, d is a list of subsets of x. a strict k-coloring of h is a surjection c : x {1,..., k} such that each member of le has two vertices assigned a common value and each member of d has two vertices assigned distinct values. the feasible set of h is {k: h has a strict k-coloring}. among other results, we prove that a finite set of positive integers is the feasible set of some mixed hypergraph if and only if it omits the number i or is an interval starting with 1. for the set {s, t} with 2 <or= s <or= t - 2, the smallest realization has 2t - s vertices. when every member of c union d is a single interval in an underlying linear order on the vertices, the feasible set is also a single interval of integers","['chromatic spectrum', 'mixed hypergraphs', 'mixed hypergraphs', 'vertex set', 'strict k-coloring', 'positive integers', 'mixed hypergraph']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['chromatic spectrum', 'mixed hypergraph', 'mixed hypergraph', 'vertex set', 'strict k - color', 'positive integer', 'mix hypergraph']","['vertex assign distinct value', 'mix hypergraph', 'feasible set', 'vertex set', 'finite set', 'vertex assign', 'small realization have', 'positive integer', 'single interval', 'color']"
989,728,Questioning the RFP process [telecom],"in the current climate, the most serious concern about the purchasing habits of telecom carriers is obviously the lack of spending. even against a backdrop of economic constraints and financial struggles, however, genuine concerns about the purchasing process itself are being raised by some of those closest to it","['telecom carriers', 'purchasing process', 'sales cycle', 'request for information', 'request for proposal']","['P', 'P', 'U', 'U', 'U']","['telecom carrier', 'purchasing process', 'sale cycle', 'request for information', 'request for proposal']","['telecom carrier', 'purchase habit', 'purchasing process', 'financial struggle', 'serious concern', 'genuine concern', 'economic constraint', 'spend', 'current climate', 'lack']"
990,790,Data assimilation of local model error forecasts in a deterministic model,"one of the most popular data assimilation techniques in use today are of the kalman filter type, which provide an improved estimate of the state of a system up to the current time level, based on actual measurements. from a forecasting viewpoint, this corresponds to an updating of the initial conditions. the standard forecasting procedure is to then run the model uncorrected into the future, driven by predicted boundary and forcing conditions. the problem with this methodology is that the updated initial conditions quickly 'wash-out', thus, after a certain forecast horizon the model predictions are no better than from an initially uncorrected model. this study demonstrates that through the assimilation of error forecasts (in the present case made using so-called local models) entire model domains can be corrected for extended forecast horizons (i.e. long after updated initial conditions have become washed-out), thus demonstrating significant improvements over the conventional methodology. some alternate uses of local models are also explored for the re-distribution of error forecasts over the entire model domain, which are then compared with more conventional kalman filter type schemes","['data assimilation', 'local model error forecasts', 'deterministic model', 'kalman filter', 'forcing conditions', 'forecast horizon', 'error prediction', 'hydrodynamic modelling']","['P', 'P', 'P', 'P', 'P', 'P', 'R', 'M']","['datum assimilation', 'local model error forecast', 'deterministic model', 'kalman filter', 'force condition', 'forecast horizon', 'error prediction', 'hydrodynamic modelling']","['extend forecast horizon', 'forecast horizon', 'forecasting viewpoint', 'forecast', 'model prediction', 'kalman filter type', 'standard forecasting', 'call local model', 'datum assimilation technique', 'local model']"
991,1380,A feature-preserving volumetric technique to merge surface triangulations,"several extensions and improvements to surface merging procedures based on the extraction of isosurfaces from a distance map defined on an adaptive background grid are presented. the main objective is to extend the application of these algorithms to surfaces with sharp edges and comers. in order to deal with objects of different length scales, the initial background grids are created using a delaunay triangulation method and local voxelizations. a point enrichment technique that introduces points into the background grid along detected surface features such as ridges is used to ensure that these features are preserved in the final merged surface. the surface merging methodology is extended to include other boolean operations between surface triangulations. the iso-surface extraction algorithms are modified to obtain the correct iso-surface for multi-component objects. the procedures are demonstrated with various examples, ranging from simple geometrical entities to complex engineering applications. the present algorithms allow realistic modelling of a large number of complex engineering geometries using overlapping components defined discretely, i.e. via surface triangulations. this capability is very useful for grid generation starting from data originated in measurements or images","['feature-preserving volumetric technique', 'merge surface triangulations', 'surface triangulations', 'surface merging procedures', 'adaptive background grid', 'sharp edges', 'delaunay triangulation method', 'local voxelizations', 'ridges', 'boolean operations', 'iso-surfaces extraction', 'multi-component objects', 'simple geometrical entities', 'complex engineering applications', 'overlapping components', 'images', 'mesh generation', 'unstructured grids', 'discrete data', 'surface intersection', 'geometric modelling', 'sharp comers', 'point enrichment technique background grid', 'arterial surfaces', 'haemoglobin molecule']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'R', 'M', 'R', 'R', 'R', 'M', 'U']","['feature - preserve volumetric technique', 'merge surface triangulation', 'surface triangulation', 'surface merge procedure', 'adaptive background grid', 'sharp edge', 'delaunay triangulation method', 'local voxelization', 'ridge', 'boolean operation', 'iso - surface extraction', 'multi - component object', 'simple geometrical entity', 'complex engineering application', 'overlap component', 'image', 'mesh generation', 'unstructured grid', 'discrete datum', 'surface intersection', 'geometric modelling', 'sharp comer', 'point enrichment technique background grid', 'arterial surface', 'haemoglobin molecule']","['surface triangulation', 'surface extraction algorithm', 'surface merge procedure', 'delaunay triangulation method', 'surface merge methodology', 'final merged surface', 'surface feature', 'adaptive background grid', 'background grid', 'surface']"
992,1039,Design of an adaptive vibration absorber to reduce electrical transformer structural vibration,"this paper considers the design of a vibration absorber to reduce structural vibration at multiple frequencies, with an enlarged bandwidth control at these target frequencies. while the basic absorber is a passive device a control system has been added to facilitate tuning, effectively giving the combination of a passive and active device, which leads to far greater stability and robustness. experimental results demonstrating the effectiveness of the absorber are also described","['adaptive vibration absorber', 'electrical transformer', 'structural vibration', 'bandwidth control']","['P', 'P', 'P', 'P']","['adaptive vibration absorber', 'electrical transformer', 'structural vibration', 'bandwidth control']","['vibration absorber', 'reduce structural vibration', 'basic absorber', 'target frequency', 'multiple frequency', 'absorber', 'tune', 'bandwidth control', 'control system', 'active device']"
993,571,Control of transient thermal response during sequential open-die forging: a trajectory optimization approach,"a trajectory optimization approach is applied to the design of a sequence of open-die forging operations in order to control the transient thermal response of a large titanium alloy billet. the amount of time the billet is soaked in furnace prior to each successive forging operation is optimized to minimize the total process time while simultaneously satisfying constraints on the maximum and minimum values of the billet temperature distribution to avoid microstructural defects during forging. the results indicate that a ""differential"" heating profile is the most effective at meeting these design goals","['open-die forging', 'trajectory optimization', 'titanium alloy billet', 'temperature distribution', 'microstructural defects', 'heating profile', 'transient thermal response control']","['P', 'P', 'P', 'P', 'P', 'P', 'R']","['open - die forge', 'trajectory optimization', 'titanium alloy billet', 'temperature distribution', 'microstructural defect', 'heating profile', 'transient thermal response control']","['titanium alloy billet', 'trajectory optimization approach', 'successive forge operation', 'billet temperature', 'forge operation', 'forge', 'transient thermal', 'heating profile', 'billet', 'optimize']"
994,1161,Model theory for hereditarily finite superstructures,"we study model-theoretic properties of hereditarily finite superstructures over models of not more than countable signatures. a question is answered in the negative inquiring whether theories of hereditarily finite superstructures which have a unique (up to isomorphism) hereditarily finite superstructure can be described via definable functions. yet theories for such superstructures admit a description in terms of iterated families tf and sf. these are constructed using a definable union taken over countable ordinals in the subsets which are unions of finitely many complete subsets and of finite subsets, respectively. simultaneously, we describe theories that share a unique (up to isomorphism) countable hereditarily finite superstructure","['model theory', 'model-theoretic properties', 'countable signatures', 'iterated families', 'definable union', 'finitely many complete subsets', 'countable hereditarily finite superstructure']","['P', 'P', 'P', 'P', 'P', 'P', 'P']","['model theory', 'model - theoretic property', 'countable signature', 'iterate family', 'definable union', 'finitely many complete subset', 'countable hereditarily finite superstructure']","['finite superstructure', 'countable ordinal', 'finite superstructure', 'countable signature', 'such superstructure', 'definable union take', 'definable function', 'theoretic property', 'describe theory', 'finite subset']"
995,1124,Data extraction from the Web based on pre-defined schema,"with the development of the internet, the world wide web has become an invaluable information source for most organizations. however, most documents available from the web are in html form which is originally designed for document formatting with little consideration of its contents. effectively extracting data from such documents remains a nontrivial task. in this paper, we present a schema-guided approach to extracting data from html pages. under the approach, the user defines a schema specifying what to be extracted and provides sample mappings between the schema and the html page. the system will induce the mapping rules and generate a wrapper that takes the html page as input and produces the required data in the form of xml conforming to the user-defined schema. a prototype system implementing the approach has been developed. the preliminary experiments indicate that the proposed semi-automatic approach is not only easy to use but also able to produce a wrapper that extracts required data from inputted pages with high accuracy","['data extraction', 'schema', 'internet', 'information source', 'html', 'wrapper generation', 'data integration', 'distributed database', 'queries']","['P', 'P', 'P', 'P', 'P', 'R', 'M', 'U', 'U']","['datum extraction', 'schema', 'internet', 'information source', 'html', 'wrapper generation', 'datum integration', 'distribute database', 'query']","['html page', 'html page', 'document format', 'html form', 'define schema', 'schema specify', 'extract datum', 'xml', 'schema', 'inputte page']"
996,118,Sensorless control of induction motor drives,"controlled induction motor drives without mechanical speed sensors at the motor shaft have the attractions of low cost and high reliability. to replace the sensor the information on the rotor speed is extracted from measured stator voltages and currents at the motor terminals. vector-controlled drives require estimating the magnitude and spatial orientation of the fundamental magnetic flux waves in the stator or in the rotor. open-loop estimators or closed-loop observers are used for this purpose. they differ with respect to accuracy, robustness, and sensitivity against model parameter variations. dynamic performance and steady-state speed accuracy in the low-speed range can be achieved by exploiting parasitic effects of the machine. the overview in this paper uses signal flow graphs of complex space vector quantities to provide an insightful description of the systems used in sensorless control of induction motors","['sensorless control', 'induction motor drives', 'reliability', 'stator voltages', 'vector-controlled drives', 'magnitude', 'spatial orientation', 'fundamental magnetic flux waves', 'open-loop estimators', 'closed-loop observers', 'robustness', 'sensitivity', 'model parameter variations', 'steady-state speed accuracy', 'parasitic effects', 'signal flow graphs', 'space vector quantities', 'stator currents']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R']","['sensorless control', 'induction motor drive', 'reliability', 'stator voltage', 'vector - control drive', 'magnitude', 'spatial orientation', 'fundamental magnetic flux wave', 'open - loop estimator', 'close - loop observer', 'robustness', 'sensitivity', 'model parameter variation', 'steady - state speed accuracy', 'parasitic effect', 'signal flow graph', 'space vector quantity', 'stator current']","['control induction motor drive', 'motor shaft', 'sensorless control', 'rotor speed', 'speed sensor', 'stator voltage', 'vector', 'motor', 'rotor', 'state speed accuracy']"
997,635,Detection and estimation of abrupt changes in the variability of a process,"detection of change-points in normal means is a well-studied problem. the parallel problem of detecting changes in variance has had less attention. the form of the generalized likelihood ratio test statistic has long been known, but its null distribution resisted exact analysis. in this paper, we formulate the change-point problem for a sequence of chi-square random variables. we describe a procedure that is exact for the distribution of the likelihood ratio statistic for all even degrees of freedom, and gives upper and lower bounds for odd (and also for non-integer) degrees of freedom. both the liberal and conservative bounds for chi /sub 1//sup 2/ degrees of freedom are shown through simulation to be reasonably tight. the important problem of testing for change in the normal variance of individual observations corresponds to the chi /sub 1//sup 2/ case. the non-null case is also covered, and confidence intervals for the true change point are derived. the methodology is illustrated with an application to quality control in a deep level gold mine. other applications include ambulatory monitoring of medical data and econometrics","['generalized likelihood ratio test statistic', 'distribution', 'sequence', 'chi-square random variables', 'even degrees of freedom', 'lower bounds', 'conservative bounds', 'simulation', 'individual observations', 'confidence intervals', 'quality control', 'deep level gold mine', 'ambulatory monitoring', 'medical data', 'econometrics', 'abrupt change detection', 'abrupt change estimation', 'process variability', 'upper bounds', 'odd degrees of freedom', 'noninteger degrees of freedom', 'liberal bounds', 'non null case']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'R', 'R', 'R', 'R', 'M', 'R', 'M']","['generalize likelihood ratio test statistic', 'distribution', 'sequence', 'chi - square random variable', 'even degree of freedom', 'low bound', 'conservative bound', 'simulation', 'individual observation', 'confidence interval', 'quality control', 'deep level gold mine', 'ambulatory monitoring', 'medical datum', 'econometric', 'abrupt change detection', 'abrupt change estimation', 'process variability', 'upper bound', 'odd degree of freedom', 'noninteger degree of freedom', 'liberal bound', 'non null case']","['generalize likelihood ratio test statistic', 'likelihood ratio statistic', 'detect change', 'normal variance', 'square random variable', 'true change point', 'null distribution resist', 'deep level gold mine', 'observation', 'test']"
998,1260,A dataflow computer which accelerates execution of sequential programs by precedent firing instructions,"in the dataflow machine, it is important to avoid degradation of performance in sequential processing, and it is important from the viewpoint of hardware scale to reduce the number of waiting operands. this paper demonstrates that processing performance is degraded by sequential processing in the switching process, and presents a method of remedy. precedent firing control is proposed as a means of remedy, and it is shown by a simulation that the execution time and the total number of waiting operands can be reduced by the precedent firing control. then the hardware scale is examined as an evaluation of precedent firing control","['dataflow computer', 'sequential programs', 'precedent firing instructions', 'hardware scale', 'waiting operands', 'processing performance', 'switching process', 'precedent firing control', 'execution time', 'execution acceleration', 'parallel processing', 'computer architecture']","['P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'R', 'M', 'M']","['dataflow computer', 'sequential program', 'precedent fire instruction', 'hardware scale', 'wait operand', 'process performance', 'switch process', 'precedent fire control', 'execution time', 'execution acceleration', 'parallel processing', 'computer architecture']","['precedent fire control', 'sequential processing', 'dataflow machine', 'process performance', 'switch process', 'hardware scale', 'execution', 'performance', 'wait operand', 'simulation']"
999,1225,BT voices its support for IP,"btexact's chief technology officer, mick reeve, gives his views on the future for voice over dsl services and virtual private networks, and defends the slow rollout of public access wlans","['btexact', 'voice over dsl', 'virtual private networks', 'public access wlans']","['P', 'P', 'P', 'P']","['btexact', 'voice over dsl', 'virtual private network', 'public access wlan']","['chief technology officer', 'virtual private network', 'dsl service', 'mick reeve', 'btexact', 'slow rollout', 'future', 'voice', 'view', 'defend']"
